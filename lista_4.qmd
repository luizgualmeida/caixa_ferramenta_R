# Lista 4 - GMM e ICC

Para resolver a lista de exercícios 4 vamos utilizar o [banco de dados THKS2](https://drive.google.com/file/d/1GVse4Sq6B66Cs9qeyA5BJwv2SxgYrip-/view?usp=sharing). O banco apresenta dados do programa "Television, School and Family Smoking Prevention and Cessation Project (TVSFP)", que avaliou a eficácia de um programa presencial para parar de fumar (Currículo) em conjunto com um programa em vídeo (TV) para prevenir o início do tabagismo e fortalecer a resiliência daqueles que deixaram de fumar.

O estudo adotou um delineamento 2x2 com quatro grupos distintos, considerando a presença do "school-based social-resistance curriculum (CC)" e do "television-based prevention program (TV)". Esses grupos foram categorizados como "Curriculum & TV", "Curriculum", "TV" e "Neither". Este último indicando que as pessoas do grupo não participaram de nenhuma intervenção.

A randomização da amostra ocorreu em dois níveis: por escolas e por salas de aula. O banco de dados inclui informações de 1600 alunos de 135 classes distintas em 28 escolas localizadas em Los Angeles. A variável dependente, a Escala de Conhecimento em Tabaco e Saúde (THKS), foi avaliada antes da randomização e após a implementação dos efeitos de cada grupo.

Com base nestes dados, por favor, apresente as questões específicas e descreva os resultados utilizando as notações apropriadas.

## Pacotes que vamos utilizar

```{r}
#| echo: true
#| message: false
#| warning: false

# Seu código R aqui
library(emmeans)
library(lme4)
library(nlme)
library(flexplot)
library(foreign)
library(dplyr)
library(multcomp)
library(effects)
library(sjstats)
library(tm)
library(report)
library(ggplot2)
library(forcats)
library(performance)
library(rempsyc)
library(easystats)
library(fitdistrplus)
library(sjPlot)
library(kableExtra)
library(psychometric)
library(misty)
```

```{r}
#| echo: true
#| message: false
#| warning: false

dataset = read.spss("THKS2.sav", to.data.frame=TRUE)
```

Como já mencionado no capítulo anterior, é muito importante averiguar os tipos de variáveis antes de começar as análises. Para isso vamos utilizar a função `glimpse()`.

```{r}
glimpse(dataset)
```

Ao analisar os arquivos provenientes de outros programas, percebe-se que todas as variáveis numéricas são tratadas como contínuas. No entanto, todas as variáveis no banco de dados são, na verdade, categóricas. Portanto, é necessário modificar o tipo das variáveis antes de iniciar as análises. Para isso vamos utilizar a função `as.factor()` nas 4 variáveis contínuas.

```{r}
dataset$SchoolID = as.factor(dataset$SchoolID)
dataset$ClassID = as.factor(dataset$ClassID)
dataset$PreTHKS = as.integer(dataset$PreTHKS)
dataset$PosTHKS = as.integer(dataset$PosTHKS)

```

Rodando novamente a função `glimpse()` podemos verificar se a mudança aconteceu.

```{r}
glimpse(dataset)
```

Podemos também calcular o número de alunos por classe também. Isso será bem útil para uma análise Extra no fim do capítulo.

```{r}
dataset$Tamanho_Classe <- ave(dataset$PreTHKS, dataset$SchoolID, dataset$ClassID, FUN = length)

```

## a) Modelos hierárquicos

::: callout-note
#### Exercício

Com base no desenho apresentado, qual é a pergunta que este estudo quer responder?
:::

Para abordar as questões específicas relacionadas ao banco de dados THKS2 utilizando um modelo linear GMM hierárquico, precisamos formular perguntas específicas que desejamos responder com a análise. Dado que o THKS é a variável dependente e foi avaliado antes e depois da implementação dos diferentes grupos de intervenção, podemos considerar algumas perguntas relevantes:

-   Efeito geral da intervenção: Como a média da escala THKS varia entre os grupos "Curriculum & TV", "Curriculum", "TV" e "Neither" após a implementação das intervenções?

-   Diferenças entre grupos específicos: Há diferenças significativas nas mudanças médias da escala THKS entre os grupos "Curriculum & TV", "Curriculum", "TV" e "Neither"?

-   Variação entre escolas e salas de aula: A variação nas médias da escala THKS é significativa entre as escolas ou entre as salas de aula, considerando o efeito das intervenções?

A análise gráfica pode ser fundamental para avaliar a validade da escolha de um modelo hierárquico. Ao comparar as médias do PreTHKS e do PosTHKS para diferentes escolas e salas de aula, os gráficos podem revelar padrões ou tendências que indicam se há variação sistemática ou não nas médias entre esses níveis hierárquicos. A identificação de padrões específicos pode orientar a decisão de usar um modelo hierárquico para capturar a estrutura aninhada dos dados.

Vamos criar um gráfico das médias de THKS entre as escolas antes e depois das intervenções.

### Média por Escola

```{r}
# Instale o pacote ggplot2 se ainda não o tiver instalado
# install.packages("ggplot2")


# Crie um novo dataframe para armazenar a média das notas por escola
media_por_escola <- aggregate(cbind(PosTHKS, PreTHKS) ~ SchoolID, data = dataset, FUN = mean)

# Transforme os dados em formato longo (tidy)
media_por_escola_long <- tidyr::pivot_longer(media_por_escola, cols = c("PreTHKS", "PosTHKS"), names_to = "tempo", values_to = "media")

# Crie um gráfico de dispersão com uma linha contínua conectando as médias das notas
ggplot(data = media_por_escola_long, aes(x = forcats::fct_rev(tempo), y = media, color = SchoolID, group = SchoolID)) +
  geom_point() +
  geom_line() +
  labs(title = "Médias por Escola",
       x = "",
       y = "Valores das médias de THKS") +
  theme_minimal() +
  theme(legend.position = "right")  # Posição da leg

```

Observe no gráfico que o efeito da intervenção é basicamente constante. Antes da intervenção a média de THKS era menor e após a intervenção a média aumentou em praticamente todas as escolas analisadas.

Vamos fazer o mesmo mas separando as médias por classes.

### Média por classe

```{r}
# Instale o pacote ggplot2 se ainda não o tiver instalado
# install.packages("ggplot2")


# Crie um novo dataframe para armazenar a média das notas por escola
media_por_classe <- aggregate(cbind(PreTHKS, PosTHKS) ~ ClassID, data = dataset, FUN = mean)

# Transforme os dados em formato longo (tidy)
media_por_classe_long <- tidyr::pivot_longer(media_por_classe, cols = c("PreTHKS", "PosTHKS"), names_to = "tempo", values_to = "media")

# Crie um gráfico de dispersão com uma linha contínua conectando as médias das notas
ggplot(data = media_por_classe_long, aes(x = forcats::fct_rev(tempo), y = media, color = ClassID, group = ClassID)) +
  geom_point() +
  geom_line() +
  labs(title = "Médias por Classe",
       x = "",
       y = "Média de Notas") +
  #scale_color_manual(values = rainbow(length(top_50_escolas))) +  # Ajuste as cores manualmente
  theme_minimal() +
  theme(legend.position = "none")  # Posição da legenda

```

Observamos que, em alguns casos, a média de THKS diminui após a intervenção, enquanto em outros ocorre um aumento. A falta de um padrão claro sugere que a classe também desempenha um papel na resposta à intervenção, indicando a necessidade de utilizar modelos hierárquicos com fatores aleatórios nessa variável.

### Média por Grupo

```{r}
# Instale o pacote ggplot2 se ainda não o tiver instalado
# install.packages("ggplot2")
head(dataset)

# Crie um novo dataframe para armazenar a média das notas por escola
media_por_grupo <- aggregate(cbind(PosTHKS, PreTHKS) ~ Group, data = dataset, FUN = mean)

# Transforme os dados em formato longo (tidy)
media_por_grupo_long <- tidyr::pivot_longer(media_por_grupo, cols = c("PreTHKS", "PosTHKS"), names_to = "tempo", values_to = "media")

# Crie um gráfico de dispersão com uma linha contínua conectando as médias das notas
ggplot(data = media_por_grupo_long, aes(x = forcats::fct_rev(tempo), y = media, color = Group, group = Group)) +
  geom_point() +
  geom_line() +
  labs(title = "Médias por Grupo",
       x = "",
       y = "Valores das médias de THKS") +
  theme_minimal() +
  theme(legend.position = "right")  # Posição da leg

```

Os grupos também parecem ter um padrão constante de aumento na média de THKS após a intervenção, indicano que não há necessidade de colocar essa variável como efeito aleatório.

## b) Efeitos fixos e aleatórios

::: callout-note
#### Exercício

Dentre os efeitos observados -- Grupo, Classe e Escola -- quais são efeitos fixos e aleatórios pelo menos do ponto de vista teórico?
:::

os gráficos são apenas uma das diversas maneiras de verificar a necessidade ou não de efeitos aleatórios. Mais a frente vamos ver outras métricas que podemos nos ajudar com a decisão.

Com base nos gráficos anteriores, podemos inferir que a classe é um efeito aleatório, enquanto a escola e o grupo são efeitos fixos. Para seguir a abordagem prática exemplificada durante a aula no SPSS, iremos construir vários modelos considerando efeitos fixos e aleatórios. Posteriormente, compararemos os índices de aderência e os resultados obtidos, com o intuito de selecionar o modelo mais adequado para os nossos dados.

## c) GLM univariado

::: callout-note
#### Exercício

Faça um GLM univariado tendo o THKS pós como VD e os grupos, escolas e classes como variáveis independentes. Coloque as variáveis como efeitos fixos e aleatórios adequadamente conforme a questão anterior. Descreva os resultados encontrados.
:::

Caso queira repetir o modelo que o Altay apresentou no vídeo, execute o código abaixo. Assim como no SPSS, no R os valores serão calculados por muito tempo e o modelo não vai convergir.

::: {.callout-caution collapse="true"}
#### Por conta e risco!

`modelo1 <- lm(PosTHKS ~ Group * SchoolID * ClassID * PreTHKS, data=dataset)`
:::

## d) Componentes da variância e ICC

::: callout-note
#### Exercício

Utilizando o "Variance Components", verifique se Classe e Escola podem ser considerados fatores aleatórios. Utilize o ICC (Coeficiente de Correlação Intraclasse) como critério para decidir.
:::

Vamos utilizar a função `lmer()` do pacote `lme4` para criar nossos primeiro modelo com efeitos fixos e aleatórios **(modelo 1)**. Em seguida vamos extrair os componentes da variância dos resultados.

```{r}
#| echo: true
#| message: false
#| warning: false

modelo_1 = lmer(PosTHKS ~ 1 + Group * PreTHKS + # Efeitos fixos
                  (1|SchoolID:ClassID) + # intercepto aleatório da classe aninhado na escola
                  (1|SchoolID), # intercepto aleatório apenas da escola
                data = dataset, 
                REML = TRUE) # Método de estimação dos parâmetros
```

Importante notar em nosso modelo que os efeitos fixos estão fora dos parênteses, ao passo que os efeitos aleatórios (SchooID e ClassID) estão contidos dentro dos parênteses. Essa estrutura informa à função lmer quais variáveis têm efeitos fixos e quais têm efeitos aleatórios.

Quanto os métodos de estimação dos parâmetros, não deixe de ler a seção "@sec-extras"

O primeiro passo para mostrar os componentes da variância é extrair os valores do modelo utilizando a função `VarCorr`. Vamos guardar a saída da função em um data-frame, tornando a visualização mais acessível. Em seguida, utilizaremos os estimadores de variância desejados no cálculo do ICC.

```{r}
var_modelo_1 = as.data.frame(VarCorr(modelo_1))
var_modelo_1
```

Os valores que precisamos para calcular o ICC estão na coluna `vcov`.

vamos agora armazenar os valores desejados em outras variáveis.

```{r}
var_classe_1 = var_modelo_1$vcov[1] # classe
var_escola_1 = var_modelo_1$vcov[2] # school
var_erro_1 = var_modelo_1$vcov[3] # total

```

O que fizemos aqui foi acessar o data-frame (comp_var_modelo_1), indicar a coluna que queremos acessar O cifrão (`$vcoc`) e a linha em que se encontra o valor, indicada pelo número dentra das chaves `[]`.

Tudo o que precisamos fazer agora é calcular o ICC, que se dá pela seguinte fórmula:

$$
ICC = \frac{\sigma^2_{\text{entre grupos}}}{\sigma^2_{\text{entre grupos}} + \sigma^2_{\text{do erro}}}
$$

### ICC Escola (modelo 1)

Vamos primeiro calcular o ICC da Escola.

```{r}

# ICC Escola
icc_escola_1 = var_escola_1 / (var_escola_1 + var_erro_1)
round(icc_escola_1, 3)
```

Arredondando o valor do cálculo temos que o valor do ICC da escola é de 0,023, ou de aproximadamente 2,3%. Se um valor de 5% fosse estabelecido para considerar uma variabilidade significativa entre os grupos, o ICC de 0,023 seria bastante baixo em relação a esse limiar.

### ICC Classe (modelo 1)

Para calcular o ICC da classe temos:

```{r}

# ICC Classe
icc_class_1 = var_classe_1 / (var_classe_1 + var_erro_1)
round(icc_class_1, 3)
```

Aqui também temos um valor de ICC abaixo dos 5%, indicando que, por esse critério, a Classe também não deveria ser considerada como um fator aletaório.

Uma manipulação viável para avaliar o ICC exclusivamente a partir das variáveis que você considera como aleatórias é incluir apenas essas variáveis no modelo, excluindo todas as outras que tenham efeito fixo. Vamos refazer todos os passos anteriores, apenas mudando o modelo **(modelo 2)**.

```{r}
modelo_2 = lmer(PosTHKS ~ 1 +
                  (1|SchoolID:ClassID) +
                  (1|SchoolID), 
                data = dataset, 
                REML = TRUE) # Método de estimação dos parâmetros
```

```{r}
var_modelo_2 = as.data.frame(VarCorr(modelo_2))
var_modelo_2
```

```{r}
var_classe_2 = var_modelo_2$vcov[1] # classe
var_escola_2 = var_modelo_2$vcov[2] # escola
var_erro_2 = var_modelo_2$vcov[3] # total

```

### ICC Escola (modelo 2)

Calculando o ICC da escola para o modelo 2 temos

```{r}
# ICC escola

icc_school_2 = var_escola_2 / (var_escola_2 + var_erro_2)
round(icc_school_2, 3)
```

Agora temos que o ICC da escola é maior que 5%, indicando que a variável é uma boa candidata para ser designada tendo efeito aleatório.

### ICC Classe (modelo 2)

```{r}
# ICC classe

icc_class_2 = var_classe_2 / (var_classe_2 + var_erro_2)
round(icc_class_2, 3)
```

Já a classe continua com um valor de ICC abaixo dos 5%

### ICC com função

Podemos utilizar a função `multilevel.icc` do pacote `misty` para não precisar calcular na mão o ICC. Digno de nota que a função não aceita efeitos fixos, portanto teremos **APENAS** o ICC do modelo com efeitos aleatórios. Além disso a função pode assumir 3 tipos:

-   ICC(1) - Mostra quanto da variação ocorre entre os grupos (nível 2) e entre os grupos de grupos (nível 3), que é semelhante ao que calculamos na mão.

```{r}
multilevel.icc(PosTHKS, # Variável dependente
               data = dataset, # Banco de dados
               cluster = c("SchoolID", "ClassID")) # Ordem dos clusters importa. Primeiro o L3 e depois o L2
```

-   ICC(1b) - Representa a correlação esperada entre dois elementos escolhidos aleatoriamente no mesmo grupo.

```{r}
multilevel.icc(PosTHKS, 
               data = dataset, 
               cluster = c("SchoolID", "ClassID"),
               type = "1b")
```

-   ICC(2) Indica quão confiáveis são as médias dos grupos (nível 2 e 3). Ou seja, o quão representativas são as médias dos grupos em relação às diferenças individuais dentro desses grupos.

```{r}
multilevel.icc(PosTHKS, data = dataset, cluster = c("SchoolID", "ClassID"),
type = "2")
```

Notem que a primeira fórmula apresenta resultado similar ao que calculamos na mão.

::: callout-important
#### Importante!

Não existe um conceito fechado de como definir se uma variável deve ser considerada ou não como efeito aleatório. A teoria deve sempre prevalecer sobre os demais critérios.
:::

Pelo critério teórico, vamos assumir que tanto escola quanto classe terão efeito aleatório em nosso modelo final.

## e) Interpretando os resultados

::: callout-note
#### Exercício

Realize um Modelo Misto Hierárquico (caso os fatores aleatórios sejam relevantes com base em d). Descreva os resultados adequadamente e verifique qual combinação de fatores aleatórios é a mais adequada para explicar a variação dos resultados do THKS (com base no ICC).
:::

### Verificando a referência do Grupo

Para seguir os passos do vídeo feito pelo Altay no SPSS primeiro temos que ajustar o nível de referência da variável Grupo. No SPSS a referência é o grupo que não fez nada (Neither). Para verificar qual o nível de referência aqui no R vamos utilizar a função `levels()`.

```{r}
levels(dataset$Group)
```

O nível de referência é sempre primeiro que aparece na lista, no caso "Curriculum & TV".

Vamos mudar para que a referência seja "Neither", utilizando a função relevel.

```{r}
dataset$Group <- relevel(dataset$Group, ref = "Neither")
levels(dataset$Group)
```

Agora sim podemos seguir com nossa análise.

### Criando o modelo

Ao contrário do SPSS, não enfrentaremos problemas de convergência em nossos modelos se a matriz de covariância não for modificada. Para demonstrar que alterar a matriz de covariância não afeta significativamente os coeficientes, podemos criar dois modelos para verificação:

-   a\) modelo com matriz de covariância simétrica;

-   b\) modelo com matriz de covariância diagonal (padrão caso não definamos explicitamente a matriz).

A função `lmer()` não oferece uma maneira direta de modificar a matriz de covariância. Portanto, da mesma forma que fizemos na Lista de Exercícios 3, vamos utilizar a função `lme()`.

```{r}

# Modelo a)
modelo_a = lme(
  fixed = PosTHKS ~ 1 + PreTHKS + Group, 
  random =~ 1|SchoolID/ClassID,
  correlation = corCompSymm(form = ~1|SchoolID/ClassID), # Aqui definimos a matriz simétrica
  data = dataset, 
  method = "REML")

# Armazenando os valores dos coeficientes do modelo a) em uma variável
coef_a = modelo_a$coefficients$fixed

# Modelo b)
modelo_b = lme(
  fixed = PosTHKS ~ 1 + PreTHKS + Group, 
  random =~ 1|SchoolID/ClassID,
  data = dataset, 
  method = "REML") # Matriz diagonal por padrão

# Armazenando os valores dos coeficientes do modelo b) em uma variável
coef_b = modelo_b$coefficients$fixed


# Criar um dataframe
df_coeficientes <- data.frame(Modelo_a = coef_a,
                              Modelo_b = coef_b)
df_coeficientes

```

Podemos observar que os valores mudam apenas depois da 3 casa após a vírgula. Portanto podemos construir os modelos sem alterar a matriz de covariância neste caso específico.

<!-- Vamos continuar utilizando a função `lmer()`, mas caso precise alterar a matriz de variância do seu modelo, veja a resolução dos exercícios da lista 3 (@sec-lista-3). -->

Vamos ao modelo:

```{r}
modelo_3 = lme(
  fixed = PosTHKS ~ 1 + PreTHKS + Group, 
  random =~ 1|SchoolID/ClassID,
  data = dataset, 
  method = "REML")

# Escolhi utilizar o lme() por ele apresentar mais resultados na saída da função anova()
```

### ICC do modelo

Não encontramos uma maneira fácil de mostrar o ICC para modelos de 3 níveis com variáveis independentes fixas. Por isso mostramos como calcular na mão o ICC anteriormente. Podemos acessar os valores de variância do modelo com a seguinte função:

```{r}
kable(VarCorr(modelo_3)) # O kable é só pra deixar com um visual melhor a saída.

```

Agora queremos acessar cada variância separadamente. Para isso executamos o scritp a seguir.

```{r}
var_escola = VarCorr(modelo_3)[2] # Variancia da Escola

var_classe = VarCorr(modelo_3)[4] # Variancia da Classe

var_res = VarCorr(modelo_3)[5] # Variancia do resíduo
```

Se você tentar fazer contas com essas variáveis vai notar algo bem estranho

```{r}
#| echo: true
#| eval: false
#| message: false
#| warning: true

var_classe + var_res
```

Isso acontece porque elas saíram como caracteres (símbolos, letras...) e não como números!

```{r}
typeof(var_classe)
```

Vamos resolver isso transformando elas para números

```{r}
var_escola = as.numeric(var_escola)
var_classe = as.numeric(var_classe)
var_res = as.numeric(var_res)

```

Agora sim!

```{r}
typeof(var_escola)
```

Calculando o ICC da Escola temos:

```{r}
var_escola/(var_escola+var_res) #ICC da escola

```

ICC da classe:

```{r}
var_classe/(var_classe+var_res)
```

### Pressupostos do modelo

Como já vimos, parte importante de analisar os modelos é verificar os pressupostos. Não entraremos em detalhes, vamos apenas vislumbrar quandos todos os pressupostos são atendidos! O melhor de tudo, usando apenas 3 palavras na linha de código, graças à função `check_model()`.

```{r}
check_model(modelo_3)
```

Que beleza, não? Resíduos normais, baixa colinearidade e ótima linearidade do modelo! Podemos interpretar os resultados com tranquilidade!

### Resultados

Vamos verificar se o efeito do grupo é significante, que é a principal variável dependente do nosso modelo. Para isso podemos utilizar a função `anova()` que é muito versátil para diversas ocasiões.

```{r}
kable(anova(modelo_3)) #função kable apenas para deixar mais bonita a tabela

```

Boa! Descobrimos que o efeito do grupo é significativo. Agora precisamos saber entre quais grupos está a diferença e de quanto ela é.

Para tanto vamos utilizar mais uma vez a função `summary()`.

```{r}
summary(modelo_3)
```

Como vocês já podem ter percebido as saídas da função `summary()` no R não geram as saídas mais fáceis de interpretar, como podemos ver no exemplo abaixo.

Agora que você enfrentou a busca nos detalhes desse fascinante output gerado pela função summary, é com satisfação que compartilhamos a boa notícia de que muitos desenvolvedores compartilham da sua experiência e criaram vários pacotes para aprimorar a visualização dos resultados. Ao longo dos exercícios, apresentaremos algumas abordagens para alcançar isso. No final da seção de modelos lineares, você encontrará um glossário que ajudará na geração de outputs mais amigáveis e formatados para publicações acadêmicas.

Por hora, vamos compartilhar uma abordagem mais "na mão" para melhorar a visualização dos resultados, para caso algum pacote não atenda completamente às suas necessidades.

```{r}
# Resumo do modelo

resumo_modelo <- summary(modelo_3)

# Extração de estimadores, intervalos de confiança e p-valores

coeficientes <- resumo_modelo$coefficients$fixed # essa linha varia muito dependendo do modelo
intervalos_confianca <- intervals(modelo_3, which = "fixed") # Função `confint()` pode ser utilizadas para outros modelos
p_valores <- resumo_modelo$tTable[, "p-value"]

# Criar um data frame

resultados_modelo <- data.frame(
  Estimador = round(coeficientes, 3),
  IC_Inf = round(intervalos_confianca$fixed[, 1], 3),
  IC_Sup = round(intervalos_confianca$fixed[, 2], 3),
  p = round(p_valores, 3)
)

# Apresentando os resultados
kable(resultados_modelo)

```

------------------------------------------------------------------------

Melhorou um pouco né? Achou muito trabalhoso??

Que tal fazer tudo em uma linha de código e ainda com correção de Bonferroni!?

```{r}
emmeans(modelo_3, pairwise ~ Group, adjust = "bonferroni") # por padrão temos a correção de Tukey
```

Os valores estão negativos porque ajustamos o nível de referência da variável Group para "Neither". No resultado temos que "Curriculum" apresenta a maior média geral. Logo seria interessante deixá-lo como variável de referência, caso queira que seus estimadores fiquem positivo. Já vimos como fazer isso anteriormente!

Tente modificar a referência para "Curriculum", mas **CUIDADO!** Não se esqueça de criar o modelo novamente, caso contrário os resultados ficarão errados!

Para acessar apenas os resultados de contraste podemos fazer o seguinte:

```{r}
emmeans(modelo_3, pairwise ~ Group, adjust = "bonferroni")$contrasts
```

## Extras! {#sec-extras}

### Métodos de estimação dos parâmetros do modelo

O REML (Residual Maximum Likelihood) e o ML (Maximum Likelihood) são duas abordagens distintas para a estimação de parâmetros em modelos de regressão linear mista (ou modelos hierárquicos). Ambas são baseadas no método da máxima verossimilhança, mas diferem na maneira como tratam os graus de liberdade.

**Maximum Likelihood (ML):**

Na abordagem ML, o foco é maximizar a verossimilhança do modelo, considerando tanto os efeitos fixos quanto os efeitos aleatórios. O ML leva em conta todos os parâmetros do modelo para maximizar a probabilidade de observar os dados dados os parâmetros. É mais adequado quando o interesse principal é fazer inferências sobre os parâmetros fixos do modelo.

**Residual Maximum Likelihood (REML):**

A abordagem REML é uma variação do ML que remove os efeitos fixos do modelo antes de calcular a verossimilhança. O REML estima a verossimilhança condicional dos efeitos aleatórios, removendo a contribuição dos efeitos fixos. Ele tende a ser mais eficiente na estimação dos efeitos aleatórios, especialmente em amostras pequenas, e fornece estimativas menos enviesadas para a variância dos efeitos aleatórios. O REML é frequentemente preferido quando o foco está na estimação dos parâmetros aleatórios e quando a inferência sobre os parâmetros fixos não é o objetivo principal.

### Extraindo valores de summary

Podemos extrair diversos valores individualmente da função `summary()`.

```{r}
#| echo: false
#| message: false
#| warning: false
#| include: false
summary(modelo_3)$coef # coeficientes para cada observação (linha)
summary(modelo_3)$sigma # desvio padrão residual
summary(modelo_3)$logLik # valor numérico que representa a log-verossimilhança do modelo
summary(modelo_3)$AIC # valor de AIC do modelo
summary(modelo_3)$BIC # valor de BIC do modelo
```

### Tamanho da classe importa?

```{r}
theme_set(theme_bw(base_size = 7, base_family = "")) 

ggplot(data = dataset, aes(x = Tamanho_Classe, y=PosTHKS))+
  facet_grid(~SchoolID)+
  coord_cartesian(ylim=c(0,30))+
  geom_point()+
  geom_smooth(method = "lm", se = TRUE)+
  xlab("Tamanho da Classe")+ylab("PosTHKS")+
  theme(legend.position = "top")


```

```{r}
Plot.Means<-dataset %>% group_by(SchoolID) %>%  
  dplyr::summarize(PosTHKSM = mean(PosTHKS, na.rm=TRUE),
                   Tamanho_CLasseM=mean(Tamanho_Classe, na.rm=TRUE))



ggplot(data = Plot.Means, aes(x = reorder(SchoolID, -PosTHKSM), y=PosTHKSM))+
  geom_point(aes(size = Tamanho_CLasseM))+
  xlab("")+ylab("PosTHKS")+
  theme_bw()+
  theme(legend.position = "top")

```

### Comparando modelos

Podemos comparar diversos modelos utilizando a função `model.comparison()` do pacote `flexplot`.

```{r}
model.comparison(modelo_1, modelo_2)

# O modelo 1 apresenta melhores resultados
```

### Plot do modelo

Criando um gráfico com os coeficientes gerados pelo modelo.

```{r}
# Com a correção de Bonferroni
results_modelo_3 = emmeans(modelo_3, pairwise ~ Group, adjust = "bonferroni")
```

```{r}
ggplot(as.data.frame(results_modelo_3$emmeans), aes(x = Group, y = emmean, color = Group)) +
  geom_errorbar(aes(ymin = lower.CL, ymax = upper.CL), width = 0.2, position = position_dodge(0.8)) +
  geom_point(position = position_dodge(0.8), size = 3) +
  labs(title = "Distribuição normal",
       x = "Tratamento",
       y = "THKS") +
  theme_minimal() +
  theme(legend.position = "none") 

```

### Função para calcular o ICC

Caso você queira calcular o ICC para diferentes modelos de 3 níveis, sugiro criar uma função que faça o trabalho repetitivo ao invés de ficar calculando tudo sempre na mão.

::: callout-important
## Importante

Funciona apenas para modelos gerados pela função `lme()`.
:::

```{r}
# Criando minha própria função

icc_lme_3nv = function(modelo) {
  # Extração da variância entre grupos e total
  var_escola = as.numeric(VarCorr(modelo)[2])
  var_classe = as.numeric(VarCorr(modelo)[4])
  var_total = as.numeric(VarCorr(modelo)[5])

  # Cálculo do ICC
  icc_escola = var_escola/(var_escola+var_res)
  icc_classe = var_classe/(var_classe+var_res)
  
  # Retorna o valor do ICC 
  return(list("ICC-Escola" = icc_escola, "ICC-Classe" = icc_classe))
}

# Uso
# icc_lme_3nv(modelo) - basta substitui "modelo" pelo nome da variável que você escolheu para salvar seu modelo.
```

## Observações

Treine criar mais modelos multinível, inclusive com apenas 2 níveis. Inclusive, se for utilzar a função `lmer()`, MUITO CUIDADO!

Este modelo:

```{r}
modelo_5b = lmer(PosTHKS ~ 1 + Group +
                   (1|SchoolID:ClassID),
                 dataset,
                 REML = TRUE)
```

É diferente deste modelo:

```{r}
modelo_5b = lmer(PosTHKS ~ 1 + Group +
                   (1|SchoolID) + # Escola como efeito aleatório
                   (1|SchoolID:ClassID), # Classe como efeito aleatório
                 dataset,
                 REML = TRUE)
```

Com a função `lmer()` precisamos indicar no modelo que queremos Escola e Classe como efeito aleatórios em linhas separadas!

## Lista 4 resolvida no SPSS

{{< video https://www.youtube.com/watch?v=_1lUvEu8M9c title=’ HGMM - Hierarchical Generalized Mixed Models - Aula Prática #4 (SPSS)’ >}}

## Referências

https://lmudge13.github.io/sample_code/mixed_effects.html \# Tabelas e gráficos de modelos lme

https://rpsychologist.com/r-guide-longitudinal-lme-lmer#three-level-models

https://search.r-project.org/CRAN/refmans/misty/html/multilevel.icc.html

https://www.rdocumentation.org/packages/psychometric/versions/2.4/topics/ICC.lme

https://www.alexanderdemos.org/Mixed5.html

https://cran.r-project.org/web/packages/rempsyc/vignettes/assumptions.html#categorical-predictors \# pressupostos dos modelos com variáveis categóricas como preditoras.


## Versões dos pacotes

```{r}
report(sessionInfo())
```