[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Técnicas e Métodos de Pesquisa no R",
    "section": "",
    "text": "Introdução\nTutorial produzido com base nas aulas práticas da disciplina “Estatística Aplicada a Psicobiologia II - 2023”, ministrada pelo Professor Altay Lino de Souza e oferecida pelo Departamento de Psicobiologia da UNIFESP."
  },
  {
    "objectID": "index.html#sobre-as-aulas",
    "href": "index.html#sobre-as-aulas",
    "title": "Técnicas e Métodos de Pesquisa no R",
    "section": "Sobre as aulas",
    "text": "Sobre as aulas\nAs aulas são gravadas e disponibilizadas gratuitamente por meio de lives no canal Cientística & Podcast Naruhodo do YouTube. Destacando aqui o agradecimento mais do que especial para a Maria Lucia Oliveira De Souza Formigoni, por tornar possível a disciplina."
  },
  {
    "objectID": "index.html#sobre-o-tutorial",
    "href": "index.html#sobre-o-tutorial",
    "title": "Técnicas e Métodos de Pesquisa no R",
    "section": "Sobre o tutorial",
    "text": "Sobre o tutorial\nEste tutorial tem como objetivo oferecer uma introdução prática à análise estatística de dados no R, utilizando diversos bancos de dados para cada tipo de anáise. O público-alvo abrange estudantes de Estatística Aplicada a Psicobiologia II, pós-graduandos e pesquisadores que buscam aprimorar suas habilidades em análise de dados. É recomendado ter conhecimento básico em estatística, particularmente Estatística Aplicada a Psicobiologia I, e alguma familiaridade com o ambiente R para acompanhar este tutorial. Abordaremos as seguintes análises:\n\nTransformação de dados para análises\nModelos lineares:\n\nModelo linear geral (GLM ) de medidas repetidas\nGeneralized Estimated Equations (GEE)\nModelos mistos e hierárquicos (GMM)\nGeneralized linear models (GzLM)\n\n\n\n\nAnálise de sobrevida\n\nKaplan-Meier\nRegressão de Cox\nCox Tempo dependente\n\n\n\n\nSéries temporais (ARIMA)\nModelagem de Equação Estrutural (SEM)\n\nPath analysis\nConfrmatory Factor Analysis (CFA)\nModeração e mediação\n\n\nAo fim de cada capítulos, nas seções intituladas “Extras”, vamos mostrar dicas sobre pacotes que podem ser úteis para suas análises, mas que não estão disponíveis no SPSS ou no Jamovi.\n\n\n\n\n\n\nImportante!\n\n\n\nO material apresentado aqui é complementar às aulas teóricas e práticas. É imprescindível que você assista às aulas antes de resolver os exercícios no R."
  },
  {
    "objectID": "index.html#r-e-rstudio",
    "href": "index.html#r-e-rstudio",
    "title": "Técnicas e Métodos de Pesquisa no R",
    "section": "R e Rstudio",
    "text": "R e Rstudio\nEmbora as aulas práticas tenham sido gravadas utilizando o SPSS, o intuito do tutorial é replicar as análises no R, que é gratuito! Portanto você precisa baixar o R e o Rstudio.\nDownload do R\nDownload do Rstudio"
  },
  {
    "objectID": "index.html#aulas-práticas-gravadas",
    "href": "index.html#aulas-práticas-gravadas",
    "title": "Técnicas e Métodos de Pesquisa no R",
    "section": "Aulas práticas gravadas",
    "text": "Aulas práticas gravadas\nOs vídeos das aulas práticas no SPSS foram anexados ao fim de cada capítulo para que você possa ter uma referência do tipo de análise realizada. Em alguns casos você notarão que os resultados não serão idênticos no SPSS e no R. Isso ocorre devido aos diferentes algorítimos de estimação de coeficientes utilizados nos programas. O importante é você sempre reportar como a análise foi feita, quais programas e sempre que possível, disponibilizar o código ou o passo-a-passo utilizado para realizar a análise."
  },
  {
    "objectID": "index.html#boas-práticas-no-rstudio",
    "href": "index.html#boas-práticas-no-rstudio",
    "title": "Técnicas e Métodos de Pesquisa no R",
    "section": "Boas práticas no Rstudio",
    "text": "Boas práticas no Rstudio\nCriar um projeto separado para cada tipo de análise no R é uma prática recomendada porque mantém o ambiente organizado, evita conflitos entre projetos, facilita a colaboração e torna a reprodução e compartilhamento de trabalho mais eficientes.\n\nCriando o projeto e alocando os arquivos\nPara criar um novo projeto no R, siga estes passos simples:\n\nAbra o RStudio.\nVá até a guia “File” (Arquivo) e selecione “New Project” (Novo Projeto).\nEscolha um diretório para o seu projeto, onde todas as pastas e arquivos relacionados a ele serão armazenados. Isso ajudará na organização.\nClique em “Create Project” (Criar Projeto).\n\nFeito isso você terá um novo projeto configurado. Qualquer arquivo que você deseje usar para o tutorial deve ser colocado dentro da pasta desse projeto. Isso garantirá que todos os caminhos e referências aos arquivos sejam relativos ao diretório do projeto, facilitando a portabilidade e compartilhamento do tutorial.\nCom esses passos, você terá um ambiente de projeto limpo e organizado para trabalhar com seus arquivos e conduzir seu tutorial no R."
  },
  {
    "objectID": "index.html#instalando-e-carregando-os-pacotes",
    "href": "index.html#instalando-e-carregando-os-pacotes",
    "title": "Técnicas e Métodos de Pesquisa no R",
    "section": "Instalando e carregando os pacotes",
    "text": "Instalando e carregando os pacotes\nNo início de cada capítulo, você encontrará uma lista completa dos pacotes necessários para reproduzir as análises correspondentes.\nPara instalar um pacote, basta executar o comando install.packages(\"nome_do_pacote\") uma única vez.\nPor exemplo: install.packages(\"effects\"). Este comando instalará o pacote “effects”, que contém funções para calcular os estimadores de modelos lineares. É importante colocar o nome do pacote entre aspas (” “)\nApós a instalação do pacote, será necessário carregá-lo sempre que desejar utilizar alguma função associada a ele. Para isso basta executar o comando library(nome_do_pacote). Note que aqui não há a necessidade de colocar o nome do pacote entre aspas.\nExemplo: library(effects).\nPronto! Agora você está familiarizado com o processo de instalação e carregamento dos pacotes que serão utilizados ao longo deste tutorial. Pode-se fazer uma analogia com uma biblioteca: adquirir os livros seria como instalar os pacotes (install.packages), e retirar um livro da prateleira seria como carregar o pacote (library) quando necessário."
  },
  {
    "objectID": "index.html#referências",
    "href": "index.html#referências",
    "title": "Técnicas e Métodos de Pesquisa no R",
    "section": "Referências",
    "text": "Referências\n\nhttps://r4ds.hadley.nz/"
  },
  {
    "objectID": "survival.html#pressupostos-da-cox-regression",
    "href": "survival.html#pressupostos-da-cox-regression",
    "title": "SURVIVAL",
    "section": "Pressupostos da Cox regression",
    "text": "Pressupostos da Cox regression\nA Regressão de Cox é uma técnica robusta, mas, como qualquer método estatístico, possui alguns pressupostos importantes. Os principais pressupostos da Regressão de Cox são:\n\nProporcionalidade dos Riscos:\n\nO pressuposto fundamental é que os riscos relativos entre dois grupos são constantes ao longo do tempo. Em outras palavras, a razão instantânea de riscos (hazard ratio) entre grupos não muda com o tempo. Este é o pressuposto de proporcionalidade dos riscos.\n\nIndependência Censura:\n\nA censura dos dados deve ser independente da probabilidade de falha. Isso significa que a probabilidade de um evento censurado (ocorrido após o fim do acompanhamento) deve ser a mesma para todos os grupos.\n\nLinearidade no Logaritmo dos Riscos:\n\nA relação entre as variáveis independentes e o logaritmo do risco deve ser linear. Isso é crucial para a interpretação dos coeficientes como log-riscos instantâneos.\n\nAuscência de Colinearidade:\n\nAs variáveis independentes no modelo não devem estar altamente correlacionadas (colinearidade). A colinearidade pode levar a estimativas imprecisas dos coeficientes.\n\nAusência de Efeito de Interferência:\n\nNão deve haver efeito de interferência entre indivíduos, o que significa que o status de um indivíduo não deve influenciar diretamente o tempo de falha de outro indivíduo.\n\nAdequação do Modelo:\n\nO modelo escolhido deve ser apropriado para os dados. Avaliações de adequação, como testes de resíduos, podem ser úteis para verificar a qualidade do ajuste do modelo aos dados.\n\n\nOs pressupostos de 2 a 6 são inerentes ao desenho do experimento e do acompanhamento durante as observações. O único que vamos abordar aqui no tutorial é o de proporcionalidade dos riscos.\n\nProporcionalidade dos riscos\nTemos duas formas de avaliar a proporcionalidade dos riscos\n\n1) Análise do gráfico da Kaplan-Meier\nAo analisar o gráfico de Kaplan-Meier para diferentes grupos, é crucial observar se as curvas de sobrevivência são aproximadamente paralelas ou se cruzam entre si. Se as curvas são paralelas, isso sugere proporcionalidade dos riscos, indicando que as diferenças nas taxas de falha entre os grupos são constantes ao longo do tempo. No entanto, se as curvas se cruzam, isso indica uma possível violação da proporcionalidade dos riscos.\nCruzamentos nas curvas podem indicar mudanças na relação de risco entre os grupos ao longo do tempo. Essa mudança pode ser devido a diferentes dinâmicas de risco em períodos distintos do estudo. Se as curvas se cruzarem, a aplicação da Regressão de Cox não deve ser feita para não gerar interpretações erradas!\n\nfit2_km\n\n\n\n\nPodemos observar que em nosso exemplo as linhas de sobrevida não cruzam, portanto podemos assumir que os riscos são proporcionais pela análise gráfica.\n\n\n2) Resíduos de Schoenfeld\nA segunda forma para se avaliar a suposição de proporcionalidade dos riscos na Regressão de Cox vamos utilizar o teste de Schoenfeld, que verifica se há uma relação sistemática entre os resíduos de Schoenfeld e o tempo, o que indicaria uma violação dessa suposição.\nA ideia central é que, se os resíduos de Schoenfeld não apresentarem uma relação significativa com o tempo, isso sugere que a proporcionalidade dos riscos é razoável. Logo, a hipótese nula é que não há relação entre os resíduos e o tempo, o que indicaria proporcionalidade dos riscos. O teste estatístico avalia se é razoável rejeitar essa hipótese nula.\n\n\n\n\n\n\nImportante!\n\n\n\nVamos torcer para o valor de p ser MAIOR que 0.05!\n\n\nUtilizando a função cox.zph() do pacote survival temos o seguinte código:\n\ntest &lt;- survival::cox.zph(cox_res)\ntest\n\n       chisq df    p\ntx      0.58  1 0.45\nGLOBAL  0.58  1 0.45\n\n\nOk! Temos riscos proporcionais!\nOutra forma de verificar a proporcionalidade dos riscos é com o gráfico dos resíduos de Schoenfeld.\n\n# Plot the Schoenfeld residuals over time for each covariate\nsurvminer::ggcoxzph(test, point.size = 0.1)[1]\n\n$`1`\n\n\n\n\n\nSe os resíduos mostrarem um padrão claro ao longo do tempo, isso pode indicar uma violação da suposição de riscos proporcionais.\nAlgumas dicas para ajudar na interpretação:\n\nSem Padrão (Resíduos Constantes): Se os resíduos aparecerem aleatoriamente espalhados em torno de zero, sem nenhuma tendência ou padrão claro, isso sugere que a suposição de riscos proporcionais é razoável.\nTendência Linear: Uma tendência linear (aumentando ou diminuindo) nos resíduos ao longo do tempo pode sugerir uma violação da suposição de riscos proporcionais. Por exemplo, se os resíduos forem consistentemente positivos ou negativos ao longo do tempo, isso indica um efeito dependente do tempo.\nPadrão Não Linear: Se os resíduos exibirem um padrão não linear ou formatos específicos (por exemplo, formato de U, formato de V), isso pode indicar desvios dos riscos proporcionais.\nParalelismo: Paralelismo significa que a propagação e distribuição dos resíduos são relativamente constantes ao longo do tempo. Se os resíduos aumentarem ou diminuirem ao longo do tempo, isso pode sugerir uma violação da suposição.\n\nRetomaremos a discussão sobre os pressupostos ao desenvolvermos nosso primeiro modelo e também o que fazer quando o pressuposto da proporcionalidade dos riscos é violado."
  },
  {
    "objectID": "lista_6.html#carregando-pacotes",
    "href": "lista_6.html#carregando-pacotes",
    "title": "6  Lista 6 - Kaplan-Meier e Cox Regression",
    "section": "6.1 Carregando pacotes",
    "text": "6.1 Carregando pacotes\n\nlibrary(tidyverse)\nlibrary(flexplot)\nlibrary(foreign)\nlibrary(dplyr)\nlibrary(tm)\nlibrary(ggplot2)\nlibrary(forcats)\nlibrary(rempsyc)\nlibrary(easystats)\nlibrary(kableExtra)\nlibrary(gtsummary)\n\n#Específicos para survival\nlibrary(survival)\nlibrary(ggsurvfit)\nlibrary(survminer)\nlibrary(broom)\nlibrary(survMisc)\nlibrary(PHInfiniteEstimates)\nlibrary(coin)\nlibrary(condSURV)"
  },
  {
    "objectID": "lista_6.html#limpando-o-ambiente",
    "href": "lista_6.html#limpando-o-ambiente",
    "title": "6  Lista 6 - Kaplan-Meier e Cox Regression",
    "section": "6.2 Limpando o ambiente",
    "text": "6.2 Limpando o ambiente\nQuando executamos diversos comandos no R muitas vezes acabamos deixando o ambiente meio “sujo”. Cheio de variáveis que não estamos mais utilizando, ou pacotes que estão carregados e não serão utilizados no momento.\nEm longas sessões utilizando o R é sempre bom dar uma limpada no ambiente entre um projeto e outro. Para isso podemos executar o código abaixo:\n\n# Limpa o ambiente\nrm(list = ls(all.names = TRUE)) # will clear all objects including hidden objects\ngc() # free up memory and report the memory usage\n\n          used  (Mb) gc trigger  (Mb) max used  (Mb)\nNcells 3170881 169.4    4805995 256.7  4805995 256.7\nVcells 5390829  41.2   10154066  77.5  8395055  64.1\n\noptions(max.print = .Machine$integer.max, scipen = 999, stringsAsFactors = F, dplyr.summarise.inform = F) # avoid truncated output in R console and scientific notation\n\n# Set seed\nset.seed(42)"
  },
  {
    "objectID": "lista_6.html#definindo-um-tema-para-os-gráficos",
    "href": "lista_6.html#definindo-um-tema-para-os-gráficos",
    "title": "6  Lista 6 - Kaplan-Meier e Cox Regression",
    "section": "6.3 Definindo um tema para os gráficos",
    "text": "6.3 Definindo um tema para os gráficos\nPreenhcer todos os parâmetros da função ggplot() é uma tarefa morosa e repetitiva. Podemos criar um tema para todos os nossos gráficos e assim manter a consistência nas figuras e não precisar ficar escrevendo toda hora aquele parâmetro para mudar a espessura da linha do eixo X…\nUma vez definido o tema, podemos apenas chamá-lo dentro da função ggplot para repetir o padrão. Vamos armazenar todas as informações da padronização em uma variável com o código a seguir:\n\nmeu_tema &lt;- theme(plot.title = element_text(size = rel(2)),\n                  panel.grid.major.y = element_line(colour = 'gray'),\n                  panel.grid.minor.y = element_line(colour = 'gray'),\n                  panel.grid.major.x = element_blank(),\n                  panel.grid.minor.x = element_blank(),\n                  plot.background = element_rect(fill = NULL, colour = 'white'),\n                  panel.background = element_rect(fill = 'white'),\n                  # Axis stuff\n                  axis.line = element_line(colour = 'black', linewidth = 1),\n                  axis.text = element_text(colour = \"black\", face = 'bold'),\n                  axis.text.x = element_text(size = rel(1)),\n                  axis.text.y = element_text(size = rel(1)),\n                  axis.title = element_text(size = rel(1.2)),\n                  axis.ticks = element_line(colour = 'black', linewidth = 1.2),\n                  # Legend stuff\n                  legend.position = \"bottom\",\n                  legend.margin = margin(6, 6, 6, 6),\n                  legend.title = element_text(face = 'bold'),\n                  legend.background = element_blank(),\n                  legend.box.background = element_rect(colour = \"black\"))\n\nVamos utilizar o tema em nossos gráficos mais adiante!"
  },
  {
    "objectID": "lista_6.html#sec-carrega_dados",
    "href": "lista_6.html#sec-carrega_dados",
    "title": "6  Lista 6 - Kaplan-Meier e Cox Regression",
    "section": "6.4 Carregando os dados e modificando o tipo de variável",
    "text": "6.4 Carregando os dados e modificando o tipo de variável\nComo de costume, vamos carregar os dados e ver os tipos das variáveis que temos no banco de dados.\n\noriginal = read.spss(\"teste Cox tempo dep Tx.sav\", to.data.frame=TRUE)\nglimpse(original)\n\nRows: 124\nColumns: 5\n$ id    &lt;chr&gt; \"13758618I                     \", \"13750502G                    …\n$ t_seg &lt;dbl&gt; 99, 98, 97, 97, 97, 96, 92, 90, 89, 87, 83, 83, 82, 82, 80, 77, …\n$ t_tx  &lt;dbl&gt; 22, 81, NA, 25, 93, 5, 1, 30, 88, 28, 30, 13, 49, NA, NA, 10, NA…\n$ tx    &lt;fct&gt; sim, sim, não, sim, sim, sim, sim, sim, sim, sim, sim, sim, sim,…\n$ obito &lt;fct&gt; não, não, não, não, não, não, não, não, sim, não, não, não, não,…\n\n\n\n\n\n\n\n\nCuidado!\n\n\n\nA variável do evento (óbito em nosso exemplo) PRECISA ser recodificada para uma variável numérica binária, ou seja, 1 e 0 caso queira realizar a análise de sobrevida.\n\n\nNa seção Section 6.16, exploraremos as distinções entre conduzir as análises com os fatores “sim” e “não” versus os números 1 e 0.\nInicialmente, ajustaremos a variável para aceitar os valores 1 e 0, representando a ocorrência do evento e a censura, respectivamente. Para isso, empregaremos o operador pipe %&gt;% para duplicar a base de dados original e efetuar a modificação no mesmo script. O operador pipe é útil para executar várias operações em uma única sequência de código.\n\ndb &lt;- original %&gt;%\n  mutate(\n    obito = as.integer(obito == \"sim\") # para transformar sim e não em 1 e 0, respectivamente\n  )\n\nglimpse(db)\n\nRows: 124\nColumns: 5\n$ id    &lt;chr&gt; \"13758618I                     \", \"13750502G                    …\n$ t_seg &lt;dbl&gt; 99, 98, 97, 97, 97, 96, 92, 90, 89, 87, 83, 83, 82, 82, 80, 77, …\n$ t_tx  &lt;dbl&gt; 22, 81, NA, 25, 93, 5, 1, 30, 88, 28, 30, 13, 49, NA, NA, 10, NA…\n$ tx    &lt;fct&gt; sim, sim, não, sim, sim, sim, sim, sim, sim, sim, sim, sim, sim,…\n$ obito &lt;int&gt; 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n\n\nPronto, agora temos que óbito assumiu os valores de números 1 e 0.\nOutra análise exploratória importante a fazer nos dados é observar se há dados faltantes (NA) e onde eles estão, caso estejam presentes. Se uma variável tiver muitos NAs, vamos precisar de cautela para inserir a variável na análise.\n\n# Verificando NAs\ndata.frame(\n  nas_t_seg = sum(is.na(db$t_seg)),\n  nas_t_seg = sum(is.na(db$t_tx)),\n  nas_tx = sum(is.na(db$tx)),\n  nas_obito = sum(is.na(db$obito))\n)\n\n  nas_t_seg nas_t_seg.1 nas_tx nas_obito\n1         0          64      0         0\n\n\n\nkable(report(db))\n\n\n\n\n\nVariable\nLevel\nn_Obs\npercentage_Obs\npercentage_Missing\nMean\nSD\nMedian\nMAD\nMin\nMax\nSkewness\nKurtosis\nn_Entries\nn_Missing\n\n\n\n\n3\nid\nNA\n124\n\n0.00\n\n\n\n\n\n\n\n\n124.00\n0\n\n\n5\nt_seg\nNA\n124\n\n0.00\n45.22\n24.08\n42.00\n19.27\n0.00\n99.00\n0.38\n-0.19\n\n\n\n\n6\nt_tx\nNA\n124\n\n51.61\n19.90\n20.05\n\n16.31\n1.00\n93.00\n1.99\n4.70\n\n\n\n\n1\ntx\nsim\n60\n48.39\n\n\n\n\n\n\n\n\n\n\n\n\n\n2\ntx\nnão\n64\n51.61\n\n\n\n\n\n\n\n\n\n\n\n\n\n4\nobito\nNA\n124\n\n0.00\n0.27\n0.45\n0.00\n0.00\n0.00\n1.00\n1.02\n-0.97\n\n\n\n\n\n\n\n\n\nO número de NAs na variável t_tx é alto (51.61%) pelo simples motivo de que pessoas que não fizeram transplante não possuem a marca do tempo que fizeram o transplante. Em todo caso podemos verificar se existem indivíduos que fizeram o transplante mas não possuem a marca do tempo em que fizeram o transplante.\n\ndb %&gt;%\n  filter(tx == \"sim\" & is.na(t_tx))\n\n[1] id    t_seg t_tx  tx    obito\n&lt;0 linhas&gt; (ou row.names de comprimento 0)\n\n\nO código acima filtra os dados de pessoas que fizeram o transplante (tx sim) e que tenham NA na coluna t_tx. Como o resultado volta com zero elementos, podemos concluir que todas as pessoas que fizeram o transplante, possuem a marca do horário em que o transplante foi feito.\nNa tabela acima podemos perceber também que a porcentagem de pessoas que não fizeram o transplante (51.61) é a mesma porcentagem de dados faltantes (missing) da variável t_tx (51.61)\nPor fim, podemos ver quantas pessoas morreram pela causa de morte do desfecho durante o período de observação.\n\nkable(table(db$obito))\n\n\n\n\nVar1\nFreq\n\n\n\n\n0\n90\n\n\n1\n34\n\n\n\n\n\n\n\nLembrando que 1 é o evento, que no nosso exemplo é ocorrência do óbito\nVamos agora às análises."
  },
  {
    "objectID": "lista_6.html#criando-a-estrutura-de-dados",
    "href": "lista_6.html#criando-a-estrutura-de-dados",
    "title": "6  Lista 6 - Kaplan-Meier e Cox Regression",
    "section": "6.5 Criando a estrutura de dados",
    "text": "6.5 Criando a estrutura de dados\nIniciamos especificando para a função Surv() as colunas referentes ao tempo observado e aos eventos de interesse, que, neste caso, são os óbitos.\n\nsurv_obj &lt;- Surv(time = db$t_seg, event = db$obito)"
  },
  {
    "objectID": "lista_6.html#a-tábua-de-vida",
    "href": "lista_6.html#a-tábua-de-vida",
    "title": "6  Lista 6 - Kaplan-Meier e Cox Regression",
    "section": "6.6 a) Tábua de vida",
    "text": "6.6 a) Tábua de vida\n\n\n\n\n\n\nExercício\n\n\n\nFaça duas tábuas de vida em função da variável óbito comparando grupos que fizeram ou não transplante: Ambas com período 0 até 99 meses. A primeira dividida em períodos de 20 meses e a segunda com períodos de 1 mês. Faça um parágrafo descrevendo as diferenças nos gráficos.\n\n\nAgora vamos criar a tabela de vida. Por enquanto, não faremos a separação dos dados por grupos.\n\nfit1 &lt;- survfit(surv_obj ~ 1, data = db)\n\nA função summary() também pode ser utilizada para verificar os resultados dos modelos de sobrevida.\n\nsummary(fit1)\n\nCall: survfit(formula = surv_obj ~ 1, data = db)\n\n time n.risk n.event survival std.err lower 95% CI upper 95% CI\n    0    124       2    0.984  0.0113        0.962        1.000\n    3    121       2    0.968  0.0159        0.937        0.999\n    4    119       2    0.951  0.0194        0.914        0.990\n    6    117       1    0.943  0.0208        0.903        0.985\n    8    116       2    0.927  0.0234        0.882        0.974\n   11    114       1    0.919  0.0246        0.872        0.968\n   13    113       1    0.911  0.0257        0.862        0.962\n   16    110       1    0.902  0.0268        0.851        0.956\n   19    108       1    0.894  0.0278        0.841        0.950\n   24    106       2    0.877  0.0297        0.821        0.937\n   25    104       1    0.869  0.0306        0.811        0.931\n   26    103       1    0.860  0.0314        0.801        0.924\n   27    102       1    0.852  0.0323        0.791        0.917\n   29    101       1    0.843  0.0330        0.781        0.911\n   34     89       3    0.815  0.0358        0.748        0.888\n   36     82       1    0.805  0.0367        0.736        0.880\n   38     70       1    0.794  0.0379        0.723        0.871\n   40     68       1    0.782  0.0391        0.709        0.862\n   41     65       2    0.758  0.0414        0.681        0.844\n   44     59       1    0.745  0.0427        0.666        0.834\n   45     55       1    0.731  0.0440        0.650        0.823\n   46     53       1    0.718  0.0453        0.634        0.812\n   49     47       1    0.702  0.0468        0.616        0.800\n   58     32       1    0.680  0.0502        0.589        0.786\n   66     24       1    0.652  0.0556        0.552        0.771\n   89      9       1    0.580  0.0843        0.436        0.771\n\n\nE a função função tidy_survfit() nos oferece uma tabela bem mais completa.\n\ntidy_survfit(fit1)\n\n# A tibble: 63 × 14\n    time n.risk n.event n.censor cum.event cum.censor estimate std.error\n   &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;      &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;\n 1     0    124       2        1         2          1    0.984    0.0115\n 2     3    121       2        0         4          1    0.968    0.0165\n 3     4    119       2        0         6          1    0.951    0.0204\n 4     6    117       1        0         7          1    0.943    0.0221\n 5     8    116       2        0         9          1    0.927    0.0253\n 6    11    114       1        0        10          1    0.919    0.0268\n 7    13    113       1        0        11          1    0.911    0.0282\n 8    14    112       0        1        11          2    0.911    0.0282\n 9    15    111       0        1        11          3    0.911    0.0282\n10    16    110       1        0        12          3    0.902    0.0297\n# ℹ 53 more rows\n# ℹ 6 more variables: conf.high &lt;dbl&gt;, conf.low &lt;dbl&gt;, estimate_type &lt;chr&gt;,\n#   estimate_type_label &lt;chr&gt;, monotonicity_type &lt;chr&gt;, conf.level &lt;dbl&gt;"
  },
  {
    "objectID": "lista_6.html#b-kaplan-meier",
    "href": "lista_6.html#b-kaplan-meier",
    "title": "6  Lista 6 - Kaplan-Meier e Cox Regression",
    "section": "6.7 b) Kaplan-Meier",
    "text": "6.7 b) Kaplan-Meier\n\n\n\n\n\n\nExercício\n\n\n\nFaça uma curva de Kaplan-meyer comparando os grupos que fizeram vs não fizeram transplante em relação ao óbito. Analise o gráfico e as saídas do teste.\n\n\nPara produzir um gráfico Kaplan-Meier simples podemos utilizar a função plot().\n\nplot(fit1)\n\n\n\n\nMeio pobrezinho e sem cor ne?\nPodemos melhorar utilizando a função ggsurvfit(), do pacote com o mesmo nome.\n\nfit1_km = ggsurvfit(fit1, linewidth = 1) +\n  labs(x = 'Dias', y = 'Overall survival') +\n  add_confidence_interval() +\n  add_risktable() +\n  scale_ggsurvfit() \n\nfit1_km\n\n\n\n\nAté aqui estamos vendo o gráfico da sobrevida sem separar por grupos. A seguir vamos comparar entre os grupos que receberam ou não o transplante de rins."
  },
  {
    "objectID": "lista_6.html#separando-por-transplante-e-nos-tempos-0-20-40-60-80",
    "href": "lista_6.html#separando-por-transplante-e-nos-tempos-0-20-40-60-80",
    "title": "6  Lista 6 - Kaplan-Meier e Cox Regression",
    "section": "6.8 Separando por transplante e nos tempos 0, 20, 40, 60, 80",
    "text": "6.8 Separando por transplante e nos tempos 0, 20, 40, 60, 80\nQueremos comparar a sobrevida entre quem fez e não fez o transplante. Para isso podemos especificar no modelo que o transplante (tx) será uma das variáveis independentes.\n\nfit2 = survfit(surv_obj ~ tx, # basta colocar tx como uma variável preditora no modelo\n               data = db) \n\n\nsummary(fit2)\n\nCall: survfit(formula = surv_obj ~ tx, data = db)\n\n                tx=sim \n time n.risk n.event survival std.err lower 95% CI upper 95% CI\n    3     59       1    0.983  0.0168        0.951        1.000\n    4     58       1    0.966  0.0236        0.921        1.000\n   24     57       1    0.949  0.0286        0.895        1.000\n   26     56       1    0.932  0.0327        0.870        0.999\n   29     55       1    0.915  0.0363        0.847        0.989\n   38     44       1    0.894  0.0410        0.818        0.978\n   41     41       1    0.873  0.0454        0.788        0.966\n   45     37       1    0.849  0.0499        0.757        0.953\n   49     32       1    0.823  0.0550        0.722        0.938\n   66     19       1    0.779  0.0670        0.658        0.922\n   89      8       1    0.682  0.1083        0.499        0.931\n\n                tx=não \n time n.risk n.event survival std.err lower 95% CI upper 95% CI\n    0     64       2    0.969  0.0217        0.927        1.000\n    3     62       1    0.953  0.0264        0.903        1.000\n    4     61       1    0.938  0.0303        0.880        0.999\n    6     60       1    0.922  0.0335        0.858        0.990\n    8     59       2    0.891  0.0390        0.817        0.970\n   11     57       1    0.875  0.0413        0.798        0.960\n   13     56       1    0.859  0.0435        0.778        0.949\n   16     53       1    0.843  0.0456        0.758        0.937\n   19     51       1    0.827  0.0476        0.738        0.925\n   24     49       1    0.810  0.0495        0.718        0.913\n   25     48       1    0.793  0.0513        0.699        0.900\n   27     47       1    0.776  0.0529        0.679        0.887\n   34     38       3    0.715  0.0594        0.607        0.841\n   36     35       1    0.694  0.0611        0.584        0.825\n   40     26       1    0.668  0.0643        0.553        0.806\n   41     24       1    0.640  0.0674        0.520        0.786\n   44     21       1    0.609  0.0707        0.485        0.765\n   46     18       1    0.575  0.0745        0.447        0.742\n   58     11       1    0.523  0.0841        0.382        0.717\n\n\nA função summary() aceita um parâmetro com intervalos específicos para aparecer nos resultados. Vamos utilizar a função seq() para criar uma sequência de números que vai do 0 ao 100 com intervalos de 20 em 20.\n\n# Cria o intervalo de tempo\n\ntempos_específicos &lt;- seq(0, 100, by = 20) # sequencia de 0 a 100 em intervalos de 20.\n\nAplicando o intervalo na função temos o seguinte script:\n\nsummary(fit2, times = tempos_específicos)\n\nCall: survfit(formula = surv_obj ~ tx, data = db)\n\n                tx=sim \n time n.risk n.event survival std.err lower 95% CI upper 95% CI\n    0     60       0    1.000  0.0000        1.000        1.000\n   20     57       2    0.966  0.0236        0.921        1.000\n   40     42       4    0.894  0.0410        0.818        0.978\n   60     21       3    0.823  0.0550        0.722        0.938\n   80     12       1    0.779  0.0670        0.658        0.922\n\n                tx=não \n time n.risk n.event survival std.err lower 95% CI upper 95% CI\n    0     64       2    0.969  0.0217        0.927        1.000\n   20     50       9    0.827  0.0476        0.738        0.925\n   40     26       8    0.668  0.0643        0.553        0.806\n   60      7       4    0.523  0.0841        0.382        0.717\n   80      3       0    0.523  0.0841        0.382        0.717\n\n\nPodemos nos perguntar também qual é a probabilidade de sobreviver após um certo tempo. Para obter a resposta basta ajustar o parâmetro times da função summary() para o tempo desejado.\n\nsummary(fit2, times = 75)\n\nCall: survfit(formula = surv_obj ~ tx, data = db)\n\n                tx=sim \n        time       n.risk      n.event     survival      std.err lower 95% CI \n      75.000       14.000       10.000        0.779        0.067        0.658 \nupper 95% CI \n       0.922 \n\n                tx=não \n        time       n.risk      n.event     survival      std.err lower 95% CI \n     75.0000       4.0000      23.0000       0.5232       0.0841       0.3818 \nupper 95% CI \n      0.7169 \n\n\nNa análise do tempo de sobrevivência neste modelo, observamos o seguinte:\nPara o grupo que realizou o transplante (tx=sim):\n\nAos 75 meses, havia 14 indivíduos em risco.\n10 eventos ocorreram até esse momento.\nA taxa de sobrevivência foi de 0.779, com um desvio padrão de 0.067.\nO intervalo de confiança de 95% para a taxa de sobrevivência variou de 0.658 a 0.922.\n\nPara o grupo que não realizou o transplante (tx=não):\n\nAos 75 meses, havia 4 indivíduos em risco.\n23 eventos ocorreram até esse momento.\nA taxa de sobrevivência foi de 0.5232, com um desvio padrão de 0.0841.\nO intervalo de confiança de 95% para a taxa de sobrevivência variou de 0.3818 a 0.7169.\n\nPodemos ainda calcular quantas vezes a probabilidade de sobrevivência é maior no grupo que realizou o transplante em comparação com o grupo que não o fez.\n\nsummary(fit2, times = 75)$surv[1] / summary(fit2, times = 75)$surv[2]\n\n[1] 1.489431\n\n\nO resultado revela que a probabilidade de sobrevivência no grupo que fez o transplante é aproximadamente 1.5 vezes maior do que no grupo que não o realizou.\n\nKaplan-Meir do novo modelo\nVamos salvar o plot padrão do segundo modelo para adicionar mais alguns parâmetros e incrementar a visualização dos resultados.\n\nfit2_km = ggsurvfit(fit2, linewidth = 1) +\n  labs(x = 'Tempo (meses)', y = '% Probabilidade de sobrevivência') +\n  add_confidence_interval() +\n  #add_risktable() + \n  scale_ggsurvfit() \n\nfit2_km\n\n\n\n\nCom o plot salvo, podemos adicionar mais elementos aos poucos, como as linhas tracejadas para enfatizar diferenças.\n\nfit2_km +\n  geom_vline(xintercept = 75, \n             linetype = 'dashed', \n             colour = 'red', \n             size = 1) + # adiciona a linha vermelha vertical \n  geom_hline(yintercept = summary(fit2, times = 75)$surv, \n             linetype = 'dashed', \n             colour = 'red', size = 1) # adiciona as linhas vermelhas horizontais.\n\n\n\n\n\n\nPorcentagem fixa, tempos diferentes\nA função ggsurvfit oferece vários parâmetros interessantes. Um deles, bastante útil, permite traçar uma linha para comparar o tempo em que a probabilidade de sobrevivência X ocorre entre grupos diferentes.\nEm quanto tempo será que a probabilidade de sobrevida chega a 75% nos dois grupos? Vamos utilizar o parâmetro add_quantile() para ter uma estimativa gráfica.\n\nfit2 %&gt;% \n  ggsurvfit(linewidth = 1) +\n  labs(x = 'Tempo (meses)', y = '% Probabilidade de sobrevivência') +\n  add_confidence_interval() +\n  #  add_risktable() +\n  add_quantile(y_value = 0.75, color = \"gray50\", linewidth = 0.75) +\n  scale_ggsurvfit()\n\n\n\n\nAo examinarmos a imagem, observamos que o grupo que não passou pelo transplante atinge uma probabilidade de sobrevida de 75% em aproximadamente 35 meses. Por outro lado, no grupo que se submeteu ao transplante, essa mesma probabilidade só ocorre por volta do 90º mês, sendo ainda maior antes desse período.\n\n\nEscolhendo um intervalo de tempo\nCaso você queira apresentar apenas um período específico de tempo em sua análise, podemos fazer isso utilizando o parâmetro coord_cartesian().\n\nggsurvfit(fit2, linewidth = 1) +\n  labs(x = 'Tempo (meses)', y = '% Probabilidade de sobrevivência') +\n  add_confidence_interval() +\n  # add_risktable() +\n  scale_ggsurvfit() + \n  coord_cartesian(xlim = c(0, 60)) # coloque os números que\n\n\n\n\nPersonalize os limites do intervalo de tempo em sua análise ajustando os valores “0” e “60”, de acordo com suas necessidades específicas."
  },
  {
    "objectID": "lista_6.html#comparando-as-curvas",
    "href": "lista_6.html#comparando-as-curvas",
    "title": "6  Lista 6 - Kaplan-Meier e Cox Regression",
    "section": "6.9 Comparando as curvas",
    "text": "6.9 Comparando as curvas\n\nLog-rank: utilizar para comparar o primeiro terço do gráfico\nGehan: utilizar para comparar o meio do gráfico\nTarone: utilizar para comparar o final do gráfico\nPeto-Peto: parecido com o Log-rank, utilizar para comparar o primeiro terço do gráfico\n\nPacote mais indicado para utilizar é o coin.\n\nTipos de testes possíveis\n“logrank”, “Gehan-Breslow”, “Tarone-Ware”, “Peto-Peto”, “Prentice”, “Prentice-Marek”, “Andersen-Borgan-Gill-Keiding”, “Fleming-Harrington”, “Gaugler-Kim-Liao”, “Self”\n\nLog-rank\n\ncoin::logrank_test(surv_obj ~ tx, data = db, type = \"logrank\" ) # padrão é o log-rank\n\n\n    Asymptotic Two-Sample Logrank Test\n\ndata:  surv_obj by tx (sim, não)\nZ = 2.9275, p-value = 0.003417\nalternative hypothesis: true theta is not equal to 1\n\n\n\n\nGehan-Breslow\n\ncoin::logrank_test(surv_obj ~ tx ,data = db, type = \"Gehan-Breslow\")\n\n\n    Asymptotic Two-Sample Gehan-Breslow Test\n\ndata:  surv_obj by tx (sim, não)\nZ = 3.0103, p-value = 0.00261\nalternative hypothesis: true theta is not equal to 1\n\n\n\n\nTarone-Ware\n\ncoin::logrank_test(surv_obj ~ tx ,data = db, type = \"Tarone-Ware\")\n\n\n    Asymptotic Two-Sample Tarone-Ware Test\n\ndata:  surv_obj by tx (sim, não)\nZ = 3.0338, p-value = 0.002415\nalternative hypothesis: true theta is not equal to 1\n\n\n\n\nPeto-Peto\n\ncoin::logrank_test(surv_obj ~ tx ,data = db, type = \"Peto-Peto\")\n\n\n    Asymptotic Two-Sample Peto-Peto Test\n\ndata:  surv_obj by tx (sim, não)\nZ = 2.9857, p-value = 0.002829\nalternative hypothesis: true theta is not equal to 1\n\n\nEm todos os testes a hipótese alternativa sugere que o verdadeiro parâmetro theta não é igual a 1, indicando assim que há diferenças significativas nas curvas de sobrevida entre os dois grupos analisados. Em termos práticos, isso sugere que a probabilidade de sobrevivência varia de maneira estatisticamente significativa entre os grupos que fizeram ou não o transplante."
  },
  {
    "objectID": "lista_6.html#c-cox-regression",
    "href": "lista_6.html#c-cox-regression",
    "title": "6  Lista 6 - Kaplan-Meier e Cox Regression",
    "section": "6.10 c) Cox Regression",
    "text": "6.10 c) Cox Regression\n\n\n\n\n\n\nExercício\n\n\n\nReproduza a análise do item b) com uma Cox Regression. Descreva os resultados\n\n\nCompare com base no resultado da Cox, qual seria a diferença na sobrevida (HR) entre uma pessoa que fez e outra que não fez transplante com 50 meses de observação\nA Regressão de Cox é uma técnica estatística utilizada para analisar a relação entre variáveis explicativas e o tempo até um evento ocorrer, como a morte. Ao contrário de modelos de regressão linear, a Regressão de Cox lida com dados de sobrevida, levando em consideração o tempo até o evento ou a censura. O código apresentado realiza uma Regressão de Cox com a função coxph().\n\n# Cox regression ======================================================\n# Fit the model\ncox_res &lt;- coxph(Surv(time = db$t_seg, event = db$obito) ~ tx, data = db)\n\nO código acima ajusta o modelo de Regressão de Cox. A variável dependente é definida como o tempo (t_seg) até o evento (obito) ocorrer, e a variável independente é tx.\nNotem que dentro da função coxph(), repetimos o código para gerar a tabela de vida.Durante a criação da estrutura dos dados, armazenamos a tabela de vida em uma variável chamada surv_obj. Podemos reutilizá-la na Regressão de Cox, evitando a necessidade de reescrever o código.\nVamos fazer isso!\n\ncox_res_2 = coxph(surv_obj ~ tx, data = db)\n\nBem mais limpo, não? E como vamos escrever mais alguns modelos, é uma boa prática salvar o padrão que se repete em uma variável.\n\nResultados dos modelos\nSabe qual função vamos utilizar para verificar o resultado? Sim, a summary().\nPrimeiro vamos verificar se as duas formas que escrevemos os modelos geram os mesmos resultados.\n\nsummary(cox_res)\n\nCall:\ncoxph(formula = Surv(time = db$t_seg, event = db$obito) ~ tx, \n    data = db)\n\n  n= 124, number of events= 34 \n\n        coef exp(coef) se(coef)     z Pr(&gt;|z|)   \ntxnão 1.0787    2.9409   0.3753 2.874  0.00405 **\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n      exp(coef) exp(-coef) lower .95 upper .95\ntxnão     2.941       0.34     1.409     6.136\n\nConcordance= 0.638  (se = 0.04 )\nLikelihood ratio test= 8.99  on 1 df,   p=0.003\nWald test            = 8.26  on 1 df,   p=0.004\nScore (logrank) test = 9.01  on 1 df,   p=0.003\n\n\n\n\nsummary(cox_res_2)\n\nCall:\ncoxph(formula = surv_obj ~ tx, data = db)\n\n  n= 124, number of events= 34 \n\n        coef exp(coef) se(coef)     z Pr(&gt;|z|)   \ntxnão 1.0787    2.9409   0.3753 2.874  0.00405 **\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n      exp(coef) exp(-coef) lower .95 upper .95\ntxnão     2.941       0.34     1.409     6.136\n\nConcordance= 0.638  (se = 0.04 )\nLikelihood ratio test= 8.99  on 1 df,   p=0.003\nWald test            = 8.26  on 1 df,   p=0.004\nScore (logrank) test = 9.01  on 1 df,   p=0.003\n\n\n\nBoa! Os resultados são idênticos, então podemos manter o padrão de escrevr o modelo utilizando a tábua de vida salva em uma variável.\nEmbora o resultado da função summary() para modelos de Regressão de Cox possa não ser visualmente atraente, ele oferece informações detalhadas sobre como o modelo se ajusta aos dados. Vamos analisar cada componente separadamente:\n\nSumário do Modelo:\n\nCall: Indica a chamada da função utilizada para ajustar o modelo.\nn= 124, number of events= 34: Informa o número total de observações (n) e o número de eventos ocorridos (number of events).\n\nCoeficientes:\n\ncoef: O coeficiente estimado para a variável tx.\nexp(coef): A interpretação deste valor é que, para pessoas do grupo que não fizeram o transplante (txnão), o risco de o evento (morte) ocorrer aumenta em 2.941 vezes.\nse(coef): O erro padrão do coeficiente.\n\nTeste de Hipótese para Coeficientes:\n\nz: O valor z do teste de Wald, indicando quão longe o coeficiente está da média em termos de erros padrão.\nPr(&gt;|z|): O p-valor associado ao teste de Wald. No exemplo, 0.00405 sugere que o efeito da variável tx é estatisticamente significativo.\nSignificância codes: ** indica significância a 0.01.\n\nIntervalo de Confiança para Exp(Coef):\n\nexp(coef) exp(-coef) lower .95 upper .95: O intervalo de confiança de 95% para o efeito da variável tx.\n\nMedidas de Desempenho do Modelo:\n\nConcordance= 0.638: A concordância é uma medida de quão bem o modelo prevê a ordem de eventos.\nLikelihood ratio test= 8.99, p=0.003: O teste de razão de verossimilhança avalia se o modelo é significativamente melhor do que um modelo nulo. O p-valor sugere que o modelo é estatisticamente significativo.\nWald test= 8.26, p=0.004: O teste de Wald também avalia a significância global do modelo.\nScore (logrank) test= 9.01, p=0.003: O teste de log-rank compara as curvas de sobrevivência entre os grupos.\n\n\nE claro que temos formas melhores de visualizar e mostrar os dados mais importantes. Vamos utilizar a função tbl_regression() do pacote gtsummary, que pega um objeto de modelo de regressão e retorna uma tabela formatada pronta para publicação.\n\ntbl_regression(cox_res, exponentiate = TRUE)\n\n\n\n\n\n  \n    \n    \n      Characteristic\n      HR1\n      95% CI1\n      p-value\n    \n  \n  \n    tx\n\n\n\n        sim\n—\n—\n\n        não\n2.94\n1.41, 6.14\n0.004\n  \n  \n  \n    \n      1 HR = Hazard Ratio, CI = Confidence Interval\n    \n  \n\n\n\n\nPra fazer isso aí no word demoraria uns 30 minutos hein? E ficaria feia ainda. Com uma linha de código fizemos miséria!\n\n\nPlots do modelo e do resultado\nTendo ajustado um modelo de Cox aos dados, é possível visualizar a proporção de sobrevivência prevista em qualquer momento para um determinado grupo de risco.\nNeste caso, construímos um novo banco de dados com duas linhas, uma para cada valor de tx.\n\ntx_df &lt;- with(db,\n              data.frame(tx = c(\"sim\", \"não\")\n              )\n)\nkable(tx_df)\n\n\n\n\ntx\n\n\n\n\nsim\n\n\nnão\n\n\n\n\n\n\n\nAgora podemos utilizar o nosso modelo para prever os valores de sobrevida e criar um gráfico da Regressão de Cox.\n\ncox_graph &lt;- survfit(cox_res, newdata = tx_df)\n\nggsurvplot(cox_graph, conf.int = TRUE, legend.labs=c(\"tx=sim\", \"tx=não\"),\n           ggtheme = theme_minimal(),\n           data = db)\n\n\n\n\n\n\n\n\n\n\nCuidado!\n\n\n\nO gráfico do modelo da Regressão de Cox é diferente do gráfico da Kaplan-Meir! O cálculo da regressão distorce os valores e encaixa o modelo aos dados. Observe a diferença!\n\n\n\n# Gráfico da Kaplan-Meir\nfit2_km\n\n\n\n\nNão podemos deixar e fora o gráfico do modelo. Com pouca tinta (e pouco código) vamos mostrar tudo o que a função summary() nos proporcionou. Para isso vamos utilizar a função ggforest() do pacote survminer.\n\nggforest(cox_res, data = db)\n\n\n\n\nSe não escorreu uma lágrima aí do outro lado da tela agora, eu desisto. E olha que utilizamos apenas uma variável independente no modelo!"
  },
  {
    "objectID": "lista_6.html#hazard-ratio-e-risco-relativo-confirmar-o-conteúdo",
    "href": "lista_6.html#hazard-ratio-e-risco-relativo-confirmar-o-conteúdo",
    "title": "6  Lista 6 - Kaplan-Meier e Cox Regression",
    "section": "6.11 Hazard ratio e risco relativo (CONFIRMAR O CONTEÚDO)",
    "text": "6.11 Hazard ratio e risco relativo (CONFIRMAR O CONTEÚDO)\nVocês repararam que tanto na tabela quanto no gráfico com os resultados no modelo aparece o resultado como “Hazard Ratio”… pois bem, isso está errado!\n\n\n\n\n\n\nAtenção!\n\n\n\nO risco relativo compara a probabilidade cumulativa de um evento ocorrer entre dois grupos ao longo de um período específico, enquanto o hazard ratio avalia a razão instantânea de riscos proporcionais entre os grupos, considerando a variação no risco ao longo do tempo. Enquanto o risco relativo se concentra em eventos cumulativos, o hazard ratio destaca as diferenças nas taxas instantâneas de falha, sendo especialmente útil em análises de sobrevida e estudos onde a dinâmica temporal do risco é crucial."
  },
  {
    "objectID": "lista_6.html#d-hazard-ratio",
    "href": "lista_6.html#d-hazard-ratio",
    "title": "6  Lista 6 - Kaplan-Meier e Cox Regression",
    "section": "6.12 d) Hazard Ratio",
    "text": "6.12 d) Hazard Ratio\n\n\n\n\n\n\nExercício\n\n\n\nCompare com base no resultado da Cox, qual seria a diferença na sobrevida (HR) entre uma pessoa que fez e outra que não fez transplante com 50 meses de observação\n\n\nPara de fato calcular o Hazard Ratio precisamos utilizar nosso modelo para prever a sobrevida em um tempo específico de nosso interesse.\nVamos começar salvando nosso modelo em uma variável\n\n# Ajuste do modelo de regressão de Cox\ncox_res &lt;- coxph(Surv(time = t_seg, event = obito) ~ tx, data = db)\n\nAgora vamos criar um conjunto de dados com informações simuladas sobre tempo de seguimento, ocorrência de evento (óbito), e uma variável indicadora de tratamento. Como queremos comparar o tempo de sobrevida entre quem fez ou não o transplante, a única variável que terá valores diferentes será a tx.\n\npred_dat &lt;- data.frame(t_seg = c(41,41),\n                       obito = c(0,0), \n                       tx = c(\"sim\",\"não\")\n                       )\nkable(pred_dat)\n\n\n\n\nt_seg\nobito\ntx\n\n\n\n\n41\n0\nsim\n\n\n41\n0\nnão\n\n\n\n\n\n\n\nA seguir vamos utiliza a função predict() para fazer previsões com base em nosso modelo previamente ajustado (cox_res).\n\npreds &lt;- predict(cox_res, newdata = pred_dat, type = \"survival\", se.fit = TRUE)\n\nSalvamos o resultado da função em uma variável para poder adicionar os resultados das predições em nosso dataframe criado anteriormente (pred_dat). Queremos os resultados da média e do Intervalo de Confiança. Para isso executamos o código a seguir:\n\npred_dat$prob &lt;- preds$fit\npred_dat$lcl &lt;- preds$fit - 1.96*preds$se.fit\npred_dat$ucl &lt;- preds$fit + 1.96*preds$se.fit\nkable(pred_dat)\n\n\n\n\nt_seg\nobito\ntx\nprob\nlcl\nucl\n\n\n\n\n41\n0\nsim\n0.8630231\n0.7805057\n0.9455404\n\n\n41\n0\nnão\n0.6484075\n0.5224067\n0.7744083\n\n\n\n\n\n\n\nPor fim, podemos finalmente verificar o Hazard Ratio no tempo de 41 meses, dividindo a probabilidade de sobrevida do grupo que fez o transplante pela probabilidade de sobrevida do grupo que não fez o transplante.\n\nHR_41 = pred_dat$prob[1] / pred_dat$prob[2] # Diferença na sobrevida (HR) no tempo 41 meses \nHR_41\n\n[1] 1.330989\n\n\n\nTemos que no tempo de 41 meses a probabilidade de sobrevida de quem não fez o transplante é 1.33 menor do que quem fez o transplante.\nCaso tenha interesse em mais pontos, podemos criar vários tempos de interesse em um único dataframe e repetir o código.\n\nmulti_pred_dat &lt;- data.frame(t_seg = c(41,41, 50, 50, 80, 80),\n                       obito = c(0,0,0,0,0,0), \n                       tx = c(\"sim\",\"não\",\"sim\",\"não\",\"sim\",\"não\")\n                       )\n\npreds &lt;- predict(cox_res, newdata = multi_pred_dat, type = \"survival\", se.fit = TRUE)\n\nmulti_pred_dat$prob &lt;- preds$fit\nmulti_pred_dat$lcl &lt;- preds$fit - 1.96*preds$se.fit\nmulti_pred_dat$ucl &lt;- preds$fit + 1.96*preds$se.fit\n\nHR_41 = multi_pred_dat$prob[1] / multi_pred_dat$prob[2] # 41 \nHR_50 = multi_pred_dat$prob[3] / multi_pred_dat$prob[4] # 50 \nHR_80 = multi_pred_dat$prob[5] / multi_pred_dat$prob[6] # 80 \n\ntabela_HR = data.frame(Tempo = c(41, 50, 80),\n                       HR_Não = c(HR_41, HR_50, HR_80))\nkable(tabela_HR)\n\n\n\n\nTempo\nHR_Não\n\n\n\n\n41\n1.330989\n\n\n50\n1.454309\n\n\n80\n1.597592"
  },
  {
    "objectID": "lista_6.html#verificando-os-pressupostos-da-cox-regression",
    "href": "lista_6.html#verificando-os-pressupostos-da-cox-regression",
    "title": "6  Lista 6 - Kaplan-Meier e Cox Regression",
    "section": "6.13 Verificando os pressupostos da Cox regression",
    "text": "6.13 Verificando os pressupostos da Cox regression\nA Regressão de Cox é uma técnica robusta, mas, como qualquer método estatístico, possui alguns pressupostos importantes. Os principais pressupostos da Regressão de Cox são:\n\nProporcionalidade dos Riscos:\n\nO pressuposto fundamental é que os riscos relativos entre dois grupos são constantes ao longo do tempo. Em outras palavras, a razão instantânea de riscos (hazard ratio) entre grupos não muda com o tempo. Este é o pressuposto de proporcionalidade dos riscos.\n\nIndependência Censura:\n\nA censura dos dados deve ser independente da probabilidade de falha. Isso significa que a probabilidade de um evento censurado (ocorrido após o fim do acompanhamento) deve ser a mesma para todos os grupos.\n\nLinearidade no Logaritmo dos Riscos:\n\nA relação entre as variáveis independentes e o logaritmo do risco deve ser linear. Isso é crucial para a interpretação dos coeficientes como log-riscos instantâneos.\n\nAuscência de Colinearidade:\n\nAs variáveis independentes no modelo não devem estar altamente correlacionadas (colinearidade). A colinearidade pode levar a estimativas imprecisas dos coeficientes.\n\nAusência de Efeito de Interferência:\n\nNão deve haver efeito de interferência entre indivíduos, o que significa que o status de um indivíduo não deve influenciar diretamente o tempo de falha de outro indivíduo.\n\nAdequação do Modelo:\n\nO modelo escolhido deve ser apropriado para os dados. Avaliações de adequação, como testes de resíduos, podem ser úteis para verificar a qualidade do ajuste do modelo aos dados.\n\n\nOs pressupostos de 2 a 6 são inerentes ao desenho do experimento e do acompanhamento durante as observações. O único que vamos abordar aqui no tutorial é o de proporcionalidade dos riscos.\n\nProporcionalidade dos riscos\nTemos duas formas de avaliar a proporcionalidade dos riscos\n\n1) Análise do gráfico da Kaplan-Meier\nAo analisar o gráfico de Kaplan-Meier para diferentes grupos, é crucial observar se as curvas de sobrevivência são aproximadamente paralelas ou se cruzam entre si. Se as curvas são paralelas, isso sugere proporcionalidade dos riscos, indicando que as diferenças nas taxas de falha entre os grupos são constantes ao longo do tempo. No entanto, se as curvas se cruzam, isso indica uma possível violação da proporcionalidade dos riscos.\nCruzamentos nas curvas podem indicar mudanças na relação de risco entre os grupos ao longo do tempo. Essa mudança pode ser devido a diferentes dinâmicas de risco em períodos distintos do estudo. Se as curvas se cruzarem, a aplicação da Regressão de Cox não deve ser feita para não gerar interpretações erradas!\n\nfit2_km\n\n\n\n\nPodemos observar que em nosso exemplo as linhas de sobrevida não cruzam, portanto podemos assumir que os riscos são proporcionais pela análise gráfica.\n\n\n2) Resíduos de Schoenfeld\nA segunda forma para se avaliar a suposição de proporcionalidade dos riscos na Regressão de Cox vamos utilizar o teste de Schoenfeld, que verifica se há uma relação sistemática entre os resíduos de Schoenfeld e o tempo, o que indicaria uma violação dessa suposição.\nA ideia central é que, se os resíduos de Schoenfeld não apresentarem uma relação significativa com o tempo, isso sugere que a proporcionalidade dos riscos é razoável. Logo, a hipótese nula é que não há relação entre os resíduos e o tempo, o que indicaria proporcionalidade dos riscos. O teste estatístico avalia se é razoável rejeitar essa hipótese nula.\n\n\n\n\n\n\nImportante!\n\n\n\nVamos torcer para o valor de p ser MAIOR que 0.05!\n\n\nUtilizando a função cox.zph() do pacote survival temos o seguinte código:\n\ntest &lt;- survival::cox.zph(cox_res)\ntest\n\n       chisq df    p\ntx      0.58  1 0.45\nGLOBAL  0.58  1 0.45\n\n\nOk! Temos riscos proporcionais!\nOutra forma de verificar a proporcionalidade dos riscos é com o gráfico dos resíduos de Schoenfeld.\n\n# Plot the Schoenfeld residuals over time for each covariate\nsurvminer::ggcoxzph(test, point.size = 0.1)[1]\n\n$`1`\n\n\n\n\n\nSe os resíduos mostrarem um padrão claro ao longo do tempo, isso pode indicar uma violação da suposição de riscos proporcionais.\nAlgumas dicas para ajudar na interpretação:\n\nSem Padrão (Resíduos Constantes): Se os resíduos aparecerem aleatoriamente espalhados em torno de zero, sem nenhuma tendência ou padrão claro, isso sugere que a suposição de riscos proporcionais é razoável.\nTendência Linear: Uma tendência linear (aumentando ou diminuindo) nos resíduos ao longo do tempo pode sugerir uma violação da suposição de riscos proporcionais. Por exemplo, se os resíduos forem consistentemente positivos ou negativos ao longo do tempo, isso indica um efeito dependente do tempo.\nPadrão Não Linear: Se os resíduos exibirem um padrão não linear ou formatos específicos (por exemplo, formato de U, formato de V), isso pode indicar desvios dos riscos proporcionais.\nParalelismo: Paralelismo significa que a propagação e distribuição dos resíduos são relativamente constantes ao longo do tempo. Se os resíduos aumentarem ou diminuirem ao longo do tempo, isso pode sugerir uma violação da suposição."
  },
  {
    "objectID": "lista_6.html#conlcusões",
    "href": "lista_6.html#conlcusões",
    "title": "6  Lista 6 - Kaplan-Meier e Cox Regression",
    "section": "6.14 Conlcusões",
    "text": "6.14 Conlcusões\nMuito bacana a análise de sobrevida e a Regressão de Cox! Na seção Extras! vamos ver mais algumas formas de plotar os gráficos e avaliar a proporcionalidade dos riscos caso a Variável Independente seja contínua!\nPróximo capitulo: Cox tempo-dependente!"
  },
  {
    "objectID": "lista_6.html#lista-6-resolvida-no-spss",
    "href": "lista_6.html#lista-6-resolvida-no-spss",
    "title": "6  Lista 6 - Kaplan-Meier e Cox Regression",
    "section": "6.15 Lista 6 resolvida no SPSS",
    "text": "6.15 Lista 6 resolvida no SPSS"
  },
  {
    "objectID": "lista_6.html#sec-extrasVI",
    "href": "lista_6.html#sec-extrasVI",
    "title": "6  Lista 6 - Kaplan-Meier e Cox Regression",
    "section": "6.16 Extras!",
    "text": "6.16 Extras!\n\nEvento como fator ou como número\nComo mencionado na seção Section 6.4, o tipo da variável do evento (morte) afeta os resultados tanto da Kaplan-Meir quanto na Regressão de Cox.\nVamos criar alguns modelos utilizando o banco de dados original (variável óbito é um fator) e também o db (variável óbito é binária, 1 e 0).\nVamos começar observando a diferença do tipo da variável nos bancos utilizando a função glimpse():\n\nglimpse(original$obito)\n\n Factor w/ 2 levels \"não\",\"sim\": 1 1 1 1 1 1 1 1 2 1 ...\n\n\n\nglimpse(db$obito)\n\n int [1:124] 0 0 0 0 0 0 0 0 1 0 ...\n\n\nE tem mais! Temos que lembrar que quando deixamos as variáveis como fatores elas sempre possuem um nível de referência. Já verificamos isso em outros exercícios utilizando a função levels().\n\nlevels(original$obito)\n\n[1] \"não\" \"sim\"\n\n\nVeja só! A referência para a variável óbito é o “não”. Para fins didáditcos vamos criar três modelos:\nÓbito como variável binária (banco db) Óbito como fator com nível de referência “não” (banco original) Óbito como fator com nível de referência “sim” (banco original_sim)\n\noriginal_sim = original\noriginal_sim$obito = relevel(original_sim$obito, ref = \"sim\")\n\nAgora vamos repetir todo o procedimento já demonstrado no início das análises, utilizando os três bancos de dados.\n\nsurv_db &lt;- Surv(time = db$t_seg, event = db$obito)\nsurv_oiriginal_não &lt;- Surv(time = original$t_seg, event = original$obito)\nsurv_oiriginal_sim &lt;- Surv(time = original_sim$t_seg, event = original_sim$obito)\n\n\nfit_db &lt;- survfit(surv_db ~ 1, data = db)\nfit_original_não &lt;- survfit(surv_oiriginal_não ~ 1, data = original)\nfit_original_sim &lt;- survfit(surv_oiriginal_sim ~ 1, data = original_sim)\n\n\nplot(fit_db)\n\n\n\nplot(fit_original_não)\n\n\n\nplot(fit_original_sim)\n\n\n\n\n\nggsurvfit(fit_db, linewidth = 1) +\n  ggtitle(\"Binário\") +\n  labs(x = 'Dias', y = 'Overall survival') +\n  add_confidence_interval() +\n    add_risktable() +\n  scale_ggsurvfit() \n\n\n\nggcuminc(fit_original_não, linewidth = 1, type = \"survival\" ) +\n  ggtitle(\"Fator - Lelvel = Não\") +\n  labs(x = 'Dias', y = 'Overall survival') +\n  add_confidence_interval() +\n  add_risktable() +\n  scale_ggsurvfit() \n\nPlotting outcome \"sim\".\n\n\nWarning in ggplot2::geom_step(ggplot2::aes(x = .data$time, y = .data$estimate),\n: Ignoring unknown parameters: `type`\n\n\n\n\nggcuminc(fit_original_sim, linewidth = 1) +\n  ggtitle(\"Fator - Lelvel = Sim\") +\n  labs(x = 'Dias', y = 'Overall survival') +\n  add_confidence_interval() +\n  add_risktable() +\n  scale_ggsurvfit() \n\nPlotting outcome \"não\".\n\n\n\n\n\nComo podemos observar, quando utilizamos a variável de evento como um fator, acabamos analisando o risco cumulativo e não a sobrevida.\n\n\nMais gráficos!\nCom o ggplot2\n\nkm_plot = survfit2(surv_obj ~ tx, data = db) %&gt;%\n  tidy_survfit() %&gt;%\n  ggplot(aes(x = time, y = estimate,\n             min = conf.low, ymax = conf.low,\n             color = strata, fill = strata)) +\n  geom_step()\n\nkm_plot\n\n\n\n\nCom a função ggsurvplot() do pacote survminer.\n\nggsurvplot(fit2, data = db,\n           size = 1,\n           palette = c('#E7B800', '#2e9fdf'),\n           censor.shape = '|', censor.size = 4,\n           conf.int = TRUE,\n           pval = TRUE,\n           risk.table = TRUE,\n           risk.table.col = 'strata',\n           legend.labs = list('0' = 'Transplante = sim', '1' = 'Transplante = não'),\n           risk.table.height = 0.25,\n           ggtheme = theme_bw())\n\n\n\n\nGráficos de proporcionalidade com outras funções\n\nggcoxdiagnostics(cox_res, type = \"dfbeta\", linear.predictions = FALSE)\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\nE um específico para variáveis contínuas.\n\n# Não é importante para variáveis categóricas, mas fica o código para eventual consulta.\nggcoxdiagnostics(cox_res, type = \"deviance\", linear.predictions = FALSE)\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\nPacots alternativos para comparar curvas\n\ngehan.wilcoxon.test(surv_obj ~ tx ,data=db)\n\n\n    Gehan-Wilcoxon\n\ndata:  \n= 9.1531, p-value = 0.002483\nalternative hypothesis: two-sided\n\n\nsurvdiff Com rho = 0 este é o teste log-rank ou Mantel-Haenszel, e com rho = 1 é equivalente à modificação Peto & Peto do teste Gehan-Wilcoxon.\n\nsurvdiff(surv_obj ~ tx, data=db, rho = 2)\n\nCall:\nsurvdiff(formula = surv_obj ~ tx, data = db, rho = 2)\n\n        N Observed Expected (O-E)^2/E (O-E)^2/V\ntx=sim 60      7.4     14.0      3.12      9.19\ntx=não 64     17.9     11.3      3.89      9.19\n\n Chisq= 9.2  on 1 degrees of freedom, p= 0.002 \n\n\n\n\nTabela completa do modelo 2\n\nlife_table2 = survfit2(Surv(time = t_seg, event = obito) ~ tx, data = db) %&gt;%\n  tidy_survfit() \n\nkable(life_table2)\n\n\n\n\ntime\nn.risk\nn.event\nn.censor\ncum.event\ncum.censor\nestimate\nstd.error\nconf.high\nconf.low\nstrata\nestimate_type\nestimate_type_label\nmonotonicity_type\nstrata_label\nconf.level\n\n\n\n\n0\n60\n0\n1\n0\n1\n1.0000000\n0.0000000\n1.0000000\n1.0000000\nsim\nsurvival\nSurvival Probability\ndecreasing\ntx\n0.95\n\n\n3\n59\n1\n0\n1\n1\n0.9830508\n0.0170946\n1.0000000\n0.9506595\nsim\nsurvival\nSurvival Probability\ndecreasing\ntx\n0.95\n\n\n4\n58\n1\n0\n2\n1\n0.9661017\n0.0243866\n1.0000000\n0.9210112\nsim\nsurvival\nSurvival Probability\ndecreasing\ntx\n0.95\n\n\n24\n57\n1\n0\n3\n1\n0.9491525\n0.0301329\n1.0000000\n0.8947194\nsim\nsurvival\nSurvival Probability\ndecreasing\ntx\n0.95\n\n\n26\n56\n1\n0\n4\n1\n0.9322034\n0.0351093\n0.9986097\n0.8702130\nsim\nsurvival\nSurvival Probability\ndecreasing\ntx\n0.95\n\n\n29\n55\n1\n0\n5\n1\n0.9152542\n0.0396152\n0.9891503\n0.8468787\nsim\nsurvival\nSurvival Probability\ndecreasing\ntx\n0.95\n\n\n32\n54\n0\n3\n5\n4\n0.9152542\n0.0396152\n0.9891503\n0.8468787\nsim\nsurvival\nSurvival Probability\ndecreasing\ntx\n0.95\n\n\n34\n51\n0\n1\n5\n5\n0.9152542\n0.0396152\n0.9891503\n0.8468787\nsim\nsurvival\nSurvival Probability\ndecreasing\ntx\n0.95\n\n\n35\n50\n0\n3\n5\n8\n0.9152542\n0.0396152\n0.9891503\n0.8468787\nsim\nsurvival\nSurvival Probability\ndecreasing\ntx\n0.95\n\n\n36\n47\n0\n1\n5\n9\n0.9152542\n0.0396152\n0.9891503\n0.8468787\nsim\nsurvival\nSurvival Probability\ndecreasing\ntx\n0.95\n\n\n37\n46\n0\n2\n5\n11\n0.9152542\n0.0396152\n0.9891503\n0.8468787\nsim\nsurvival\nSurvival Probability\ndecreasing\ntx\n0.95\n\n\n38\n44\n1\n0\n6\n11\n0.8944530\n0.0458029\n0.9784644\n0.8176548\nsim\nsurvival\nSurvival Probability\ndecreasing\ntx\n0.95\n\n\n39\n43\n0\n1\n6\n12\n0.8944530\n0.0458029\n0.9784644\n0.8176548\nsim\nsurvival\nSurvival Probability\ndecreasing\ntx\n0.95\n\n\n40\n42\n0\n1\n6\n13\n0.8944530\n0.0458029\n0.9784644\n0.8176548\nsim\nsurvival\nSurvival Probability\ndecreasing\ntx\n0.95\n\n\n41\n41\n1\n0\n7\n13\n0.8726371\n0.0520352\n0.9663315\n0.7880272\nsim\nsurvival\nSurvival Probability\ndecreasing\ntx\n0.95\n\n\n42\n40\n0\n2\n7\n15\n0.8726371\n0.0520352\n0.9663315\n0.7880272\nsim\nsurvival\nSurvival Probability\ndecreasing\ntx\n0.95\n\n\n44\n38\n0\n1\n7\n16\n0.8726371\n0.0520352\n0.9663315\n0.7880272\nsim\nsurvival\nSurvival Probability\ndecreasing\ntx\n0.95\n\n\n45\n37\n1\n1\n8\n17\n0.8490523\n0.0588083\n0.9527789\n0.7566181\nsim\nsurvival\nSurvival Probability\ndecreasing\ntx\n0.95\n\n\n46\n35\n0\n1\n8\n18\n0.8490523\n0.0588083\n0.9527789\n0.7566181\nsim\nsurvival\nSurvival Probability\ndecreasing\ntx\n0.95\n\n\n48\n34\n0\n2\n8\n20\n0.8490523\n0.0588083\n0.9527789\n0.7566181\nsim\nsurvival\nSurvival Probability\ndecreasing\ntx\n0.95\n\n\n49\n32\n1\n2\n9\n22\n0.8225194\n0.0668317\n0.9376341\n0.7215375\nsim\nsurvival\nSurvival Probability\ndecreasing\ntx\n0.95\n\n\n51\n29\n0\n1\n9\n23\n0.8225194\n0.0668317\n0.9376341\n0.7215375\nsim\nsurvival\nSurvival Probability\ndecreasing\ntx\n0.95\n\n\n52\n28\n0\n1\n9\n24\n0.8225194\n0.0668317\n0.9376341\n0.7215375\nsim\nsurvival\nSurvival Probability\ndecreasing\ntx\n0.95\n\n\n54\n27\n0\n1\n9\n25\n0.8225194\n0.0668317\n0.9376341\n0.7215375\nsim\nsurvival\nSurvival Probability\ndecreasing\ntx\n0.95\n\n\n55\n26\n0\n4\n9\n29\n0.8225194\n0.0668317\n0.9376341\n0.7215375\nsim\nsurvival\nSurvival Probability\ndecreasing\ntx\n0.95\n\n\n57\n22\n0\n1\n9\n30\n0.8225194\n0.0668317\n0.9376341\n0.7215375\nsim\nsurvival\nSurvival Probability\ndecreasing\ntx\n0.95\n\n\n65\n21\n0\n2\n9\n32\n0.8225194\n0.0668317\n0.9376341\n0.7215375\nsim\nsurvival\nSurvival Probability\ndecreasing\ntx\n0.95\n\n\n66\n19\n1\n1\n10\n33\n0.7792289\n0.0859678\n0.9222336\n0.6583990\nsim\nsurvival\nSurvival Probability\ndecreasing\ntx\n0.95\n\n\n67\n17\n0\n1\n10\n34\n0.7792289\n0.0859678\n0.9222336\n0.6583990\nsim\nsurvival\nSurvival Probability\ndecreasing\ntx\n0.95\n\n\n73\n16\n0\n1\n10\n35\n0.7792289\n0.0859678\n0.9222336\n0.6583990\nsim\nsurvival\nSurvival Probability\ndecreasing\ntx\n0.95\n\n\n74\n15\n0\n1\n10\n36\n0.7792289\n0.0859678\n0.9222336\n0.6583990\nsim\nsurvival\nSurvival Probability\ndecreasing\ntx\n0.95\n\n\n75\n14\n0\n1\n10\n37\n0.7792289\n0.0859678\n0.9222336\n0.6583990\nsim\nsurvival\nSurvival Probability\ndecreasing\ntx\n0.95\n\n\n77\n13\n0\n1\n10\n38\n0.7792289\n0.0859678\n0.9222336\n0.6583990\nsim\nsurvival\nSurvival Probability\ndecreasing\ntx\n0.95\n\n\n82\n12\n0\n1\n10\n39\n0.7792289\n0.0859678\n0.9222336\n0.6583990\nsim\nsurvival\nSurvival Probability\ndecreasing\ntx\n0.95\n\n\n83\n11\n0\n2\n10\n41\n0.7792289\n0.0859678\n0.9222336\n0.6583990\nsim\nsurvival\nSurvival Probability\ndecreasing\ntx\n0.95\n\n\n87\n9\n0\n1\n10\n42\n0.7792289\n0.0859678\n0.9222336\n0.6583990\nsim\nsurvival\nSurvival Probability\ndecreasing\ntx\n0.95\n\n\n89\n8\n1\n0\n11\n42\n0.6818253\n0.1588949\n0.9309465\n0.4993689\nsim\nsurvival\nSurvival Probability\ndecreasing\ntx\n0.95\n\n\n90\n7\n0\n1\n11\n43\n0.6818253\n0.1588949\n0.9309465\n0.4993689\nsim\nsurvival\nSurvival Probability\ndecreasing\ntx\n0.95\n\n\n92\n6\n0\n1\n11\n44\n0.6818253\n0.1588949\n0.9309465\n0.4993689\nsim\nsurvival\nSurvival Probability\ndecreasing\ntx\n0.95\n\n\n96\n5\n0\n1\n11\n45\n0.6818253\n0.1588949\n0.9309465\n0.4993689\nsim\nsurvival\nSurvival Probability\ndecreasing\ntx\n0.95\n\n\n97\n4\n0\n2\n11\n47\n0.6818253\n0.1588949\n0.9309465\n0.4993689\nsim\nsurvival\nSurvival Probability\ndecreasing\ntx\n0.95\n\n\n98\n2\n0\n1\n11\n48\n0.6818253\n0.1588949\n0.9309465\n0.4993689\nsim\nsurvival\nSurvival Probability\ndecreasing\ntx\n0.95\n\n\n99\n1\n0\n1\n11\n49\n0.6818253\n0.1588949\n0.9309465\n0.4993689\nsim\nsurvival\nSurvival Probability\ndecreasing\ntx\n0.95\n\n\n0\n64\n2\n0\n2\n0\n0.9687500\n0.0224507\n1.0000000\n0.9270468\nnão\nsurvival\nSurvival Probability\ndecreasing\ntx\n0.95\n\n\n3\n62\n1\n0\n3\n0\n0.9531250\n0.0277208\n1.0000000\n0.9027217\nnão\nsurvival\nSurvival Probability\ndecreasing\ntx\n0.95\n\n\n4\n61\n1\n0\n4\n0\n0.9375000\n0.0322749\n0.9987199\n0.8800328\nnão\nsurvival\nSurvival Probability\ndecreasing\ntx\n0.95\n\n\n6\n60\n1\n0\n5\n0\n0.9218750\n0.0363889\n0.9900254\n0.8584159\nnão\nsurvival\nSurvival Probability\ndecreasing\ntx\n0.95\n\n\n8\n59\n2\n0\n7\n0\n0.8906250\n0.0438048\n0.9704688\n0.8173502\nnão\nsurvival\nSurvival Probability\ndecreasing\ntx\n0.95\n\n\n11\n57\n1\n0\n8\n0\n0.8750000\n0.0472456\n0.9598946\n0.7976136\nnão\nsurvival\nSurvival Probability\ndecreasing\ntx\n0.95\n\n\n13\n56\n1\n0\n9\n0\n0.8593750\n0.0505650\n0.9489071\n0.7782905\nnão\nsurvival\nSurvival Probability\ndecreasing\ntx\n0.95\n\n\n14\n55\n0\n1\n9\n1\n0.8593750\n0.0505650\n0.9489071\n0.7782905\nnão\nsurvival\nSurvival Probability\ndecreasing\ntx\n0.95\n\n\n15\n54\n0\n1\n9\n2\n0.8593750\n0.0505650\n0.9489071\n0.7782905\nnão\nsurvival\nSurvival Probability\ndecreasing\ntx\n0.95\n\n\n16\n53\n1\n0\n10\n2\n0.8431604\n0.0540339\n0.9373546\n0.7584316\nnão\nsurvival\nSurvival Probability\ndecreasing\ntx\n0.95\n\n\n18\n52\n0\n1\n10\n3\n0.8431604\n0.0540339\n0.9373546\n0.7584316\nnão\nsurvival\nSurvival Probability\ndecreasing\ntx\n0.95\n\n\n19\n51\n1\n0\n11\n3\n0.8266278\n0.0575484\n0.9253272\n0.7384562\nnão\nsurvival\nSurvival Probability\ndecreasing\ntx\n0.95\n\n\n22\n50\n0\n1\n11\n4\n0.8266278\n0.0575484\n0.9253272\n0.7384562\nnão\nsurvival\nSurvival Probability\ndecreasing\ntx\n0.95\n\n\n24\n49\n1\n0\n12\n4\n0.8097579\n0.0611309\n0.9128300\n0.7183241\nnão\nsurvival\nSurvival Probability\ndecreasing\ntx\n0.95\n\n\n25\n48\n1\n0\n13\n4\n0.7928879\n0.0646549\n0.9000075\n0.6985178\nnão\nsurvival\nSurvival Probability\ndecreasing\ntx\n0.95\n\n\n27\n47\n1\n0\n14\n4\n0.7760180\n0.0681380\n0.8868924\n0.6790044\nnão\nsurvival\nSurvival Probability\ndecreasing\ntx\n0.95\n\n\n29\n46\n0\n1\n14\n5\n0.7760180\n0.0681380\n0.8868924\n0.6790044\nnão\nsurvival\nSurvival Probability\ndecreasing\ntx\n0.95\n\n\n30\n45\n0\n4\n14\n9\n0.7760180\n0.0681380\n0.8868924\n0.6790044\nnão\nsurvival\nSurvival Probability\ndecreasing\ntx\n0.95\n\n\n31\n41\n0\n1\n14\n10\n0.7760180\n0.0681380\n0.8868924\n0.6790044\nnão\nsurvival\nSurvival Probability\ndecreasing\ntx\n0.95\n\n\n32\n40\n0\n2\n14\n12\n0.7760180\n0.0681380\n0.8868924\n0.6790044\nnão\nsurvival\nSurvival Probability\ndecreasing\ntx\n0.95\n\n\n34\n38\n3\n0\n17\n12\n0.7147534\n0.0830568\n0.8411128\n0.6073768\nnão\nsurvival\nSurvival Probability\ndecreasing\ntx\n0.95\n\n\n36\n35\n1\n5\n18\n17\n0.6943319\n0.0879702\n0.8249877\n0.5843684\nnão\nsurvival\nSurvival Probability\ndecreasing\ntx\n0.95\n\n\n37\n29\n0\n3\n18\n20\n0.6943319\n0.0879702\n0.8249877\n0.5843684\nnão\nsurvival\nSurvival Probability\ndecreasing\ntx\n0.95\n\n\n40\n26\n1\n1\n19\n21\n0.6676268\n0.0963183\n0.8063435\n0.5527738\nnão\nsurvival\nSurvival Probability\ndecreasing\ntx\n0.95\n\n\n41\n24\n1\n0\n20\n21\n0.6398090\n0.1053035\n0.7864748\n0.5204942\nnão\nsurvival\nSurvival Probability\ndecreasing\ntx\n0.95\n\n\n42\n23\n0\n2\n20\n23\n0.6398090\n0.1053035\n0.7864748\n0.5204942\nnão\nsurvival\nSurvival Probability\ndecreasing\ntx\n0.95\n\n\n44\n21\n1\n2\n21\n25\n0.6093419\n0.1160593\n0.7649815\n0.4853680\nnão\nsurvival\nSurvival Probability\ndecreasing\ntx\n0.95\n\n\n46\n18\n1\n2\n22\n27\n0.5754896\n0.1293744\n0.7415854\n0.4465949\nnão\nsurvival\nSurvival Probability\ndecreasing\ntx\n0.95\n\n\n50\n15\n0\n1\n22\n28\n0.5754896\n0.1293744\n0.7415854\n0.4465949\nnão\nsurvival\nSurvival Probability\ndecreasing\ntx\n0.95\n\n\n51\n14\n0\n1\n22\n29\n0.5754896\n0.1293744\n0.7415854\n0.4465949\nnão\nsurvival\nSurvival Probability\ndecreasing\ntx\n0.95\n\n\n54\n13\n0\n1\n22\n30\n0.5754896\n0.1293744\n0.7415854\n0.4465949\nnão\nsurvival\nSurvival Probability\ndecreasing\ntx\n0.95\n\n\n56\n12\n0\n1\n22\n31\n0.5754896\n0.1293744\n0.7415854\n0.4465949\nnão\nsurvival\nSurvival Probability\ndecreasing\ntx\n0.95\n\n\n58\n11\n1\n3\n23\n34\n0.5231723\n0.1607130\n0.7168758\n0.3818086\nnão\nsurvival\nSurvival Probability\ndecreasing\ntx\n0.95\n\n\n60\n7\n0\n1\n23\n35\n0.5231723\n0.1607130\n0.7168758\n0.3818086\nnão\nsurvival\nSurvival Probability\ndecreasing\ntx\n0.95\n\n\n65\n6\n0\n1\n23\n36\n0.5231723\n0.1607130\n0.7168758\n0.3818086\nnão\nsurvival\nSurvival Probability\ndecreasing\ntx\n0.95\n\n\n71\n5\n0\n1\n23\n37\n0.5231723\n0.1607130\n0.7168758\n0.3818086\nnão\nsurvival\nSurvival Probability\ndecreasing\ntx\n0.95\n\n\n77\n4\n0\n1\n23\n38\n0.5231723\n0.1607130\n0.7168758\n0.3818086\nnão\nsurvival\nSurvival Probability\ndecreasing\ntx\n0.95\n\n\n80\n3\n0\n1\n23\n39\n0.5231723\n0.1607130\n0.7168758\n0.3818086\nnão\nsurvival\nSurvival Probability\ndecreasing\ntx\n0.95\n\n\n82\n2\n0\n1\n23\n40\n0.5231723\n0.1607130\n0.7168758\n0.3818086\nnão\nsurvival\nSurvival Probability\ndecreasing\ntx\n0.95\n\n\n97\n1\n0\n1\n23\n41\n0.5231723\n0.1607130\n0.7168758\n0.3818086\nnão\nsurvival\nSurvival Probability\ndecreasing\ntx\n0.95\n\n\n\n\n\n\nsummary(life_table2)\n\n      time           n.risk        n.event          n.censor    \n Min.   : 0.00   Min.   : 1.0   Min.   :0.0000   Min.   :0.000  \n 1st Qu.:28.00   1st Qu.:13.5   1st Qu.:0.0000   1st Qu.:0.000  \n Median :42.00   Median :34.0   Median :0.0000   Median :1.000  \n Mean   :46.25   Mean   :31.9   Mean   :0.4096   Mean   :1.084  \n 3rd Qu.:65.50   3rd Qu.:50.0   3rd Qu.:1.0000   3rd Qu.:1.000  \n Max.   :99.00   Max.   :64.0   Max.   :3.0000   Max.   :5.000  \n   cum.event       cum.censor       estimate        std.error      \n Min.   : 0.00   Min.   : 0.00   Min.   :0.5232   Min.   :0.00000  \n 1st Qu.: 7.00   1st Qu.: 4.00   1st Qu.:0.6818   1st Qu.:0.05056  \n Median :10.00   Median :20.00   Median :0.7929   Median :0.06683  \n Mean   :11.48   Mean   :20.04   Mean   :0.7757   Mean   :0.08234  \n 3rd Qu.:14.00   3rd Qu.:34.50   3rd Qu.:0.8726   3rd Qu.:0.11068  \n Max.   :23.00   Max.   :49.00   Max.   :1.0000   Max.   :0.16071  \n   conf.high         conf.low      strata   estimate_type     \n Min.   :0.7169   Min.   :0.3818   sim:43   Length:83         \n 1st Qu.:0.8869   1st Qu.:0.5099   não:40   Class :character  \n Median :0.9309   Median :0.6985            Mode  :character  \n Mean   :0.9015   Mean   :0.6716                              \n 3rd Qu.:0.9663   3rd Qu.:0.7880                              \n Max.   :1.0000   Max.   :1.0000                              \n estimate_type_label monotonicity_type  strata_label         conf.level  \n Length:83           Length:83          Length:83          Min.   :0.95  \n Class :character    Class :character   Class :character   1st Qu.:0.95  \n Mode  :character    Mode  :character   Mode  :character   Median :0.95  \n                                                           Mean   :0.95  \n                                                           3rd Qu.:0.95  \n                                                           Max.   :0.95  \n\nsummary(life_table2, times = tempos_específicos)\n\n      time           n.risk        n.event          n.censor    \n Min.   : 0.00   Min.   : 1.0   Min.   :0.0000   Min.   :0.000  \n 1st Qu.:28.00   1st Qu.:13.5   1st Qu.:0.0000   1st Qu.:0.000  \n Median :42.00   Median :34.0   Median :0.0000   Median :1.000  \n Mean   :46.25   Mean   :31.9   Mean   :0.4096   Mean   :1.084  \n 3rd Qu.:65.50   3rd Qu.:50.0   3rd Qu.:1.0000   3rd Qu.:1.000  \n Max.   :99.00   Max.   :64.0   Max.   :3.0000   Max.   :5.000  \n   cum.event       cum.censor       estimate        std.error      \n Min.   : 0.00   Min.   : 0.00   Min.   :0.5232   Min.   :0.00000  \n 1st Qu.: 7.00   1st Qu.: 4.00   1st Qu.:0.6818   1st Qu.:0.05056  \n Median :10.00   Median :20.00   Median :0.7929   Median :0.06683  \n Mean   :11.48   Mean   :20.04   Mean   :0.7757   Mean   :0.08234  \n 3rd Qu.:14.00   3rd Qu.:34.50   3rd Qu.:0.8726   3rd Qu.:0.11068  \n Max.   :23.00   Max.   :49.00   Max.   :1.0000   Max.   :0.16071  \n   conf.high         conf.low      strata   estimate_type     \n Min.   :0.7169   Min.   :0.3818   sim:43   Length:83         \n 1st Qu.:0.8869   1st Qu.:0.5099   não:40   Class :character  \n Median :0.9309   Median :0.6985            Mode  :character  \n Mean   :0.9015   Mean   :0.6716                              \n 3rd Qu.:0.9663   3rd Qu.:0.7880                              \n Max.   :1.0000   Max.   :1.0000                              \n estimate_type_label monotonicity_type  strata_label         conf.level  \n Length:83           Length:83          Length:83          Min.   :0.95  \n Class :character    Class :character   Class :character   1st Qu.:0.95  \n Mode  :character    Mode  :character   Mode  :character   Median :0.95  \n                                                           Mean   :0.95  \n                                                           3rd Qu.:0.95  \n                                                           Max.   :0.95  \n\nhead(life_table2)\n\n# A tibble: 6 × 16\n   time n.risk n.event n.censor cum.event cum.censor estimate std.error\n  &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;      &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;\n1     0     60       0        1         0          1    1        0     \n2     3     59       1        0         1          1    0.983    0.0171\n3     4     58       1        0         2          1    0.966    0.0244\n4    24     57       1        0         3          1    0.949    0.0301\n5    26     56       1        0         4          1    0.932    0.0351\n6    29     55       1        0         5          1    0.915    0.0396\n# ℹ 8 more variables: conf.high &lt;dbl&gt;, conf.low &lt;dbl&gt;, strata &lt;fct&gt;,\n#   estimate_type &lt;chr&gt;, estimate_type_label &lt;chr&gt;, monotonicity_type &lt;chr&gt;,\n#   strata_label &lt;chr&gt;, conf.level &lt;dbl&gt;\n\n\n\n\nCódigo não usado\n\n# Create the new data  \nnew_df &lt;- with(db,\n               data.frame(tx = c(\"sim\", \"não\")\n               )\n)\nglimpse(new_df)\n\nRows: 2\nColumns: 1\n$ tx &lt;chr&gt; \"sim\", \"não\"\n\nnew_df$tx = as.factor(new_df$tx)\n\n\n# Survival curves with new data\n#%%%%%%%%%%%%%%%%%%%%%%%%%%%\nfit_cox &lt;- survfit(cox_res, newdata = new_df)\n\n\nggsurvplot(fit_cox, data = db,\n           size = 1,\n           palette = c('#E7B800', '#2e9fdf'),\n           censor.shape = '|', censor.size = 4,\n           conf.int = TRUE,\n           pval = TRUE,\n          # risk.table = TRUE,\n         #  risk.table.col = 'strata',\n           legend.labs = list('0' = 'Transplante = sim', '1' = 'Transplante = não'),\n           risk.table.height = 0.25,\n           ggtheme = theme_bw())\n\nWarning in .pvalue(fit, data = data, method = method, pval = pval, pval.coord = pval.coord, : There are no survival curves to be compared. \n This is a null model.\n\n\n\n\n\n\n\nPara salvar os valores de sobrevida\n\nsurv_fit_cox = survfit(cox_res)\n\n# Extrai os tempos de sobrevida e as estimativas de sobrevida\nsurv_df_cox &lt;- data.frame(time = surv_fit_cox$time, surv = surv_fit_cox$surv)\nsurv_df_cox\n\n   time      surv\n1     0 0.9919270\n2     3 0.9837071\n3     4 0.9754200\n4     6 0.9712508\n5     8 0.9628064\n6    11 0.9585298\n7    13 0.9542158\n8    14 0.9542158\n9    15 0.9542158\n10   16 0.9497436\n11   18 0.9497436\n12   19 0.9451662\n13   22 0.9451662\n14   24 0.9357670\n15   25 0.9310329\n16   26 0.9262516\n17   27 0.9214703\n18   29 0.9166403\n19   30 0.9166403\n20   31 0.9166403\n21   32 0.9166403\n22   34 0.8995899\n23   35 0.8995899\n24   36 0.8936099\n25   37 0.8936099\n26   38 0.8862225\n27   39 0.8862225\n28   40 0.8787730\n29   41 0.8630231\n30   42 0.8630231\n31   44 0.8544152\n32   45 0.8449676\n33   46 0.8354131\n34   48 0.8354131\n35   49 0.8245091\n36   50 0.8245091\n37   51 0.8245091\n38   52 0.8245091\n39   54 0.8245091\n40   55 0.8245091\n41   56 0.8245091\n42   57 0.8245091\n43   58 0.8091983\n44   60 0.8091983\n45   65 0.8091983\n46   66 0.7855423\n47   67 0.7855423\n48   71 0.7855423\n49   73 0.7855423\n50   74 0.7855423\n51   75 0.7855423\n52   77 0.7855423\n53   80 0.7855423\n54   82 0.7855423\n55   83 0.7855423\n56   87 0.7855423\n57   89 0.7169271\n58   90 0.7169271\n59   92 0.7169271\n60   96 0.7169271\n61   97 0.7169271\n62   98 0.7169271\n63   99 0.7169271"
  },
  {
    "objectID": "lista_6.html#referências",
    "href": "lista_6.html#referências",
    "title": "6  Lista 6 - Kaplan-Meier e Cox Regression",
    "section": "6.17 Referências",
    "text": "6.17 Referências\nhttps://bookdown.org/mpfoley1973/survival/semiparametric.html#fitting-the-model-1\nhttps://biostatsquid.com/easy-survival-analysis-r-tutorial/\nhttps://www.youtube.com/watch?v=XrvCCFQRCZE\nhttps://www.youtube.com/watch?v=vX3l36ptrTU&list=PLqzoL9-eJTNDdnKvep_YHIwk2AMqHhuJ0\nhttp://www.sthda.com/english/wiki/cox-proportional-hazards-model"
  },
  {
    "objectID": "lista_6.html#versões-dos-pacotes",
    "href": "lista_6.html#versões-dos-pacotes",
    "title": "6  Lista 6 - Kaplan-Meier e Cox Regression",
    "section": "6.18 Versões dos pacotes",
    "text": "6.18 Versões dos pacotes\n\nreport(sessionInfo())\n\nAnalyses were conducted using the R Statistical language (version 4.3.1; R Core\nTeam, 2023) on Windows 11 x64 (build 22621), using the packages effectsize\n(version 0.8.6; Ben-Shachar MS et al., 2020), lpSolve (version 5.6.19;\nBerkelaar M, others, 2023), survMisc (version 0.5.6; Dardis C, 2022), tm\n(version 0.7.11; Feinerer I, Hornik K, 2023), flexplot (version 0.20.5; Fife D,\n2024), lubridate (version 1.9.3; Grolemund G, Wickham H, 2011), coxphf (version\n1.13.4; Heinze G et al., 2023), NLP (version 0.2.1; Hornik K, 2020), coin\n(version 1.4.3; Hothorn T et al., 2006), ggpubr (version 0.6.0; Kassambara A,\n2023), survminer (version 0.4.9; Kassambara A et al., 2021),\nPHInfiniteEstimates (version 2.9.5; Kolassa JE, Zhang J, 2023), parameters\n(version 0.21.3; Lüdecke D et al., 2020), performance (version 0.10.8; Lüdecke\nD et al., 2021), easystats (version 0.6.0; Lüdecke D et al., 2022), see\n(version 0.8.1; Lüdecke D et al., 2021), insight (version 0.19.6; Lüdecke D et\nal., 2019), bayestestR (version 0.13.1; Makowski D et al., 2019), modelbased\n(version 0.8.6; Makowski D et al., 2020), report (version 0.5.7; Makowski D et\nal., 2023), correlation (version 0.8.4; Makowski D et al., 2022), condSURV\n(version 2.0.4; Meira-Machado L, Sestelo M, 2023), tibble (version 3.2.1;\nMüller K, Wickham H, 2023), datawizard (version 0.9.0; Patil I et al., 2022),\nforeign (version 0.8.85; R Core Team, 2023), nph (version 2.1; Ristl R et al.,\n2021), broom (version 1.0.5; Robinson D et al., 2023), ggsurvfit (version\n1.0.0; Sjoberg D et al., 2023), gtsummary (version 1.7.2; Sjoberg D et al.,\n2021), rempsyc (version 0.1.6; Thériault R, 2023), survival (version 3.5.7;\nTherneau T, 2023), ggplot2 (version 3.4.4; Wickham H, 2016), forcats (version\n1.0.0; Wickham H, 2023), stringr (version 1.5.1; Wickham H, 2023), tidyverse\n(version 2.0.0; Wickham H et al., 2019), dplyr (version 1.1.3; Wickham H et\nal., 2023), purrr (version 1.0.2; Wickham H, Henry L, 2023), readr (version\n2.1.4; Wickham H et al., 2023), tidyr (version 1.3.0; Wickham H et al., 2023)\nand kableExtra (version 1.3.4; Zhu H, 2021).\n\nReferences\n----------\n  - Ben-Shachar MS, Lüdecke D, Makowski D (2020). \"effectsize: Estimation of\nEffect Size Indices and Standardized Parameters.\" _Journal of Open Source\nSoftware_, *5*(56), 2815. doi:10.21105/joss.02815\n&lt;https://doi.org/10.21105/joss.02815&gt;, &lt;https://doi.org/10.21105/joss.02815&gt;.\n  - Berkelaar M, others (2023). _lpSolve: Interface to 'Lp_solve' v. 5.5 to Solve\nLinear/Integer Programs_. R package version 5.6.19,\n&lt;https://CRAN.R-project.org/package=lpSolve&gt;.\n  - Dardis C (2022). _survMisc: Miscellaneous Functions for Survival Data_. R\npackage version 0.5.6, &lt;https://CRAN.R-project.org/package=survMisc&gt;.\n  - Feinerer I, Hornik K (2023). _tm: Text Mining Package_. R package version\n0.7-11, &lt;https://CRAN.R-project.org/package=tm&gt;. Feinerer I, Hornik K, Meyer D\n(2008). \"Text Mining Infrastructure in R.\" _Journal of Statistical Software_,\n*25*(5), 1-54. doi:10.18637/jss.v025.i05\n&lt;https://doi.org/10.18637/jss.v025.i05&gt;.\n  - Fife D (2024). _flexplot: Graphically Based Data Analysis Using 'flexplot'_.\nR package version 0.20.5.\n  - Grolemund G, Wickham H (2011). \"Dates and Times Made Easy with lubridate.\"\n_Journal of Statistical Software_, *40*(3), 1-25.\n&lt;https://www.jstatsoft.org/v40/i03/&gt;.\n  - Heinze G, Ploner M, Jiricka L, Steiner G (2023). _coxphf: Cox Regression with\nFirth's Penalized Likelihood_. R package version 1.13.4,\n&lt;https://CRAN.R-project.org/package=coxphf&gt;.\n  - Hornik K (2020). _NLP: Natural Language Processing Infrastructure_. R package\nversion 0.2-1, &lt;https://CRAN.R-project.org/package=NLP&gt;.\n  - Hothorn T, Hornik K, van de Wiel MA, Zeileis A (2006). \"A Lego system for\nconditional inference.\" _The American Statistician_, *60*(3), 257-263.\ndoi:10.1198/000313006X118430 &lt;https://doi.org/10.1198/000313006X118430&gt;.\nHothorn T, Hornik K, van de Wiel MA, Zeileis A (2008). \"Implementing a class of\npermutation tests: The coin package.\" _Journal of Statistical Software_,\n*28*(8), 1-23. doi:10.18637/jss.v028.i08\n&lt;https://doi.org/10.18637/jss.v028.i08&gt;.\n  - Kassambara A (2023). _ggpubr: 'ggplot2' Based Publication Ready Plots_. R\npackage version 0.6.0, &lt;https://CRAN.R-project.org/package=ggpubr&gt;.\n  - Kassambara A, Kosinski M, Biecek P (2021). _survminer: Drawing Survival\nCurves using 'ggplot2'_. R package version 0.4.9,\n&lt;https://CRAN.R-project.org/package=survminer&gt;.\n  - Kolassa JE, Zhang J (2023). _PHInfiniteEstimates: Tools for Inference in the\nPresence of a Monotone Likelihood_. R package version 2.9.5,\n&lt;https://CRAN.R-project.org/package=PHInfiniteEstimates&gt;.\n  - Lüdecke D, Ben-Shachar M, Patil I, Makowski D (2020). \"Extracting, Computing\nand Exploring the Parameters of Statistical Models using R.\" _Journal of Open\nSource Software_, *5*(53), 2445. doi:10.21105/joss.02445\n&lt;https://doi.org/10.21105/joss.02445&gt;.\n  - Lüdecke D, Ben-Shachar M, Patil I, Waggoner P, Makowski D (2021).\n\"performance: An R Package for Assessment, Comparison and Testing of\nStatistical Models.\" _Journal of Open Source Software_, *6*(60), 3139.\ndoi:10.21105/joss.03139 &lt;https://doi.org/10.21105/joss.03139&gt;.\n  - Lüdecke D, Ben-Shachar M, Patil I, Wiernik B, Makowski D (2022). \"easystats:\nFramework for Easy Statistical Modeling, Visualization, and Reporting.\" _CRAN_.\nR package, &lt;https://easystats.github.io/easystats/&gt;.\n  - Lüdecke D, Patil I, Ben-Shachar M, Wiernik B, Waggoner P, Makowski D (2021).\n\"see: An R Package for Visualizing Statistical Models.\" _Journal of Open Source\nSoftware_, *6*(64), 3393. doi:10.21105/joss.03393\n&lt;https://doi.org/10.21105/joss.03393&gt;.\n  - Lüdecke D, Waggoner P, Makowski D (2019). \"insight: A Unified Interface to\nAccess Information from Model Objects in R.\" _Journal of Open Source Software_,\n*4*(38), 1412. doi:10.21105/joss.01412 &lt;https://doi.org/10.21105/joss.01412&gt;.\n  - Makowski D, Ben-Shachar M, Lüdecke D (2019). \"bayestestR: Describing Effects\nand their Uncertainty, Existence and Significance within the Bayesian\nFramework.\" _Journal of Open Source Software_, *4*(40), 1541.\ndoi:10.21105/joss.01541 &lt;https://doi.org/10.21105/joss.01541&gt;,\n&lt;https://joss.theoj.org/papers/10.21105/joss.01541&gt;.\n  - Makowski D, Ben-Shachar M, Patil I, Lüdecke D (2020). \"Estimation of\nModel-Based Predictions, Contrasts and Means.\" _CRAN_.\n&lt;https://github.com/easystats/modelbased&gt;.\n  - Makowski D, Lüdecke D, Patil I, Thériault R, Ben-Shachar M, Wiernik B (2023).\n\"Automated Results Reporting as a Practical Tool to Improve Reproducibility and\nMethodological Best Practices Adoption.\" _CRAN_.\n&lt;https://easystats.github.io/report/&gt;.\n  - Makowski D, Wiernik B, Patil I, Lüdecke D, Ben-Shachar M (2022).\n\"correlation: Methods for Correlation Analysis.\" Version 0.8.3,\n&lt;https://CRAN.R-project.org/package=correlation&gt;. Makowski D, Ben-Shachar M,\nPatil I, Lüdecke D (2020). \"Methods and Algorithms for Correlation Analysis in\nR.\" _Journal of Open Source Software_, *5*(51), 2306. doi:10.21105/joss.02306\n&lt;https://doi.org/10.21105/joss.02306&gt;,\n&lt;https://joss.theoj.org/papers/10.21105/joss.02306&gt;.\n  - Meira-Machado L, Sestelo M (2023). _condSURV: Estimation of the Conditional\nSurvival Function for Ordered Multivariate Failure Time Data_. R package\nversion 2.0.4, &lt;https://CRAN.R-project.org/package=condSURV&gt;.\n  - Müller K, Wickham H (2023). _tibble: Simple Data Frames_. R package version\n3.2.1, &lt;https://CRAN.R-project.org/package=tibble&gt;.\n  - Patil I, Makowski D, Ben-Shachar M, Wiernik B, Bacher E, Lüdecke D (2022).\n\"datawizard: An R Package for Easy Data Preparation and Statistical\nTransformations.\" _Journal of Open Source Software_, *7*(78), 4684.\ndoi:10.21105/joss.04684 &lt;https://doi.org/10.21105/joss.04684&gt;.\n  - R Core Team (2023). _foreign: Read Data Stored by 'Minitab', 'S', 'SAS',\n'SPSS', 'Stata', 'Systat', 'Weka', 'dBase', ..._. R package version 0.8-85,\n&lt;https://CRAN.R-project.org/package=foreign&gt;.\n  - R Core Team (2023). _R: A Language and Environment for Statistical\nComputing_. R Foundation for Statistical Computing, Vienna, Austria.\n&lt;https://www.R-project.org/&gt;.\n  - Ristl R, Ballarini N, Götte H, Schüler A, Posch M, König F (2021). \"Delayed\ntreatment effects, treatment switching and heterogeneous patient populations:\nHow to design and analyze RCTs in oncology.\" _Pharmaceutical statistics_,\n*20*(1), 129-145.\n  - Robinson D, Hayes A, Couch S (2023). _broom: Convert Statistical Objects into\nTidy Tibbles_. R package version 1.0.5,\n&lt;https://CRAN.R-project.org/package=broom&gt;.\n  - Sjoberg D, Baillie M, Fruechtenicht C, Haesendonckx S, Treis T (2023).\n_ggsurvfit: Flexible Time-to-Event Figures_. R package version 1.0.0,\n&lt;https://CRAN.R-project.org/package=ggsurvfit&gt;.\n  - Sjoberg D, Whiting K, Curry M, Lavery J, Larmarange J (2021). \"Reproducible\nSummary Tables with the gtsummary Package.\" _The R Journal_, *13*, 570-580.\ndoi:10.32614/RJ-2021-053 &lt;https://doi.org/10.32614/RJ-2021-053&gt;,\n&lt;https://doi.org/10.32614/RJ-2021-053&gt;.\n  - Thériault R (2023). \"rempsyc: Convenience functions for psychology.\" _Journal\nof Open Source Software_, *8*(87), 5466. doi:10.21105/joss.05466\n&lt;https://doi.org/10.21105/joss.05466&gt;, &lt;https://doi.org/10.21105/joss.05466&gt;.\n  - Therneau T (2023). _A Package for Survival Analysis in R_. R package version\n3.5-7, &lt;https://CRAN.R-project.org/package=survival&gt;. Terry M. Therneau,\nPatricia M. Grambsch (2000). _Modeling Survival Data: Extending the Cox Model_.\nSpringer, New York. ISBN 0-387-98784-3.\n  - Wickham H (2016). _ggplot2: Elegant Graphics for Data Analysis_.\nSpringer-Verlag New York. ISBN 978-3-319-24277-4,\n&lt;https://ggplot2.tidyverse.org&gt;.\n  - Wickham H (2023). _forcats: Tools for Working with Categorical Variables\n(Factors)_. R package version 1.0.0,\n&lt;https://CRAN.R-project.org/package=forcats&gt;.\n  - Wickham H (2023). _stringr: Simple, Consistent Wrappers for Common String\nOperations_. R package version 1.5.1,\n&lt;https://CRAN.R-project.org/package=stringr&gt;.\n  - Wickham H, Averick M, Bryan J, Chang W, McGowan LD, François R, Grolemund G,\nHayes A, Henry L, Hester J, Kuhn M, Pedersen TL, Miller E, Bache SM, Müller K,\nOoms J, Robinson D, Seidel DP, Spinu V, Takahashi K, Vaughan D, Wilke C, Woo K,\nYutani H (2019). \"Welcome to the tidyverse.\" _Journal of Open Source Software_,\n*4*(43), 1686. doi:10.21105/joss.01686 &lt;https://doi.org/10.21105/joss.01686&gt;.\n  - Wickham H, François R, Henry L, Müller K, Vaughan D (2023). _dplyr: A Grammar\nof Data Manipulation_. R package version 1.1.3,\n&lt;https://CRAN.R-project.org/package=dplyr&gt;.\n  - Wickham H, Henry L (2023). _purrr: Functional Programming Tools_. R package\nversion 1.0.2, &lt;https://CRAN.R-project.org/package=purrr&gt;.\n  - Wickham H, Hester J, Bryan J (2023). _readr: Read Rectangular Text Data_. R\npackage version 2.1.4, &lt;https://CRAN.R-project.org/package=readr&gt;.\n  - Wickham H, Vaughan D, Girlich M (2023). _tidyr: Tidy Messy Data_. R package\nversion 1.3.0, &lt;https://CRAN.R-project.org/package=tidyr&gt;.\n  - Zhu H (2021). _kableExtra: Construct Complex Table with 'kable' and Pipe\nSyntax_. R package version 1.3.4,\n&lt;https://CRAN.R-project.org/package=kableExtra&gt;."
  },
  {
    "objectID": "lista_6_1.html#carregando-pacotes",
    "href": "lista_6_1.html#carregando-pacotes",
    "title": "7  Lista 6.1 - Cox tempo dependente",
    "section": "7.1 Carregando pacotes",
    "text": "7.1 Carregando pacotes\n\nlibrary(tidyverse)\nlibrary(flexplot)\nlibrary(foreign)\nlibrary(dplyr)\nlibrary(tm)\nlibrary(ggplot2)\nlibrary(forcats)\nlibrary(rempsyc)\nlibrary(easystats)\nlibrary(kableExtra)\nlibrary(gtsummary)\n\n#Específicos para survival\nlibrary(survival)\nlibrary(ggsurvfit)\nlibrary(survminer)\nlibrary(broom)\nlibrary(survMisc)\nlibrary(PHInfiniteEstimates)\nlibrary(coin)\nlibrary(condSURV)"
  },
  {
    "objectID": "lista_6_1.html#carregando-os-dados-e-modificando-o-tipo-de-variável",
    "href": "lista_6_1.html#carregando-os-dados-e-modificando-o-tipo-de-variável",
    "title": "7  Lista 6.1 - Cox tempo dependente",
    "section": "7.2 Carregando os dados e modificando o tipo de variável",
    "text": "7.2 Carregando os dados e modificando o tipo de variável\nMantendo as boas práticas das análises, logo após carregar os dados em uma variável, vamos verificar os tipos de variávels que temos em nosso banco.\n\noriginal = read.spss(\"Cox tempo dependente 2_1.sav\", to.data.frame=TRUE)\nglimpse(original)\n\nRows: 628\nColumns: 7\n$ ID            &lt;dbl&gt; 112, 91, 113, 150, 22, 139, 104, 590, 189, 171, 338, 492…\n$ age           &lt;dbl&gt; 35, 33, 35, 31, 33, 43, 25, 35, 29, 27, 35, 23, 24, 23, …\n$ race          &lt;fct&gt; branco, branco, branco, branco, branco, branco, branco, …\n$ treat         &lt;dbl&gt; 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1,…\n$ Tempo_dialise &lt;dbl&gt; 51, 67, 88, 156, 12, 139, 90, 25, 187, 34, 29, 78, 63, 8…\n$ time          &lt;dbl&gt; 1172, 762, 734, 720, 659, 658, 655, 654, 634, 630, 621, …\n$ morte         &lt;fct&gt; Não, Não, Não, Não, Não, Não, Não, Não, Não, Não, Não, N…\n\n\nNovamente podemos observar que o evento de interesse (morte) está como um fator. Vamos modificar como já fizemos a lista 6 e também já vamos ajustar a variável “treat” para que ela seja um fator e não um número.\n\ndb &lt;- original %&gt;%\n  mutate(\n    morte = as.integer(morte == \"Sim\"), # para transformar sim e não em 1 e 0, respectivamente\n    treat = as.factor(treat)\n  )\nglimpse(db)\n\nRows: 628\nColumns: 7\n$ ID            &lt;dbl&gt; 112, 91, 113, 150, 22, 139, 104, 590, 189, 171, 338, 492…\n$ age           &lt;dbl&gt; 35, 33, 35, 31, 33, 43, 25, 35, 29, 27, 35, 23, 24, 23, …\n$ race          &lt;fct&gt; branco, branco, branco, branco, branco, branco, branco, …\n$ treat         &lt;fct&gt; 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1,…\n$ Tempo_dialise &lt;dbl&gt; 51, 67, 88, 156, 12, 139, 90, 25, 187, 34, 29, 78, 63, 8…\n$ time          &lt;dbl&gt; 1172, 762, 734, 720, 659, 658, 655, 654, 634, 630, 621, …\n$ morte         &lt;int&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n\n\nFeito! Vamos também verificar se há presença de dados faltantes e em quais variáveis.\n\n# Verificando NAs\nresumo_nas &lt;- db %&gt;%\n  summarise(\n    nas_age = sum(is.na(age)),\n    nas_race = sum(is.na(race)),\n    nas_treat = sum(is.na(treat)),\n    nas_t_dialise = sum(is.na(Tempo_dialise)),\n    nas_time = sum(is.na(time)),\n    nas_morte = sum(is.na(morte)),\n  )\nkable(resumo_nas)\n\n\n\n\nnas_age\nnas_race\nnas_treat\nnas_t_dialise\nnas_time\nnas_morte\n\n\n\n\n5\n6\n0\n0\n0\n0\n\n\n\n\n\n\n\nAté chegar na Cox tempo dependente, vamos repetir basicamente o que já fizemos no Capítulo 6"
  },
  {
    "objectID": "lista_6_1.html#criando-a-estrutura-de-dados",
    "href": "lista_6_1.html#criando-a-estrutura-de-dados",
    "title": "7  Lista 6.1 - Cox tempo dependente",
    "section": "7.3 Criando a estrutura de dados",
    "text": "7.3 Criando a estrutura de dados\n\n# Create a survival object\nsurv_obj &lt;- Surv(time = db$time, event = db$morte)\n\n\nTábua de vida\n\n# Create survival curve\nfit1 &lt;- survfit(surv_obj ~ treat, data = db)\nkable(head(tidy(fit1)))\n\n\n\n\ntime\nn.risk\nn.event\nn.censor\nestimate\nstd.error\nconf.high\nconf.low\nstrata\n\n\n\n\n3\n320\n2\n0\n0.993750\n0.0044333\n1.0000000\n0.9851526\ntreat=0\n\n\n4\n318\n2\n0\n0.987500\n0.0062894\n0.9997483\n0.9754017\ntreat=0\n\n\n5\n316\n1\n0\n0.984375\n0.0070430\n0.9980575\n0.9708801\ntreat=0\n\n\n6\n315\n2\n0\n0.978125\n0.0083599\n0.9942837\n0.9622289\ntreat=0\n\n\n7\n313\n2\n0\n0.971875\n0.0095097\n0.9901593\n0.9539283\ntreat=0\n\n\n8\n311\n1\n0\n0.968750\n0.0100402\n0.9880024\n0.9498728\ntreat=0\n\n\n\n\n\n\n\n\n\nGráfico Kaplan-Meir\n\nkm_plot = survfit2(surv_obj ~ treat, data = db) %&gt;%\n  tidy_survfit() %&gt;%\n  ggplot(aes(x = time, y = estimate,\n             min = conf.low, ymax = conf.low,\n             color = strata, fill = strata)) +\n  geom_step()\nkm_plot\n\n\n\n\nPodemos ajustar as configurações do eixo X para exibir uma escala temporal com intervalos de 50 unidades.\n\n# km_plot2 = fit1 %&gt;%\n#   tidy_survfit() %&gt;%\n#   ggplot(aes(x = time, y = estimate,\n#              min = conf.low, ymax = conf.low,\n#              color = strata, fill = strata)) +\n#   geom_step()\n\nkm_plot2 = fit1 %&gt;%\n  tidy_survfit() %&gt;%\n  ggplot(aes(x = time, y = estimate,\n             min = conf.low, ymax = conf.low,\n             color = strata, fill = strata)) +\n  geom_step() +\n  scale_x_continuous(breaks = seq(0, max(fit1$time), by = 50))\n\n\nkm_plot2\n\n\n\n\n\n\nTabela com Sobrevida em tempos espcíficos.\n\ntbl_survfit_ex3 &lt;-\n  list(\n    survfit(surv_obj ~ 1, db),\n    survfit(surv_obj ~ treat, db)\n  ) %&gt;%\n  tbl_survfit(times = c(100, 600))\ntbl_survfit_ex3\n\n\n\n\n\n  \n    \n    \n      Characteristic\n      Time 100\n      Time 600\n    \n  \n  \n    Overall\n66% (63%, 70%)\n19% (16%, 22%)\n    treat\n\n\n        0\n61% (56%, 66%)\n16% (13%, 21%)\n        1\n72% (67%, 77%)\n21% (17%, 26%)\n  \n  \n  \n\n\n\n\n\n\nLog-rank\n\ncoin::logrank_test(surv_obj ~ treat, data = db, type = \"logrank\" ) # padrão é o log-rank\n\n\n    Asymptotic Two-Sample Logrank Test\n\ndata:  surv_obj by treat (0, 1)\nZ = -2.5984, p-value = 0.009365\nalternative hypothesis: true theta is not equal to 1\n\n\n\n\nGehan-Breslow\n\ncoin::logrank_test(surv_obj ~ treat ,data = db, type = \"Gehan-Breslow\")\n\n\n    Asymptotic Two-Sample Gehan-Breslow Test\n\ndata:  surv_obj by treat (0, 1)\nZ = -3.0713, p-value = 0.002132\nalternative hypothesis: true theta is not equal to 1\n\n\n\n\nTarone-Ware\n\ncoin::logrank_test(surv_obj ~ treat ,data = db, type = \"Tarone-Ware\")\n\n\n    Asymptotic Two-Sample Tarone-Ware Test\n\ndata:  surv_obj by treat (0, 1)\nZ = -2.9622, p-value = 0.003055\nalternative hypothesis: true theta is not equal to 1\n\n\n\n\nPeto-Peto\n\ncoin::logrank_test(surv_obj ~ treat ,data = db, type = \"Peto-Peto\")\n\n\n    Asymptotic Two-Sample Peto-Peto Test\n\ndata:  surv_obj by treat (0, 1)\nZ = -3.0608, p-value = 0.002207\nalternative hypothesis: true theta is not equal to 1"
  },
  {
    "objectID": "lista_6_1.html#cox-regression",
    "href": "lista_6_1.html#cox-regression",
    "title": "7  Lista 6.1 - Cox tempo dependente",
    "section": "7.4 Cox regression",
    "text": "7.4 Cox regression\n\n# Cox regression ======================================================\n# Fit the model\n\ncox_res &lt;- coxph(Surv(time = db$time, event = db$morte) ~ treat, data = db)\n### Para testar todas as variáveis\n#cox_res &lt;- coxph(Surv(time = db$time, event = db$morte2) ~ treat + age + Tempo_dialise, data = db)\n\ntbl_regression(cox_res, exponentiate = TRUE)\n\n\n\n\n\n  \n    \n    \n      Characteristic\n      HR1\n      95% CI1\n      p-value\n    \n  \n  \n    treat\n\n\n\n        0\n—\n—\n\n        1\n0.79\n0.67, 0.94\n0.009\n  \n  \n  \n    \n      1 HR = Hazard Ratio, CI = Confidence Interval\n    \n  \n\n\n\n\n\nVerificando os pressupostos da Cox regression\nRelembrando a análise dos riscos proporcionais com base nos resíduos de Schoenfeld:\n\np-val &lt; 0,05: há evidências contra a pressuposto de riscos proporcionais, os HRs não são constantes ao longo do tempo\nchisq: quanto maior o valor, mais forte a violação dos pressupostos"
  },
  {
    "objectID": "lista_6_1.html#plot-dos-resíduos-de-schoenfeld",
    "href": "lista_6_1.html#plot-dos-resíduos-de-schoenfeld",
    "title": "7  Lista 6.1 - Cox tempo dependente",
    "section": "7.5 Plot dos resíduos de Schoenfeld",
    "text": "7.5 Plot dos resíduos de Schoenfeld\n\n# Plot the Schoenfeld residuals over time for each covariate\nsurvminer::ggcoxzph(cox.zph(cox_res), point.size = 0.1)\n\n\n\n\nSe os resíduos mostrarem um padrão claro ao longo do tempo, isso pode indicar uma violação da suposição de riscos proporcionais.\nAlgumas dicas para ajudar na interpretação:\n\nSem Padrão (Resíduos Constantes): Se os resíduos aparecerem aleatoriamente espalhados em torno de zero, sem nenhuma tendência ou padrão claro, isso sugere que a suposição de riscos proporcionais é razoável.\nTendência Linear: Uma tendência linear (aumentando ou diminuindo) nos resíduos ao longo do tempo pode sugerir uma violação da suposição de riscos proporcionais. Por exemplo, se os resíduos forem consistentemente positivos ou negativos ao longo do tempo, isso indica um efeito dependente do tempo.\nPadrão Não Linear: Se os resíduos exibirem um padrão não linear ou formatos específicos (por exemplo, formato de U, formato de V), isso pode indicar desvios dos riscos proporcionais.\nParalelismo: Paralelismo significa que a propagação e distribuição dos resíduos são relativamente constantes ao longo do tempo. Se os resíduos aumentarem ou diminuirem ao longo do tempo, isso pode sugerir uma violação da suposição.\n\n\nggcoxdiagnostics(cox_res, type = \"dfbeta\", linear.predictions = FALSE)\n\nWarning: `gather_()` was deprecated in tidyr 1.2.0.\nℹ Please use `gather()` instead.\nℹ The deprecated feature was likely used in the survminer package.\n  Please report the issue at &lt;https://github.com/kassambara/survminer/issues&gt;.\n\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n# Não é importante para variáveis categóricas, mas fica o código para eventual consulta.\nggcoxdiagnostics(cox_res, type = \"deviance\", linear.predictions = FALSE)\n\n`geom_smooth()` using formula = 'y ~ x'"
  },
  {
    "objectID": "lista_6_1.html#plots-do-modelo",
    "href": "lista_6_1.html#plots-do-modelo",
    "title": "7  Lista 6.1 - Cox tempo dependente",
    "section": "7.6 Plots do modelo",
    "text": "7.6 Plots do modelo\n\nForest plot\n\n# Forest plots ================================================================\n# Visualise your Cox model results\nggforest(cox_res, data = db)\n\n\n\n\n\n\nGráfico de sobrevida\nAssim como fizemos no exercício anterior, precisamos criar um novo banco de dados para visualizar o gráfico da Regressão de Cox:\n\n# Precisa ser feito apenas com uma variável\ncox_res2 &lt;- coxph(Surv(time = db$time, event = db$morte) ~ treat, data = db)\n\n# Criando o novo banco de dados\nnew_df &lt;- with(db,\n               data.frame(treat = c(\"0\", \"1\"))\n)\n\nE precisamos transformar a variável treat em um fator.\n\nnew_df$treat = as.factor(new_df$treat)\nkable(new_df)\n\n\n\n\ntreat\n\n\n\n\n0\n\n\n1\n\n\n\n\n\n\n\nCriando os dados com base no modelo e plotando o gráfico.\n\nfit_cox &lt;- survfit(cox_res2, newdata = new_df)\n\nJ = ggsurvplot(fit_cox, conf.int = TRUE, legend.labs=c(\"tx=sim\", \"tx=não\"),\n           ggtheme = theme_minimal(),\n           data = db)\n\nJ$plot = J$plot +\n  scale_x_continuous(breaks = seq(0, 900, 20))\n\nScale for x is already present.\nAdding another scale for x, which will replace the existing scale.\n\nJ\n\n\n\n\nReparem na distorção do gráfico em relação à Kaplan-Meir\n\nkm_plot"
  },
  {
    "objectID": "lista_6_1.html#cox-tempo-dependente",
    "href": "lista_6_1.html#cox-tempo-dependente",
    "title": "7  Lista 6.1 - Cox tempo dependente",
    "section": "7.7 Cox tempo-dependente",
    "text": "7.7 Cox tempo-dependente\nJá vimos que os riscos não são proporcionais neste caso. Porém, nem tudo está perdido. Podemos finalmente agora falar da Cox Tempo-dependente.\nO primeiro passo é identificar um possível fator que esteja afetando a proporcionalidade dos riscos no estudo. Pela literatura tempos que o tempo em diálise afeta os riscos entre pessoas que fizeram ou não o transplante de rim. Daí a importância de entender bem o fenômeno que estamos estudando. Como bons pesquisadores, também coletamos o tempo em diálise e esses dados estão no banco de dados\n\nglimpse(db$Tempo_dialise)\n\n num [1:628] 51 67 88 156 12 139 90 25 187 34 ...\n\n\nA variável é numérica e contínua, logo ela já está formatada para continuarmos com a análise.\nNão existe regras escritas na pedra para contornar o problema de não proporcionalidade. Vamos mostrar uma abordagem aqui. Não deixe de ver as referências para outros casos.\n\nCovariáveis tempo dependente\nNo R, há diversas formas de indicar uma variável como tempo-dependente. A escolha do método dependerá da natureza da variável independente e da sua relação teórica com o evento em estudo. A função coxph() oferece a opção de utilizar o argumento tt(), o qual especifica qual variável independente será considerada uma covariável tempo-dependente e como o coeficiente associado a ela deve ser modificado ao longo do tempo.\nO modelo deve seguir a seguinte estrutura\ncoxph(Surv(time, event) ~ covariavel1 + covariavel2 + tt(covariavel2), data, tt=function(x,t,…) x*t)\nPodemos substituir o Surv(time, event) pela variável que salvamos com o objeto survival, surv_obj.\nA função tt (function(x,t,…)___) pode assumir alguns modelos. A seguir trazemos três exemplos mais utilizados em diversas análises:\n\nx*t permitirá que o coeficiente mude linearmente com o tempo\nx*log(t) permite que o coeficiente mude com o log do tempo\nx*(t&gt;tempo) permite que o coeficiente assuma 2 valores diferentes, um valor quando t&lt;=tempo e outro valor t&gt;tempo\n\nVamos gerar vários modelos e avaliá-los comparando os índices de ajuste e os resultados obtidos.\n\n\nSem variável tempo dependente\n\ndialise &lt;- coxph(surv_obj ~ treat + Tempo_dialise, \n                          data=db) # corte no 660\n\nsummary(dialise)\n\nCall:\ncoxph(formula = surv_obj ~ treat + Tempo_dialise, data = db)\n\n  n= 628, number of events= 508 \n\n                    coef  exp(coef)   se(coef)       z            Pr(&gt;|z|)    \ntreat1         0.0618983  1.0638541  0.0899990   0.688               0.492    \nTempo_dialise -0.0084493  0.9915863  0.0007709 -10.960 &lt;0.0000000000000002 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n              exp(coef) exp(-coef) lower .95 upper .95\ntreat1           1.0639      0.940    0.8918    1.2691\nTempo_dialise    0.9916      1.008    0.9901    0.9931\n\nConcordance= 0.75  (se = 0.012 )\nLikelihood ratio test= 151.4  on 2 df,   p=&lt;0.0000000000000002\nWald test            = 121.2  on 2 df,   p=&lt;0.0000000000000002\nScore (logrank) test = 120.6  on 2 df,   p=&lt;0.0000000000000002\n\n\n\n\nMudança linear\n\ndialise_linear &lt;- coxph(surv_obj ~ treat + Tempo_dialise + tt(Tempo_dialise),\n                        data=db,\n                          tt=function(x,t,...) x*t) \nsummary(dialise_linear)\n\nCall:\ncoxph(formula = surv_obj ~ treat + Tempo_dialise + tt(Tempo_dialise), \n    data = db, tt = function(x, t, ...) x * t)\n\n  n= 628, number of events= 508 \n\n                          coef    exp(coef)     se(coef)       z\ntreat1            -0.016001236  0.984126103  0.091676088  -0.175\nTempo_dialise     -0.023777102  0.976503346  0.001506128 -15.787\ntt(Tempo_dialise)  0.000070699  1.000070701  0.000005184  13.637\n                             Pr(&gt;|z|)    \ntreat1                          0.861    \nTempo_dialise     &lt;0.0000000000000002 ***\ntt(Tempo_dialise) &lt;0.0000000000000002 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n                  exp(coef) exp(-coef) lower .95 upper .95\ntreat1               0.9841     1.0161    0.8223    1.1778\nTempo_dialise        0.9765     1.0241    0.9736    0.9794\ntt(Tempo_dialise)    1.0001     0.9999    1.0001    1.0001\n\nConcordance= 0.761  (se = 0.009 )\nLikelihood ratio test= 337.6  on 3 df,   p=&lt;0.0000000000000002\nWald test            = 249.3  on 3 df,   p=&lt;0.0000000000000002\nScore (logrank) test = 229.1  on 3 df,   p=&lt;0.0000000000000002\n\n\n\n\nModelo log\n\ndialise_log &lt;- coxph(surv_obj ~ treat + Tempo_dialise + tt(Tempo_dialise),\n                          data=db,\n                          tt=function(x,t,...) x*log(t)) \n\nsummary(dialise_log)\n\nCall:\ncoxph(formula = surv_obj ~ treat + Tempo_dialise + tt(Tempo_dialise), \n    data = db, tt = function(x, t, ...) x * log(t))\n\n  n= 628, number of events= 508 \n\n                       coef exp(coef)  se(coef)      z            Pr(&gt;|z|)    \ntreat1            -0.071106  0.931363  0.092369  -0.77               0.441    \nTempo_dialise     -0.097417  0.907178  0.005942 -16.40 &lt;0.0000000000000002 ***\ntt(Tempo_dialise)  0.017178  1.017326  0.001087  15.80 &lt;0.0000000000000002 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n                  exp(coef) exp(-coef) lower .95 upper .95\ntreat1               0.9314      1.074    0.7771    1.1162\nTempo_dialise        0.9072      1.102    0.8967    0.9178\ntt(Tempo_dialise)    1.0173      0.983    1.0152    1.0195\n\nConcordance= 0.759  (se = 0.01 )\nLikelihood ratio test= 461.5  on 3 df,   p=&lt;0.0000000000000002\nWald test            = 284.6  on 3 df,   p=&lt;0.0000000000000002\nScore (logrank) test = 223.9  on 3 df,   p=&lt;0.0000000000000002\n\n\n\n\nModelo temporal\n\ndialise_tempo_650 &lt;- coxph(surv_obj ~ treat + Tempo_dialise + tt(Tempo_dialise),\n                          data=db,\n                          tt=function(x,t,...) x*(t&gt;650))\n\nsummary(dialise_tempo_650)\n\nCall:\ncoxph(formula = surv_obj ~ treat + Tempo_dialise + tt(Tempo_dialise), \n    data = db, tt = function(x, t, ...) x * (t &gt; 650))\n\n  n= 628, number of events= 508 \n\n                        coef  exp(coef)   se(coef)       z            Pr(&gt;|z|)\ntreat1             0.0617615  1.0637086  0.0900051   0.686               0.493\nTempo_dialise     -0.0084524  0.9915832  0.0007713 -10.958 &lt;0.0000000000000002\ntt(Tempo_dialise)  0.0028519  1.0028560  0.0221016   0.129               0.897\n                     \ntreat1               \nTempo_dialise     ***\ntt(Tempo_dialise)    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n                  exp(coef) exp(-coef) lower .95 upper .95\ntreat1               1.0637     0.9401    0.8917    1.2689\nTempo_dialise        0.9916     1.0085    0.9901    0.9931\ntt(Tempo_dialise)    1.0029     0.9972    0.9603    1.0473\n\nConcordance= 0.75  (se = 0.01 )\nLikelihood ratio test= 151.5  on 3 df,   p=&lt;0.0000000000000002\nWald test            = 121.2  on 3 df,   p=&lt;0.0000000000000002\nScore (logrank) test = 120.6  on 3 df,   p=&lt;0.0000000000000002\n\n\n\n\nÍndices de aderência (AIC e BIC)\nPodemos comparar os modelos computando os valores de AIC e BIC\n\ncombined_df &lt;- data.frame(\n  Model = c(\"dialise\", \"dialise_linear\", \"dialise_log\", \"dialise_tempo_650\"),\n  AIC = c(AIC(dialise), AIC(dialise_linear), AIC(dialise_log), AIC(dialise_tempo_650)),\n  BIC = c(BIC(dialise), BIC(dialise_linear), BIC(dialise_log), BIC(dialise_tempo_650))\n)\n\nkable(combined_df)\n\n\n\n\nModel\nAIC\nBIC\n\n\n\n\ndialise\n5771.688\n5780.149\n\n\ndialise_linear\n5587.564\n5600.256\n\n\ndialise_log\n5463.651\n5476.343\n\n\ndialise_tempo_650\n5773.672\n5786.363\n\n\n\n\n\n\n\nPor esse critério, temos que o melhor modelo é o log em seguida o linear.\n\n\nResíduos de Schoenfeld\nAgora vamos analisar mais uma vez os resíduos de Schoenfeld, mas agora variando pelo “Tempo em Diálise”.\n\ncox_res_T_Cov &lt;- coxph(Surv(time = db$time, event = db$morte) ~ treat + Tempo_dialise, data = db)  \nggcoxzph(cox.zph(cox_res_T_Cov), var =\"Tempo_dialise\") \n\n\n\n\nPodemos observar que o Beta do tempo em diálise tem um aumento linear conforme maior o tempo. O resultado pode indicar que o efeito do tempo sobre a o tempo em diálise pode ser linear.\n\n\nInterpretando os resultados.\nA interpretação dos coeficientes da Cox Tempo-dependente é diferente das outras regressõs.\nVamos interpretar o valor do modelo com mudança linear.\n\nsummary(dialise_linear)\n\nCall:\ncoxph(formula = surv_obj ~ treat + Tempo_dialise + tt(Tempo_dialise), \n    data = db, tt = function(x, t, ...) x * t)\n\n  n= 628, number of events= 508 \n\n                          coef    exp(coef)     se(coef)       z\ntreat1            -0.016001236  0.984126103  0.091676088  -0.175\nTempo_dialise     -0.023777102  0.976503346  0.001506128 -15.787\ntt(Tempo_dialise)  0.000070699  1.000070701  0.000005184  13.637\n                             Pr(&gt;|z|)    \ntreat1                          0.861    \nTempo_dialise     &lt;0.0000000000000002 ***\ntt(Tempo_dialise) &lt;0.0000000000000002 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n                  exp(coef) exp(-coef) lower .95 upper .95\ntreat1               0.9841     1.0161    0.8223    1.1778\nTempo_dialise        0.9765     1.0241    0.9736    0.9794\ntt(Tempo_dialise)    1.0001     0.9999    1.0001    1.0001\n\nConcordance= 0.761  (se = 0.009 )\nLikelihood ratio test= 337.6  on 3 df,   p=&lt;0.0000000000000002\nWald test            = 249.3  on 3 df,   p=&lt;0.0000000000000002\nScore (logrank) test = 229.1  on 3 df,   p=&lt;0.0000000000000002\n\n\nO coeficiente Tempo_dialise = -0.023, deve ser interpretado como o efeito do tempo de diálise no tempo zero. Já o coeficiente tt(Tempo_dialise) = deve ser interpretado como o a mudança do efeito do tempo em diálise a cada unidade de tempo a mais.\n\n\nObservações SPSS e R\nNa aula prática o modelo não é feito com o Tempo em Diálise fora da variável tempo dependente. Já na aula teórica do curso II de 2023, o modelo é escrito como foi feito aqui no R, levando em conta o Tempo em Diálise como uma variável tempo dependente e também como covariável no modelo."
  },
  {
    "objectID": "lista_6_1.html#covariando-para-idade-e-raça",
    "href": "lista_6_1.html#covariando-para-idade-e-raça",
    "title": "7  Lista 6.1 - Cox tempo dependente",
    "section": "7.8 Covariando para idade e raça",
    "text": "7.8 Covariando para idade e raça\nO conjunto de dados ainda possui duas variáveis que não foram incluídas no modelo: idade e raça. Conforme o procedimento padrão, vamos examinar a natureza dessas variáveis. Começando com a idade.\n\nglimpse(db)\n\nRows: 628\nColumns: 7\n$ ID            &lt;dbl&gt; 112, 91, 113, 150, 22, 139, 104, 590, 189, 171, 338, 492…\n$ age           &lt;dbl&gt; 35, 33, 35, 31, 33, 43, 25, 35, 29, 27, 35, 23, 24, 23, …\n$ race          &lt;fct&gt; branco, branco, branco, branco, branco, branco, branco, …\n$ treat         &lt;fct&gt; 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1,…\n$ Tempo_dialise &lt;dbl&gt; 51, 67, 88, 156, 12, 139, 90, 25, 187, 34, 29, 78, 63, 8…\n$ time          &lt;dbl&gt; 1172, 762, 734, 720, 659, 658, 655, 654, 634, 630, 621, …\n$ morte         &lt;int&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n\n\nÓtimo, idade já está como uma variável numérica e contínua e raça está como um fator. Por fim, vamos verificar qual o nível de referência da variável “race”.\n\nlevels(db$race)\n\n[1] \"branco\"      \"negro/pardo\"\n\n\nO nível “branco” está como referência, logo, os resultados do modelo mostrarão os valores dos coeficientes do nível “negro/pardo” em relação ao nível “branco”.\nVamos ao modelo completo.\n\nModelo completo Cox tempo dependente\n\ncox_full_model &lt;- coxph(surv_obj ~ age + race + treat + Tempo_dialise + tt(Tempo_dialise),\n                        data=db,\n                          tt=function(x,t,...) x*t) \nsummary(cox_full_model)\n\nCall:\ncoxph(formula = surv_obj ~ age + race + treat + Tempo_dialise + \n    tt(Tempo_dialise), data = db, tt = function(x, t, ...) x * \n    t)\n\n  n= 617, number of events= 500 \n   (11 observations deleted due to missingness)\n\n                          coef    exp(coef)     se(coef)       z\nage               -0.005531327  0.994483942  0.007272881  -0.761\nracenegro/pardo   -0.342009991  0.710341107  0.108147939  -3.162\ntreat1             0.042207387  1.043110784  0.093368582   0.452\nTempo_dialise     -0.023671737  0.976606241  0.001511519 -15.661\ntt(Tempo_dialise)  0.000068807  1.000068809  0.000005196  13.242\n                              Pr(&gt;|z|)    \nage                            0.44693    \nracenegro/pardo                0.00156 ** \ntreat1                         0.65123    \nTempo_dialise     &lt; 0.0000000000000002 ***\ntt(Tempo_dialise) &lt; 0.0000000000000002 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n                  exp(coef) exp(-coef) lower .95 upper .95\nage                  0.9945     1.0055    0.9804    1.0088\nracenegro/pardo      0.7103     1.4078    0.5747    0.8781\ntreat1               1.0431     0.9587    0.8687    1.2526\nTempo_dialise        0.9766     1.0240    0.9737    0.9795\ntt(Tempo_dialise)    1.0001     0.9999    1.0001    1.0001\n\nConcordance= 0.765  (se = 0.009 )\nLikelihood ratio test= 343.2  on 5 df,   p=&lt;0.0000000000000002\nWald test            = 259.4  on 5 df,   p=&lt;0.0000000000000002\nScore (logrank) test = 243.3  on 5 df,   p=&lt;0.0000000000000002\n\n\nAgora temos que a raça tem um efeito significativo no modelo. Seguindo o vídeo da aula prática, podemos segmentar o banco de dados para as duas raças que temos no banco de dados.\n\n\nSegmentando o banco de dados por raça\n\ndb_branco = db %&gt;%\n  filter(race == \"branco\")\n\ndb_pardo_negro = db %&gt;% \n  filter(race == \"negro/pardo\")\n\n\n\nKM por raça = Branco\n\n# Criando um novo objeto Surv\nsurv_obj_branco &lt;- Surv(time = db_branco$time, event = db_branco$morte)\n\nfit_br = survfit(surv_obj_branco ~ treat, data = db_branco)\nggsurvfit(fit_br)\n\n\n\nggsurvfit(fit_br, linewidth = 1) +\n  labs(x = 'Dias', y = 'Overall survival') +\n  add_confidence_interval() +\n # add_risktable() +\n  scale_ggsurvfit() + \n  biostatsquid_theme #+  coord_cartesian(xlim = c(0, 8))\n\n\n\n\n\n\nModelo completo para brancos\n\n# Escrevendo o modelo\n\ncox_full_model_branco &lt;- coxph(surv_obj_branco ~ age + treat + Tempo_dialise + tt(Tempo_dialise),\n                        data=db_branco,\n                          tt=function(x,t,...) x*t) \n\nsummary(cox_full_model_branco)\n\nCall:\ncoxph(formula = surv_obj_branco ~ age + treat + Tempo_dialise + \n    tt(Tempo_dialise), data = db_branco, tt = function(x, t, \n    ...) x * t)\n\n  n= 464, number of events= 385 \n   (3 observations deleted due to missingness)\n\n                          coef    exp(coef)     se(coef)      z\nage               -0.000811624  0.999188705  0.008137628  -0.10\ntreat1             0.028995294  1.029419750  0.107276897   0.27\nTempo_dialise     -0.024166842  0.976122838  0.001707544 -14.15\ntt(Tempo_dialise)  0.000070240  1.000070242  0.000005841  12.03\n                             Pr(&gt;|z|)    \nage                             0.921    \ntreat1                          0.787    \nTempo_dialise     &lt;0.0000000000000002 ***\ntt(Tempo_dialise) &lt;0.0000000000000002 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n                  exp(coef) exp(-coef) lower .95 upper .95\nage                  0.9992     1.0008    0.9834    1.0153\ntreat1               1.0294     0.9714    0.8342    1.2703\nTempo_dialise        0.9761     1.0245    0.9729    0.9794\ntt(Tempo_dialise)    1.0001     0.9999    1.0001    1.0001\n\nConcordance= 0.78  (se = 0.01 )\nLikelihood ratio test= 286.5  on 4 df,   p=&lt;0.0000000000000002\nWald test            = 201.8  on 4 df,   p=&lt;0.0000000000000002\nScore (logrank) test = 185.6  on 4 df,   p=&lt;0.0000000000000002\n\n\n\n\nKM por raça = negro/pardo\n\n# Criando um novo objeto Surv\n\nsurv_obj_pardo_negro&lt;- Surv(time = db_pardo_negro$time, event = db_pardo_negro$morte)\n\nfit_pn = survfit(surv_obj_pardo_negro ~ treat, data = db_pardo_negro)\n\nggsurvfit(fit_pn, linewidth = 1) +\n  labs(x = 'Dias', y = 'Overall survival') +\n  add_confidence_interval() +\n # add_risktable() +\n  scale_ggsurvfit() + \n  biostatsquid_theme #+  coord_cartesian(xlim = c(0, 8))\n\n\n\n\n\n\nModelo completo para pardo/negro\n\n# Escrevendo o modelo\n\ncox_full_model_pardo_negro &lt;- coxph(surv_obj_pardo_negro ~ age + treat + Tempo_dialise + tt(Tempo_dialise),\n                        data=db_pardo_negro,\n                          tt=function(x,t,...) x*t) \n\nsummary(cox_full_model_pardo_negro)\n\nCall:\ncoxph(formula = surv_obj_pardo_negro ~ age + treat + Tempo_dialise + \n    tt(Tempo_dialise), data = db_pardo_negro, tt = function(x, \n    t, ...) x * t)\n\n  n= 153, number of events= 115 \n   (2 observations deleted due to missingness)\n\n                         coef   exp(coef)    se(coef)      z      Pr(&gt;|z|)    \nage               -0.02336224  0.97690855  0.01673857 -1.396         0.163    \ntreat1             0.07806397  1.08119182  0.19431411  0.402         0.688    \nTempo_dialise     -0.02367178  0.97660620  0.00397339 -5.958 0.00000000256 ***\ntt(Tempo_dialise)  0.00007639  1.00007639  0.00001784  4.282 0.00001853157 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n                  exp(coef) exp(-coef) lower .95 upper .95\nage                  0.9769     1.0236    0.9454    1.0095\ntreat1               1.0812     0.9249    0.7388    1.5824\nTempo_dialise        0.9766     1.0240    0.9690    0.9842\ntt(Tempo_dialise)    1.0001     0.9999    1.0000    1.0001\n\nConcordance= 0.696  (se = 0.025 )\nLikelihood ratio test= 48.53  on 4 df,   p=0.0000000007\nWald test            = 39.77  on 4 df,   p=0.00000005\nScore (logrank) test = 42.56  on 4 df,   p=0.00000001"
  },
  {
    "objectID": "lista_6_1.html#lista-6.1-resolvida-no-spss",
    "href": "lista_6_1.html#lista-6.1-resolvida-no-spss",
    "title": "7  Lista 6.1 - Cox tempo dependente",
    "section": "7.9 Lista 6.1 resolvida no SPSS",
    "text": "7.9 Lista 6.1 resolvida no SPSS"
  },
  {
    "objectID": "lista_6_1.html#extras",
    "href": "lista_6_1.html#extras",
    "title": "7  Lista 6.1 - Cox tempo dependente",
    "section": "7.10 Extras",
    "text": "7.10 Extras\n\nMais gráficos\nE utilizar nosso tema para personalizar e padronizar.\n\nfit2_km &lt;- ggsurvfit(fit1, linewidth = 1) +\n  labs(x = 'Dias', y = 'Porcentagem de sobrevida') +\n  add_confidence_interval() +\n # add_risktable() +\n  scale_ggsurvfit() + \n  biostatsquid_theme #+  coord_cartesian(xlim = c(0, 8))\n\nfit2_km\n\n\n\n\nCuidado com o p-value do gráfico a seguir, ele se refere apenas ao Log-rank\n\nggsurvplot(fit1, data = db,\n           size = 1,\n           palette = c('#E7B800', '#2e9fdf'),\n           censor.shape = '|', censor.size = 4,\n           conf.int = TRUE,\n           pval = TRUE, # CUIDADO, apenas log-rank\n          # risk.table = TRUE,\n         #  risk.table.col = 'strata',\n           legend.labs = list('0' = 'Transplante = sim', '1' = 'Transplante = não'),\n           risk.table.height = 0.25,\n           ggtheme = theme_bw())\n\n\n\n\n\n\nCox tempo dependente log\n\ncox_full_model_2 &lt;- coxph(surv_obj ~ age + race + treat + Tempo_dialise + tt(Tempo_dialise),\n                        data=db,\n                          tt=function(x,t,...) x*log(t)) \nsummary(cox_full_model_2)\n\nCall:\ncoxph(formula = surv_obj ~ age + race + treat + Tempo_dialise + \n    tt(Tempo_dialise), data = db, tt = function(x, t, ...) x * \n    log(t))\n\n  n= 617, number of events= 500 \n   (11 observations deleted due to missingness)\n\n                       coef exp(coef)  se(coef)       z             Pr(&gt;|z|)\nage               -0.005656  0.994360  0.007318  -0.773              0.43960\nracenegro/pardo   -0.296846  0.743159  0.108704  -2.731              0.00632\ntreat1            -0.007682  0.992348  0.094183  -0.082              0.93499\nTempo_dialise     -0.096272  0.908217  0.005996 -16.056 &lt; 0.0000000000000002\ntt(Tempo_dialise)  0.016885  1.017028  0.001098  15.383 &lt; 0.0000000000000002\n                     \nage                  \nracenegro/pardo   ** \ntreat1               \nTempo_dialise     ***\ntt(Tempo_dialise) ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n                  exp(coef) exp(-coef) lower .95 upper .95\nage                  0.9944     1.0057    0.9802    1.0087\nracenegro/pardo      0.7432     1.3456    0.6006    0.9196\ntreat1               0.9923     1.0077    0.8251    1.1935\nTempo_dialise        0.9082     1.1011    0.8976    0.9190\ntt(Tempo_dialise)    1.0170     0.9833    1.0148    1.0192\n\nConcordance= 0.764  (se = 0.009 )\nLikelihood ratio test= 459.7  on 5 df,   p=&lt;0.0000000000000002\nWald test            = 290.9  on 5 df,   p=&lt;0.0000000000000002\nScore (logrank) test = 237.8  on 5 df,   p=&lt;0.0000000000000002\n\nAIC(cox_full_model_2)\n\n[1] 5356.724"
  },
  {
    "objectID": "lista_6_1.html#referencias",
    "href": "lista_6_1.html#referencias",
    "title": "7  Lista 6.1 - Cox tempo dependente",
    "section": "7.11 Referencias",
    "text": "7.11 Referencias\nhttps://stats.oarc.ucla.edu/wp-content/uploads/2022/05/survival_r.html#(48)\nhttps://www.youtube.com/watch?v=Y_83HXuHMdc\nhttps://youtu.be/Y_83HXuHMdc?t=9151"
  },
  {
    "objectID": "lista_6_1.html#códigos-não-utilizados",
    "href": "lista_6_1.html#códigos-não-utilizados",
    "title": "7  Lista 6.1 - Cox tempo dependente",
    "section": "7.12 Códigos não utilizados",
    "text": "7.12 Códigos não utilizados\n\n# Ajustando o banco de dados\n\ndb3 = db\n\n\n# db3$time = pmax(0.5, db3$time - 0) caso eu tenha zeros no tempo de morte\n# db3$time660 = as.integer(db3$time660)\n# head(db3)\n\n# db3$time660 = as.integer(db3$time660)\n\ndb3 &lt;- tmerge(\n  data1 = db3,\n  data2 = db3,\n  id = ID,\n # death = event(T1, delta1), caso tenha dois eventos de morte independentes. Duas doenças diferentes, por exemplo\n  death = event(time, morte),\n  T_Cov = tdc(Tempo_dialise) # indicando a covariavel tempo-dependente\n)\n\nhead(db3)\n\n   ID age   race treat Tempo_dialise time morte tstart tstop death T_Cov\n1 112  35 branco     1            51 1172     0      0    51     0     0\n2 112  35 branco     1            51 1172     0     51  1172     0     1\n3  91  33 branco     0            67  762     0      0    67     0     0\n4  91  33 branco     0            67  762     0     67   762     0     1\n5 113  35 branco     0            88  734     0      0    88     0     0\n6 113  35 branco     0            88  734     0     88   734     0     1\n\n\n\n# Duvida para Altay - colocar o evento como morte2 ou death\ncox_model_T_Cov &lt;- coxph(Surv(time = tstart, time2 = tstop, event = morte) ~ treat + T_Cov, data = db3)\n\nsummary(cox_model_T_Cov)\n\nCall:\ncoxph(formula = Surv(time = tstart, time2 = tstop, event = morte) ~ \n    treat + T_Cov, data = db3)\n\n  n= 1174, number of events= 934 \n\n           coef exp(coef) se(coef)      z Pr(&gt;|z|)   \ntreat1 -0.17205   0.84194  0.06668 -2.580  0.00987 **\nT_Cov   0.03829   1.03903  0.08493  0.451  0.65210   \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n       exp(coef) exp(-coef) lower .95 upper .95\ntreat1    0.8419     1.1877    0.7388    0.9595\nT_Cov     1.0390     0.9624    0.8797    1.2272\n\nConcordance= 0.539  (se = 0.01 )\nLikelihood ratio test= 7.53  on 2 df,   p=0.02\nWald test            = 7.53  on 2 df,   p=0.02\nScore (logrank) test = 7.54  on 2 df,   p=0.02\n\ndb3 %&gt;% \n  coxph(Surv(time = tstart, time2 = tstop, event = death) ~ treat + age + race + T_Cov, data = .) %&gt;% \n  gtsummary::tbl_regression(exp = TRUE)\n\n\n\n\n\n  \n    \n    \n      Characteristic\n      HR1\n      95% CI1\n      p-value\n    \n  \n  \n    treat\n\n\n\n        0\n—\n—\n\n        1\n1.05\n0.88, 1.25\n0.6\n    age\n1.00\n0.98, 1.01\n0.5\n    race\n\n\n\n        branco\n—\n—\n\n        negro/pardo\n0.68\n0.55, 0.84\n&lt;0.001\n    T_Cov\n13.6\n10.1, 18.4\n&lt;0.001\n  \n  \n  \n    \n      1 HR = Hazard Ratio, CI = Confidence Interval\n    \n  \n\n\n\n\n\nTempo em diálise como covariante tempo-dependente\n\n# Ajustando o banco de dados\n\ndb2 = db\n\n\n#db2$time = pmax(0.5, db2$time - 0)\n\n\ndb2 &lt;- tmerge(\n  data1 = db,\n  data2 = db,\n  id = ID,\n # death = event(T1, delta1), caso tenha dois eventos de morte independentes. Duas doenças diferentes, por exemplo\n  death = event(time, morte),\n  T_Tempo_dialise = tdc(Tempo_dialise) # indicando a covariavel tempo-dependente\n)\nhead(db2)\n\n   ID age   race treat Tempo_dialise time morte tstart tstop death\n1 112  35 branco     1            51 1172     0      0    51     0\n2 112  35 branco     1            51 1172     0     51  1172     0\n3  91  33 branco     0            67  762     0      0    67     0\n4  91  33 branco     0            67  762     0     67   762     0\n5 113  35 branco     0            88  734     0      0    88     0\n6 113  35 branco     0            88  734     0     88   734     0\n  T_Tempo_dialise\n1               0\n2               1\n3               0\n4               1\n5               0\n6               1\n\n\n\ncox_model_time_dependent &lt;- coxph(Surv(time = tstart, time2 = tstop, event = death) ~ T_Tempo_dialise + treat, data = db2)\n\nsummary(cox_model_time_dependent)\n\nCall:\ncoxph(formula = Surv(time = tstart, time2 = tstop, event = death) ~ \n    T_Tempo_dialise + treat, data = db2)\n\n  n= 1174, number of events= 508 \n\n                     coef exp(coef)  se(coef)      z            Pr(&gt;|z|)    \nT_Tempo_dialise  2.585761 13.273384  0.150925 17.133 &lt;0.0000000000000002 ***\ntreat1          -0.003201  0.996804  0.089471 -0.036               0.971    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n                exp(coef) exp(-coef) lower .95 upper .95\nT_Tempo_dialise   13.2734    0.07534    9.8745    17.842\ntreat1             0.9968    1.00321    0.8365     1.188\n\nConcordance= 0.699  (se = 0.014 )\nLikelihood ratio test= 382.7  on 2 df,   p=&lt;0.0000000000000002\nWald test            = 294.6  on 2 df,   p=&lt;0.0000000000000002\nScore (logrank) test = 354.7  on 2 df,   p=&lt;0.0000000000000002\n\ndb2 %&gt;% \n  coxph(Surv(time = tstart, time2 = tstop, event = death) ~ T_Tempo_dialise * treat, data = .) %&gt;% \n  gtsummary::tbl_regression(exp = TRUE)\n\n\n\n\n\n  \n    \n    \n      Characteristic\n      HR1\n      95% CI1\n      p-value\n    \n  \n  \n    T_Tempo_dialise\n9.78\n6.78, 14.1\n&lt;0.001\n    treat\n\n\n\n        0\n—\n—\n\n        1\n0.59\n0.38, 0.92\n0.020\n    T_Tempo_dialise * treat\n\n\n\n        T_Tempo_dialise * 1\n1.86\n1.15, 3.02\n0.012\n  \n  \n  \n    \n      1 HR = Hazard Ratio, CI = Confidence Interval"
  },
  {
    "objectID": "lista_6_1.html#versões-dos-pacotes",
    "href": "lista_6_1.html#versões-dos-pacotes",
    "title": "7  Lista 6.1 - Cox tempo dependente",
    "section": "7.13 Versões dos pacotes",
    "text": "7.13 Versões dos pacotes\n\nreport(sessionInfo())\n\nAnalyses were conducted using the R Statistical language (version 4.3.1; R Core\nTeam, 2023) on Windows 11 x64 (build 22621), using the packages effectsize\n(version 0.8.6; Ben-Shachar MS et al., 2020), lpSolve (version 5.6.19;\nBerkelaar M, others, 2023), survMisc (version 0.5.6; Dardis C, 2022), tm\n(version 0.7.11; Feinerer I, Hornik K, 2023), flexplot (version 0.20.5; Fife D,\n2024), lubridate (version 1.9.3; Grolemund G, Wickham H, 2011), coxphf (version\n1.13.4; Heinze G et al., 2023), NLP (version 0.2.1; Hornik K, 2020), coin\n(version 1.4.3; Hothorn T et al., 2006), ggpubr (version 0.6.0; Kassambara A,\n2023), survminer (version 0.4.9; Kassambara A et al., 2021),\nPHInfiniteEstimates (version 2.9.5; Kolassa JE, Zhang J, 2023), parameters\n(version 0.21.3; Lüdecke D et al., 2020), performance (version 0.10.8; Lüdecke\nD et al., 2021), easystats (version 0.6.0; Lüdecke D et al., 2022), see\n(version 0.8.1; Lüdecke D et al., 2021), insight (version 0.19.6; Lüdecke D et\nal., 2019), bayestestR (version 0.13.1; Makowski D et al., 2019), modelbased\n(version 0.8.6; Makowski D et al., 2020), report (version 0.5.7; Makowski D et\nal., 2023), correlation (version 0.8.4; Makowski D et al., 2022), condSURV\n(version 2.0.4; Meira-Machado L, Sestelo M, 2023), tibble (version 3.2.1;\nMüller K, Wickham H, 2023), datawizard (version 0.9.0; Patil I et al., 2022),\nforeign (version 0.8.85; R Core Team, 2023), nph (version 2.1; Ristl R et al.,\n2021), broom (version 1.0.5; Robinson D et al., 2023), ggsurvfit (version\n1.0.0; Sjoberg D et al., 2023), gtsummary (version 1.7.2; Sjoberg D et al.,\n2021), rempsyc (version 0.1.6; Thériault R, 2023), survival (version 3.5.7;\nTherneau T, 2023), ggplot2 (version 3.4.4; Wickham H, 2016), forcats (version\n1.0.0; Wickham H, 2023), stringr (version 1.5.1; Wickham H, 2023), tidyverse\n(version 2.0.0; Wickham H et al., 2019), dplyr (version 1.1.3; Wickham H et\nal., 2023), purrr (version 1.0.2; Wickham H, Henry L, 2023), readr (version\n2.1.4; Wickham H et al., 2023), tidyr (version 1.3.0; Wickham H et al., 2023)\nand kableExtra (version 1.3.4; Zhu H, 2021).\n\nReferences\n----------\n  - Ben-Shachar MS, Lüdecke D, Makowski D (2020). \"effectsize: Estimation of\nEffect Size Indices and Standardized Parameters.\" _Journal of Open Source\nSoftware_, *5*(56), 2815. doi:10.21105/joss.02815\n&lt;https://doi.org/10.21105/joss.02815&gt;, &lt;https://doi.org/10.21105/joss.02815&gt;.\n  - Berkelaar M, others (2023). _lpSolve: Interface to 'Lp_solve' v. 5.5 to Solve\nLinear/Integer Programs_. R package version 5.6.19,\n&lt;https://CRAN.R-project.org/package=lpSolve&gt;.\n  - Dardis C (2022). _survMisc: Miscellaneous Functions for Survival Data_. R\npackage version 0.5.6, &lt;https://CRAN.R-project.org/package=survMisc&gt;.\n  - Feinerer I, Hornik K (2023). _tm: Text Mining Package_. R package version\n0.7-11, &lt;https://CRAN.R-project.org/package=tm&gt;. Feinerer I, Hornik K, Meyer D\n(2008). \"Text Mining Infrastructure in R.\" _Journal of Statistical Software_,\n*25*(5), 1-54. doi:10.18637/jss.v025.i05\n&lt;https://doi.org/10.18637/jss.v025.i05&gt;.\n  - Fife D (2024). _flexplot: Graphically Based Data Analysis Using 'flexplot'_.\nR package version 0.20.5.\n  - Grolemund G, Wickham H (2011). \"Dates and Times Made Easy with lubridate.\"\n_Journal of Statistical Software_, *40*(3), 1-25.\n&lt;https://www.jstatsoft.org/v40/i03/&gt;.\n  - Heinze G, Ploner M, Jiricka L, Steiner G (2023). _coxphf: Cox Regression with\nFirth's Penalized Likelihood_. R package version 1.13.4,\n&lt;https://CRAN.R-project.org/package=coxphf&gt;.\n  - Hornik K (2020). _NLP: Natural Language Processing Infrastructure_. R package\nversion 0.2-1, &lt;https://CRAN.R-project.org/package=NLP&gt;.\n  - Hothorn T, Hornik K, van de Wiel MA, Zeileis A (2006). \"A Lego system for\nconditional inference.\" _The American Statistician_, *60*(3), 257-263.\ndoi:10.1198/000313006X118430 &lt;https://doi.org/10.1198/000313006X118430&gt;.\nHothorn T, Hornik K, van de Wiel MA, Zeileis A (2008). \"Implementing a class of\npermutation tests: The coin package.\" _Journal of Statistical Software_,\n*28*(8), 1-23. doi:10.18637/jss.v028.i08\n&lt;https://doi.org/10.18637/jss.v028.i08&gt;.\n  - Kassambara A (2023). _ggpubr: 'ggplot2' Based Publication Ready Plots_. R\npackage version 0.6.0, &lt;https://CRAN.R-project.org/package=ggpubr&gt;.\n  - Kassambara A, Kosinski M, Biecek P (2021). _survminer: Drawing Survival\nCurves using 'ggplot2'_. R package version 0.4.9,\n&lt;https://CRAN.R-project.org/package=survminer&gt;.\n  - Kolassa JE, Zhang J (2023). _PHInfiniteEstimates: Tools for Inference in the\nPresence of a Monotone Likelihood_. R package version 2.9.5,\n&lt;https://CRAN.R-project.org/package=PHInfiniteEstimates&gt;.\n  - Lüdecke D, Ben-Shachar M, Patil I, Makowski D (2020). \"Extracting, Computing\nand Exploring the Parameters of Statistical Models using R.\" _Journal of Open\nSource Software_, *5*(53), 2445. doi:10.21105/joss.02445\n&lt;https://doi.org/10.21105/joss.02445&gt;.\n  - Lüdecke D, Ben-Shachar M, Patil I, Waggoner P, Makowski D (2021).\n\"performance: An R Package for Assessment, Comparison and Testing of\nStatistical Models.\" _Journal of Open Source Software_, *6*(60), 3139.\ndoi:10.21105/joss.03139 &lt;https://doi.org/10.21105/joss.03139&gt;.\n  - Lüdecke D, Ben-Shachar M, Patil I, Wiernik B, Makowski D (2022). \"easystats:\nFramework for Easy Statistical Modeling, Visualization, and Reporting.\" _CRAN_.\nR package, &lt;https://easystats.github.io/easystats/&gt;.\n  - Lüdecke D, Patil I, Ben-Shachar M, Wiernik B, Waggoner P, Makowski D (2021).\n\"see: An R Package for Visualizing Statistical Models.\" _Journal of Open Source\nSoftware_, *6*(64), 3393. doi:10.21105/joss.03393\n&lt;https://doi.org/10.21105/joss.03393&gt;.\n  - Lüdecke D, Waggoner P, Makowski D (2019). \"insight: A Unified Interface to\nAccess Information from Model Objects in R.\" _Journal of Open Source Software_,\n*4*(38), 1412. doi:10.21105/joss.01412 &lt;https://doi.org/10.21105/joss.01412&gt;.\n  - Makowski D, Ben-Shachar M, Lüdecke D (2019). \"bayestestR: Describing Effects\nand their Uncertainty, Existence and Significance within the Bayesian\nFramework.\" _Journal of Open Source Software_, *4*(40), 1541.\ndoi:10.21105/joss.01541 &lt;https://doi.org/10.21105/joss.01541&gt;,\n&lt;https://joss.theoj.org/papers/10.21105/joss.01541&gt;.\n  - Makowski D, Ben-Shachar M, Patil I, Lüdecke D (2020). \"Estimation of\nModel-Based Predictions, Contrasts and Means.\" _CRAN_.\n&lt;https://github.com/easystats/modelbased&gt;.\n  - Makowski D, Lüdecke D, Patil I, Thériault R, Ben-Shachar M, Wiernik B (2023).\n\"Automated Results Reporting as a Practical Tool to Improve Reproducibility and\nMethodological Best Practices Adoption.\" _CRAN_.\n&lt;https://easystats.github.io/report/&gt;.\n  - Makowski D, Wiernik B, Patil I, Lüdecke D, Ben-Shachar M (2022).\n\"correlation: Methods for Correlation Analysis.\" Version 0.8.3,\n&lt;https://CRAN.R-project.org/package=correlation&gt;. Makowski D, Ben-Shachar M,\nPatil I, Lüdecke D (2020). \"Methods and Algorithms for Correlation Analysis in\nR.\" _Journal of Open Source Software_, *5*(51), 2306. doi:10.21105/joss.02306\n&lt;https://doi.org/10.21105/joss.02306&gt;,\n&lt;https://joss.theoj.org/papers/10.21105/joss.02306&gt;.\n  - Meira-Machado L, Sestelo M (2023). _condSURV: Estimation of the Conditional\nSurvival Function for Ordered Multivariate Failure Time Data_. R package\nversion 2.0.4, &lt;https://CRAN.R-project.org/package=condSURV&gt;.\n  - Müller K, Wickham H (2023). _tibble: Simple Data Frames_. R package version\n3.2.1, &lt;https://CRAN.R-project.org/package=tibble&gt;.\n  - Patil I, Makowski D, Ben-Shachar M, Wiernik B, Bacher E, Lüdecke D (2022).\n\"datawizard: An R Package for Easy Data Preparation and Statistical\nTransformations.\" _Journal of Open Source Software_, *7*(78), 4684.\ndoi:10.21105/joss.04684 &lt;https://doi.org/10.21105/joss.04684&gt;.\n  - R Core Team (2023). _foreign: Read Data Stored by 'Minitab', 'S', 'SAS',\n'SPSS', 'Stata', 'Systat', 'Weka', 'dBase', ..._. R package version 0.8-85,\n&lt;https://CRAN.R-project.org/package=foreign&gt;.\n  - R Core Team (2023). _R: A Language and Environment for Statistical\nComputing_. R Foundation for Statistical Computing, Vienna, Austria.\n&lt;https://www.R-project.org/&gt;.\n  - Ristl R, Ballarini N, Götte H, Schüler A, Posch M, König F (2021). \"Delayed\ntreatment effects, treatment switching and heterogeneous patient populations:\nHow to design and analyze RCTs in oncology.\" _Pharmaceutical statistics_,\n*20*(1), 129-145.\n  - Robinson D, Hayes A, Couch S (2023). _broom: Convert Statistical Objects into\nTidy Tibbles_. R package version 1.0.5,\n&lt;https://CRAN.R-project.org/package=broom&gt;.\n  - Sjoberg D, Baillie M, Fruechtenicht C, Haesendonckx S, Treis T (2023).\n_ggsurvfit: Flexible Time-to-Event Figures_. R package version 1.0.0,\n&lt;https://CRAN.R-project.org/package=ggsurvfit&gt;.\n  - Sjoberg D, Whiting K, Curry M, Lavery J, Larmarange J (2021). \"Reproducible\nSummary Tables with the gtsummary Package.\" _The R Journal_, *13*, 570-580.\ndoi:10.32614/RJ-2021-053 &lt;https://doi.org/10.32614/RJ-2021-053&gt;,\n&lt;https://doi.org/10.32614/RJ-2021-053&gt;.\n  - Thériault R (2023). \"rempsyc: Convenience functions for psychology.\" _Journal\nof Open Source Software_, *8*(87), 5466. doi:10.21105/joss.05466\n&lt;https://doi.org/10.21105/joss.05466&gt;, &lt;https://doi.org/10.21105/joss.05466&gt;.\n  - Therneau T (2023). _A Package for Survival Analysis in R_. R package version\n3.5-7, &lt;https://CRAN.R-project.org/package=survival&gt;. Terry M. Therneau,\nPatricia M. Grambsch (2000). _Modeling Survival Data: Extending the Cox Model_.\nSpringer, New York. ISBN 0-387-98784-3.\n  - Wickham H (2016). _ggplot2: Elegant Graphics for Data Analysis_.\nSpringer-Verlag New York. ISBN 978-3-319-24277-4,\n&lt;https://ggplot2.tidyverse.org&gt;.\n  - Wickham H (2023). _forcats: Tools for Working with Categorical Variables\n(Factors)_. R package version 1.0.0,\n&lt;https://CRAN.R-project.org/package=forcats&gt;.\n  - Wickham H (2023). _stringr: Simple, Consistent Wrappers for Common String\nOperations_. R package version 1.5.1,\n&lt;https://CRAN.R-project.org/package=stringr&gt;.\n  - Wickham H, Averick M, Bryan J, Chang W, McGowan LD, François R, Grolemund G,\nHayes A, Henry L, Hester J, Kuhn M, Pedersen TL, Miller E, Bache SM, Müller K,\nOoms J, Robinson D, Seidel DP, Spinu V, Takahashi K, Vaughan D, Wilke C, Woo K,\nYutani H (2019). \"Welcome to the tidyverse.\" _Journal of Open Source Software_,\n*4*(43), 1686. doi:10.21105/joss.01686 &lt;https://doi.org/10.21105/joss.01686&gt;.\n  - Wickham H, François R, Henry L, Müller K, Vaughan D (2023). _dplyr: A Grammar\nof Data Manipulation_. R package version 1.1.3,\n&lt;https://CRAN.R-project.org/package=dplyr&gt;.\n  - Wickham H, Henry L (2023). _purrr: Functional Programming Tools_. R package\nversion 1.0.2, &lt;https://CRAN.R-project.org/package=purrr&gt;.\n  - Wickham H, Hester J, Bryan J (2023). _readr: Read Rectangular Text Data_. R\npackage version 2.1.4, &lt;https://CRAN.R-project.org/package=readr&gt;.\n  - Wickham H, Vaughan D, Girlich M (2023). _tidyr: Tidy Messy Data_. R package\nversion 1.3.0, &lt;https://CRAN.R-project.org/package=tidyr&gt;.\n  - Zhu H (2021). _kableExtra: Construct Complex Table with 'kable' and Pipe\nSyntax_. R package version 1.3.4,\n&lt;https://CRAN.R-project.org/package=kableExtra&gt;."
  },
  {
    "objectID": "ARIMA.html#fundamentos-do-arima",
    "href": "ARIMA.html#fundamentos-do-arima",
    "title": "ARIMA",
    "section": "Fundamentos do ARIMA:",
    "text": "Fundamentos do ARIMA:\nAutoRegressivo (AR): Refere-se à relação entre uma observação atual e suas observações passadas. O termo “AutoRegressivo” destaca a dependência linear de uma observação em relação a suas antecessoras.\nIntegrated (I): Indica o número de diferenciações necessárias para tornar a série temporal estacionária, ou seja, para remover tendências e padrões sistemáticos. A estacionarização é crucial para garantir a estabilidade do modelo.\nMédia Móvel (MA): Considera os erros residuais das observações anteriores para prever a próxima. O componente “Média Móvel” reflete a média dos erros anteriores, incorporando informações sobre o comportamento recente da série.\nNúmero de observações: O número ideal de observações repetidas para uma única unidade de análise é de pelo menos 40, sendo preferível alcançar 50 observações. Não é necessário ter um grande número de pessoas ou unidades de análise; até mesmo com N = 1, você pode obter várias observações do mesmo indivíduo, tornando o ARIMA uma ferramenta eficaz de análise."
  },
  {
    "objectID": "ARIMA.html#condições-e-pressupostos",
    "href": "ARIMA.html#condições-e-pressupostos",
    "title": "ARIMA",
    "section": "Condições e Pressupostos:",
    "text": "Condições e Pressupostos:\nEstacionariedade: O ARIMA assume que a série temporal seja estacionária, o que significa que a média, a variância e a estrutura de autocorrelação não devem variar significativamente ao longo do tempo. Se a série não for estacionária, é necessário aplicar diferenciação até atingir a estacionariedade.\nIdentificação de Ordem: A escolha adequada dos parâmetros p, d, e q (ordens AR, I, e MA) é crucial. Isso geralmente é feito por meio de análise visual, funções de autocorrelação (ACF) e autocorrelação parcial (PACF), bem como métodos estatísticos como o critério de informação de Akaike (AIC).\nRuído Branco: Os resíduos do modelo ARIMA devem se comportar como um “ruído branco”, ou seja, serem independentes, terem média zero e variância constante. Isso garante que não haja padrões significativos nos erros residuais não capturados pelo modelo.\nAlém dos componentes fundamentais, o ARIMA pode ser estendido para lidar com sazonalidade através do SARIMA (Seasonal ARIMA), que incorpora parâmetros adicionais para modelar padrões recorrentes em determinados intervalos de tempo.\nA adequada compreensão dos fundamentos, condições e pressupostos é essencial para explorar todo o potencial desse método e fazer previsões precisas em uma variedade de contextos."
  },
  {
    "objectID": "ARIMA.html#passo-a-passo-da-arima",
    "href": "ARIMA.html#passo-a-passo-da-arima",
    "title": "ARIMA",
    "section": "Passo a Passo da ARIMA",
    "text": "Passo a Passo da ARIMA\n\nColeta e Exploração de Dados:\n\nInicie coletando dados temporais relevantes para sua análise.\nExplore graficamente a série temporal para identificar padrões, sazonalidades e tendências.\n\nEstacionarização da Série:\n\nDiferencie a série temporal para torná-la estacionária.\nUtilize gráficos, como sequence charts, para visualizar mudanças ao longo do tempo.\n\nIdentificação dos Parâmetros (p, d, q):\n\nAnalise as funções de autocorrelação (ACF) e autocorrelação parcial (PACF) para determinar os valores ideais de p (ordem AR) e q (ordem MA).\nEstabeleça a ordem de diferenciação d necessária para atingir a estacionariedade.\n\nDivisão dos Dados:\n\nSepare os dados em conjuntos de treinamento e teste para avaliar o desempenho do modelo posteriormente.\n\nAjuste do Modelo ARIMA:\n\nUtilize os parâmetros (p, d, q) identificados para ajustar o modelo ARIMA aos dados de treinamento.\nAjuste também os parâmetros sazonais, se aplicável (SARIMA).\n\nValidação do Modelo:\n\nAvalie a qualidade do modelo usando critérios de informação como AIC (Akaike Information Criterion) e BIC (Bayesian Information Criterion) para modelos com os mesmos valores de p, d, e q.\nCalcule o erro médio quadrático (RMSE) para comparar modelos com diferentes configurações de p, d, e q.\n\nPrevisões e Avaliação:\n\nFaça previsões utilizando o modelo ARIMA ajustado nos dados de teste.\nAvalie a precisão das previsões comparando-as com os valores reais.\n\nAjustes Finais e Refinamentos:\n\nSe necessário, ajuste os parâmetros do modelo com base na análise da qualidade das previsões.\nConsidere iterar nos passos anteriores para melhorar a performance do modelo.\n\nInterpretação e Comunicação dos Resultados:\n\nComunique os resultados do modelo de forma clara, destacando as tendências identificadas e a capacidade de previsão.\n\n\nNa lista prática de exercícios vamos analisar dois bancos de dados, um apenas para verificar se o modelo é estacionário ou não e outro para de fato criar modelos ARIMA.\nPara mais informações sobre os parâmetros p, d, q, consulte as referências"
  },
  {
    "objectID": "ARIMA.html#referências",
    "href": "ARIMA.html#referências",
    "title": "ARIMA",
    "section": "Referências",
    "text": "Referências\nhttps://people.duke.edu/~rnau/411arim.htm"
  },
  {
    "objectID": "lista_7.html",
    "href": "lista_7.html",
    "title": "8  Lista 7 - Séries Temporais (ARIMA)",
    "section": "",
    "text": "9 Cigarro"
  },
  {
    "objectID": "lista_7.html#pacotes",
    "href": "lista_7.html#pacotes",
    "title": "8  Lista 7 - Séries Temporais (ARIMA)",
    "section": "8.1 Pacotes",
    "text": "8.1 Pacotes\n\nlibrary(tidyverse)\nlibrary(flexplot)\nlibrary(foreign)\nlibrary(dplyr)\nlibrary(tm)\nlibrary(ggplot2)\nlibrary(forcats)\nlibrary(rempsyc)\nlibrary(easystats)\nlibrary(kableExtra)\n\n#Específicos para series temporais\nlibrary(prophet)\nlibrary(forecast)\nlibrary(tseries)"
  },
  {
    "objectID": "lista_7.html#limpando-o-ambiente",
    "href": "lista_7.html#limpando-o-ambiente",
    "title": "8  Lista 7 - Séries Temporais (ARIMA)",
    "section": "8.2 Limpando o ambiente",
    "text": "8.2 Limpando o ambiente"
  },
  {
    "objectID": "lista_7.html#carregando-os-dados-e-modificando-o-tipo-de-variável",
    "href": "lista_7.html#carregando-os-dados-e-modificando-o-tipo-de-variável",
    "title": "8  Lista 7 - Séries Temporais (ARIMA)",
    "section": "9.1 Carregando os dados e modificando o tipo de variável",
    "text": "9.1 Carregando os dados e modificando o tipo de variável\n\noriginal = read.spss(\"CigarrosROD_1.sav\", to.data.frame=TRUE)\nglimpse(original)\n\nRows: 20\nColumns: 2\n$ Dia         &lt;dbl&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17,…\n$ cigarrosROD &lt;dbl&gt; 6, 10, 4, 13, 4, 11, 4, 6, 4, 15, 5, 14, 5, 21, 10, 31, 13…\n\ndb = original"
  },
  {
    "objectID": "lista_7.html#verificando-se-os-dados-são-estacionários",
    "href": "lista_7.html#verificando-se-os-dados-são-estacionários",
    "title": "8  Lista 7 - Séries Temporais (ARIMA)",
    "section": "9.2 Verificando se os dados são estacionários",
    "text": "9.2 Verificando se os dados são estacionários\nIniciaremos nossa primeira análise para verificar a estacionaridade dos dados por meio de uma abordagem gráfica. Este gráfico simples exibirá o número de cigarros consumidos ao longo do tempo, apresentando uma linha média que atravessa toda a linha temporal. A ideia é observar se os números de cigarros oscilam próximos à média, proporcionando uma visualização intuitiva da estacionariedade dos dados.\n\n# Plot estilizado\n# media_cigarros &lt;- mean(db$cigarrosROD)\n# \n# # Cria o gráfico com ggplot\n# ggplot(data = data.frame(cigarrosROD = db$cigarrosROD), aes(x = seq_along(cigarrosROD), y = cigarrosROD)) +\n#   geom_line(color = \"black\", size = 1) +\n#   geom_point(color = \"black\", size = 3) +\n#   geom_hline(yintercept = media_cigarros, linetype = \"dashed\", color = \"blue\", size = 1) +  # Adiciona a linha média\n#   labs(x = \"Dias\", y = \"Cigarros por dia\") +\n#   scale_x_continuous(breaks = seq_along(db$cigarrosROD), labels = seq_along(db$cigarrosROD)) +\n#   theme_minimal() +\n#   theme(panel.grid = element_blank(),\n#         axis.ticks = element_line())  # Adiciona ticks nos eixos x e y\n\n\nPlot simples\n\nmedia_cigarros &lt;- mean(db$cigarrosROD)\n\n# plot mais simples\nplot.ts(db$cigarrosROD)\nabline(h = media_cigarros, col = \"blue\", lty = 2, lwd = 2)\naxis(1, at = db$Dia, labels = db$Dia)\n\n\n\n\nClaramente os dados desviam bastante da média, logo essa não é uma série estacionária.\n\n\nAdf teste\nPodemos também utilizar o Augmented Dickey-Fuller (ADF) Test para avaliar a estacionaridade em séries temporais. A função para realizar o teste é a adf.test().\nInterpretação do Resultado:\n\nSe a estatística do teste for menor que o valor crítico (p &lt; 0.05), rejeitamos a hipótese nula e concluímos que a série é estacionária.\nSe a estatística do teste for maior que o valor crítico (p &gt; 0.05), falhamos em rejeitar a hipótese nula, sugerindo que a série é não estacionária.\n\n\n# Adf teste\nadf.test(db$cigarrosROD)\n\n\n    Augmented Dickey-Fuller Test\n\ndata:  db$cigarrosROD\nDickey-Fuller = -0.38979, Lag order = 2, p-value = 0.9797\nalternative hypothesis: stationary\n\n\nCorroborando a análise visual, falhamos em rejeitar a hipótese nula, logo podemos assumir que a série temporal em questão não é estacionária. Em seguida vamos ver como podemos ajustar os dados.\n\n\nAutocorrelação\nA função acf() (AutoCorrelation Function) no R é utilizada para calcular e visualizar os coeficientes de autocorrelação em uma série temporal. A autocorrelação mede a correlação entre uma observação e suas observações anteriores em diferentes defasagens (lags de tempo).\n\n# Calcula as autocorrelações e cria o gráfico\n\nautocorrelacoes = acf(db$cigarrosROD, plot = FALSE)\n\nautoplot(autocorrelacoes)\n\n\n\n\n\nggtsdisplay(db$cigarrosROD)\n\n\n\n\nOs valores de lag que tiveram um AFC além do intervalo de confiança (linha tracejada), são candidatos para utilizarmos em nosso modelo ARIMA. Portanto lag 2 e 4 são candidatos. Além disso podemos basear nossa decisão também o teste de Ljung-Box.\n\n\nTeste Ljung-Box\nO Teste Ljung-Box avalia para cada lag se a séria é estacionária ou não. Podemos testar individualmente para cada lag.\n\n# Teste Ljung-Box com lag 2\nBox.test(autocorrelacoes$acf , lag = 3, type = \"Ljung-Box\")\n\n\n    Box-Ljung test\n\ndata:  autocorrelacoes$acf\nX-squared = 8.5179, df = 3, p-value = 0.03644\n\nlag(db$cigarrosROD,1)\n\n [1] NA  6 10  4 13  4 11  4  6  4 15  5 14  5 21 10 31 13 39 16\n\n\nUma outra forma é criar um dataframe com todos os valores de lags calculados na autocorrelação.\n\n# Obtém o número máximo de lags disponíveis\nmax_lags &lt;- length(autocorrelacoes$acf) - 1\n\n# Inicialize os vetores para armazenar os resultados\nlags &lt;- numeric(max_lags)\np_values &lt;- numeric(max_lags)\n\n# Itere sobre os lags\nfor (lag in 1:max_lags) {\n  # Execute o teste de Ljung-Box para o lag atual\n  resultado_teste &lt;- Box.test(autocorrelacoes$acf, lag = lag, type = \"Ljung-Box\")\n  \n  # Armazene os resultados\n  lags[lag] &lt;- lag\n  p_values[lag] &lt;- resultado_teste$p.value\n}\n\n# Crie um dataframe com os resultados\nresultados_df &lt;- data.frame(Lag = lags, P_Value = p_values)\nkable(resultados_df)\n\n\n\n\nLag\nP_Value\n\n\n\n\n1\n0.9409683\n\n\n2\n0.0166341\n\n\n3\n0.0364377\n\n\n4\n0.0200419\n\n\n5\n0.0236724\n\n\n6\n0.0359384\n\n\n7\n0.0197526\n\n\n8\n0.0337181\n\n\n9\n0.0101406\n\n\n10\n0.0150763\n\n\n11\n0.0030557\n\n\n12\n0.0038952\n\n\n13\n0.0006256\n\n\n\n\n\n\n\nOu ainda\n\ntsdiag(auto.arima(db$cigarrosROD))"
  },
  {
    "objectID": "lista_7.html#transformação-variabilidade-e-estacionária",
    "href": "lista_7.html#transformação-variabilidade-e-estacionária",
    "title": "8  Lista 7 - Séries Temporais (ARIMA)",
    "section": "9.3 Transformação variabilidade e estacionária",
    "text": "9.3 Transformação variabilidade e estacionária\nPrimeiro vamos modificar a série para que tenha variabilidade constante\n\nlambda = BoxCox.lambda(db$cigarrosROD)\nlambda\n\n[1] -0.1713367\n\nvar_const = BoxCox(db$cigarrosROD, lambda = lambda)\n\nggtsdisplay(var_const)\n\n\n\n\nE agora podemos ajustar a serie para que ela fique estacionária.\n\nndiffs(var_const)\n\n[1] 1\n\n\n\nestacio = diff(var_const, 1)\nggtsdisplay(estacio)\n\n\n\n\nDe acordo com os resultados, qualquer lag, a não ser o lag 1, poderá ser utilizado para transformar os dados.\nPara decidir devemos levar em conta tanto a análise gráfica da autocorrelação quanto o teste de Ljung-Box.\nLogo os lags 2 e 4 são bons candidatos. Por parcimônia e sem nenhum critério teórico, vamos optar pelo lag menor, ou seja, lag 2."
  },
  {
    "objectID": "lista_7.html#transformando-os-dados-para-estacionários",
    "href": "lista_7.html#transformando-os-dados-para-estacionários",
    "title": "8  Lista 7 - Séries Temporais (ARIMA)",
    "section": "9.4 Transformando os dados para estacionários",
    "text": "9.4 Transformando os dados para estacionários\nPara modificar nossa série temporal utilizando lag 2 vamos utilizar a função diff().\n\n# Log\nlag_2 = diff(db$cigarrosROD, differences = 2) # posso colocar o log da diferença também caso os valores fiquem muito pequenos.\n\n\nPlot\n\nmedia_lag_2 = mean(lag_2)\nplot.ts(lag_2)\nabline(h = media_lag_2, col = \"blue\", lty = 2, lwd = 2)\naxis(1, at = db$Dia, labels = db$Dia)\n\n\n\n\nPronto! Agora os valores estão ocilando em torno da média. Apenas para confirmar que agora temos uma série temporal estacionária, podemos rodar novamente o adf.test.\n\nadf.test(lag_2) # testar com outros valores de K(lag) para verificar o p-value\n\n\n    Augmented Dickey-Fuller Test\n\ndata:  lag_2\nDickey-Fuller = -4.3237, Lag order = 2, p-value = 0.01196\nalternative hypothesis: stationary\n\n\nEsse banco de dados era apenas para transformar os dados não estacionários para estacionários. Vamos agora carregar outro banco de dados e criar o modelo ARIMA."
  },
  {
    "objectID": "lista_7.html#dados-séries-temporais",
    "href": "lista_7.html#dados-séries-temporais",
    "title": "8  Lista 7 - Séries Temporais (ARIMA)",
    "section": "9.5 Dados séries temporais",
    "text": "9.5 Dados séries temporais\n\noriginal_ts = read.spss(\"dados series temporais.sav\", to.data.frame=TRUE)\n\nre-encoding from CP1252\n\ndb_ts = original_ts\n\nglimpse(db_ts)\n\nRows: 120\nColumns: 11\n$ date         &lt;dbl&gt; 12818995200, 12821673600, 12824092800, 12826771200, 12829…\n$ men          &lt;dbl&gt; 11357.92, 10605.95, 16998.57, 6563.75, 6607.69, 9839.00, …\n$ women        &lt;dbl&gt; 16578.93, 18236.13, 43393.55, 30908.49, 28701.58, 29647.5…\n$ horas        &lt;dbl&gt; 7978, 8290, 8029, 7752, 8685, 7847, 7881, 8121, 7811, 870…\n$ divida       &lt;dbl&gt; 73, 88, 65, 85, 74, 87, 79, 72, 83, 111, 74, 105, 66, 59,…\n$ idade        &lt;dbl&gt; 34, 29, 24, 20, 17, 30, 28, 27, 35, 25, 30, 45, 35, 20, 2…\n$ propaganda   &lt;dbl&gt; 22294.48, 27426.47, 27978.66, 28949.65, 22642.27, 27210.6…\n$ escolaridade &lt;dbl&gt; 20, 20, 26, 22, 21, 23, 22, 20, 15, 20, 16, 29, 22, 28, 2…\n$ YEAR_        &lt;dbl&gt; 1989, 1989, 1989, 1989, 1989, 1989, 1989, 1989, 1989, 198…\n$ MONTH_       &lt;dbl&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 1, 2, 3, 4, 5, 6, …\n$ DATE_        &lt;chr&gt; \"JAN 1989\", \"FEB 1989\", \"MAR 1989\", \"APR 1989\", \"MAY 1989…\n\n\n\nPlot simples\n\nmedia_sal_men &lt;- mean(db_ts$men)\ndb_season = ts(db_ts$men,\n               frequency = 12,\n               start = c(1989, 1))\n\nts.plot(db_season)\nabline(h = media_sal_men, col = \"blue\", lty = 2, lwd = 2)\n\n\n\n\n\nseasonplot(db_season,\n           col = rainbow(12),\n           year.labels = TRUE,\n           type = \"o\",\n           pch = 16)\n\n\n\n\n\nggtsdisplay(db_season)\n\n\n\n\nSemelhante ao ARIMA (0,0,0)\n\n\nAdf teste\n\n# Adf teste\nadf.test(db_ts$men, k =1) #já está no formato estacionário\n\nWarning in adf.test(db_ts$men, k = 1): p-value smaller than printed p-value\n\n\n\n    Augmented Dickey-Fuller Test\n\ndata:  db_ts$men\nDickey-Fuller = -6.1931, Lag order = 1, p-value = 0.01\nalternative hypothesis: stationary\n\n\n\n\nLjung-Box\nDescrever\n\n# Teste Ljung-Box com lag 2\nBox.test(db_ts$men , lag = 1, type = \"Ljung-Box\")\n\n\n    Box-Ljung test\n\ndata:  db_ts$men\nX-squared = 19.742, df = 1, p-value = 0.000008865"
  },
  {
    "objectID": "lista_7.html#modelo-arima-100",
    "href": "lista_7.html#modelo-arima-100",
    "title": "8  Lista 7 - Séries Temporais (ARIMA)",
    "section": "9.6 Modelo ARIMA (1,0,0)",
    "text": "9.6 Modelo ARIMA (1,0,0)\n\nmodelo_sal_men = Arima(db_ts$men, order = c(1,0,0))\n\n\nPlot 1 do modelo (1,0,0)\n\n# Supondo que você tenha as séries temporais 'modelo_sal_men$fitted' e 'db_ts$men'\n\n# Cria o gráfico\nplot(modelo_sal_men$x, type = \"l\", col = \"red\", lty = 1, lwd = 2, xlab = \"Tempo\", ylab = \"Salário\")\nlines(modelo_sal_men$fitted, col = \"blue\", lty = 1, lwd = 2)\n\n# Adiciona uma legenda\nlegend(\"topright\", legend = c(\"Real\", \"Modelo\"), col = c(\"red\", \"blue\"), lty = c(1, 1), lwd = 2)\n\n# Adiciona um título ao gráfico\ntitle(main = \"Valores e Reais e do Modelo ARIMA de Salário para Homens\")"
  },
  {
    "objectID": "lista_7.html#modelo-arima-010",
    "href": "lista_7.html#modelo-arima-010",
    "title": "8  Lista 7 - Séries Temporais (ARIMA)",
    "section": "9.7 Modelo ARIMA (0,1,0)",
    "text": "9.7 Modelo ARIMA (0,1,0)\n\nmodelo2_sal_men = Arima(db_ts$men, order = c(0,1,0))\n\n\nPlot 1 do modelo (0,1,0)\n\n# Supondo que você tenha as séries temporais 'modelo2_sal_men$fitted' e 'db_ts$men'\n\n# Cria o gráfico\nplot(modelo2_sal_men$x, type = \"l\", col = \"red\", lty = 1, lwd = 2, xlab = \"Tempo\", ylab = \"Salário\")\nlines(modelo2_sal_men$fitted, col = \"blue\", lty = 1, lwd = 2)\n\n# Adiciona uma legenda\nlegend(\"topright\", legend = c(\"Real\", \"Modelo\"), col = c(\"red\", \"blue\"), lty = c(1, 1), lwd = 2)\n\n# Adiciona um título ao gráfico\ntitle(main = \"Valores e Reais e do Modelo ARIMA de Salário para Homens\")"
  },
  {
    "objectID": "lista_7.html#modelo-autoarima",
    "href": "lista_7.html#modelo-autoarima",
    "title": "8  Lista 7 - Séries Temporais (ARIMA)",
    "section": "9.8 Modelo autoARIMA",
    "text": "9.8 Modelo autoARIMA\nAssim como o SPSS o R também tem uma função que determina automaticamente os parâmetros p, d, q. Vamos verificar qual modelo a função auto.arima()sugere.\n\n# Para verificar qual o modelo sugerido pela função auto.arima\nauto.arima(db_ts$men, trace = TRUE)\n\n\n ARIMA(2,1,2) with drift         : Inf\n ARIMA(0,1,0) with drift         : 2434.823\n ARIMA(1,1,0) with drift         : 2412.096\n ARIMA(0,1,1) with drift         : Inf\n ARIMA(0,1,0)                    : 2432.897\n ARIMA(2,1,0) with drift         : 2411.86\n ARIMA(3,1,0) with drift         : 2408.495\n ARIMA(4,1,0) with drift         : 2407.461\n ARIMA(5,1,0) with drift         : 2408.674\n ARIMA(4,1,1) with drift         : Inf\n ARIMA(3,1,1) with drift         : Inf\n ARIMA(5,1,1) with drift         : Inf\n ARIMA(4,1,0)                    : 2405.816\n ARIMA(3,1,0)                    : 2406.731\n ARIMA(5,1,0)                    : 2407.075\n ARIMA(4,1,1)                    : 2394.525\n ARIMA(3,1,1)                    : 2392.515\n ARIMA(2,1,1)                    : 2392.416\n ARIMA(1,1,1)                    : 2391.073\n ARIMA(0,1,1)                    : 2393.07\n ARIMA(1,1,0)                    : 2410.255\n ARIMA(1,1,2)                    : 2392.894\n ARIMA(0,1,2)                    : 2391.92\n ARIMA(2,1,0)                    : 2410.02\n ARIMA(2,1,2)                    : Inf\n ARIMA(1,1,1) with drift         : Inf\n\n Best model: ARIMA(1,1,1)                    \n\n\nSeries: db_ts$men \nARIMA(1,1,1) \n\nCoefficients:\n         ar1      ma1\n      0.2036  -0.9139\ns.e.  0.1002   0.0347\n\nsigma^2 = 29737029:  log likelihood = -1192.43\nAIC=2390.86   AICc=2391.07   BIC=2399.2\n\n\nA função sugeriu o modelo 1, 1, 1. Vamos verificar os resultados.\n\nmodelo_auto_sal_men = Arima(db_ts$men, order = c(1,1,1))\n\n\nPlot 1 do modelo (1,1,1)\n\n# Supondo que você tenha as séries temporais 'modelo_atuo_sal_men$fitted' e 'db_ts$men'\n\n# Cria o gráfico\nplot(modelo_auto_sal_men$x, type = \"l\", col = \"red\", lty = 1, lwd = 2, xlab = \"Tempo\", ylab = \"Salário\")\nlines(modelo_auto_sal_men$fitted, col = \"blue\", lty = 1, lwd = 2)\n\n# Adiciona uma legenda\nlegend(\"topright\", legend = c(\"Real\", \"Modelo\"), col = c(\"red\", \"blue\"), lty = c(1, 1), lwd = 2)\n\n# Adiciona um título ao gráfico\ntitle(main = \"Valores e Reais e do Modelo ARIMA de Salário para Homens\")"
  },
  {
    "objectID": "lista_7.html#homens---modelo-com-variáveis-independentes",
    "href": "lista_7.html#homens---modelo-com-variáveis-independentes",
    "title": "8  Lista 7 - Séries Temporais (ARIMA)",
    "section": "9.9 Homens - Modelo com variáveis independentes",
    "text": "9.9 Homens - Modelo com variáveis independentes\n\n\n\n\n\n\nAtenção!\n\n\n\nAinda falta modificar os índices p, d, q das variáveis indepentendes como foi feito no SPSS.\n\n\n\nAuto arima\n\n# Defina as variáveis independentes originais\nnomes_variaveis &lt;- c(\"horas\", \"divida\", \"idade\", \"propaganda\", \"escolaridade\")\n\n# Crie a matriz de covariáveis\ncovars &lt;- as.matrix(db_ts[, nomes_variaveis, drop = FALSE])\n\n\n\n# Atribua os nomes diretamente à matriz de covariáveis\ncolnames(covars) &lt;- nomes_variaveis\n\n\n# \n# covars &lt;- cbind(\n#   db_ts$horas,\n#   db_ts$divida,\n#   db_ts$idade,\n#   db_ts$propaganda,\n#   db_ts$escolaridade\n# )\n\nauto.arima(db_ts$men, xreg = covars)\n\nSeries: db_ts$men \nRegression with ARIMA(1,0,0) errors \n\nCoefficients:\n         ar1   intercept   horas   divida     idade  propaganda  escolaridade\n      0.1968  -23753.966  2.0271  34.5286  342.9908      0.2046      -30.3841\ns.e.  0.1000    2752.767  0.2204  20.1900   43.9319      0.0733       41.3101\n\nsigma^2 = 8316739:  log likelihood = -1122.71\nAIC=2261.43   AICc=2262.72   BIC=2283.73\n\n\nModelo sugerido é o c(1,0,0)\n\n# Ajuste o modelo ARIMA com covariáveis\nmodelo_completo = Arima(\n  db_ts$men,\n  order = c(1, 0, 0),\n  xreg = covars, \n)\n\n\n# Defina as variáveis independentes originais\nnomes_variaveis &lt;- c(\"horas\", \"divida\", \"idade\", \"propaganda\", \"escolaridade\")\n\n# Inicialize uma lista para armazenar os modelos ajustados para cada VI\nmodelos_vi &lt;- list()\n\n# Loop através das variáveis independentes\nfor (variavel in nomes_variaveis) {\n  \n  # Selecione a VI específica\n  variavel_ts &lt;- db_ts[, variavel, drop = FALSE]\n  \n  # Ajuste as ordens p, d, q para a VI específica\n  ordens_vi &lt;- c(1, 0, 0)  # p, d, q\n  \n  # Ajuste o modelo ARIMA para a VI específica\n  modelo_vi &lt;- Arima(\n    variavel_ts,\n    order = ordens_vi,\n    include.mean = TRUE,\n    transform.pars = TRUE,\n    fixed = NULL,\n    include.drift = FALSE,\n    method = \"ML\",  # Mude conforme necessário\n    optim.control = list(trace = FALSE, REPORT = 1),\n    kappa = 1\n  )\n  \n  # Adicione o modelo ao vetor de modelos\n  modelos_vi[[variavel]] &lt;- modelo_vi\n}\n\n# Agora, você tem modelos ajustados para cada VI na lista modelos_vi\n\n# Combine os modelos ARIMA para as VI em uma única matriz\ncovars &lt;- cbind(\n  modelos_vi$horas$fitted, \n  modelos_vi$divida$fitted, \n  modelos_vi$idade$fitted, \n  modelos_vi$propaganda$fitted, \n  modelos_vi$escolaridade$fitted\n)\n\n# Ajuste o modelo ARIMA principal com as covariáveis\nmodelo_completo &lt;- Arima(\n  db_ts$men,\n  order = c(1, 0, 0),\n  xreg = covars,\n  seasonal = list(order = c(0, 0, 0)),  # Adapte conforme necessário\n  include.mean = TRUE,\n  transform.pars = TRUE,\n  fixed = NULL,\n  include.drift = FALSE,\n  method = \"ML\",  # Mude conforme necessário\n  optim.control = list(trace = FALSE, REPORT = 1),\n  kappa = 1\n)\n\n\n\nPlot do modelo com VIs\n\n# Criar um dataframe com as séries temporais\ndf_full &lt;- data.frame(\n  Tempo = seq_along(modelo_completo$fitted),\n  Ajustado = modelo_completo$fitted,\n  Real = modelo_completo$x\n)\n\n# Criar o gráfico com ggplot2\nggplot(df_full, aes(x = Tempo)) +\n  geom_line(aes(y = Ajustado, color = \"Ajustado\"), size = 1) +\n  geom_line(aes(y = Real, color = \"Real\"), size = 1) +\n  labs(x = \"Tempo\", y = \"Salário\", title = \"Valores Ajustados e Reais de Salário para Homens ao Longo do Tempo\") +\n  scale_color_manual(values = c(\"Ajustado\" = \"blue\", \"Real\" = \"red\"), guide = \"legend\") +\n  theme_minimal()\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead.\n\n\nDon't know how to automatically pick scale for object of type &lt;ts&gt;. Defaulting\nto continuous.\n\n\n\n\n\n\n\nAIC, BIC e RMSE\n\nperformance(modelo_completo)\n\n# Indices of model performance\n\nAIC      |     AICc |      BIC | R2.modelos_vi$horas$fitted | R2.modelos_vi$divida$fitted | R2.modelos_vi$idade$fitted | R2.modelos_vi$propaganda$fitted | R2.modelos_vi$escolaridade$fitted |     RMSE |    Sigma\n------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n2421.052 | 6925.052 | 2443.352 |                      0.397 |                       0.213 |                      0.722 |                       5.366e-04 |                             0.656 | 5442.460 | 5633.481\n\n\n\n\nResultados\n\n# Visualize o resumo do modelo\nsummary(modelo_completo)\n\nSeries: db_ts$men \nRegression with ARIMA(1,0,0) errors \n\nCoefficients:\n          ar1  intercept  modelos_vi$horas$fitted  modelos_vi$divida$fitted\n      -0.1727   34621.57                   0.7594                 -607.0271\ns.e.   0.1639   40027.85                   1.3741                  316.5860\n      modelos_vi$idade$fitted  modelos_vi$propaganda$fitted\n                     371.3498                        0.1770\ns.e.                 127.6716                        1.0677\n      modelos_vi$escolaridade$fitted\n                            135.8938\ns.e.                         81.0383\n\nsigma^2 = 31455262:  log likelihood = -1202.53\nAIC=2421.05   AICc=2422.35   BIC=2443.35\n\nTraining set error measures:\n                   ME    RMSE      MAE       MPE     MAPE     MASE        ACF1\nTraining set -5.05266 5442.46 3863.789 -11.92625 27.46778 0.826093 0.002906111\n\n# db_ts$horas,       xreg1    \n# db_ts$divida  ,    xreg2\n# db_ts$idade,       xreg3\n# db_ts$propaganda,  xreg4    \n# db_ts$escolaridade xreg5\n\n\nCoeficientes e valores de p\n\nlibrary(lmtest) # pacote para calcular os estimates e valores de p\n\nWarning: package 'lmtest' was built under R version 4.3.2\n\n\nCarregando pacotes exigidos: zoo\n\n\n\nAttaching package: 'zoo'\n\n\nThe following objects are masked from 'package:base':\n\n    as.Date, as.Date.numeric\n\n# Use a função coeftest para obter coeficientes e p-valores\ntest_coef &lt;- coeftest(modelo_completo)\n\n# Acesse os coeficientes estimados e os p-valores\ncoeficientes &lt;- round(test_coef[, \"Estimate\"], 3)\np_valores &lt;- round(test_coef[, \"Pr(&gt;|z|)\"], 3)\n\n# Crie uma nova coluna com asteriscos para valores de p significativos\ntest_coef$Significativo &lt;- ifelse(p_valores &lt; 0.05, \"*\", \"\")\n\nWarning in test_coef$Significativo &lt;- ifelse(p_valores &lt; 0.05, \"*\", \"\"):\nRealizando coerção de LHD para uma lista\n\n# Exiba os resultados\nresultados &lt;- data.frame(Coeficientes = coeficientes, p_valores = paste0(format(p_valores, digits = 3), test_coef$Significativo))\nprint(resultados)\n\n                               Coeficientes p_valores\nar1                                  -0.173     0.292\nintercept                         34621.566     0.387\nmodelos_vi$horas$fitted               0.759     0.581\nmodelos_vi$divida$fitted           -607.027     0.055\nmodelos_vi$idade$fitted             371.350    0.004*\nmodelos_vi$propaganda$fitted          0.177     0.868\nmodelos_vi$escolaridade$fitted      135.894     0.094\n\n\n\n\n\nMulheres - Modelo com variáveis independentes para\n\nVerificar qual o melhor modelo utilizando as VIs no auto.arima\n\n# Supondo que você tenha um dataframe 'db_ts' com as variáveis mencionadas\n\n# Defina as variáveis independentes originais\nnomes_variaveis &lt;- c(\"horas\", \"divida\", \"idade\", \"propaganda\", \"escolaridade\")\n\n# Crie a matriz de covariáveis\ncovars &lt;- as.matrix(db_ts[, nomes_variaveis, drop = FALSE])\n\n# Atribua os nomes diretamente à matriz de covariáveis\ncolnames(covars) &lt;- nomes_variaveis\n\n\n# \n# covars &lt;- cbind(\n#   db_ts$horas,\n#   db_ts$divida,\n#   db_ts$idade,\n#   db_ts$propaganda,\n#   db_ts$escolaridade\n# )\n\nauto.arima(db_ts$women, xreg = covars)\n\nSeries: db_ts$women \nRegression with ARIMA(0,0,1) errors \n\nCoefficients:\n         ma1   intercept   horas   divida     idade  propaganda  escolaridade\n      0.3351  -37941.151  2.6828  90.5433    1.6294      0.9805      445.6786\ns.e.  0.1096    6458.967  0.5145  52.4388  110.2176      0.1693      102.0171\n\nsigma^2 = 49641429:  log likelihood = -1229.95\nAIC=2475.89   AICc=2477.19   BIC=2498.19\n\n\nModelo sugerido é o c(0,0,1)\n\n# Ajuste o modelo ARIMA com covariáveis\nmodelo_completo_women = Arima(\n  db_ts$women,\n  order = c(0, 0, 1),\n  xreg = covars\n)\n\n\n\n# Visualize o resumo do modelo\nsummary(modelo_completo_women)\n\nSeries: db_ts$women \nRegression with ARIMA(0,0,1) errors \n\nCoefficients:\n         ma1   intercept   horas   divida     idade  propaganda  escolaridade\n      0.3351  -37941.151  2.6828  90.5433    1.6294      0.9805      445.6786\ns.e.  0.1096    6458.967  0.5145  52.4388  110.2176      0.1693      102.0171\n\nsigma^2 = 49641429:  log likelihood = -1229.95\nAIC=2475.89   AICc=2477.19   BIC=2498.19\n\nTraining set error measures:\n                     ME     RMSE  MAE       MPE    MAPE      MASE        ACF1\nTraining set -0.1962005 6837.081 4889 -3.414187 14.6811 0.5114592 -0.01923702\n\n\n\n# db_ts$horas,       xreg1    \n# db_ts$divida  ,    xreg2\n# db_ts$idade,       xreg3\n# db_ts$propaganda,  xreg4    \n# db_ts$escolaridade xreg5\n\ncheckresiduals(modelo_completo_women)\n\n\n\n\n\n    Ljung-Box test\n\ndata:  Residuals from Regression with ARIMA(0,0,1) errors\nQ* = 10.048, df = 9, p-value = 0.3466\n\nModel df: 1.   Total lags used: 10\n\n\n\n\nPlot do modelo com VIs\n\n# Criar um dataframe com as séries temporais\ndf_full_women &lt;- data.frame(\n  Tempo = seq_along(modelo_completo_women$fitted),\n  Ajustado = modelo_completo_women$fitted,\n  Real = modelo_completo_women$x\n)\n\n# Criar o gráfico com ggplot2\nggplot(df_full_women, aes(x = Tempo)) +\n  geom_line(aes(y = Ajustado, color = \"Ajustado\"), size = 1) +\n  geom_line(aes(y = Real, color = \"Real\"), size = 1) +\n  labs(x = \"Tempo\", y = \"Salário\", title = \"Valores Ajustados e Reais de Salário para Mulheres ao Longo do Tempo\") +\n  scale_color_manual(values = c(\"Ajustado\" = \"red\", \"Real\" = \"blue\"), guide = \"legend\") +\n  theme_minimal()\n\nDon't know how to automatically pick scale for object of type &lt;ts&gt;. Defaulting\nto continuous.\n\n\n\n\n\n\n\nCoeficientes e valores de p\n\nlibrary(lmtest) # pacote para calcular os estimates e valores de p\n\n\n# Use a função coeftest para obter coeficientes e p-valores\ntest_coef_women &lt;- coeftest(modelo_completo_women)\n\n# Acesse os coeficientes estimados e os p-valores\ncoeficientes_women &lt;- round(test_coef_women[, \"Estimate\"], 3)\np_valores_women &lt;- round(test_coef_women[, \"Pr(&gt;|z|)\"], 3)\n\n# Crie uma nova coluna com asteriscos para valores de p significativos\ntest_coef_women$Significativo &lt;- ifelse(p_valores_women &lt; 0.05, \"*\", \"\")\n\nWarning in test_coef_women$Significativo &lt;- ifelse(p_valores_women &lt; 0.05, :\nRealizando coerção de LHD para uma lista\n\n# Exiba os resultados\nresultados_women &lt;- data.frame(Coeficientes = coeficientes_women, Pvalores = paste0(format(p_valores_women, digits = 3), test_coef_women$Significativo))\nprint(resultados_women)\n\n             Coeficientes Pvalores\nma1                 0.335   0.002*\nintercept      -37941.151   0.000*\nhoras               2.683   0.000*\ndivida             90.543    0.084\nidade               1.629    0.988\npropaganda          0.981   0.000*\nescolaridade      445.679   0.000*"
  },
  {
    "objectID": "lista_7.html#forecast-previsões",
    "href": "lista_7.html#forecast-previsões",
    "title": "8  Lista 7 - Séries Temporais (ARIMA)",
    "section": "9.10 Forecast (previsões)",
    "text": "9.10 Forecast (previsões)\n\nMulheres - 50 anos\n\nwomen_salary_ts = ts(db_ts$women,\n               frequency = 12,\n               start = c(1989, 1))\n\n\nfit_arima_women = auto.arima(women_salary_ts)\n\nfcast_women = forecast(fit_arima_women, h=50)\nautoplot(fcast_women)\n\n\n\n\n\n\nHomens - 50 anos\n\nmen_salary_ts = ts(db_ts$men,\n               frequency = 12,\n               start = c(1989, 1))\n\n\nfit_arima_men = auto.arima(men_salary_ts)\n\nfcast_men = forecast(fit_arima_men, h=50)\nautoplot(fcast_men)"
  },
  {
    "objectID": "lista_7.html#extras",
    "href": "lista_7.html#extras",
    "title": "8  Lista 7 - Séries Temporais (ARIMA)",
    "section": "9.11 Extras",
    "text": "9.11 Extras\n\nMais gráficos\n\nPlot 2 do modelo (1,0,0)\n\nmodelo_sal_men = Arima(db_ts$men, order = c(1,0,0))\n\n# Criar um dataframe com as séries temporais\ndf_100 &lt;- data.frame(\n  Tempo = seq_along(modelo_sal_men$fitted),\n  Ajustado = modelo_sal_men$fitted,\n  Real = modelo_sal_men$x\n)\n\n# Criar o gráfico com ggplot2\nggplot(df_100, aes(x = Tempo)) +\n  geom_line(aes(y = Ajustado, color = \"Ajustado\"), size = 1) +\n  geom_line(aes(y = Real, color = \"Real\"), size = 1) +\n  labs(x = \"Tempo\", y = \"Salário\", title = \"Valores Ajustados e Reais de Salário para Homens ao Longo do Tempo\") +\n  scale_color_manual(values = c(\"Ajustado\" = \"red\", \"Real\" = \"blue\"), guide = \"legend\") +\n  theme_minimal()\n\nDon't know how to automatically pick scale for object of type &lt;ts&gt;. Defaulting\nto continuous.\n\n\n\n\n\n\n\nPlot 2 do modelo (0,1,0)\n\n# Criar um dataframe com as séries temporais\ndf_010 &lt;- data.frame(\n  Tempo = seq_along(modelo2_sal_men$fitted),\n  Ajustado = modelo2_sal_men$fitted,\n  Real = modelo2_sal_men$x\n)\n\n# Criar o gráfico com ggplot2\nggplot(df_010, aes(x = Tempo)) +\n  geom_line(aes(y = Ajustado, color = \"Ajustado\"), size = 1) +\n  geom_line(aes(y = Real, color = \"Real\"), size = 1) +\n  labs(x = \"Tempo\", y = \"Salário\", title = \"Valores Ajustados e Reais de Salário para Homens ao Longo do Tempo\") +\n  scale_color_manual(values = c(\"Ajustado\" = \"red\", \"Real\" = \"blue\"), guide = \"legend\") +\n  theme_minimal()\n\nDon't know how to automatically pick scale for object of type &lt;ts&gt;. Defaulting\nto continuous.\n\n\n\n\n\n\n\nPlot 2 do modelo (1,1,1)\n\nmodelo_atuo_sal_men = Arima(db_ts$men, order = c(1,1,1))\n\n# Criar um dataframe com as séries temporais\ndf_111 &lt;- data.frame(\n  Tempo = seq_along(modelo_atuo_sal_men$fitted),\n  Ajustado = modelo_atuo_sal_men$fitted,\n  Real = modelo_atuo_sal_men$x\n)\n\n# Criar o gráfico com ggplot2\nggplot(df_111, aes(x = Tempo)) +\n  geom_line(aes(y = Ajustado, color = \"Ajustado\"), size = 1) +\n  geom_line(aes(y = Real, color = \"Real\"), size = 1) +\n  labs(x = \"Tempo\", y = \"Salário\", title = \"Valores Ajustados e Reais de Salário para Homens ao Longo do Tempo\") +\n  scale_color_manual(values = c(\"Ajustado\" = \"red\", \"Real\" = \"blue\"), guide = \"legend\") +\n  theme_minimal()\n\nDon't know how to automatically pick scale for object of type &lt;ts&gt;. Defaulting\nto continuous."
  },
  {
    "objectID": "lista_7.html#verificando-resíduos",
    "href": "lista_7.html#verificando-resíduos",
    "title": "8  Lista 7 - Séries Temporais (ARIMA)",
    "section": "9.12 Verificando resíduos",
    "text": "9.12 Verificando resíduos\n\ncheckresiduals(modelo_auto_sal_men)\n\n\n\n\n\n    Ljung-Box test\n\ndata:  Residuals from ARIMA(1,1,1)\nQ* = 10.891, df = 8, p-value = 0.208\n\nModel df: 2.   Total lags used: 10\n\nsummary(modelo_auto_sal_men)\n\nSeries: db_ts$men \nARIMA(1,1,1) \n\nCoefficients:\n         ar1      ma1\n      0.2036  -0.9139\ns.e.  0.1002   0.0347\n\nsigma^2 = 29737029:  log likelihood = -1192.43\nAIC=2390.86   AICc=2391.07   BIC=2399.2\n\nTraining set error measures:\n                   ME     RMSE      MAE       MPE     MAPE      MASE\nTraining set 915.6723 5384.571 3662.003 -5.571742 25.15003 0.7829504\n                    ACF1\nTraining set -0.04692903"
  },
  {
    "objectID": "lista_7.html#lista-7-resolvida-no-spss",
    "href": "lista_7.html#lista-7-resolvida-no-spss",
    "title": "8  Lista 7 - Séries Temporais (ARIMA)",
    "section": "9.13 Lista 7 resolvida no SPSS",
    "text": "9.13 Lista 7 resolvida no SPSS"
  },
  {
    "objectID": "lista_7.html#referências",
    "href": "lista_7.html#referências",
    "title": "8  Lista 7 - Séries Temporais (ARIMA)",
    "section": "9.14 Referências",
    "text": "9.14 Referências\nhttps://facebook.github.io/prophet/docs/installation.html#r\nhttps://rpubs.com/mpleo/timeseries_prophet\nhttps://www.youtube.com/watch?v=ny3gRhfVsi4&t=10s\nhttps://www.youtube.com/watch?v=Txuo9JQjnKE ótima ref em PT-BR\nhttps://www.youtube.com/watch?v=RJzmHkGWCxs&list=PLEuzmtv9IuT_vg5oE0lQyZR-wgbVeGztt"
  },
  {
    "objectID": "lista_7.html#versões-dos-pacotes",
    "href": "lista_7.html#versões-dos-pacotes",
    "title": "8  Lista 7 - Séries Temporais (ARIMA)",
    "section": "9.15 Versões dos pacotes",
    "text": "9.15 Versões dos pacotes\n\nreport(sessionInfo())\n\nAnalyses were conducted using the R Statistical language (version 4.3.1; R Core\nTeam, 2023) on Windows 11 x64 (build 22621), using the packages effectsize\n(version 0.8.6; Ben-Shachar MS et al., 2020), Rcpp (version 1.0.11;\nEddelbuettel D et al., 2023), tm (version 0.7.11; Feinerer I, Hornik K, 2023),\nflexplot (version 0.20.5; Fife D, 2024), lubridate (version 1.9.3; Grolemund G,\nWickham H, 2011), rlang (version 1.1.1; Henry L, Wickham H, 2023), NLP (version\n0.2.1; Hornik K, 2020), forecast (version 8.21.1; Hyndman R et al., 2023),\nparameters (version 0.21.3; Lüdecke D et al., 2020), performance (version\n0.10.8; Lüdecke D et al., 2021), easystats (version 0.6.0; Lüdecke D et al.,\n2022), see (version 0.8.1; Lüdecke D et al., 2021), insight (version 0.19.6;\nLüdecke D et al., 2019), bayestestR (version 0.13.1; Makowski D et al., 2019),\nmodelbased (version 0.8.6; Makowski D et al., 2020), report (version 0.5.7;\nMakowski D et al., 2023), correlation (version 0.8.4; Makowski D et al., 2022),\ntibble (version 3.2.1; Müller K, Wickham H, 2023), datawizard (version 0.9.0;\nPatil I et al., 2022), foreign (version 0.8.85; R Core Team, 2023), prophet\n(version 1.0; Taylor S, Letham B, 2021), rempsyc (version 0.1.6; Thériault R,\n2023), tseries (version 0.10.55; Trapletti A, Hornik K, 2023), ggplot2 (version\n3.4.4; Wickham H, 2016), forcats (version 1.0.0; Wickham H, 2023), stringr\n(version 1.5.1; Wickham H, 2023), tidyverse (version 2.0.0; Wickham H et al.,\n2019), dplyr (version 1.1.3; Wickham H et al., 2023), purrr (version 1.0.2;\nWickham H, Henry L, 2023), readr (version 2.1.4; Wickham H et al., 2023), tidyr\n(version 1.3.0; Wickham H et al., 2023), zoo (version 1.8.12; Zeileis A,\nGrothendieck G, 2005), lmtest (version 0.9.40; Zeileis A, Hothorn T, 2002) and\nkableExtra (version 1.3.4; Zhu H, 2021).\n\nReferences\n----------\n  - Ben-Shachar MS, Lüdecke D, Makowski D (2020). \"effectsize: Estimation of\nEffect Size Indices and Standardized Parameters.\" _Journal of Open Source\nSoftware_, *5*(56), 2815. doi:10.21105/joss.02815\n&lt;https://doi.org/10.21105/joss.02815&gt;, &lt;https://doi.org/10.21105/joss.02815&gt;.\n  - Eddelbuettel D, Francois R, Allaire J, Ushey K, Kou Q, Russell N, Ucar I,\nBates D, Chambers J (2023). _Rcpp: Seamless R and C++ Integration_. R package\nversion 1.0.11, &lt;https://CRAN.R-project.org/package=Rcpp&gt;. Eddelbuettel D,\nFrançois R (2011). \"Rcpp: Seamless R and C++ Integration.\" _Journal of\nStatistical Software_, *40*(8), 1-18. doi:10.18637/jss.v040.i08\n&lt;https://doi.org/10.18637/jss.v040.i08&gt;. Eddelbuettel D (2013). _Seamless R and\nC++ Integration with Rcpp_. Springer, New York. doi:10.1007/978-1-4614-6868-4\n&lt;https://doi.org/10.1007/978-1-4614-6868-4&gt;, ISBN 978-1-4614-6867-7.\nEddelbuettel D, Balamuta J (2018). \"Extending R with C++: A Brief Introduction\nto Rcpp.\" _The American Statistician_, *72*(1), 28-36.\ndoi:10.1080/00031305.2017.1375990\n&lt;https://doi.org/10.1080/00031305.2017.1375990&gt;.\n  - Feinerer I, Hornik K (2023). _tm: Text Mining Package_. R package version\n0.7-11, &lt;https://CRAN.R-project.org/package=tm&gt;. Feinerer I, Hornik K, Meyer D\n(2008). \"Text Mining Infrastructure in R.\" _Journal of Statistical Software_,\n*25*(5), 1-54. doi:10.18637/jss.v025.i05\n&lt;https://doi.org/10.18637/jss.v025.i05&gt;.\n  - Fife D (2024). _flexplot: Graphically Based Data Analysis Using 'flexplot'_.\nR package version 0.20.5.\n  - Grolemund G, Wickham H (2011). \"Dates and Times Made Easy with lubridate.\"\n_Journal of Statistical Software_, *40*(3), 1-25.\n&lt;https://www.jstatsoft.org/v40/i03/&gt;.\n  - Henry L, Wickham H (2023). _rlang: Functions for Base Types and Core R and\n'Tidyverse' Features_. R package version 1.1.1,\n&lt;https://CRAN.R-project.org/package=rlang&gt;.\n  - Hornik K (2020). _NLP: Natural Language Processing Infrastructure_. R package\nversion 0.2-1, &lt;https://CRAN.R-project.org/package=NLP&gt;.\n  - Hyndman R, Athanasopoulos G, Bergmeir C, Caceres G, Chhay L, O'Hara-Wild M,\nPetropoulos F, Razbash S, Wang E, Yasmeen F (2023). _forecast: Forecasting\nfunctions for time series and linear models_. R package version 8.21.1,\n&lt;https://pkg.robjhyndman.com/forecast/&gt;. Hyndman RJ, Khandakar Y (2008).\n\"Automatic time series forecasting: the forecast package for R.\" _Journal of\nStatistical Software_, *26*(3), 1-22. doi:10.18637/jss.v027.i03\n&lt;https://doi.org/10.18637/jss.v027.i03&gt;.\n  - Lüdecke D, Ben-Shachar M, Patil I, Makowski D (2020). \"Extracting, Computing\nand Exploring the Parameters of Statistical Models using R.\" _Journal of Open\nSource Software_, *5*(53), 2445. doi:10.21105/joss.02445\n&lt;https://doi.org/10.21105/joss.02445&gt;.\n  - Lüdecke D, Ben-Shachar M, Patil I, Waggoner P, Makowski D (2021).\n\"performance: An R Package for Assessment, Comparison and Testing of\nStatistical Models.\" _Journal of Open Source Software_, *6*(60), 3139.\ndoi:10.21105/joss.03139 &lt;https://doi.org/10.21105/joss.03139&gt;.\n  - Lüdecke D, Ben-Shachar M, Patil I, Wiernik B, Makowski D (2022). \"easystats:\nFramework for Easy Statistical Modeling, Visualization, and Reporting.\" _CRAN_.\nR package, &lt;https://easystats.github.io/easystats/&gt;.\n  - Lüdecke D, Patil I, Ben-Shachar M, Wiernik B, Waggoner P, Makowski D (2021).\n\"see: An R Package for Visualizing Statistical Models.\" _Journal of Open Source\nSoftware_, *6*(64), 3393. doi:10.21105/joss.03393\n&lt;https://doi.org/10.21105/joss.03393&gt;.\n  - Lüdecke D, Waggoner P, Makowski D (2019). \"insight: A Unified Interface to\nAccess Information from Model Objects in R.\" _Journal of Open Source Software_,\n*4*(38), 1412. doi:10.21105/joss.01412 &lt;https://doi.org/10.21105/joss.01412&gt;.\n  - Makowski D, Ben-Shachar M, Lüdecke D (2019). \"bayestestR: Describing Effects\nand their Uncertainty, Existence and Significance within the Bayesian\nFramework.\" _Journal of Open Source Software_, *4*(40), 1541.\ndoi:10.21105/joss.01541 &lt;https://doi.org/10.21105/joss.01541&gt;,\n&lt;https://joss.theoj.org/papers/10.21105/joss.01541&gt;.\n  - Makowski D, Ben-Shachar M, Patil I, Lüdecke D (2020). \"Estimation of\nModel-Based Predictions, Contrasts and Means.\" _CRAN_.\n&lt;https://github.com/easystats/modelbased&gt;.\n  - Makowski D, Lüdecke D, Patil I, Thériault R, Ben-Shachar M, Wiernik B (2023).\n\"Automated Results Reporting as a Practical Tool to Improve Reproducibility and\nMethodological Best Practices Adoption.\" _CRAN_.\n&lt;https://easystats.github.io/report/&gt;.\n  - Makowski D, Wiernik B, Patil I, Lüdecke D, Ben-Shachar M (2022).\n\"correlation: Methods for Correlation Analysis.\" Version 0.8.3,\n&lt;https://CRAN.R-project.org/package=correlation&gt;. Makowski D, Ben-Shachar M,\nPatil I, Lüdecke D (2020). \"Methods and Algorithms for Correlation Analysis in\nR.\" _Journal of Open Source Software_, *5*(51), 2306. doi:10.21105/joss.02306\n&lt;https://doi.org/10.21105/joss.02306&gt;,\n&lt;https://joss.theoj.org/papers/10.21105/joss.02306&gt;.\n  - Müller K, Wickham H (2023). _tibble: Simple Data Frames_. R package version\n3.2.1, &lt;https://CRAN.R-project.org/package=tibble&gt;.\n  - Patil I, Makowski D, Ben-Shachar M, Wiernik B, Bacher E, Lüdecke D (2022).\n\"datawizard: An R Package for Easy Data Preparation and Statistical\nTransformations.\" _Journal of Open Source Software_, *7*(78), 4684.\ndoi:10.21105/joss.04684 &lt;https://doi.org/10.21105/joss.04684&gt;.\n  - R Core Team (2023). _foreign: Read Data Stored by 'Minitab', 'S', 'SAS',\n'SPSS', 'Stata', 'Systat', 'Weka', 'dBase', ..._. R package version 0.8-85,\n&lt;https://CRAN.R-project.org/package=foreign&gt;.\n  - R Core Team (2023). _R: A Language and Environment for Statistical\nComputing_. R Foundation for Statistical Computing, Vienna, Austria.\n&lt;https://www.R-project.org/&gt;.\n  - Taylor S, Letham B (2021). _prophet: Automatic Forecasting Procedure_. R\npackage version 1.0, &lt;https://CRAN.R-project.org/package=prophet&gt;.\n  - Thériault R (2023). \"rempsyc: Convenience functions for psychology.\" _Journal\nof Open Source Software_, *8*(87), 5466. doi:10.21105/joss.05466\n&lt;https://doi.org/10.21105/joss.05466&gt;, &lt;https://doi.org/10.21105/joss.05466&gt;.\n  - Trapletti A, Hornik K (2023). _tseries: Time Series Analysis and\nComputational Finance_. R package version 0.10-55,\n&lt;https://CRAN.R-project.org/package=tseries&gt;.\n  - Wickham H (2016). _ggplot2: Elegant Graphics for Data Analysis_.\nSpringer-Verlag New York. ISBN 978-3-319-24277-4,\n&lt;https://ggplot2.tidyverse.org&gt;.\n  - Wickham H (2023). _forcats: Tools for Working with Categorical Variables\n(Factors)_. R package version 1.0.0,\n&lt;https://CRAN.R-project.org/package=forcats&gt;.\n  - Wickham H (2023). _stringr: Simple, Consistent Wrappers for Common String\nOperations_. R package version 1.5.1,\n&lt;https://CRAN.R-project.org/package=stringr&gt;.\n  - Wickham H, Averick M, Bryan J, Chang W, McGowan LD, François R, Grolemund G,\nHayes A, Henry L, Hester J, Kuhn M, Pedersen TL, Miller E, Bache SM, Müller K,\nOoms J, Robinson D, Seidel DP, Spinu V, Takahashi K, Vaughan D, Wilke C, Woo K,\nYutani H (2019). \"Welcome to the tidyverse.\" _Journal of Open Source Software_,\n*4*(43), 1686. doi:10.21105/joss.01686 &lt;https://doi.org/10.21105/joss.01686&gt;.\n  - Wickham H, François R, Henry L, Müller K, Vaughan D (2023). _dplyr: A Grammar\nof Data Manipulation_. R package version 1.1.3,\n&lt;https://CRAN.R-project.org/package=dplyr&gt;.\n  - Wickham H, Henry L (2023). _purrr: Functional Programming Tools_. R package\nversion 1.0.2, &lt;https://CRAN.R-project.org/package=purrr&gt;.\n  - Wickham H, Hester J, Bryan J (2023). _readr: Read Rectangular Text Data_. R\npackage version 2.1.4, &lt;https://CRAN.R-project.org/package=readr&gt;.\n  - Wickham H, Vaughan D, Girlich M (2023). _tidyr: Tidy Messy Data_. R package\nversion 1.3.0, &lt;https://CRAN.R-project.org/package=tidyr&gt;.\n  - Zeileis A, Grothendieck G (2005). \"zoo: S3 Infrastructure for Regular and\nIrregular Time Series.\" _Journal of Statistical Software_, *14*(6), 1-27.\ndoi:10.18637/jss.v014.i06 &lt;https://doi.org/10.18637/jss.v014.i06&gt;.\n  - Zeileis A, Hothorn T (2002). \"Diagnostic Checking in Regression\nRelationships.\" _R News_, *2*(3), 7-10.\n&lt;https://CRAN.R-project.org/doc/Rnews/&gt;.\n  - Zhu H (2021). _kableExtra: Construct Complex Table with 'kable' and Pipe\nSyntax_. R package version 1.3.4,\n&lt;https://CRAN.R-project.org/package=kableExtra&gt;."
  },
  {
    "objectID": "SEM.html#referências",
    "href": "SEM.html#referências",
    "title": "SEM",
    "section": "Referências",
    "text": "Referências\nhttps://repositorio.ufba.br/bitstream/ri/17684/1/ebook_SEM_2012.pdf\nhttps://statplace.com.br/blog/modelagem-de-equacoes-estruturais/"
  },
  {
    "objectID": "lista_8.html#a-regressão-linear",
    "href": "lista_8.html#a-regressão-linear",
    "title": "9  Lista 8 - CFA e Path Analysis",
    "section": "9.1 a) Regressão linear",
    "text": "9.1 a) Regressão linear\n\n\n\n\n\n\nExercício\n\n\n\nVeja o banco de dados DADOSPATH.sav. Nele temos os dados de Idade, IMC, numero de treinos e sociabilidade (questionario) de um grupo de 94 pessoas. Faca um modelo de regressao linear tendo como variavel dependente o numero de Treinos e as demais variaveis como independentes.\n\n\n\noriginal = read.spss(\"DADOS PATH.sav\", to.data.frame=TRUE)\nmodelo_1 = lm(Treinos ~ Idade + IMC1 + Sociabilidade, data = original)\n\nModelo:\n\\[\nY \\sim \\beta_0 + \\beta_1*idade + \\beta_2*IMC1 + \\beta_3*Sociabilidade + \\epsilon\n\\]\n\nResultados\n\nkable(summary(modelo_1)$coef)\n\n\n\n\n\nEstimate\nStd. Error\nt value\nPr(&gt;|t|)\n\n\n\n\n(Intercept)\n78.0103771\n33.1315541\n2.3545644\n0.0207191\n\n\nIdade\n1.9071028\n0.5479748\n3.4802749\n0.0007745\n\n\nIMC1\n-2.8021799\n1.1809989\n-2.3727202\n0.0197865\n\n\nSociabilidade\n0.5177685\n0.5903261\n0.8770889\n0.3827736\n\n\n\n\n\n\n\nUm modelo linear (estimado usando Mínimos Quadrados Ordinários - OLS) foi utilizado para prever a variável Treinos com base nas variáveis Idade, IMC1 e Sociabilidade. O modelo explica uma proporção estatisticamente significativa e moderada da variância (R² = 0,14, F(3, 90) = 5,06, p = 0,003, R² ajustado = 0,12). Dentro desse modelo: • O efeito da Idade é estatisticamente significativo e positivo (beta = 1,91, IC 95% [0,82, 3,00], t(90) = 3,48, p &lt; 0,001; Beta padronizado = 0,35, IC 95% [0,15, 0,56]) • O efeito do IMC1 é estatisticamente significativo e negativo (beta = -2,80, IC 95% [-5,15, -0,46], t(90) = -2,37, p = 0,020; Beta padronizado = -0,24, IC 95% [-0,44, -0,04]) • O efeito da Sociabilidade é estatisticamente não significativo e positivo (beta = 0,52, IC 95% [-0,66, 1,69], t(90) = 0,88, p = 0,383; Beta padronizado = 0,09, IC 95% [-0,11, 0,28]) Parâmetros padronizados foram obtidos ajustando o modelo a uma versão padronizada do conjunto de dados. Intervalos de Confiança (ICs) de 95% e valores-p foram calculados usando uma aproximação da distribuição t de Wald."
  },
  {
    "objectID": "lista_8.html#b-path-analysis",
    "href": "lista_8.html#b-path-analysis",
    "title": "9  Lista 8 - CFA e Path Analysis",
    "section": "9.2 b) Path Analysis",
    "text": "9.2 b) Path Analysis\n\n\n\n\n\n\nExercício\n\n\n\nCom base no mesmo banco acima faça uma Path Analysis e monte um diagrama no AMOS R. Compare os resultados com os dados encontrados na regressão linear.\n\n\n\npath_1 = \"Treinos ~ Idade + IMC1 + Sociabilidade\"\n\n\npath_model_1 = sem(\n  model = path_1,\n  data = original,\n)\n\n\nTabela com os resultados\nComo sempre, podemos utilizar a função summary() para retornar um resumo com os resultados do modelo\n\nsummary(path_model_1) # posso colocar o parametro fit.measures = TRUE para obter os valores de aderência do modelo\n\nlavaan 0.6.16 ended normally after 1 iteration\n\n  Estimator                                         ML\n  Optimization method                           NLMINB\n  Number of model parameters                         4\n\n  Number of observations                            94\n\nModel Test User Model:\n                                                      \n  Test statistic                                 0.000\n  Degrees of freedom                                 0\n\nParameter Estimates:\n\n  Standard errors                             Standard\n  Information                                 Expected\n  Information saturated (h1) model          Structured\n\nRegressions:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n  Treinos ~                                           \n    Idade             1.907    0.536    3.557    0.000\n    IMC1             -2.802    1.156   -2.425    0.015\n    Sociabilidade     0.518    0.578    0.896    0.370\n\nVariances:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n   .Treinos        2050.999  299.169    6.856    0.000\n\n\nNo caso da path analisys recomendamos utilizar a função parameterEstimates() do pacote lavaan para ter uma tabela mais direta com os resultados dos estimadores.\n\nkable(parameterEstimates(path_model_1))\n\n\n\n\nlhs\nop\nrhs\nest\nse\nz\npvalue\nci.lower\nci.upper\n\n\n\n\nTreinos\n~\nIdade\n1.9071028\n0.5361890\n3.5567736\n0.0003754\n0.8561917\n2.9580139\n\n\nTreinos\n~\nIMC1\n-2.8021799\n1.1555981\n-2.4248741\n0.0153137\n-5.0671106\n-0.5372493\n\n\nTreinos\n~\nSociabilidade\n0.5177685\n0.5776294\n0.8963679\n0.3700563\n-0.6143644\n1.6499014\n\n\nTreinos\n~~\nTreinos\n2050.9987436\n299.1689143\n6.8556546\n0.0000000\n1464.6384463\n2637.3590409\n\n\nIdade\n~~\nIdade\n82.5840878\n0.0000000\nNA\nNA\n82.5840878\n82.5840878\n\n\nIdade\n~~\nIMC1\n10.7872961\n0.0000000\nNA\nNA\n10.7872961\n10.7872961\n\n\nIdade\n~~\nSociabilidade\n3.7635808\n0.0000000\nNA\nNA\n3.7635808\n3.7635808\n\n\nIMC1\n~~\nIMC1\n17.7567863\n0.0000000\nNA\nNA\n17.7567863\n17.7567863\n\n\nIMC1\n~~\nSociabilidade\n1.2498636\n0.0000000\nNA\nNA\n1.2498636\n1.2498636\n\n\nSociabilidade\n~~\nSociabilidade\n65.6008375\n0.0000000\nNA\nNA\n65.6008375\n65.6008375\n\n\n\n\n\n\n\nOs resultados foram os mesmos obtidos tanto pela path analysis quanto pela regressão linear simples.\n\n\nIndices de qualidade do modelo\n\nmodel_performance(path_model_1, metrics = c(\"Chi2\", \"Chi2_df\", \"NFI\", \"NNFI\", \"CFI\", \"RMSEA\", \"AIC\", \"BIC\"))\n\n# Indices of model performance\n\nChi2(0) |   NFI |  NNFI |   CFI | RMSEA |     AIC |      BIC\n------------------------------------------------------------\n0.000   | 1.000 | 1.000 | 1.000 | 0.000 | 991.612 | 1001.785\n\nAIC(path_model_1)\n\n[1] 991.6122\n\n\n\n\nDiagrama da path analysis\n\nP &lt;- semPaths(\n          object = path_model_1,\n          what = \"path\",\n          whatLabels = \"par\",\n          style = \"ram\",\n          layout = \"tree\",\n          rotation = 2,\n          sizeMan = 7,\n          sizeLat = 7,\n          color = \"lightgray\",\n          edge.label.cex = 1.2,\n          label.cex = 1.3\n)"
  },
  {
    "objectID": "lista_8.html#c-cfa",
    "href": "lista_8.html#c-cfa",
    "title": "9  Lista 8 - CFA e Path Analysis",
    "section": "9.3 c) CFA",
    "text": "9.3 c) CFA\n\n\n\n\n\n\nExercício\n\n\n\nVeja o banco de dados Fatorial escala.sav. Faça uma Análise fatorial confirmatória (CFA) gerando os seguintes fatores com base no questionário de apego a amigos (IAA).\n\n\nSegundo a teoria esperada, os fatores teriam o seguinte agrupamento: a. Confianca – Q13 Q14 Q15 b. Alienacao – Q1 Q2 Q3 Monte o diagrama e discuta a qualidade do modelo e suas limitações caso existam.\nEquação do Modelo 1:\ncfa_eq = \" Alienação =~ IAa1 + IAa2 + IAa3 Confiança =~ IAa13 + IAa14 + IAa15  \"\nAnálise Fatorial Confirmatória do modelo 1\ncfa_modelo = cfa(   model = cfa_eq,   data = dados_CFA,   std.lv = TRUE  )\n\ndados_CFA = read.spss(\"fatorial CFA.sav\", to.data.frame=TRUE)\n\n\ncfa_eq = \"\nAlienação =~ IAa1 + IAa2 + IAa3\nConfiança =~ IAa13 + IAa14 + IAa15\n\n\"\n\n\ncfa_modelo = cfa(\n  model = cfa_eq,\n  data = dados_CFA,\n  std.lv = TRUE #If TRUE, the metric of each latent variable is determined by fixing their (residual) variances to 1.0. If FALSE, the metric of each latent variable is determined by fixing the factor loading of the first indicator to 1.0.\n  \n)\n\n\nResultados do modelo sem covariâncias entre os resíduos (modelo 1)\n\nsummary(cfa_modelo) # posso colocar no summary o parametro fit.measures = TRUE\n\nlavaan 0.6.16 ended normally after 18 iterations\n\n  Estimator                                         ML\n  Optimization method                           NLMINB\n  Number of model parameters                        13\n\n                                                  Used       Total\n  Number of observations                           347         348\n\nModel Test User Model:\n                                                      \n  Test statistic                                39.166\n  Degrees of freedom                                 8\n  P-value (Chi-square)                           0.000\n\nParameter Estimates:\n\n  Standard errors                             Standard\n  Information                                 Expected\n  Information saturated (h1) model          Structured\n\nLatent Variables:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n  Alienação =~                                        \n    IAa1              0.578    0.069    8.408    0.000\n    IAa2              0.842    0.069   12.135    0.000\n    IAa3              0.423    0.051    8.278    0.000\n  Confiança =~                                        \n    IAa13             0.580    0.044   13.279    0.000\n    IAa14             0.660    0.052   12.652    0.000\n    IAa15             0.586    0.053   11.105    0.000\n\nCovariances:\n                  Estimate  Std.Err  z-value  P(&gt;|z|)\n  Alienação ~~                                       \n    Confiança        0.865    0.051   16.807    0.000\n\nVariances:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n   .IAa1              1.023    0.088   11.607    0.000\n   .IAa2              0.676    0.089    7.627    0.000\n   .IAa3              0.568    0.049   11.667    0.000\n   .IAa13             0.316    0.036    8.898    0.000\n   .IAa14             0.485    0.051    9.564    0.000\n   .IAa15             0.564    0.052   10.767    0.000\n    Alienação         1.000                           \n    Confiança         1.000                           \n\n\n\nkable(parameterEstimates(cfa_modelo))\n\n\n\n\nlhs\nop\nrhs\nest\nse\nz\npvalue\nci.lower\nci.upper\n\n\n\n\nAlienação\n=~\nIAa1\n0.5783085\n0.0687768\n8.408481\n0\n0.4435084\n0.7131086\n\n\nAlienação\n=~\nIAa2\n0.8419500\n0.0693835\n12.134735\n0\n0.7059609\n0.9779391\n\n\nAlienação\n=~\nIAa3\n0.4226729\n0.0510624\n8.277581\n0\n0.3225925\n0.5227533\n\n\nConfiança\n=~\nIAa13\n0.5796173\n0.0436497\n13.278840\n0\n0.4940655\n0.6651691\n\n\nConfiança\n=~\nIAa14\n0.6603480\n0.0521921\n12.652247\n0\n0.5580533\n0.7626427\n\n\nConfiança\n=~\nIAa15\n0.5856667\n0.0527386\n11.105077\n0\n0.4823008\n0.6890325\n\n\nIAa1\n~~\nIAa1\n1.0234312\n0.0881741\n11.606933\n0\n0.8506131\n1.1962493\n\n\nIAa2\n~~\nIAa2\n0.6763156\n0.0886784\n7.626611\n0\n0.5025092\n0.8501221\n\n\nIAa3\n~~\nIAa3\n0.5677370\n0.0486609\n11.667220\n0\n0.4723635\n0.6631105\n\n\nIAa13\n~~\nIAa13\n0.3160382\n0.0355192\n8.897671\n0\n0.2464219\n0.3856546\n\n\nIAa14\n~~\nIAa14\n0.4851673\n0.0507280\n9.564088\n0\n0.3857422\n0.5845925\n\n\nIAa15\n~~\nIAa15\n0.5636709\n0.0523500\n10.767362\n0\n0.4610669\n0.6662750\n\n\nAlienação\n~~\nAlienação\n1.0000000\n0.0000000\nNA\nNA\n1.0000000\n1.0000000\n\n\nConfiança\n~~\nConfiança\n1.0000000\n0.0000000\nNA\nNA\n1.0000000\n1.0000000\n\n\nAlienação\n~~\nConfiança\n0.8646695\n0.0514471\n16.806951\n0\n0.7638349\n0.9655040\n\n\n\n\n\n\n\nOs resultados da análise de equações estruturais indicam que o modelo ajustado apresenta um bom ajuste aos dados observados (χ² = 39,166, df = 8, p &lt; 0,001). O modelo envolve duas variáveis latentes, “Alienação” e “Confiança”, e suas variáveis observadas.\nOs coeficientes de carga (estimates) indicam que as perguntas associadas a “Alienação” (IAa1, IAa2, IAa3) e “Confiança” (IAa13, IAa14, IAa15) têm influências positivas significativas em suas respectivas variáveis latentes.\nAlém disso, a covariância entre “Alienação” e “Confiança” é estatisticamente significativa (estimate = 0,865, p &lt; 0,001), sugerindo uma relação entre essas duas dimensões.\nEsses resultados fornecem evidências de que o modelo proposto é estatisticamente significativo.\n\n\nÍndices de qualidade do modelo 1\n\nmodel_performance(cfa_modelo, metrics = c(\"Chi2\", \"Chi2_df\", \"NFI\", \"CFI\", \"RMSEA\", \"p_RMSEA\", \"AIC\", \"BIC\", \"NNFI\") )\n\n# Indices of model performance\n\nChi2(8) |   NFI |   CFI | RMSEA | p (RMSEA) |      AIC |      BIC |  NNFI\n-------------------------------------------------------------------------\n39.166  | 0.918 | 0.933 | 0.106 |     0.003 | 5402.476 | 5452.517 | 0.874\n\n\nOs resultados dos índices de qualidade indicam que o modelo apresenta uma adequada qualidade de aderência aos dados observados, conforme evidenciado pelos índices de ajuste (NFI, CFI) acima de 0.9. Apenas o NNFI (ou TFI) está abaixo de 0.9, indicando um bom ajuste relativo.\nNo entanto, o valor do RMSEA é alto (10%), indicando que o modelo pode ser aprimorado.\nOs valores de AIC e BIC serão utilizados para efeito de comparação com os modelos a seguir.\n\n\nDiagrama da CFA com o modelo 1\n\nplot_CFA &lt;- semPaths(\n          object = cfa_modelo,\n          what = \"path\",\n          whatLabels = \"par\",\n          style = \"ram\",\n          layout = \"tree\",\n          rotation = 2,\n          sizeMan = 7,\n          sizeLat = 7,\n          color = \"lightgray\",\n          edge.label.cex = 1.2,\n          label.cex = 1.3\n)\n\n\n\n\n\n\nVerificar os índices de modificações do modelo 1\nOs índices de modificação podem ser obtidos utilizando a função modindices(). Por padrão, os índices de modificação são impressos para cada parâmetro não livre (ou fixado como zero). Os índices de modificação são complementados pelos valores de mudança esperada nos parâmetros (EPC) (coluna epc). As últimas três colunas contêm os valores padronizados de EPC (sepc.lv: padronização apenas das variáveis latentes; sepc.all: padronização de todas as variáveis; sepc.nox: padronização de todas, exceto variáveis observadas exógenas).\n\nkable(modificationindices(cfa_modelo, sort = TRUE, minimum.value = 5))\n\n\n\n\n\nlhs\nop\nrhs\nmi\nepc\nsepc.lv\nsepc.all\nsepc.nox\n\n\n\n\n34\nIAa13\n~~\nIAa14\n18.245523\n0.1825252\n0.1825252\n0.4661302\n0.4661302\n\n\n18\nAlienação\n=~\nIAa15\n18.245517\n0.9569991\n0.9569991\n1.0050447\n1.0050447\n\n\n29\nIAa2\n~~\nIAa14\n17.160433\n-0.2043919\n-0.2043919\n-0.3568151\n-0.3568151\n\n\n30\nIAa2\n~~\nIAa15\n10.461405\n0.1539148\n0.1539148\n0.2492832\n0.2492832\n\n\n20\nConfiança\n=~\nIAa2\n8.403845\n-1.6415789\n-1.6415789\n-1.3947817\n-1.3947817\n\n\n23\nIAa1\n~~\nIAa3\n8.403843\n-0.1390871\n-0.1390871\n-0.1824669\n-0.1824669\n\n\n35\nIAa13\n~~\nIAa15\n5.006171\n-0.0840609\n-0.0840609\n-0.1991642\n-0.1991642\n\n\n17\nAlienação\n=~\nIAa14\n5.006165\n-0.5603084\n-0.5603084\n-0.5837728\n-0.5837728\n\n\n\n\n\n\n\n\n\nNovo modelo com a covariância dos resíduos (modelo 2)\n\ncfa_eq_2 = \"\nAlienação =~ IAa1 + IAa2 + IAa3\nConfiança =~ IAa13 + IAa14 + IAa15\n\n# Covariancia dos resíduos\nIAa1 ~~ IAa3\nIAa13 ~~ IAa14\nIAa13 ~~ IAa15\n\n\"\n\n\ncfa_modelo_2 = cfa(\n  model = cfa_eq_2,\n  data = dados_CFA,\n  std.lv = TRUE\n)\n\nEquação do Modelo 2:\ncfa_eq_2 = \" Alienação =~ IAa1 + IAa2 + IAa3 Confiança =~ IAa13 + IAa14 + IAa15  # Covariancia dos resíduos IAa1 ~~ IAa3  IAa13 ~~ IAa14 IAa13 ~~ IAa15  \"\nAnálise Fatorial Confirmatória do modelo 2\ncfa_modelo_2 = cfa(   model = cfa_eq_2,   data = dados_CFA,   std.lv = TRUE    )\n\n\nResultados modelo 2\n\nsummary(cfa_modelo_2) # posso colocar no summary o parametro fit.measures = TRUE\n\nlavaan 0.6.16 ended normally after 24 iterations\n\n  Estimator                                         ML\n  Optimization method                           NLMINB\n  Number of model parameters                        16\n\n                                                  Used       Total\n  Number of observations                           347         348\n\nModel Test User Model:\n                                                      \n  Test statistic                                14.194\n  Degrees of freedom                                 5\n  P-value (Chi-square)                           0.014\n\nParameter Estimates:\n\n  Standard errors                             Standard\n  Information                                 Expected\n  Information saturated (h1) model          Structured\n\nLatent Variables:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n  Alienação =~                                        \n    IAa1              0.625    0.069    9.009    0.000\n    IAa2              0.844    0.066   12.774    0.000\n    IAa3              0.440    0.052    8.484    0.000\n  Confiança =~                                        \n    IAa13             0.486    0.054    9.010    0.000\n    IAa14             0.558    0.057    9.744    0.000\n    IAa15             0.627    0.058   10.741    0.000\n\nCovariances:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n .IAa1 ~~                                             \n   .IAa3             -0.131    0.047   -2.812    0.005\n .IAa13 ~~                                            \n   .IAa14             0.156    0.042    3.700    0.000\n   .IAa15             0.005    0.037    0.123    0.902\n  Alienação ~~                                        \n    Confiança         0.945    0.063   15.041    0.000\n\nVariances:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n   .IAa1              0.968    0.088   11.049    0.000\n   .IAa2              0.674    0.081    8.299    0.000\n   .IAa3              0.553    0.049   11.303    0.000\n   .IAa13             0.416    0.048    8.717    0.000\n   .IAa14             0.609    0.059   10.323    0.000\n   .IAa15             0.514    0.060    8.497    0.000\n    Alienação         1.000                           \n    Confiança         1.000                           \n\n\n\nkable(parameterEstimates(cfa_modelo_2))\n\n\n\n\nlhs\nop\nrhs\nest\nse\nz\npvalue\nci.lower\nci.upper\n\n\n\n\nAlienação\n=~\nIAa1\n0.6246375\n0.0693348\n9.0090043\n0.0000000\n0.4887438\n0.7605313\n\n\nAlienação\n=~\nIAa2\n0.8436173\n0.0660435\n12.7736683\n0.0000000\n0.7141745\n0.9730601\n\n\nAlienação\n=~\nIAa3\n0.4398298\n0.0518412\n8.4841676\n0.0000000\n0.3382228\n0.5414367\n\n\nConfiança\n=~\nIAa13\n0.4855333\n0.0538885\n9.0099663\n0.0000000\n0.3799138\n0.5911527\n\n\nConfiança\n=~\nIAa14\n0.5583551\n0.0573047\n9.7436136\n0.0000000\n0.4460399\n0.6706703\n\n\nConfiança\n=~\nIAa15\n0.6267943\n0.0583571\n10.7406769\n0.0000000\n0.5124166\n0.7411721\n\n\nIAa1\n~~\nIAa3\n-0.1314725\n0.0467540\n-2.8120052\n0.0049234\n-0.2231086\n-0.0398363\n\n\nIAa13\n~~\nIAa14\n0.1558199\n0.0421126\n3.7000779\n0.0002155\n0.0732807\n0.2383591\n\n\nIAa13\n~~\nIAa15\n0.0045594\n0.0370060\n0.1232056\n0.9019443\n-0.0679712\n0.0770899\n\n\nIAa1\n~~\nIAa1\n0.9676998\n0.0875801\n11.0493149\n0.0000000\n0.7960460\n1.1393536\n\n\nIAa2\n~~\nIAa2\n0.6735053\n0.0811578\n8.2987178\n0.0000000\n0.5144390\n0.8325716\n\n\nIAa3\n~~\nIAa3\n0.5529392\n0.0489190\n11.3031626\n0.0000000\n0.4570597\n0.6488186\n\n\nIAa13\n~~\nIAa13\n0.4162519\n0.0477495\n8.7174157\n0.0000000\n0.3226647\n0.5098391\n\n\nIAa14\n~~\nIAa14\n0.6094664\n0.0590382\n10.3232593\n0.0000000\n0.4937537\n0.7251790\n\n\nIAa15\n~~\nIAa15\n0.5138053\n0.0604718\n8.4966149\n0.0000000\n0.3952828\n0.6323277\n\n\nAlienação\n~~\nAlienação\n1.0000000\n0.0000000\nNA\nNA\n1.0000000\n1.0000000\n\n\nConfiança\n~~\nConfiança\n1.0000000\n0.0000000\nNA\nNA\n1.0000000\n1.0000000\n\n\nAlienação\n~~\nConfiança\n0.9447949\n0.0628146\n15.0410074\n0.0000000\n0.8216805\n1.0679092\n\n\n\n\n\n\n\nOs resultados da análise indicam que o modelo apresenta um razoável ajuste aos dados observados, conforme evidenciado pelos índices de ajuste, embora o teste qui-quadrado seja estatisticamente significativo (χ² = 14.194, df = 5, p = 0.014), indicando diferenças entre o modelo e os dados.\nAs cargas fatoriais para os indicadores associados às variáveis latentes “Alienação” e “Confiança” são todas estatisticamente significativas (p &lt; 0.001), indicando que esses indicadores têm uma relação com suas respectivas variáveis latentes.\n\n\nÍndices de qualidade do modelo 2\n\nmodel_performance(cfa_modelo_2, metrics = c(\"Chi2\", \"Chi2_df\", \"NFI\", \"CFI\", \"RMSEA\", \"p_RMSEA\", \"AIC\", \"BIC\", \"NNFI\"))\n\n# Indices of model performance\n\nChi2(5) |   NFI |   CFI | RMSEA | p (RMSEA) |      AIC |      BIC |  NNFI\n-------------------------------------------------------------------------\n14.194  | 0.970 | 0.980 | 0.073 |     0.165 | 5383.504 | 5445.093 | 0.940\n\n\nOs resultados dos índices de qualidade indicam que o modelo apresenta uma adequada qualidade de aderência aos dados observados, conforme evidenciado pelos índices de ajuste (NFI, CFI e NNFI) acima de 0.9.\nNo entanto, o valor do RMSEA é moderado (7%), indicando que o modelo pode ser aprimorado.\nOs valores de AIC e BIC serão utilizados para efeito de comparação com os modelos a seguir.\n\n\nDiagrama do modelo 2\n\nplot_CFA &lt;- semPaths(\n          object = cfa_modelo_2,\n          what = \"path\",\n          whatLabels = \"par\",\n          style = \"ram\",\n          layout = \"tree\",\n          rotation = 2,\n          sizeMan = 7,\n          sizeLat = 7,\n          color = \"lightgray\",\n          edge.label.cex = 1.2,\n          label.cex = 1.3\n)\n\n\n\n\n\n\nComparação entre os modelos\n\ncompare_performance(cfa_modelo, cfa_modelo_2, \n                    metrics = c(\"NFI\", \"CFI\", \"RMSEA\", \"p_RMSEA\", \"AIC\", \"BIC\", \"NNFI\"),\n                    rank = TRUE, verbose = F)\n\n# Comparison of Model Performance Indices\n\nName         |  Model |   NFI |   CFI | RMSEA | p (RMSEA) |  NNFI | AIC weights | BIC weights | Performance-Score\n-----------------------------------------------------------------------------------------------------------------\ncfa_modelo_2 | lavaan | 0.970 | 0.980 | 0.073 |     0.165 | 0.940 |       1.000 |       0.976 |            85.71%\ncfa_modelo   | lavaan | 0.918 | 0.933 | 0.106 |     0.003 | 0.874 |    7.59e-05 |       0.024 |            14.29%\n\n\nO modelo_2 demonstra superioridade em relação ao modelo_1 com base nos critérios de ajuste avaliados."
  },
  {
    "objectID": "lista_8.html#complementar-modelo-com-apenas-um-fator-latente-modelo-3",
    "href": "lista_8.html#complementar-modelo-com-apenas-um-fator-latente-modelo-3",
    "title": "9  Lista 8 - CFA e Path Analysis",
    "section": "9.4 Complementar: Modelo com apenas um fator latente (modelo 3)",
    "text": "9.4 Complementar: Modelo com apenas um fator latente (modelo 3)\n\ncfa_eq_3 = \"\nF1 =~ IAa1 + IAa2 + IAa3 + IAa13 + IAa14 + IAa15\n\"\n\n\ncfa_modelo_3 = cfa(\n  model = cfa_eq_3,\n  data = dados_CFA,\n  std.lv = TRUE\n)\n\nEquação do modelo 3:\ncfa_eq_3 = \" F1 =~ IAa1 + IAa2 + IAa3 + IAa13 + IAa14 + IAa15 \"\nAnálise Fatorial Confirmatória do modelo 2\ncfa_modelo_3 = cfa(   model = cfa_eq_3,   data = dados_CFA,   std.lv = TRUE    )\n\nResultados do modelo 3\n\nkable(parameterEstimates(cfa_modelo_3))\n\n\n\n\nlhs\nop\nrhs\nest\nse\nz\npvalue\nci.lower\nci.upper\n\n\n\n\nF1\n=~\nIAa1\n0.5580340\n0.0664300\n8.400335\n0\n0.4278336\n0.6882343\n\n\nF1\n=~\nIAa2\n0.7651182\n0.0637750\n11.997154\n0\n0.6401216\n0.8901149\n\n\nF1\n=~\nIAa3\n0.4044799\n0.0493864\n8.190103\n0\n0.3076843\n0.5012755\n\n\nF1\n=~\nIAa13\n0.5564023\n0.0432259\n12.871965\n0\n0.4716811\n0.6411235\n\n\nF1\n=~\nIAa14\n0.6400430\n0.0517363\n12.371268\n0\n0.5386419\n0.7414442\n\n\nF1\n=~\nIAa15\n0.5959511\n0.0519930\n11.462144\n0\n0.4940467\n0.6978555\n\n\nIAa1\n~~\nIAa1\n1.0464704\n0.0865635\n12.089050\n0\n0.8768091\n1.2161317\n\n\nIAa2\n~~\nIAa2\n0.7997900\n0.0764096\n10.467135\n0\n0.6500299\n0.9495502\n\n\nIAa3\n~~\nIAa3\n0.5827853\n0.0479619\n12.151008\n0\n0.4887817\n0.6767889\n\n\nIAa13\n~~\nIAa13\n0.3424110\n0.0348598\n9.822517\n0\n0.2740870\n0.4107349\n\n\nIAa14\n~~\nIAa14\n0.5115718\n0.0501136\n10.208248\n0\n0.4133510\n0.6097926\n\n\nIAa15\n~~\nIAa15\n0.5515190\n0.0510740\n10.798424\n0\n0.4514157\n0.6516222\n\n\nF1\n~~\nF1\n1.0000000\n0.0000000\nNA\nNA\n1.0000000\n1.0000000\n\n\n\n\n\n\n\nO modelo de uma única variável latente “F1” apresenta um ajuste geral adequado aos dados, conforme indicado pelo teste qui-quadrado significativo (χ² = 45.034, df = 9, p = 0.000).\nAs cargas fatoriais dos indicadores para “F1” são todas estatisticamente significativas (p &lt; 0.001), indicando que essas variáveis observadas têm uma relação com a variável latente “F1”.\n\n\nÍndices de qualidade do modelo 3\n\nmodel_performance(cfa_modelo_3, metrics = c(\"Chi2\", \"Chi2_df\", \"NFI\", \"CFI\", \"RMSEA\", \"p_RMSEA\", \"AIC\", \"BIC\", \"NNFI\") )\n\n# Indices of model performance\n\nChi2(9) |   NFI |   CFI | RMSEA | p (RMSEA) |      AIC |      BIC |  NNFI\n-------------------------------------------------------------------------\n45.034  | 0.906 | 0.922 | 0.107 |     0.001 | 5406.344 | 5452.536 | 0.870\n\n\n\n\nDiagrama do modelo 3\n\nplot_CFA &lt;- semPaths(\n          object = cfa_modelo_3,\n          what = \"path\",\n          whatLabels = \"par\",\n          style = \"ram\",\n          layout = \"tree\",\n          rotation = 2,\n          sizeMan = 7,\n          sizeLat = 7,\n          color = \"lightgray\",\n          edge.label.cex = 1.2,\n          label.cex = 1.3\n)\n\n\n\n\n\n\nÍndices de modificação para o modelo\n\nkable(modificationindices(cfa_modelo_3, standardized = FALSE, minimum.value = 5))\n\n\n\n\n\nlhs\nop\nrhs\nmi\nepc\n\n\n\n\n16\nIAa1\n~~\nIAa13\n6.419170\n-0.1034145\n\n\n19\nIAa2\n~~\nIAa3\n5.260435\n0.1017547\n\n\n21\nIAa2\n~~\nIAa14\n19.900038\n-0.2224777\n\n\n22\nIAa2\n~~\nIAa15\n6.284104\n0.1223301\n\n\n26\nIAa13\n~~\nIAa14\n24.013115\n0.1712177"
  },
  {
    "objectID": "lista_8.html#modelo-4-com-covariância-entre-os-resíduos",
    "href": "lista_8.html#modelo-4-com-covariância-entre-os-resíduos",
    "title": "9  Lista 8 - CFA e Path Analysis",
    "section": "9.5 Modelo 4 com covariância entre os resíduos",
    "text": "9.5 Modelo 4 com covariância entre os resíduos\n\ncfa_eq_4 = \"\nF1 =~ IAa1 + IAa2 + IAa3 + IAa13 + IAa14 + IAa15\n\n#Covariância dos resíduos\nIAa2    ~~  IAa14\nIAa13   ~~  IAa14\n\"\n\nAnálise Fatorial Confirmatória do modelo 4\n\ncfa_modelo_4 = cfa(\n  model = cfa_eq_4,\n  data = dados_CFA,\n  std.lv = TRUE\n)\n\n\nResultados do modelo 4\n\nkable(parameterEstimates(cfa_modelo_4))\n\n\n\n\nlhs\nop\nrhs\nest\nse\nz\npvalue\nci.lower\nci.upper\n\n\n\n\nF1\n=~\nIAa1\n0.5755782\n0.0658579\n8.739696\n0.0000000\n0.4464990\n0.7046573\n\n\nF1\n=~\nIAa2\n0.8812882\n0.0659778\n13.357336\n0.0000000\n0.7519740\n1.0106024\n\n\nF1\n=~\nIAa3\n0.4106200\n0.0490163\n8.377216\n0.0000000\n0.3145499\n0.5066902\n\n\nF1\n=~\nIAa13\n0.4773285\n0.0461558\n10.341675\n0.0000000\n0.3868648\n0.5677923\n\n\nF1\n=~\nIAa14\n0.6235655\n0.0604044\n10.323181\n0.0000000\n0.5051751\n0.7419560\n\n\nF1\n=~\nIAa15\n0.5905868\n0.0525289\n11.243084\n0.0000000\n0.4876320\n0.6935415\n\n\nIAa2\n~~\nIAa14\n-0.1604716\n0.0490176\n-3.273757\n0.0010613\n-0.2565442\n-0.0643989\n\n\nIAa13\n~~\nIAa14\n0.1249518\n0.0402391\n3.105235\n0.0019013\n0.0460846\n0.2038189\n\n\nIAa1\n~~\nIAa1\n1.0265817\n0.0852570\n12.041031\n0.0000000\n0.8594811\n1.1936823\n\n\nIAa2\n~~\nIAa2\n0.6085266\n0.0820552\n7.416062\n0.0000000\n0.4477013\n0.7693519\n\n\nIAa3\n~~\nIAa3\n0.5777805\n0.0475147\n12.160028\n0.0000000\n0.4846534\n0.6709077\n\n\nIAa13\n~~\nIAa13\n0.4241519\n0.0395633\n10.720852\n0.0000000\n0.3466093\n0.5016945\n\n\nIAa14\n~~\nIAa14\n0.5298461\n0.0642606\n8.245273\n0.0000000\n0.4038976\n0.6557945\n\n\nIAa15\n~~\nIAa15\n0.5578837\n0.0519546\n10.737912\n0.0000000\n0.4560546\n0.6597128\n\n\nF1\n~~\nF1\n1.0000000\n0.0000000\nNA\nNA\n1.0000000\n1.0000000\n\n\n\n\n\n\n\nOs resultados do modelo sugerem que o ajuste do modelo aos dados é razoável, conforme indicado pelo teste qui-quadrado (χ² = 12.216, df = 7, p = 0.094). O modelo envolve uma única variável latente “F1,” e por seis variáveis observadas (IAa1, IAa2, IAa3, IAa13, IAa14, IAa15). As cargas fatoriais associadas a cada indicador são todas estatisticamente significativas (p &lt; 0.001), indicando uma relação entre esses indicadores e a variável latente “F1”. As variâncias dos indicadores também são significativas, sugerindo que cada indicador contribui para a variabilidade total da variável latente “F1”.\nAlém disso, há duas covariâncias estimadas entre os indicadores: uma entre IAa2 e IAa14, e outra entre IAa13 e IAa14. Essas covariâncias indicam associações adicionais entre os indicadores além daquelas explicadas pelas relações com a variável latente “F1”.\n\n\nÍndices de qualidade do modelo 4\n\nmodel_performance(cfa_modelo_4, metrics = c(\"Chi2\", \"Chi2_df\", \"NFI\", \"CFI\", \"RMSEA\", \"p_RMSEA\", \"AIC\", \"BIC\", \"NNFI\"))\n\n# Indices of model performance\n\nChi2(7) |   NFI |   CFI | RMSEA | p (RMSEA) |      AIC |      BIC |  NNFI\n-------------------------------------------------------------------------\n12.216  | 0.974 | 0.989 | 0.046 |     0.498 | 5377.526 | 5431.416 | 0.976\n\n\nO modelo apresenta índices NFI (0.974), CFI (0.989) e NNFI (0.976) próximos de 1, indicando um bom ajuste. O RMSEA (0.046) é baixo, sugerindo uma adequada aproximação do modelo aos dados.\n\n\nDiagrama do modelo 4\n\nplot_CFA &lt;- semPaths(\n          object = cfa_modelo_4,\n          what = \"path\",\n          whatLabels = \"par\",\n          style = \"ram\",\n          layout = \"tree\",\n          rotation = 2,\n          sizeMan = 7,\n          sizeLat = 7,\n          color = \"lightgray\",\n          edge.label.cex = 1.2,\n          label.cex = 1.3\n)\n\n\n\n\n\n\nComparação entre os modelos\n\ncompare_performance(cfa_modelo, cfa_modelo_2, cfa_modelo_3, cfa_modelo_4,\n                    metrics = c(\"NFI\", \"CFI\", \"RMSEA\", \"p_RMSEA\", \"AIC\", \"BIC\", \"NNFI\"),\n                    rank = TRUE, verbose = F)\n\n# Comparison of Model Performance Indices\n\nName         |  Model |   NFI |   CFI | RMSEA | p (RMSEA) |  NNFI | AIC weights | BIC weights | Performance-Score\n-----------------------------------------------------------------------------------------------------------------\ncfa_modelo_4 | lavaan | 0.974 | 0.989 | 0.046 |     0.498 | 0.976 |       0.952 |       0.999 |            85.71%\ncfa_modelo_2 | lavaan | 0.970 | 0.980 | 0.073 |     0.165 | 0.940 |       0.048 |       0.001 |            47.00%\ncfa_modelo   | lavaan | 0.918 | 0.933 | 0.106 |     0.003 | 0.874 |    3.64e-06 |    2.62e-05 |            19.27%\ncfa_modelo_3 | lavaan | 0.906 | 0.922 | 0.107 |     0.001 | 0.870 |    5.26e-07 |    2.59e-05 |            14.29%\n\n\nO modelo_4 demonstra superioridade em relação aos demais modelos com base nos critérios de ajuste avaliados.\n\n# Links de referência\n\n# https://rdrr.io/cran/performance/man/model_performance.lavaan.html\n# https://methodenlehre.github.io/SGSCLM-R-course/cfa-and-sem-with-lavaan.html#structural-equation-modelling-sem"
  },
  {
    "objectID": "lista_8.html#lista-8-resolvida-no-spss",
    "href": "lista_8.html#lista-8-resolvida-no-spss",
    "title": "9  Lista 8 - CFA e Path Analysis",
    "section": "9.6 Lista 8 resolvida no SPSS",
    "text": "9.6 Lista 8 resolvida no SPSS"
  },
  {
    "objectID": "lista_8.html#extras",
    "href": "lista_8.html#extras",
    "title": "9  Lista 8 - CFA e Path Analysis",
    "section": "9.7 Extras!",
    "text": "9.7 Extras!\n\nMais gráficos\n\nsemPaths(cfa_modelo, \"std\", weighted = FALSE, nCharNodes = 7, shapeMan = \"rectangle\",\n         sizeMan = 8, sizeMan2 = 5)"
  },
  {
    "objectID": "lista_8.html#referências",
    "href": "lista_8.html#referências",
    "title": "9  Lista 8 - CFA e Path Analysis",
    "section": "9.8 Referências",
    "text": "9.8 Referências\nhttps://www.jstatsoft.org/article/view/v048i02\nhttps://lavaan.ugent.be/tutorial/inspect.html"
  },
  {
    "objectID": "lista_8.html#versões-dos-pacotes",
    "href": "lista_8.html#versões-dos-pacotes",
    "title": "9  Lista 8 - CFA e Path Analysis",
    "section": "9.9 Versões dos pacotes",
    "text": "9.9 Versões dos pacotes\n\nreport(sessionInfo())\n\nAnalyses were conducted using the R Statistical language (version 4.3.1; R Core\nTeam, 2023) on Windows 11 x64 (build 22621), using the packages effectsize\n(version 0.8.6; Ben-Shachar MS et al., 2020), semPlot (version 1.1.6; Epskamp\nS, 2022), lubridate (version 1.9.3; Grolemund G, Wickham H, 2011), parameters\n(version 0.21.3; Lüdecke D et al., 2020), performance (version 0.10.8; Lüdecke\nD et al., 2021), easystats (version 0.6.0; Lüdecke D et al., 2022), see\n(version 0.8.1; Lüdecke D et al., 2021), insight (version 0.19.6; Lüdecke D et\nal., 2019), bayestestR (version 0.13.1; Makowski D et al., 2019), modelbased\n(version 0.8.6; Makowski D et al., 2020), report (version 0.5.7; Makowski D et\nal., 2023), correlation (version 0.8.4; Makowski D et al., 2022), tibble\n(version 3.2.1; Müller K, Wickham H, 2023), datawizard (version 0.9.0; Patil I\net al., 2022), foreign (version 0.8.85; R Core Team, 2023), lavaan (version\n0.6.16; Rosseel Y, 2012), ggplot2 (version 3.4.4; Wickham H, 2016), forcats\n(version 1.0.0; Wickham H, 2023), stringr (version 1.5.1; Wickham H, 2023),\ntidyverse (version 2.0.0; Wickham H et al., 2019), dplyr (version 1.1.3;\nWickham H et al., 2023), purrr (version 1.0.2; Wickham H, Henry L, 2023), readr\n(version 2.1.4; Wickham H et al., 2023), tidyr (version 1.3.0; Wickham H et\nal., 2023) and kableExtra (version 1.3.4; Zhu H, 2021).\n\nReferences\n----------\n  - Ben-Shachar MS, Lüdecke D, Makowski D (2020). \"effectsize: Estimation of\nEffect Size Indices and Standardized Parameters.\" _Journal of Open Source\nSoftware_, *5*(56), 2815. doi:10.21105/joss.02815\n&lt;https://doi.org/10.21105/joss.02815&gt;, &lt;https://doi.org/10.21105/joss.02815&gt;.\n  - Epskamp S (2022). _semPlot: Path Diagrams and Visual Analysis of Various SEM\nPackages' Output_. R package version 1.1.6,\n&lt;https://CRAN.R-project.org/package=semPlot&gt;.\n  - Grolemund G, Wickham H (2011). \"Dates and Times Made Easy with lubridate.\"\n_Journal of Statistical Software_, *40*(3), 1-25.\n&lt;https://www.jstatsoft.org/v40/i03/&gt;.\n  - Lüdecke D, Ben-Shachar M, Patil I, Makowski D (2020). \"Extracting, Computing\nand Exploring the Parameters of Statistical Models using R.\" _Journal of Open\nSource Software_, *5*(53), 2445. doi:10.21105/joss.02445\n&lt;https://doi.org/10.21105/joss.02445&gt;.\n  - Lüdecke D, Ben-Shachar M, Patil I, Waggoner P, Makowski D (2021).\n\"performance: An R Package for Assessment, Comparison and Testing of\nStatistical Models.\" _Journal of Open Source Software_, *6*(60), 3139.\ndoi:10.21105/joss.03139 &lt;https://doi.org/10.21105/joss.03139&gt;.\n  - Lüdecke D, Ben-Shachar M, Patil I, Wiernik B, Makowski D (2022). \"easystats:\nFramework for Easy Statistical Modeling, Visualization, and Reporting.\" _CRAN_.\nR package, &lt;https://easystats.github.io/easystats/&gt;.\n  - Lüdecke D, Patil I, Ben-Shachar M, Wiernik B, Waggoner P, Makowski D (2021).\n\"see: An R Package for Visualizing Statistical Models.\" _Journal of Open Source\nSoftware_, *6*(64), 3393. doi:10.21105/joss.03393\n&lt;https://doi.org/10.21105/joss.03393&gt;.\n  - Lüdecke D, Waggoner P, Makowski D (2019). \"insight: A Unified Interface to\nAccess Information from Model Objects in R.\" _Journal of Open Source Software_,\n*4*(38), 1412. doi:10.21105/joss.01412 &lt;https://doi.org/10.21105/joss.01412&gt;.\n  - Makowski D, Ben-Shachar M, Lüdecke D (2019). \"bayestestR: Describing Effects\nand their Uncertainty, Existence and Significance within the Bayesian\nFramework.\" _Journal of Open Source Software_, *4*(40), 1541.\ndoi:10.21105/joss.01541 &lt;https://doi.org/10.21105/joss.01541&gt;,\n&lt;https://joss.theoj.org/papers/10.21105/joss.01541&gt;.\n  - Makowski D, Ben-Shachar M, Patil I, Lüdecke D (2020). \"Estimation of\nModel-Based Predictions, Contrasts and Means.\" _CRAN_.\n&lt;https://github.com/easystats/modelbased&gt;.\n  - Makowski D, Lüdecke D, Patil I, Thériault R, Ben-Shachar M, Wiernik B (2023).\n\"Automated Results Reporting as a Practical Tool to Improve Reproducibility and\nMethodological Best Practices Adoption.\" _CRAN_.\n&lt;https://easystats.github.io/report/&gt;.\n  - Makowski D, Wiernik B, Patil I, Lüdecke D, Ben-Shachar M (2022).\n\"correlation: Methods for Correlation Analysis.\" Version 0.8.3,\n&lt;https://CRAN.R-project.org/package=correlation&gt;. Makowski D, Ben-Shachar M,\nPatil I, Lüdecke D (2020). \"Methods and Algorithms for Correlation Analysis in\nR.\" _Journal of Open Source Software_, *5*(51), 2306. doi:10.21105/joss.02306\n&lt;https://doi.org/10.21105/joss.02306&gt;,\n&lt;https://joss.theoj.org/papers/10.21105/joss.02306&gt;.\n  - Müller K, Wickham H (2023). _tibble: Simple Data Frames_. R package version\n3.2.1, &lt;https://CRAN.R-project.org/package=tibble&gt;.\n  - Patil I, Makowski D, Ben-Shachar M, Wiernik B, Bacher E, Lüdecke D (2022).\n\"datawizard: An R Package for Easy Data Preparation and Statistical\nTransformations.\" _Journal of Open Source Software_, *7*(78), 4684.\ndoi:10.21105/joss.04684 &lt;https://doi.org/10.21105/joss.04684&gt;.\n  - R Core Team (2023). _foreign: Read Data Stored by 'Minitab', 'S', 'SAS',\n'SPSS', 'Stata', 'Systat', 'Weka', 'dBase', ..._. R package version 0.8-85,\n&lt;https://CRAN.R-project.org/package=foreign&gt;.\n  - R Core Team (2023). _R: A Language and Environment for Statistical\nComputing_. R Foundation for Statistical Computing, Vienna, Austria.\n&lt;https://www.R-project.org/&gt;.\n  - Rosseel Y (2012). \"lavaan: An R Package for Structural Equation Modeling.\"\n_Journal of Statistical Software_, *48*(2), 1-36. doi:10.18637/jss.v048.i02\n&lt;https://doi.org/10.18637/jss.v048.i02&gt;.\n  - Wickham H (2016). _ggplot2: Elegant Graphics for Data Analysis_.\nSpringer-Verlag New York. ISBN 978-3-319-24277-4,\n&lt;https://ggplot2.tidyverse.org&gt;.\n  - Wickham H (2023). _forcats: Tools for Working with Categorical Variables\n(Factors)_. R package version 1.0.0,\n&lt;https://CRAN.R-project.org/package=forcats&gt;.\n  - Wickham H (2023). _stringr: Simple, Consistent Wrappers for Common String\nOperations_. R package version 1.5.1,\n&lt;https://CRAN.R-project.org/package=stringr&gt;.\n  - Wickham H, Averick M, Bryan J, Chang W, McGowan LD, François R, Grolemund G,\nHayes A, Henry L, Hester J, Kuhn M, Pedersen TL, Miller E, Bache SM, Müller K,\nOoms J, Robinson D, Seidel DP, Spinu V, Takahashi K, Vaughan D, Wilke C, Woo K,\nYutani H (2019). \"Welcome to the tidyverse.\" _Journal of Open Source Software_,\n*4*(43), 1686. doi:10.21105/joss.01686 &lt;https://doi.org/10.21105/joss.01686&gt;.\n  - Wickham H, François R, Henry L, Müller K, Vaughan D (2023). _dplyr: A Grammar\nof Data Manipulation_. R package version 1.1.3,\n&lt;https://CRAN.R-project.org/package=dplyr&gt;.\n  - Wickham H, Henry L (2023). _purrr: Functional Programming Tools_. R package\nversion 1.0.2, &lt;https://CRAN.R-project.org/package=purrr&gt;.\n  - Wickham H, Hester J, Bryan J (2023). _readr: Read Rectangular Text Data_. R\npackage version 2.1.4, &lt;https://CRAN.R-project.org/package=readr&gt;.\n  - Wickham H, Vaughan D, Girlich M (2023). _tidyr: Tidy Messy Data_. R package\nversion 1.3.0, &lt;https://CRAN.R-project.org/package=tidyr&gt;.\n  - Zhu H (2021). _kableExtra: Construct Complex Table with 'kable' and Pipe\nSyntax_. R package version 1.3.4,\n&lt;https://CRAN.R-project.org/package=kableExtra&gt;."
  },
  {
    "objectID": "lista_8_1.html#a-modelo-causal-teórico",
    "href": "lista_8_1.html#a-modelo-causal-teórico",
    "title": "10  Lista 8.1 - Moderação e Mediação",
    "section": "10.1 a) Modelo causal teórico",
    "text": "10.1 a) Modelo causal teórico\n\n\n\n\n\n\nExercício\n\n\n\nVerifique esse modelo causal teórico e veja se ele faz sentido, utilizando um modelo SEM com mediação. Avalie os efeitos diretos e indiretos e decida se esse modelo teórico faz sentido, utilizando o AMOS e o Process.\n\n\nResolução do exercício foi baseada no vídeo “Simple Mediation using lavaan package of R” https://www.youtube.com/watch?v=nfQOCy9xMnk\n\noriginal = read.spss(\"DADOS PATH.sav\", to.data.frame=TRUE)\nglimpse(original)\n\nRows: 94\nColumns: 4\n$ Idade         &lt;dbl&gt; 57, 41, 29, 26, 33, 37, 26, 44, 31, 36, 30, 55, 43, 27, …\n$ IMC1          &lt;dbl&gt; 28.46122, 32.62609, 26.99050, 19.03602, 28.76650, 24.686…\n$ Treinos       &lt;dbl&gt; 108, 144, 48, 102, 123, 63, 39, 105, 6, 48, 144, 144, 11…\n$ Sociabilidade &lt;dbl&gt; 14, 34, 17, 20, 26, 19, 15, 32, 27, 19, 28, 9, 30, 29, 1…\n\n\n\nmodelo_1 = \"Treinos ~ c_*Sociabilidade + b*IMC1 \n            IMC1 ~ a*Sociabilidade\n            Indireto := a*b\n            Total_direto_C := a*b + c_\"\n\n\nfit_1 = sem(modelo_1, original, se = \"bootstrap\", bootstrap = 500)\n\n\n#summary(fit_1) # parâmetros adicionais summary(fit_1, fit.measures = TRUE, standardized = TRUE, rsquare = TRUE) \n\nkable(parameterEstimates(fit_1))\n\n\n\n\nlhs\nop\nrhs\nlabel\nest\nse\nz\npvalue\nci.lower\nci.upper\n\n\n\n\nTreinos\n~\nSociabilidade\nc_\n0.6052243\n0.6619768\n0.9142682\n0.3605759\n-0.6524603\n1.8245324\n\n\nTreinos\n~\nIMC1\nb\n-1.6497656\n1.0185007\n-1.6197982\n0.1052756\n-3.6551562\n0.4350822\n\n\nIMC1\n~\nSociabilidade\na\n0.0190526\n0.0507549\n0.3753835\n0.7073753\n-0.0861290\n0.1130998\n\n\nTreinos\n~~\nTreinos\n\n2327.0247317\n187.7869286\n12.3918355\n0.0000000\n1884.6418875\n2629.3007296\n\n\nIMC1\n~~\nIMC1\n\n17.7329732\n3.0046312\n5.9018802\n0.0000000\n12.1538364\n23.9097897\n\n\nSociabilidade\n~~\nSociabilidade\n\n65.6008375\n0.0000000\nNA\nNA\n65.6008375\n65.6008375\n\n\nIndireto\n:=\na*b\nIndireto\n-0.0314322\n0.0996909\n-0.3152970\n0.7525362\n-0.2192393\n0.2283743\n\n\nTotal_direto_C\n:=\na*b+c_\nTotal_direto_C\n0.5737921\n0.6689293\n0.8577768\n0.3910157\n-0.7354611\n1.7852540\n\n\n\n\n\n\n\n\nResultados\n\nRegressões:\n\n\nO coeficiente estimado para a relação entre Sociabilidae e Treinos é 0.605, mas não é estatisticamente significativo (p = 0.360).\nO coeficiente estimado para a relação entre IMC e Treinos é -1.650, indicando uma relação negativa. No entanto, esse coeficiente também não é estatisticamente significativo (p = 0.100).\nO coeficiente estimado para a relação entre Sociabilidae e IMC é 0.019 e não é estatisticamente significativo (p = 0.693).\n\n\nParâmetros Definidos:\n\n\nO efeito indireto é estimado como -0.031, mas não é estatisticamente significativo (p = 0.717). Isso sugere que a variável IMC não medeia significativamente a relação entre Sociabilidae e Treinos.\nO efeito direto da Sociabilidade no Treino é estimado como 0.574 e também não é estatisticamente significativo (p = 0.386).\n\nCom base nos resultados, podemos concluir que o modelo teórico não se sustenta, pois não há evidência estatística significativa para sugerir relações entre as variáveis Sociabilidae , IMC e Treinos."
  },
  {
    "objectID": "lista_8_1.html#b-mediação-vs-regressões-lineares",
    "href": "lista_8_1.html#b-mediação-vs-regressões-lineares",
    "title": "10  Lista 8.1 - Moderação e Mediação",
    "section": "10.2 b) Mediação vs Regressões lineares",
    "text": "10.2 b) Mediação vs Regressões lineares\n\n\n\n\n\n\nExercício\n\n\n\nCompare os dados encontrados com aqueles realizados por um conjunto de regressões lineares (OLS). Fazer esta análise de mediação por regressão linear e utilizando o AMOS+Process é a mesma coisa? Coloque também o diagrama gerado aqui.\n\n\n\nValor de “c”\n\nsoc_treinos = lm(Treinos ~ Sociabilidade, data = original) #valor de c\nkable(summary(soc_treinos)$coef)\n\n\n\n\n\nEstimate\nStd. Error\nt value\nPr(&gt;|t|)\n\n\n\n\n(Intercept)\n69.4395522\n14.1638541\n4.9025888\n0.0000041\n\n\nSociabilidade\n0.5737921\n0.6273496\n0.9146289\n0.3627775\n\n\n\n\n\n\n\n\n\nValor de a\n\nsoc_imc = lm(IMC1 ~ Sociabilidade, data = original) \nkable(summary(soc_imc)$coef)\n\n\n\n\n\nEstimate\nStd. Error\nt value\nPr(&gt;|t|)\n\n\n\n\n(Intercept)\n25.3971491\n1.2238100\n20.7525264\n0.0000000\n\n\nSociabilidade\n0.0190526\n0.0542054\n0.3514884\n0.7260257\n\n\n\n\n\n\n\n\n\nvalor de b e de c’\n\nsoc_E_imc_treinos = lm(Treinos ~ IMC1 + Sociabilidade, data = original) \nkable(summary(soc_E_imc_treinos)$coef)\n\n\n\n\n\nEstimate\nStd. Error\nt value\nPr(&gt;|t|)\n\n\n\n\n(Intercept)\n111.3388945\n33.5981763\n3.3138374\n0.0013220\n\n\nIMC1\n-1.6497656\n1.2008507\n-1.3738307\n0.1728690\n\n\nSociabilidade\n0.6052243\n0.6247647\n0.9687235\n0.3352508\n\n\n\n\n\n\n\nOs resultados são diferentes. As mediações apenas por regressão linear não apresentam o resultado do efeito indireto, mostrado no resultado do exercício anterior\n\n\nDiagrama do modelo\n\ndiagrama_1 &lt;- semPaths(\n          object = fit_1,\n          what = \"path\",\n          whatLabels = \"par\",\n          style = \"ram\",\n          layout = \"tree\",\n          rotation = 2,\n          sizeMan = 7,\n          sizeLat = 7,\n          color = \"lightgray\",\n          edge.label.cex = 1.2,\n          label.cex = 1.3\n)"
  },
  {
    "objectID": "lista_8_1.html#modelo-2-opcional-1",
    "href": "lista_8_1.html#modelo-2-opcional-1",
    "title": "10  Lista 8.1 - Moderação e Mediação",
    "section": "10.3 Modelo 2 (Opcional 1)",
    "text": "10.3 Modelo 2 (Opcional 1)\nRefaça o modelo tendo a variável Idade como mediador.\n\nmodelo_2 = \"Treinos ~ c_*Sociabilidade + b*Idade \n            Idade ~ a*Sociabilidade\n            Indireto := a*b\n            Total_direto_C := a*b + c_\"\n\n\nfit_2 = sem(modelo_2, original, se = \"bootstrap\", bootstrap = 500)\n\nkable(parameterEstimates(fit_2)) # parâmetros adicionais summary(fit_1, fit.measures = TRUE, standardized = TRUE, rsquare = TRUE) \n\n\n\n\nlhs\nop\nrhs\nlabel\nest\nse\nz\npvalue\nci.lower\nci.upper\n\n\n\n\nTreinos\n~\nSociabilidade\nc_\n0.4852942\n0.6196786\n0.7831385\n0.4335458\n-0.7090243\n1.6900127\n\n\nTreinos\n~\nIdade\nb\n1.5425565\n0.4588149\n3.3620452\n0.0007737\n0.6913514\n2.4044144\n\n\nIdade\n~\nSociabilidade\na\n0.0573709\n0.1100893\n0.5211310\n0.6022755\n-0.1575502\n0.2725941\n\n\nTreinos\n~~\nTreinos\n\n2179.2955768\n194.4639552\n11.2066813\n0.0000000\n1707.6722717\n2479.7855236\n\n\nIdade\n~~\nIdade\n\n82.3681677\n10.5597227\n7.8002207\n0.0000000\n61.5549212\n102.4772562\n\n\nSociabilidade\n~~\nSociabilidade\n\n65.6008375\n0.0000000\nNA\nNA\n65.6008375\n65.6008375\n\n\nIndireto\n:=\na*b\nIndireto\n0.0884979\n0.1735841\n0.5098273\n0.6101725\n-0.2660349\n0.4446866\n\n\nTotal_direto_C\n:=\na*b+c_\nTotal_direto_C\n0.5737921\n0.6808613\n0.8427445\n0.3993714\n-0.7934420\n1.9182149\n\n\n\n\n\n\n\n\nResultados\n\nRegressões:\n\nA relação estimada entre Sociabilidade e Treinos é 0.485, mas não é estatisticamente significativa (p = 0.384).\nA relação estimada entre Idade e Treinos é 1.543, indicando uma relação positiva e significativa (p = 0.001).\nA relação estimada entre Sociabldd e Idade é 0.057 e não é estatisticamente significativa (p = 0.592).\n\nParâmetros Definidos:\n\nO efeito Indireto é estimado como 0.088, mas não é estatisticamente significativo (p = 0.605). Isso sugere que a variável Idade não medeia significativamente a relação entre Sociabilidade e Treinos.\nO efeito total direto da Sociabilidae nos Treinos é estimado como 0.574 e não é estatisticamente significativo (p = 0.345).\n\n\nOs resultados sugerem que a variável Idade está significativamente relacionada à variável Treinos, enquanto a variável Sociabilidade não tem uma relação significativa com Treinos. O efeito indireto através de Idade não é estatisticamente significativo, e o efeito total direto também não é significativo.\n\n\nDiagrama do modelo 2\n\ndiagrama_2 &lt;- semPaths(\n          object = fit_2,\n          what = \"path\",\n          whatLabels = \"par\",\n          style = \"ram\",\n          layout = \"tree\",\n          rotation = 2,\n          sizeMan = 7,\n          sizeLat = 7,\n          color = \"lightgray\",\n          edge.label.cex = 1.2,\n          label.cex = 1.3\n)\n\n\n\n\n\nmediation_model_2 = lm(Idade ~ Sociabilidade, data = original)\nkable(summary(mediation_model_2)$coef)\n\n\n\n\n\nEstimate\nStd. Error\nt value\nPr(&gt;|t|)\n\n\n\n\n(Intercept)\n32.8228531\n2.6375635\n12.4443843\n0.0000000\n\n\nSociabilidade\n0.0573709\n0.1168237\n0.4910896\n0.6245325\n\n\n\n\n\n\n# library(flexplot)\n# visualize(mediation_model_2) análise gráfica do modelo\n\n\nfull_model_2 = lm(Treinos ~ Idade + Sociabilidade, data = original)\nkable(summary(full_model_2)$coef)\n\n\n\n\n\nEstimate\nStd. Error\nt value\nPr(&gt;|t|)\n\n\n\n\n(Intercept)\n18.8084463\n22.3454098\n0.8417141\n0.4021546\n\n\nIdade\n1.5425565\n0.5392097\n2.8607731\n0.0052418\n\n\nSociabilidade\n0.4852942\n0.6049941\n0.8021469\n0.4245578\n\n\n\n\n\n\n#visualize(full_model_2) análise gráfica do modelo\n\n\nresults_2 = mediate(mediation_model_2, full_model_2,\n                  treat = \"Sociabilidade\",\n                  mediator = \"Idade\",\n                  boot = TRUE,\n                  sims = 500)\n\nsummary(results_2)\n\n\nCausal Mediation Analysis \n\nNonparametric Bootstrap Confidence Intervals with the Percentile Method\n\n               Estimate 95% CI Lower 95% CI Upper p-value\nACME             0.0885      -0.2126         0.45    0.52\nADE              0.4853      -0.6804         1.70    0.37\nTotal Effect     0.5738      -0.6401         1.88    0.33\nProp. Mediated   0.1542      -1.7984         1.59    0.50\n\nSample Size Used: 94 \n\n\nSimulations: 500 \n\n\n\nmediate_plot(Treinos ~ Idade  + Sociabilidade  , data = original)"
  },
  {
    "objectID": "lista_8_1.html#modelo-3-opcional-2",
    "href": "lista_8_1.html#modelo-3-opcional-2",
    "title": "10  Lista 8.1 - Moderação e Mediação",
    "section": "10.4 Modelo 3 (Opcional 2)",
    "text": "10.4 Modelo 3 (Opcional 2)\nTestando outros modelos, foi possível observar que o efeito do IMC sobre o treinamento é mediado pela Idade\n\nmodelo_3 = \"Treinos ~ c_*IMC1 + b*Idade \n            Idade ~ a*IMC1\n            Indireto := a*b\n            Total_direto_C := a*b + c_\"\n\n\nfit_3 = sem(modelo_3, original, se = \"bootstrap\", bootstrap = 500) #demora um tempo para executar\n\n\nkable(parameterEstimates(fit_3)) # parâmetros adicionais summary(fit_1, fit.measures = TRUE, standardized = TRUE, rsquare = TRUE)\n\n\n\n\nlhs\nop\nrhs\nlabel\nest\nse\nz\npvalue\nci.lower\nci.upper\n\n\n\n\nTreinos\n~\nIMC1\nc_\n-2.7781642\n1.0067476\n-2.759544\n0.0057882\n-4.6800358\n-0.6198768\n\n\nTreinos\n~\nIdade\nb\n1.9275620\n0.4583106\n4.205798\n0.0000260\n0.9813260\n2.7588243\n\n\nIdade\n~\nIMC1\na\n0.6075027\n0.2252141\n2.697446\n0.0069874\n0.2357407\n1.0753598\n\n\nTreinos\n~~\nTreinos\n\n2068.5298836\n190.9705838\n10.831668\n0.0000000\n1660.9183246\n2429.8198497\n\n\nIdade\n~~\nIdade\n\n76.0307760\n9.8646493\n7.707398\n0.0000000\n55.5284839\n95.0898386\n\n\nIMC1\n~~\nIMC1\n\n17.7567863\n0.0000000\nNA\nNA\n17.7567863\n17.7567863\n\n\nIndireto\n:=\na*b\nIndireto\n1.1709992\n0.5155848\n2.271206\n0.0231345\n0.3149790\n2.3125077\n\n\nTotal_direto_C\n:=\na*b+c_\nTotal_direto_C\n-1.6071651\n1.0825367\n-1.484629\n0.1376422\n-3.6571736\n0.6752811\n\n\n\n\n\n\n\n\nResultados\n\nRegressões:\n\nA relação estimada entre IMC1 (Índice de Massa Corporal) e Treinos é -2.778, indicando uma relação negativa e significativa (p = 0.006).\nA relação estimada entre Idade e Treinos é 1.928, indicando uma relação positiva e significativa (p = 0.000).\nA relação estimada entre IMC e Idade é 0.608 e é estatisticamente significativa (p = 0.005).\n\nParâmetros Definidos:\n\nO efeito Indireto é estimado como 1.171 e é estatisticamente significativo (p = 0.030). Isso sugere que a variável Idade medeia significativamente a relação entre IMC e Treinos.\nO efeito total direto de IMC nos Treinos é estimado como -1.607, mas não é estatisticamente significativo (p = 0.114).\n\n\nOs resultados indicam que a variável IMC está significativamente relacionada negativamente à variável Treinos. A variável Idade atua como mediadora nessa relação. O efeito indireto é estimado como 1.171 (p = 0.030), indicando que a inclusão de Idade no modelo altera a relação entre IMC1 e Treinos, tornando-a mais negativa do que a relação direta."
  },
  {
    "objectID": "lista_8_1.html#diagrama-do-modelo-3",
    "href": "lista_8_1.html#diagrama-do-modelo-3",
    "title": "10  Lista 8.1 - Moderação e Mediação",
    "section": "10.5 Diagrama do modelo 3",
    "text": "10.5 Diagrama do modelo 3\n\ndiagrama_3 &lt;- semPaths(\n          object = fit_3,\n          what = \"path\",\n          whatLabels = \"par\",\n          style = \"ram\",\n          layout = \"tree\",\n          rotation = 2,\n          sizeMan = 7,\n          sizeLat = 7,\n          color = \"lightgray\",\n          edge.label.cex = 1.2,\n          label.cex = 1.3\n)\n\n\n\n\n\nmediation_model_3 = lm(Idade ~ IMC1, data = original)\nsummary(mediation_model_3)$coef\n\n              Estimate Std. Error  t value    Pr(&gt;|t|)\n(Intercept) 18.3591515   5.639405 3.255512 0.001584908\nIMC1         0.6075027   0.215734 2.815980 0.005949584\n\nvisualize(mediation_model_3) \n\n\n\n\n\nfull_model_3 = lm(Treinos ~ Idade + IMC1, data = original)\nsummary(full_model_3)$coef\n\n             Estimate Std. Error   t value     Pr(&gt;|t|)\n(Intercept) 87.606237 31.2333809  2.804891 0.0061538896\nIdade        1.927562  0.5467836  3.525274 0.0006645242\nIMC1        -2.778164  1.1791838 -2.356006 0.0206193649\n\nvisualize(full_model_3)\n\n\n\n\n\nresults_3 = mediate(mediation_model_3, full_model_3,\n                  treat = \"IMC1\",\n                  mediator = \"Idade\",\n                  boot = TRUE,\n                  sims = 500)\n\nsummary(results_3)\n\n\nCausal Mediation Analysis \n\nNonparametric Bootstrap Confidence Intervals with the Percentile Method\n\n               Estimate 95% CI Lower 95% CI Upper p-value    \nACME              1.171        0.339         2.43  &lt;2e-16 ***\nADE              -2.778       -4.585        -0.62   0.024 *  \nTotal Effect     -1.607       -3.441         0.57   0.156    \nProp. Mediated   -0.729      -11.591         7.21   0.156    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nSample Size Used: 94 \n\n\nSimulations: 500 \n\n\n\nmediate_plot(Treinos ~ Idade  + IMC1  , data = original)"
  },
  {
    "objectID": "lista_8_1.html#lista-8.1-resolvida-no-spss",
    "href": "lista_8_1.html#lista-8.1-resolvida-no-spss",
    "title": "10  Lista 8.1 - Moderação e Mediação",
    "section": "10.6 Lista 8.1 resolvida no SPSS",
    "text": "10.6 Lista 8.1 resolvida no SPSS"
  },
  {
    "objectID": "lista_8_1.html#extras",
    "href": "lista_8_1.html#extras",
    "title": "10  Lista 8.1 - Moderação e Mediação",
    "section": "10.7 Extras!",
    "text": "10.7 Extras!\nOutro tipo de resolução baseada no vídeo do Dustin Fife (How to do a mediation analysis in R…with visuals!)\n\n# Mediação com visualização\nlibrary(mediation)\nlibrary(flexplot)\n\n\nmediation_model = lm(IMC1 ~ Sociabilidade, data = original)\nsummary(mediation_model)\n\n\nCall:\nlm(formula = IMC1 ~ Sociabilidade, data = original)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-7.3645 -2.8931 -0.4598  2.7881 14.5354 \n\nCoefficients:\n              Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)   25.39715    1.22381  20.753   &lt;2e-16 ***\nSociabilidade  0.01905    0.05421   0.351    0.726    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 4.257 on 92 degrees of freedom\nMultiple R-squared:  0.001341,  Adjusted R-squared:  -0.009514 \nF-statistic: 0.1235 on 1 and 92 DF,  p-value: 0.726\n\n\n\nvisualize(mediation_model, plot = \"model\")\n\n\n\n\n\nfull_model = lm(Treinos ~ IMC1 + Sociabilidade, data = original)\nsummary(full_model)\n\n\nCall:\nlm(formula = Treinos ~ IMC1 + Sociabilidade, data = original)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-85.683 -42.165   2.807  47.623  69.596 \n\nCoefficients:\n              Estimate Std. Error t value Pr(&gt;|t|)   \n(Intercept)   111.3389    33.5982   3.314  0.00132 **\nIMC1           -1.6498     1.2009  -1.374  0.17287   \nSociabilidade   0.6052     0.6248   0.969  0.33525   \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 49.03 on 91 degrees of freedom\nMultiple R-squared:  0.02915,   Adjusted R-squared:  0.00781 \nF-statistic: 1.366 on 2 and 91 DF,  p-value: 0.2603\n\n\n\nvisualize(full_model)\n\n\n\n\n\nresults = mediate(mediation_model, full_model,\n                  treat = \"Sociabilidade\",\n                  mediator = \"IMC1\",\n                  boot = TRUE,\n                  sims = 500)\n\n\nsummary(results)\n\n\nCausal Mediation Analysis \n\nNonparametric Bootstrap Confidence Intervals with the Percentile Method\n\n               Estimate 95% CI Lower 95% CI Upper p-value\nACME            -0.0314      -0.1976         0.17    0.78\nADE              0.6052      -0.6669         1.95    0.29\nTotal Effect     0.5738      -0.6201         1.89    0.30\nProp. Mediated  -0.0548      -1.3478         1.26    0.87\n\nSample Size Used: 94 \n\n\nSimulations: 500 \n\n\n\nmediate_plot(Treinos ~ IMC1 +  Sociabilidade, data = original) # Ordem em que aparece as variáveis é muito importante. A última variável será sempre a variável DEPENDENTE (X). Todas as outras que vierem antes dela, serão tratadas como MEDIADORAS (no caso IMC1)"
  },
  {
    "objectID": "lista_8_1.html#referências",
    "href": "lista_8_1.html#referências",
    "title": "10  Lista 8.1 - Moderação e Mediação",
    "section": "10.8 Referências",
    "text": "10.8 Referências\nhttps://www.youtube.com/watch?v=_4Fu8SZID2k"
  },
  {
    "objectID": "lista_8_1.html#versões-dos-pacotes",
    "href": "lista_8_1.html#versões-dos-pacotes",
    "title": "10  Lista 8.1 - Moderação e Mediação",
    "section": "10.9 Versões dos pacotes",
    "text": "10.9 Versões dos pacotes\n\nreport(sessionInfo())\n\nAnalyses were conducted using the R Statistical language (version 4.3.1; R Core\nTeam, 2023) on Windows 11 x64 (build 22621), using the packages Matrix (version\n1.6.0; Bates D et al., 2023), effectsize (version 0.8.6; Ben-Shachar MS et al.,\n2020), semPlot (version 1.1.6; Epskamp S, 2022), flexplot (version 0.20.5; Fife\nD, 2024), mvtnorm (version 1.2.3; Genz A, Bretz F, 2009), lubridate (version\n1.9.3; Grolemund G, Wickham H, 2011), semTools (version 0.5.6; Jorgensen TD et\nal., 2022), parameters (version 0.21.3; Lüdecke D et al., 2020), performance\n(version 0.10.8; Lüdecke D et al., 2021), easystats (version 0.6.0; Lüdecke D\net al., 2022), see (version 0.8.1; Lüdecke D et al., 2021), insight (version\n0.19.6; Lüdecke D et al., 2019), bayestestR (version 0.13.1; Makowski D et al.,\n2019), modelbased (version 0.8.6; Makowski D et al., 2020), report (version\n0.5.7; Makowski D et al., 2023), correlation (version 0.8.4; Makowski D et al.,\n2022), tibble (version 3.2.1; Müller K, Wickham H, 2023), datawizard (version\n0.9.0; Patil I et al., 2022), foreign (version 0.8.85; R Core Team, 2023),\nlavaan (version 0.6.16; Rosseel Y, 2012), mediation (version 4.5.0; Tingley D\net al., 2014), MASS (version 7.3.60; Venables WN, Ripley BD, 2002), ggplot2\n(version 3.4.4; Wickham H, 2016), forcats (version 1.0.0; Wickham H, 2023),\nstringr (version 1.5.1; Wickham H, 2023), tidyverse (version 2.0.0; Wickham H\net al., 2019), dplyr (version 1.1.3; Wickham H et al., 2023), purrr (version\n1.0.2; Wickham H, Henry L, 2023), readr (version 2.1.4; Wickham H et al.,\n2023), tidyr (version 1.3.0; Wickham H et al., 2023), sandwich (version 3.1.0;\nZeileis A et al., 2020) and kableExtra (version 1.3.4; Zhu H, 2021).\n\nReferences\n----------\n  - Bates D, Maechler M, Jagan M (2023). _Matrix: Sparse and Dense Matrix Classes\nand Methods_. R package version 1.6-0,\n&lt;https://CRAN.R-project.org/package=Matrix&gt;.\n  - Ben-Shachar MS, Lüdecke D, Makowski D (2020). \"effectsize: Estimation of\nEffect Size Indices and Standardized Parameters.\" _Journal of Open Source\nSoftware_, *5*(56), 2815. doi:10.21105/joss.02815\n&lt;https://doi.org/10.21105/joss.02815&gt;, &lt;https://doi.org/10.21105/joss.02815&gt;.\n  - Epskamp S (2022). _semPlot: Path Diagrams and Visual Analysis of Various SEM\nPackages' Output_. R package version 1.1.6,\n&lt;https://CRAN.R-project.org/package=semPlot&gt;.\n  - Fife D (2024). _flexplot: Graphically Based Data Analysis Using 'flexplot'_.\nR package version 0.20.5.\n  - Genz A, Bretz F (2009). _Computation of Multivariate Normal and t\nProbabilities_, series Lecture Notes in Statistics. Springer-Verlag,\nHeidelberg. ISBN 978-3-642-01688-2.\n  - Grolemund G, Wickham H (2011). \"Dates and Times Made Easy with lubridate.\"\n_Journal of Statistical Software_, *40*(3), 1-25.\n&lt;https://www.jstatsoft.org/v40/i03/&gt;.\n  - Jorgensen TD, Pornprasertmanit S, Schoemann AM, Rosseel Y (2022).\n_\\texttt{semTools}: Useful tools for structural equation modeling_. R package\nversion 0.5-6, &lt;https://CRAN.R-project.org/package=semTools&gt;.\n  - Lüdecke D, Ben-Shachar M, Patil I, Makowski D (2020). \"Extracting, Computing\nand Exploring the Parameters of Statistical Models using R.\" _Journal of Open\nSource Software_, *5*(53), 2445. doi:10.21105/joss.02445\n&lt;https://doi.org/10.21105/joss.02445&gt;.\n  - Lüdecke D, Ben-Shachar M, Patil I, Waggoner P, Makowski D (2021).\n\"performance: An R Package for Assessment, Comparison and Testing of\nStatistical Models.\" _Journal of Open Source Software_, *6*(60), 3139.\ndoi:10.21105/joss.03139 &lt;https://doi.org/10.21105/joss.03139&gt;.\n  - Lüdecke D, Ben-Shachar M, Patil I, Wiernik B, Makowski D (2022). \"easystats:\nFramework for Easy Statistical Modeling, Visualization, and Reporting.\" _CRAN_.\nR package, &lt;https://easystats.github.io/easystats/&gt;.\n  - Lüdecke D, Patil I, Ben-Shachar M, Wiernik B, Waggoner P, Makowski D (2021).\n\"see: An R Package for Visualizing Statistical Models.\" _Journal of Open Source\nSoftware_, *6*(64), 3393. doi:10.21105/joss.03393\n&lt;https://doi.org/10.21105/joss.03393&gt;.\n  - Lüdecke D, Waggoner P, Makowski D (2019). \"insight: A Unified Interface to\nAccess Information from Model Objects in R.\" _Journal of Open Source Software_,\n*4*(38), 1412. doi:10.21105/joss.01412 &lt;https://doi.org/10.21105/joss.01412&gt;.\n  - Makowski D, Ben-Shachar M, Lüdecke D (2019). \"bayestestR: Describing Effects\nand their Uncertainty, Existence and Significance within the Bayesian\nFramework.\" _Journal of Open Source Software_, *4*(40), 1541.\ndoi:10.21105/joss.01541 &lt;https://doi.org/10.21105/joss.01541&gt;,\n&lt;https://joss.theoj.org/papers/10.21105/joss.01541&gt;.\n  - Makowski D, Ben-Shachar M, Patil I, Lüdecke D (2020). \"Estimation of\nModel-Based Predictions, Contrasts and Means.\" _CRAN_.\n&lt;https://github.com/easystats/modelbased&gt;.\n  - Makowski D, Lüdecke D, Patil I, Thériault R, Ben-Shachar M, Wiernik B (2023).\n\"Automated Results Reporting as a Practical Tool to Improve Reproducibility and\nMethodological Best Practices Adoption.\" _CRAN_.\n&lt;https://easystats.github.io/report/&gt;.\n  - Makowski D, Wiernik B, Patil I, Lüdecke D, Ben-Shachar M (2022).\n\"correlation: Methods for Correlation Analysis.\" Version 0.8.3,\n&lt;https://CRAN.R-project.org/package=correlation&gt;. Makowski D, Ben-Shachar M,\nPatil I, Lüdecke D (2020). \"Methods and Algorithms for Correlation Analysis in\nR.\" _Journal of Open Source Software_, *5*(51), 2306. doi:10.21105/joss.02306\n&lt;https://doi.org/10.21105/joss.02306&gt;,\n&lt;https://joss.theoj.org/papers/10.21105/joss.02306&gt;.\n  - Müller K, Wickham H (2023). _tibble: Simple Data Frames_. R package version\n3.2.1, &lt;https://CRAN.R-project.org/package=tibble&gt;.\n  - Patil I, Makowski D, Ben-Shachar M, Wiernik B, Bacher E, Lüdecke D (2022).\n\"datawizard: An R Package for Easy Data Preparation and Statistical\nTransformations.\" _Journal of Open Source Software_, *7*(78), 4684.\ndoi:10.21105/joss.04684 &lt;https://doi.org/10.21105/joss.04684&gt;.\n  - R Core Team (2023). _foreign: Read Data Stored by 'Minitab', 'S', 'SAS',\n'SPSS', 'Stata', 'Systat', 'Weka', 'dBase', ..._. R package version 0.8-85,\n&lt;https://CRAN.R-project.org/package=foreign&gt;.\n  - R Core Team (2023). _R: A Language and Environment for Statistical\nComputing_. R Foundation for Statistical Computing, Vienna, Austria.\n&lt;https://www.R-project.org/&gt;.\n  - Rosseel Y (2012). \"lavaan: An R Package for Structural Equation Modeling.\"\n_Journal of Statistical Software_, *48*(2), 1-36. doi:10.18637/jss.v048.i02\n&lt;https://doi.org/10.18637/jss.v048.i02&gt;.\n  - Tingley D, Yamamoto T, Hirose K, Keele L, Imai K (2014). \"mediation: R\nPackage for Causal Mediation Analysis.\" _Journal of Statistical Software_,\n*59*(5), 1-38. &lt;http://www.jstatsoft.org/v59/i05/&gt;. Imai K, Keele L, Yamamoto T\n(2010). \"Identification, Inference, and Sensitivity Analysis for Causal\nMediation Effects.\" _Statistical Science_, *25*(1), 51-71.\n&lt;http://imai.princeton.edu/research/mediation.html&gt;. Imai K, Keele L, Tingley D\n(2010). \"A General Approach to Causal Mediation Analysis.\" _Psychological\nMethods_, *15*(4), 309-334.\n&lt;http://imai.princeton.edu/research/BaronKenny.html&gt;. Imai K, Keele L, Tingley\nD, Yamamoto T (2011). \"Unpacking the Black Box of Causality: Learning about\nCausal Mechanisms from Experimental and Observational Studies.\" _American\nPolitical Science Review_, *105*(4), 765-789.\n&lt;http://imai.princeton.edu/research/mediationP.html&gt;. Imai K, Yamamoto T\n(2013). \"Identification and Sensitivity Analysis for Multiple Causal\nMechanisms: Revisiting Evidence from Framing Experiments.\" _Political\nAnalysis_, *21*(2), 141-171. &lt;http://imai.princeton.edu/research/medsens.html&gt;.\nImai K, Keele L, Tingley D, Yamamoto T (2010). \"Causal Mediation Analysis Using\nR.\" In Vinod HD (ed.), _Advances in Social Science Research Using R_.\nSpringer-Verlag, New York.\n  - Venables WN, Ripley BD (2002). _Modern Applied Statistics with S_, Fourth\nedition. Springer, New York. ISBN 0-387-95457-0,\n&lt;https://www.stats.ox.ac.uk/pub/MASS4/&gt;.\n  - Wickham H (2016). _ggplot2: Elegant Graphics for Data Analysis_.\nSpringer-Verlag New York. ISBN 978-3-319-24277-4,\n&lt;https://ggplot2.tidyverse.org&gt;.\n  - Wickham H (2023). _forcats: Tools for Working with Categorical Variables\n(Factors)_. R package version 1.0.0,\n&lt;https://CRAN.R-project.org/package=forcats&gt;.\n  - Wickham H (2023). _stringr: Simple, Consistent Wrappers for Common String\nOperations_. R package version 1.5.1,\n&lt;https://CRAN.R-project.org/package=stringr&gt;.\n  - Wickham H, Averick M, Bryan J, Chang W, McGowan LD, François R, Grolemund G,\nHayes A, Henry L, Hester J, Kuhn M, Pedersen TL, Miller E, Bache SM, Müller K,\nOoms J, Robinson D, Seidel DP, Spinu V, Takahashi K, Vaughan D, Wilke C, Woo K,\nYutani H (2019). \"Welcome to the tidyverse.\" _Journal of Open Source Software_,\n*4*(43), 1686. doi:10.21105/joss.01686 &lt;https://doi.org/10.21105/joss.01686&gt;.\n  - Wickham H, François R, Henry L, Müller K, Vaughan D (2023). _dplyr: A Grammar\nof Data Manipulation_. R package version 1.1.3,\n&lt;https://CRAN.R-project.org/package=dplyr&gt;.\n  - Wickham H, Henry L (2023). _purrr: Functional Programming Tools_. R package\nversion 1.0.2, &lt;https://CRAN.R-project.org/package=purrr&gt;.\n  - Wickham H, Hester J, Bryan J (2023). _readr: Read Rectangular Text Data_. R\npackage version 2.1.4, &lt;https://CRAN.R-project.org/package=readr&gt;.\n  - Wickham H, Vaughan D, Girlich M (2023). _tidyr: Tidy Messy Data_. R package\nversion 1.3.0, &lt;https://CRAN.R-project.org/package=tidyr&gt;.\n  - Zeileis A, Köll S, Graham N (2020). \"Various Versatile Variances: An\nObject-Oriented Implementation of Clustered Covariances in R.\" _Journal of\nStatistical Software_, *95*(1), 1-36. doi:10.18637/jss.v095.i01\n&lt;https://doi.org/10.18637/jss.v095.i01&gt;. Zeileis A (2004). \"Econometric\nComputing with HC and HAC Covariance Matrix Estimators.\" _Journal of\nStatistical Software_, *11*(10), 1-17. doi:10.18637/jss.v011.i10\n&lt;https://doi.org/10.18637/jss.v011.i10&gt;. Zeileis A (2006). \"Object-Oriented\nComputation of Sandwich Estimators.\" _Journal of Statistical Software_,\n*16*(9), 1-16. doi:10.18637/jss.v016.i09\n&lt;https://doi.org/10.18637/jss.v016.i09&gt;.\n  - Zhu H (2021). _kableExtra: Construct Complex Table with 'kable' and Pipe\nSyntax_. R package version 1.3.4,\n&lt;https://CRAN.R-project.org/package=kableExtra&gt;."
  }
]