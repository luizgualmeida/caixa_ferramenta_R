[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Técnicas e Métodos de Pesquisa no R",
    "section": "",
    "text": "Bem-vindo",
    "crumbs": [
      "Bem-vindo"
    ]
  },
  {
    "objectID": "index.html#sobre-as-aulas",
    "href": "index.html#sobre-as-aulas",
    "title": "Técnicas e Métodos de Pesquisa no R",
    "section": "Sobre as aulas",
    "text": "Sobre as aulas\nAs aulas são gravadas e disponibilizadas gratuitamente por meio de lives no canal Cientística & Podcast Naruhodo do YouTube. Destacando aqui o agradecimento mais do que especial para a Maria Lucia Oliveira De Souza Formigoni, por tornar possível a disciplina.",
    "crumbs": [
      "Introdução"
    ]
  },
  {
    "objectID": "index.html#sobre-o-tutorial",
    "href": "index.html#sobre-o-tutorial",
    "title": "Técnicas e Métodos de Pesquisa no R",
    "section": "Sobre o tutorial",
    "text": "Sobre o tutorial\nEste tutorial tem como objetivo oferecer uma introdução prática à análise estatística de dados no R, utilizando diversos bancos de dados para cada tipo de anáise. O público-alvo abrange estudantes de Estatística Aplicada a Psicobiologia II, pós-graduandos e pesquisadores que buscam aprimorar suas habilidades em análise de dados. É recomendado ter conhecimento básico em estatística, particularmente Estatística Aplicada a Psicobiologia I, e alguma familiaridade com o ambiente R para acompanhar este tutorial. Abordaremos as seguintes análises:\n\nTransformação de dados para análises\nModelos lineares:\n\nModelo linear geral (GLM ) de medidas repetidas\nGeneralized Estimated Equations (GEE)\nModelos mistos e hierárquicos (GMM)\nGeneralized linear models (GzLM)\n\n\n\n\nAnálise de sobrevida\n\nKaplan-Meier\nRegressão de Cox\nCox Tempo dependente\n\n\n\n\nSéries temporais (ARIMA)\nModelagem de Equação Estrutural (SEM)\n\nPath analysis\nConfrmatory Factor Analysis (CFA)\nModeração e mediação\n\n\nAo fim de cada capítulos, nas seções intituladas “Extras”, vamos mostrar dicas sobre pacotes que podem ser úteis para suas análises, mas que não estão disponíveis no SPSS ou no Jamovi.\n\n\n\n\n\n\nImportante!\n\n\n\nO material apresentado aqui é complementar às aulas teóricas e práticas. É imprescindível que você assista às aulas antes de resolver os exercícios no R.",
    "crumbs": [
      "Introdução"
    ]
  },
  {
    "objectID": "index.html#r-e-rstudio",
    "href": "index.html#r-e-rstudio",
    "title": "Técnicas e Métodos de Pesquisa no R",
    "section": "R e Rstudio",
    "text": "R e Rstudio\nEmbora as aulas práticas tenham sido gravadas utilizando o SPSS, o intuito do tutorial é replicar as análises no R, que é gratuito! Portanto você precisa baixar o R e o Rstudio.\nDownload do R\nDownload do Rstudio",
    "crumbs": [
      "Introdução"
    ]
  },
  {
    "objectID": "index.html#aulas-práticas-gravadas",
    "href": "index.html#aulas-práticas-gravadas",
    "title": "Técnicas e Métodos de Pesquisa no R",
    "section": "Aulas práticas gravadas",
    "text": "Aulas práticas gravadas\nOs vídeos das aulas práticas no SPSS foram anexados ao fim de cada capítulo para que você possa ter uma referência do tipo de análise realizada. Em alguns casos você notarão que os resultados não serão idênticos no SPSS e no R. Isso ocorre devido aos diferentes algorítimos de estimação de coeficientes utilizados nos programas. O importante é você sempre reportar como a análise foi feita, quais programas e sempre que possível, disponibilizar o código ou o passo-a-passo utilizado para realizar a análise.",
    "crumbs": [
      "Introdução"
    ]
  },
  {
    "objectID": "index.html#boas-práticas-no-rstudio",
    "href": "index.html#boas-práticas-no-rstudio",
    "title": "Técnicas e Métodos de Pesquisa no R",
    "section": "Boas práticas no Rstudio",
    "text": "Boas práticas no Rstudio\nCriar um projeto separado para cada tipo de análise no R é uma prática recomendada porque mantém o ambiente organizado, evita conflitos entre projetos, facilita a colaboração e torna a reprodução e compartilhamento de trabalho mais eficientes.\n\nCriando o projeto e alocando os arquivos\nPara criar um novo projeto no R, siga estes passos simples:\n\nAbra o RStudio.\nVá até a guia “File” (Arquivo) e selecione “New Project” (Novo Projeto).\nEscolha um diretório para o seu projeto, onde todas as pastas e arquivos relacionados a ele serão armazenados. Isso ajudará na organização.\nClique em “Create Project” (Criar Projeto).\n\nFeito isso você terá um novo projeto configurado. Qualquer arquivo que você deseje usar para o tutorial deve ser colocado dentro da pasta desse projeto. Isso garantirá que todos os caminhos e referências aos arquivos sejam relativos ao diretório do projeto, facilitando a portabilidade e compartilhamento do tutorial.\nCom esses passos, você terá um ambiente de projeto limpo e organizado para trabalhar com seus arquivos e conduzir seu tutorial no R.",
    "crumbs": [
      "Introdução"
    ]
  },
  {
    "objectID": "index.html#instalando-e-carregando-os-pacotes",
    "href": "index.html#instalando-e-carregando-os-pacotes",
    "title": "Técnicas e Métodos de Pesquisa no R",
    "section": "Instalando e carregando os pacotes",
    "text": "Instalando e carregando os pacotes\nNo início de cada capítulo, você encontrará uma lista completa dos pacotes necessários para reproduzir as análises correspondentes.\nPara instalar um pacote, basta executar o comando install.packages(\"nome_do_pacote\") uma única vez.\nPor exemplo: install.packages(\"effects\"). Este comando instalará o pacote “effects”, que contém funções para calcular os estimadores de modelos lineares. É importante colocar o nome do pacote entre aspas (” “)\nApós a instalação do pacote, será necessário carregá-lo sempre que desejar utilizar alguma função associada a ele. Para isso basta executar o comando library(nome_do_pacote). Note que aqui não há a necessidade de colocar o nome do pacote entre aspas.\nExemplo: library(effects).\nPronto! Agora você está familiarizado com o processo de instalação e carregamento dos pacotes que serão utilizados ao longo deste tutorial. Pode-se fazer uma analogia com uma biblioteca: adquirir os livros seria como instalar os pacotes (install.packages), e retirar um livro da prateleira seria como carregar o pacote (library) quando necessário.",
    "crumbs": [
      "Introdução"
    ]
  },
  {
    "objectID": "index.html#referências",
    "href": "index.html#referências",
    "title": "Técnicas e Métodos de Pesquisa no R",
    "section": "Referências",
    "text": "Referências\n\nhttps://r4ds.hadley.nz/",
    "crumbs": [
      "Introdução"
    ]
  },
  {
    "objectID": "survival.html#pressupostos-da-cox-regression",
    "href": "survival.html#pressupostos-da-cox-regression",
    "title": "SURVIVAL",
    "section": "",
    "text": "Proporcionalidade dos Riscos:\n\nO pressuposto fundamental é que os riscos relativos entre dois grupos são constantes ao longo do tempo. Em outras palavras, a razão instantânea de riscos (hazard ratio) entre grupos não muda com o tempo. Este é o pressuposto de proporcionalidade dos riscos.\n\nIndependência Censura:\n\nA censura dos dados deve ser independente da probabilidade de falha. Isso significa que a probabilidade de um evento censurado (ocorrido após o fim do acompanhamento) deve ser a mesma para todos os grupos.\n\nLinearidade no Logaritmo dos Riscos:\n\nA relação entre as variáveis independentes e o logaritmo do risco deve ser linear. Isso é crucial para a interpretação dos coeficientes como log-riscos instantâneos.\n\nAuscência de Colinearidade:\n\nAs variáveis independentes no modelo não devem estar altamente correlacionadas (colinearidade). A colinearidade pode levar a estimativas imprecisas dos coeficientes.\n\nAusência de Efeito de Interferência:\n\nNão deve haver efeito de interferência entre indivíduos, o que significa que o status de um indivíduo não deve influenciar diretamente o tempo de falha de outro indivíduo.\n\nAdequação do Modelo:\n\nO modelo escolhido deve ser apropriado para os dados. Avaliações de adequação, como testes de resíduos, podem ser úteis para verificar a qualidade do ajuste do modelo aos dados.\n\n\n\n\nProporcionalidade dos riscos\nTemos duas formas de avaliar a proporcionalidade dos riscos\n\n1) Análise do gráfico da Kaplan-Meier\nAo analisar o gráfico de Kaplan-Meier para diferentes grupos, é crucial observar se as curvas de sobrevivência são aproximadamente paralelas ou se cruzam entre si. Se as curvas são paralelas, isso sugere proporcionalidade dos riscos, indicando que as diferenças nas taxas de falha entre os grupos são constantes ao longo do tempo. No entanto, se as curvas se cruzam, isso indica uma possível violação da proporcionalidade dos riscos.\nCruzamentos nas curvas podem indicar mudanças na relação de risco entre os grupos ao longo do tempo. Essa mudança pode ser devido a diferentes dinâmicas de risco em períodos distintos do estudo. Se as curvas se cruzarem, a aplicação da Regressão de Cox não deve ser feita para não gerar interpretações erradas!\n\nfit2_km\n\n\n\n\n\n\n\n\nPodemos observar que em nosso exemplo as linhas de sobrevida não cruzam, portanto podemos assumir que os riscos são proporcionais pela análise gráfica.\n\n\n2) Resíduos de Schoenfeld\nA segunda forma para se avaliar a suposição de proporcionalidade dos riscos na Regressão de Cox vamos utilizar o teste de Schoenfeld, que verifica se há uma relação sistemática entre os resíduos de Schoenfeld e o tempo, o que indicaria uma violação dessa suposição.\nA ideia central é que, se os resíduos de Schoenfeld não apresentarem uma relação significativa com o tempo, isso sugere que a proporcionalidade dos riscos é razoável. Logo, a hipótese nula é que não há relação entre os resíduos e o tempo, o que indicaria proporcionalidade dos riscos. O teste estatístico avalia se é razoável rejeitar essa hipótese nula.\n\n\n\n\n\n\nImportante!\n\n\n\nVamos torcer para o valor de p ser MAIOR que 0.05!\n\n\nUtilizando a função cox.zph() do pacote survival temos o seguinte código:\n\ntest &lt;- survival::cox.zph(cox_res)\ntest\n\n       chisq df    p\ntx      0.58  1 0.45\nGLOBAL  0.58  1 0.45\n\n\nOk! Temos riscos proporcionais!\nOutra forma de verificar a proporcionalidade dos riscos é com o gráfico dos resíduos de Schoenfeld.\n\n# Plot the Schoenfeld residuals over time for each covariate\nsurvminer::ggcoxzph(test, point.size = 0.1)[1]\n\n$`1`\n\n\n\n\n\n\n\n\n\nSe os resíduos mostrarem um padrão claro ao longo do tempo, isso pode indicar uma violação da suposição de riscos proporcionais.\nAlgumas dicas para ajudar na interpretação:\n\nSem Padrão (Resíduos Constantes): Se os resíduos aparecerem aleatoriamente espalhados em torno de zero, sem nenhuma tendência ou padrão claro, isso sugere que a suposição de riscos proporcionais é razoável.\nTendência Linear: Uma tendência linear (aumentando ou diminuindo) nos resíduos ao longo do tempo pode sugerir uma violação da suposição de riscos proporcionais. Por exemplo, se os resíduos forem consistentemente positivos ou negativos ao longo do tempo, isso indica um efeito dependente do tempo.\nPadrão Não Linear: Se os resíduos exibirem um padrão não linear ou formatos específicos (por exemplo, formato de U, formato de V), isso pode indicar desvios dos riscos proporcionais.\nParalelismo: Paralelismo significa que a propagação e distribuição dos resíduos são relativamente constantes ao longo do tempo. Se os resíduos aumentarem ou diminuirem ao longo do tempo, isso pode sugerir uma violação da suposição.\n\nRetomaremos a discussão sobre os pressupostos ao desenvolvermos nosso primeiro modelo e também o que fazer quando o pressuposto da proporcionalidade dos riscos é violado.",
    "crumbs": [
      "SURVIVAL"
    ]
  },
  {
    "objectID": "lista_6.html#carregando-pacotes",
    "href": "lista_6.html#carregando-pacotes",
    "title": "6  Lista 6 - Kaplan-Meier e Cox Regression",
    "section": "6.1 Carregando pacotes",
    "text": "6.1 Carregando pacotes\n\nlibrary(tidyverse)\nlibrary(flexplot)\nlibrary(foreign)\nlibrary(dplyr)\nlibrary(tm)\nlibrary(ggplot2)\nlibrary(forcats)\nlibrary(rempsyc)\nlibrary(easystats)\nlibrary(kableExtra)\nlibrary(gtsummary)\n\n#Específicos para survival\nlibrary(survival)\nlibrary(ggsurvfit)\nlibrary(survminer)\nlibrary(broom)\nlibrary(survMisc)\nlibrary(PHInfiniteEstimates)\nlibrary(coin)\nlibrary(condSURV)"
  },
  {
    "objectID": "lista_6.html#limpando-o-ambiente",
    "href": "lista_6.html#limpando-o-ambiente",
    "title": "6  Lista 6 - Kaplan-Meier e Cox Regression",
    "section": "6.2 Limpando o ambiente",
    "text": "6.2 Limpando o ambiente\nQuando executamos diversos comandos no R muitas vezes acabamos deixando o ambiente meio “sujo”. Cheio de variáveis que não estamos mais utilizando, ou pacotes que estão carregados e não serão utilizados no momento.\nEm longas sessões utilizando o R é sempre bom dar uma limpada no ambiente entre um projeto e outro. Para isso podemos executar o código abaixo:\n\n# Limpa o ambiente\nrm(list = ls(all.names = TRUE)) # will clear all objects including hidden objects\ngc() # free up memory and report the memory usage\n\n          used  (Mb) gc trigger  (Mb) max used  (Mb)\nNcells 3170881 169.4    4805995 256.7  4805995 256.7\nVcells 5390829  41.2   10154066  77.5  8395055  64.1\n\noptions(max.print = .Machine$integer.max, scipen = 999, stringsAsFactors = F, dplyr.summarise.inform = F) # avoid truncated output in R console and scientific notation\n\n# Set seed\nset.seed(42)"
  },
  {
    "objectID": "lista_6.html#definindo-um-tema-para-os-gráficos",
    "href": "lista_6.html#definindo-um-tema-para-os-gráficos",
    "title": "6  Lista 6 - Kaplan-Meier e Cox Regression",
    "section": "6.3 Definindo um tema para os gráficos",
    "text": "6.3 Definindo um tema para os gráficos\nPreenhcer todos os parâmetros da função ggplot() é uma tarefa morosa e repetitiva. Podemos criar um tema para todos os nossos gráficos e assim manter a consistência nas figuras e não precisar ficar escrevendo toda hora aquele parâmetro para mudar a espessura da linha do eixo X…\nUma vez definido o tema, podemos apenas chamá-lo dentro da função ggplot para repetir o padrão. Vamos armazenar todas as informações da padronização em uma variável com o código a seguir:\n\nmeu_tema &lt;- theme(plot.title = element_text(size = rel(2)),\n                  panel.grid.major.y = element_line(colour = 'gray'),\n                  panel.grid.minor.y = element_line(colour = 'gray'),\n                  panel.grid.major.x = element_blank(),\n                  panel.grid.minor.x = element_blank(),\n                  plot.background = element_rect(fill = NULL, colour = 'white'),\n                  panel.background = element_rect(fill = 'white'),\n                  # Axis stuff\n                  axis.line = element_line(colour = 'black', linewidth = 1),\n                  axis.text = element_text(colour = \"black\", face = 'bold'),\n                  axis.text.x = element_text(size = rel(1)),\n                  axis.text.y = element_text(size = rel(1)),\n                  axis.title = element_text(size = rel(1.2)),\n                  axis.ticks = element_line(colour = 'black', linewidth = 1.2),\n                  # Legend stuff\n                  legend.position = \"bottom\",\n                  legend.margin = margin(6, 6, 6, 6),\n                  legend.title = element_text(face = 'bold'),\n                  legend.background = element_blank(),\n                  legend.box.background = element_rect(colour = \"black\"))\n\nVamos utilizar o tema em nossos gráficos mais adiante!"
  },
  {
    "objectID": "lista_6.html#sec-carrega_dados",
    "href": "lista_6.html#sec-carrega_dados",
    "title": "6  Lista 6 - Kaplan-Meier e Cox Regression",
    "section": "6.4 Carregando os dados e modificando o tipo de variável",
    "text": "6.4 Carregando os dados e modificando o tipo de variável\nComo de costume, vamos carregar os dados e ver os tipos das variáveis que temos no banco de dados.\n\noriginal = read.spss(\"teste Cox tempo dep Tx.sav\", to.data.frame=TRUE)\nglimpse(original)\n\nRows: 124\nColumns: 5\n$ id    &lt;chr&gt; \"13758618I                     \", \"13750502G                    …\n$ t_seg &lt;dbl&gt; 99, 98, 97, 97, 97, 96, 92, 90, 89, 87, 83, 83, 82, 82, 80, 77, …\n$ t_tx  &lt;dbl&gt; 22, 81, NA, 25, 93, 5, 1, 30, 88, 28, 30, 13, 49, NA, NA, 10, NA…\n$ tx    &lt;fct&gt; sim, sim, não, sim, sim, sim, sim, sim, sim, sim, sim, sim, sim,…\n$ obito &lt;fct&gt; não, não, não, não, não, não, não, não, sim, não, não, não, não,…\n\n\n\n\n\n\n\n\nCuidado!\n\n\n\nA variável do evento (óbito em nosso exemplo) PRECISA ser recodificada para uma variável numérica binária, ou seja, 1 e 0 caso queira realizar a análise de sobrevida.\n\n\nNa seção Section 6.16, exploraremos as distinções entre conduzir as análises com os fatores “sim” e “não” versus os números 1 e 0.\nInicialmente, ajustaremos a variável para aceitar os valores 1 e 0, representando a ocorrência do evento e a censura, respectivamente. Para isso, empregaremos o operador pipe %&gt;% para duplicar a base de dados original e efetuar a modificação no mesmo script. O operador pipe é útil para executar várias operações em uma única sequência de código.\n\ndb &lt;- original %&gt;%\n  mutate(\n    obito = as.integer(obito == \"sim\") # para transformar sim e não em 1 e 0, respectivamente\n  )\n\nglimpse(db)\n\nRows: 124\nColumns: 5\n$ id    &lt;chr&gt; \"13758618I                     \", \"13750502G                    …\n$ t_seg &lt;dbl&gt; 99, 98, 97, 97, 97, 96, 92, 90, 89, 87, 83, 83, 82, 82, 80, 77, …\n$ t_tx  &lt;dbl&gt; 22, 81, NA, 25, 93, 5, 1, 30, 88, 28, 30, 13, 49, NA, NA, 10, NA…\n$ tx    &lt;fct&gt; sim, sim, não, sim, sim, sim, sim, sim, sim, sim, sim, sim, sim,…\n$ obito &lt;int&gt; 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n\n\nPronto, agora temos que óbito assumiu os valores de números 1 e 0.\nOutra análise exploratória importante a fazer nos dados é observar se há dados faltantes (NA) e onde eles estão, caso estejam presentes. Se uma variável tiver muitos NAs, vamos precisar de cautela para inserir a variável na análise.\n\n# Verificando NAs\ndata.frame(\n  nas_t_seg = sum(is.na(db$t_seg)),\n  nas_t_seg = sum(is.na(db$t_tx)),\n  nas_tx = sum(is.na(db$tx)),\n  nas_obito = sum(is.na(db$obito))\n)\n\n  nas_t_seg nas_t_seg.1 nas_tx nas_obito\n1         0          64      0         0\n\n\n\nkable(report(db))\n\n\n\n\n\nVariable\nLevel\nn_Obs\npercentage_Obs\npercentage_Missing\nMean\nSD\nMedian\nMAD\nMin\nMax\nSkewness\nKurtosis\nn_Entries\nn_Missing\n\n\n\n\n3\nid\nNA\n124\n\n0.00\n\n\n\n\n\n\n\n\n124.00\n0\n\n\n5\nt_seg\nNA\n124\n\n0.00\n45.22\n24.08\n42.00\n19.27\n0.00\n99.00\n0.38\n-0.19\n\n\n\n\n6\nt_tx\nNA\n124\n\n51.61\n19.90\n20.05\n\n16.31\n1.00\n93.00\n1.99\n4.70\n\n\n\n\n1\ntx\nsim\n60\n48.39\n\n\n\n\n\n\n\n\n\n\n\n\n\n2\ntx\nnão\n64\n51.61\n\n\n\n\n\n\n\n\n\n\n\n\n\n4\nobito\nNA\n124\n\n0.00\n0.27\n0.45\n0.00\n0.00\n0.00\n1.00\n1.02\n-0.97\n\n\n\n\n\n\n\n\n\nO número de NAs na variável t_tx é alto (51.61%) pelo simples motivo de que pessoas que não fizeram transplante não possuem a marca do tempo que fizeram o transplante. Em todo caso podemos verificar se existem indivíduos que fizeram o transplante mas não possuem a marca do tempo em que fizeram o transplante.\n\ndb %&gt;%\n  filter(tx == \"sim\" & is.na(t_tx))\n\n[1] id    t_seg t_tx  tx    obito\n&lt;0 linhas&gt; (ou row.names de comprimento 0)\n\n\nO código acima filtra os dados de pessoas que fizeram o transplante (tx sim) e que tenham NA na coluna t_tx. Como o resultado volta com zero elementos, podemos concluir que todas as pessoas que fizeram o transplante, possuem a marca do horário em que o transplante foi feito.\nNa tabela acima podemos perceber também que a porcentagem de pessoas que não fizeram o transplante (51.61) é a mesma porcentagem de dados faltantes (missing) da variável t_tx (51.61)\nPor fim, podemos ver quantas pessoas morreram pela causa de morte do desfecho durante o período de observação.\n\nkable(table(db$obito))\n\n\n\n\nVar1\nFreq\n\n\n\n\n0\n90\n\n\n1\n34\n\n\n\n\n\n\n\nLembrando que 1 é o evento, que no nosso exemplo é ocorrência do óbito\nVamos agora às análises."
  },
  {
    "objectID": "lista_6.html#criando-a-estrutura-de-dados",
    "href": "lista_6.html#criando-a-estrutura-de-dados",
    "title": "6  Lista 6 - Kaplan-Meier e Cox Regression",
    "section": "6.5 Criando a estrutura de dados",
    "text": "6.5 Criando a estrutura de dados\nIniciamos especificando para a função Surv() as colunas referentes ao tempo observado e aos eventos de interesse, que, neste caso, são os óbitos.\n\nsurv_obj &lt;- Surv(time = db$t_seg, event = db$obito)"
  },
  {
    "objectID": "lista_6.html#a-tábua-de-vida",
    "href": "lista_6.html#a-tábua-de-vida",
    "title": "6  Lista 6 - Kaplan-Meier e Cox Regression",
    "section": "6.6 a) Tábua de vida",
    "text": "6.6 a) Tábua de vida\n\n\n\n\n\n\nExercício\n\n\n\nFaça duas tábuas de vida em função da variável óbito comparando grupos que fizeram ou não transplante: Ambas com período 0 até 99 meses. A primeira dividida em períodos de 20 meses e a segunda com períodos de 1 mês. Faça um parágrafo descrevendo as diferenças nos gráficos.\n\n\nAgora vamos criar a tabela de vida. Por enquanto, não faremos a separação dos dados por grupos.\n\nfit1 &lt;- survfit(surv_obj ~ 1, data = db)\n\nA função summary() também pode ser utilizada para verificar os resultados dos modelos de sobrevida.\n\nsummary(fit1)\n\nCall: survfit(formula = surv_obj ~ 1, data = db)\n\n time n.risk n.event survival std.err lower 95% CI upper 95% CI\n    0    124       2    0.984  0.0113        0.962        1.000\n    3    121       2    0.968  0.0159        0.937        0.999\n    4    119       2    0.951  0.0194        0.914        0.990\n    6    117       1    0.943  0.0208        0.903        0.985\n    8    116       2    0.927  0.0234        0.882        0.974\n   11    114       1    0.919  0.0246        0.872        0.968\n   13    113       1    0.911  0.0257        0.862        0.962\n   16    110       1    0.902  0.0268        0.851        0.956\n   19    108       1    0.894  0.0278        0.841        0.950\n   24    106       2    0.877  0.0297        0.821        0.937\n   25    104       1    0.869  0.0306        0.811        0.931\n   26    103       1    0.860  0.0314        0.801        0.924\n   27    102       1    0.852  0.0323        0.791        0.917\n   29    101       1    0.843  0.0330        0.781        0.911\n   34     89       3    0.815  0.0358        0.748        0.888\n   36     82       1    0.805  0.0367        0.736        0.880\n   38     70       1    0.794  0.0379        0.723        0.871\n   40     68       1    0.782  0.0391        0.709        0.862\n   41     65       2    0.758  0.0414        0.681        0.844\n   44     59       1    0.745  0.0427        0.666        0.834\n   45     55       1    0.731  0.0440        0.650        0.823\n   46     53       1    0.718  0.0453        0.634        0.812\n   49     47       1    0.702  0.0468        0.616        0.800\n   58     32       1    0.680  0.0502        0.589        0.786\n   66     24       1    0.652  0.0556        0.552        0.771\n   89      9       1    0.580  0.0843        0.436        0.771\n\n\nE a função função tidy_survfit() nos oferece uma tabela bem mais completa.\n\ntidy_survfit(fit1)\n\n# A tibble: 63 × 14\n    time n.risk n.event n.censor cum.event cum.censor estimate std.error\n   &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;      &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;\n 1     0    124       2        1         2          1    0.984    0.0115\n 2     3    121       2        0         4          1    0.968    0.0165\n 3     4    119       2        0         6          1    0.951    0.0204\n 4     6    117       1        0         7          1    0.943    0.0221\n 5     8    116       2        0         9          1    0.927    0.0253\n 6    11    114       1        0        10          1    0.919    0.0268\n 7    13    113       1        0        11          1    0.911    0.0282\n 8    14    112       0        1        11          2    0.911    0.0282\n 9    15    111       0        1        11          3    0.911    0.0282\n10    16    110       1        0        12          3    0.902    0.0297\n# ℹ 53 more rows\n# ℹ 6 more variables: conf.high &lt;dbl&gt;, conf.low &lt;dbl&gt;, estimate_type &lt;chr&gt;,\n#   estimate_type_label &lt;chr&gt;, monotonicity_type &lt;chr&gt;, conf.level &lt;dbl&gt;"
  },
  {
    "objectID": "lista_6.html#b-kaplan-meier",
    "href": "lista_6.html#b-kaplan-meier",
    "title": "6  Lista 6 - Kaplan-Meier e Cox Regression",
    "section": "6.7 b) Kaplan-Meier",
    "text": "6.7 b) Kaplan-Meier\n\n\n\n\n\n\nExercício\n\n\n\nFaça uma curva de Kaplan-meyer comparando os grupos que fizeram vs não fizeram transplante em relação ao óbito. Analise o gráfico e as saídas do teste.\n\n\nPara produzir um gráfico Kaplan-Meier simples podemos utilizar a função plot().\n\nplot(fit1)\n\n\n\n\nMeio pobrezinho e sem cor ne?\nPodemos melhorar utilizando a função ggsurvfit(), do pacote com o mesmo nome.\n\nfit1_km = ggsurvfit(fit1, linewidth = 1) +\n  labs(x = 'Dias', y = 'Overall survival') +\n  add_confidence_interval() +\n  add_risktable() +\n  scale_ggsurvfit() \n\nfit1_km\n\n\n\n\nAté aqui estamos vendo o gráfico da sobrevida sem separar por grupos. A seguir vamos comparar entre os grupos que receberam ou não o transplante de rins."
  },
  {
    "objectID": "lista_6.html#separando-por-transplante-e-nos-tempos-0-20-40-60-80",
    "href": "lista_6.html#separando-por-transplante-e-nos-tempos-0-20-40-60-80",
    "title": "6  Lista 6 - Kaplan-Meier e Cox Regression",
    "section": "6.8 Separando por transplante e nos tempos 0, 20, 40, 60, 80",
    "text": "6.8 Separando por transplante e nos tempos 0, 20, 40, 60, 80\nQueremos comparar a sobrevida entre quem fez e não fez o transplante. Para isso podemos especificar no modelo que o transplante (tx) será uma das variáveis independentes.\n\nfit2 = survfit(surv_obj ~ tx, # basta colocar tx como uma variável preditora no modelo\n               data = db) \n\n\nsummary(fit2)\n\nCall: survfit(formula = surv_obj ~ tx, data = db)\n\n                tx=sim \n time n.risk n.event survival std.err lower 95% CI upper 95% CI\n    3     59       1    0.983  0.0168        0.951        1.000\n    4     58       1    0.966  0.0236        0.921        1.000\n   24     57       1    0.949  0.0286        0.895        1.000\n   26     56       1    0.932  0.0327        0.870        0.999\n   29     55       1    0.915  0.0363        0.847        0.989\n   38     44       1    0.894  0.0410        0.818        0.978\n   41     41       1    0.873  0.0454        0.788        0.966\n   45     37       1    0.849  0.0499        0.757        0.953\n   49     32       1    0.823  0.0550        0.722        0.938\n   66     19       1    0.779  0.0670        0.658        0.922\n   89      8       1    0.682  0.1083        0.499        0.931\n\n                tx=não \n time n.risk n.event survival std.err lower 95% CI upper 95% CI\n    0     64       2    0.969  0.0217        0.927        1.000\n    3     62       1    0.953  0.0264        0.903        1.000\n    4     61       1    0.938  0.0303        0.880        0.999\n    6     60       1    0.922  0.0335        0.858        0.990\n    8     59       2    0.891  0.0390        0.817        0.970\n   11     57       1    0.875  0.0413        0.798        0.960\n   13     56       1    0.859  0.0435        0.778        0.949\n   16     53       1    0.843  0.0456        0.758        0.937\n   19     51       1    0.827  0.0476        0.738        0.925\n   24     49       1    0.810  0.0495        0.718        0.913\n   25     48       1    0.793  0.0513        0.699        0.900\n   27     47       1    0.776  0.0529        0.679        0.887\n   34     38       3    0.715  0.0594        0.607        0.841\n   36     35       1    0.694  0.0611        0.584        0.825\n   40     26       1    0.668  0.0643        0.553        0.806\n   41     24       1    0.640  0.0674        0.520        0.786\n   44     21       1    0.609  0.0707        0.485        0.765\n   46     18       1    0.575  0.0745        0.447        0.742\n   58     11       1    0.523  0.0841        0.382        0.717\n\n\nA função summary() aceita um parâmetro com intervalos específicos para aparecer nos resultados. Vamos utilizar a função seq() para criar uma sequência de números que vai do 0 ao 100 com intervalos de 20 em 20.\n\n# Cria o intervalo de tempo\n\ntempos_específicos &lt;- seq(0, 100, by = 20) # sequencia de 0 a 100 em intervalos de 20.\n\nAplicando o intervalo na função temos o seguinte script:\n\nsummary(fit2, times = tempos_específicos)\n\nCall: survfit(formula = surv_obj ~ tx, data = db)\n\n                tx=sim \n time n.risk n.event survival std.err lower 95% CI upper 95% CI\n    0     60       0    1.000  0.0000        1.000        1.000\n   20     57       2    0.966  0.0236        0.921        1.000\n   40     42       4    0.894  0.0410        0.818        0.978\n   60     21       3    0.823  0.0550        0.722        0.938\n   80     12       1    0.779  0.0670        0.658        0.922\n\n                tx=não \n time n.risk n.event survival std.err lower 95% CI upper 95% CI\n    0     64       2    0.969  0.0217        0.927        1.000\n   20     50       9    0.827  0.0476        0.738        0.925\n   40     26       8    0.668  0.0643        0.553        0.806\n   60      7       4    0.523  0.0841        0.382        0.717\n   80      3       0    0.523  0.0841        0.382        0.717\n\n\nPodemos nos perguntar também qual é a probabilidade de sobreviver após um certo tempo. Para obter a resposta basta ajustar o parâmetro times da função summary() para o tempo desejado.\n\nsummary(fit2, times = 75)\n\nCall: survfit(formula = surv_obj ~ tx, data = db)\n\n                tx=sim \n        time       n.risk      n.event     survival      std.err lower 95% CI \n      75.000       14.000       10.000        0.779        0.067        0.658 \nupper 95% CI \n       0.922 \n\n                tx=não \n        time       n.risk      n.event     survival      std.err lower 95% CI \n     75.0000       4.0000      23.0000       0.5232       0.0841       0.3818 \nupper 95% CI \n      0.7169 \n\n\nNa análise do tempo de sobrevivência neste modelo, observamos o seguinte:\nPara o grupo que realizou o transplante (tx=sim):\n\nAos 75 meses, havia 14 indivíduos em risco.\n10 eventos ocorreram até esse momento.\nA taxa de sobrevivência foi de 0.779, com um desvio padrão de 0.067.\nO intervalo de confiança de 95% para a taxa de sobrevivência variou de 0.658 a 0.922.\n\nPara o grupo que não realizou o transplante (tx=não):\n\nAos 75 meses, havia 4 indivíduos em risco.\n23 eventos ocorreram até esse momento.\nA taxa de sobrevivência foi de 0.5232, com um desvio padrão de 0.0841.\nO intervalo de confiança de 95% para a taxa de sobrevivência variou de 0.3818 a 0.7169.\n\nPodemos ainda calcular quantas vezes a probabilidade de sobrevivência é maior no grupo que realizou o transplante em comparação com o grupo que não o fez.\n\nsummary(fit2, times = 75)$surv[1] / summary(fit2, times = 75)$surv[2]\n\n[1] 1.489431\n\n\nO resultado revela que a probabilidade de sobrevivência no grupo que fez o transplante é aproximadamente 1.5 vezes maior do que no grupo que não o realizou.\n\nKaplan-Meir do novo modelo\nVamos salvar o plot padrão do segundo modelo para adicionar mais alguns parâmetros e incrementar a visualização dos resultados.\n\nfit2_km = ggsurvfit(fit2, linewidth = 1) +\n  labs(x = 'Tempo (meses)', y = '% Probabilidade de sobrevivência') +\n  add_confidence_interval() +\n  #add_risktable() + \n  scale_ggsurvfit() \n\nfit2_km\n\n\n\n\nCom o plot salvo, podemos adicionar mais elementos aos poucos, como as linhas tracejadas para enfatizar diferenças.\n\nfit2_km +\n  geom_vline(xintercept = 75, \n             linetype = 'dashed', \n             colour = 'red', \n             size = 1) + # adiciona a linha vermelha vertical \n  geom_hline(yintercept = summary(fit2, times = 75)$surv, \n             linetype = 'dashed', \n             colour = 'red', size = 1) # adiciona as linhas vermelhas horizontais.\n\n\n\n\n\n\nPorcentagem fixa, tempos diferentes\nA função ggsurvfit oferece vários parâmetros interessantes. Um deles, bastante útil, permite traçar uma linha para comparar o tempo em que a probabilidade de sobrevivência X ocorre entre grupos diferentes.\nEm quanto tempo será que a probabilidade de sobrevida chega a 75% nos dois grupos? Vamos utilizar o parâmetro add_quantile() para ter uma estimativa gráfica.\n\nfit2 %&gt;% \n  ggsurvfit(linewidth = 1) +\n  labs(x = 'Tempo (meses)', y = '% Probabilidade de sobrevivência') +\n  add_confidence_interval() +\n  #  add_risktable() +\n  add_quantile(y_value = 0.75, color = \"gray50\", linewidth = 0.75) +\n  scale_ggsurvfit()\n\n\n\n\nAo examinarmos a imagem, observamos que o grupo que não passou pelo transplante atinge uma probabilidade de sobrevida de 75% em aproximadamente 35 meses. Por outro lado, no grupo que se submeteu ao transplante, essa mesma probabilidade só ocorre por volta do 90º mês, sendo ainda maior antes desse período.\n\n\nEscolhendo um intervalo de tempo\nCaso você queira apresentar apenas um período específico de tempo em sua análise, podemos fazer isso utilizando o parâmetro coord_cartesian().\n\nggsurvfit(fit2, linewidth = 1) +\n  labs(x = 'Tempo (meses)', y = '% Probabilidade de sobrevivência') +\n  add_confidence_interval() +\n  # add_risktable() +\n  scale_ggsurvfit() + \n  coord_cartesian(xlim = c(0, 60)) # coloque os números que\n\n\n\n\nPersonalize os limites do intervalo de tempo em sua análise ajustando os valores “0” e “60”, de acordo com suas necessidades específicas."
  },
  {
    "objectID": "lista_6.html#comparando-as-curvas",
    "href": "lista_6.html#comparando-as-curvas",
    "title": "6  Lista 6 - Kaplan-Meier e Cox Regression",
    "section": "6.9 Comparando as curvas",
    "text": "6.9 Comparando as curvas\n\nLog-rank: utilizar para comparar o primeiro terço do gráfico\nGehan: utilizar para comparar o meio do gráfico\nTarone: utilizar para comparar o final do gráfico\nPeto-Peto: parecido com o Log-rank, utilizar para comparar o primeiro terço do gráfico\n\nPacote mais indicado para utilizar é o coin.\n\nTipos de testes possíveis\n“logrank”, “Gehan-Breslow”, “Tarone-Ware”, “Peto-Peto”, “Prentice”, “Prentice-Marek”, “Andersen-Borgan-Gill-Keiding”, “Fleming-Harrington”, “Gaugler-Kim-Liao”, “Self”\n\nLog-rank\n\ncoin::logrank_test(surv_obj ~ tx, data = db, type = \"logrank\" ) # padrão é o log-rank\n\n\n    Asymptotic Two-Sample Logrank Test\n\ndata:  surv_obj by tx (sim, não)\nZ = 2.9275, p-value = 0.003417\nalternative hypothesis: true theta is not equal to 1\n\n\n\n\nGehan-Breslow\n\ncoin::logrank_test(surv_obj ~ tx ,data = db, type = \"Gehan-Breslow\")\n\n\n    Asymptotic Two-Sample Gehan-Breslow Test\n\ndata:  surv_obj by tx (sim, não)\nZ = 3.0103, p-value = 0.00261\nalternative hypothesis: true theta is not equal to 1\n\n\n\n\nTarone-Ware\n\ncoin::logrank_test(surv_obj ~ tx ,data = db, type = \"Tarone-Ware\")\n\n\n    Asymptotic Two-Sample Tarone-Ware Test\n\ndata:  surv_obj by tx (sim, não)\nZ = 3.0338, p-value = 0.002415\nalternative hypothesis: true theta is not equal to 1\n\n\n\n\nPeto-Peto\n\ncoin::logrank_test(surv_obj ~ tx ,data = db, type = \"Peto-Peto\")\n\n\n    Asymptotic Two-Sample Peto-Peto Test\n\ndata:  surv_obj by tx (sim, não)\nZ = 2.9857, p-value = 0.002829\nalternative hypothesis: true theta is not equal to 1\n\n\nEm todos os testes a hipótese alternativa sugere que o verdadeiro parâmetro theta não é igual a 1, indicando assim que há diferenças significativas nas curvas de sobrevida entre os dois grupos analisados. Em termos práticos, isso sugere que a probabilidade de sobrevivência varia de maneira estatisticamente significativa entre os grupos que fizeram ou não o transplante."
  },
  {
    "objectID": "lista_6.html#c-cox-regression",
    "href": "lista_6.html#c-cox-regression",
    "title": "6  Lista 6 - Kaplan-Meier e Cox Regression",
    "section": "6.10 c) Cox Regression",
    "text": "6.10 c) Cox Regression\n\n\n\n\n\n\nExercício\n\n\n\nReproduza a análise do item b) com uma Cox Regression. Descreva os resultados\n\n\nCompare com base no resultado da Cox, qual seria a diferença na sobrevida (HR) entre uma pessoa que fez e outra que não fez transplante com 50 meses de observação\nA Regressão de Cox é uma técnica estatística utilizada para analisar a relação entre variáveis explicativas e o tempo até um evento ocorrer, como a morte. Ao contrário de modelos de regressão linear, a Regressão de Cox lida com dados de sobrevida, levando em consideração o tempo até o evento ou a censura. O código apresentado realiza uma Regressão de Cox com a função coxph().\n\n# Cox regression ======================================================\n# Fit the model\ncox_res &lt;- coxph(Surv(time = db$t_seg, event = db$obito) ~ tx, data = db)\n\nO código acima ajusta o modelo de Regressão de Cox. A variável dependente é definida como o tempo (t_seg) até o evento (obito) ocorrer, e a variável independente é tx.\nNotem que dentro da função coxph(), repetimos o código para gerar a tabela de vida.Durante a criação da estrutura dos dados, armazenamos a tabela de vida em uma variável chamada surv_obj. Podemos reutilizá-la na Regressão de Cox, evitando a necessidade de reescrever o código.\nVamos fazer isso!\n\ncox_res_2 = coxph(surv_obj ~ tx, data = db)\n\nBem mais limpo, não? E como vamos escrever mais alguns modelos, é uma boa prática salvar o padrão que se repete em uma variável.\n\nResultados dos modelos\nSabe qual função vamos utilizar para verificar o resultado? Sim, a summary().\nPrimeiro vamos verificar se as duas formas que escrevemos os modelos geram os mesmos resultados.\n\nsummary(cox_res)\n\nCall:\ncoxph(formula = Surv(time = db$t_seg, event = db$obito) ~ tx, \n    data = db)\n\n  n= 124, number of events= 34 \n\n        coef exp(coef) se(coef)     z Pr(&gt;|z|)   \ntxnão 1.0787    2.9409   0.3753 2.874  0.00405 **\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n      exp(coef) exp(-coef) lower .95 upper .95\ntxnão     2.941       0.34     1.409     6.136\n\nConcordance= 0.638  (se = 0.04 )\nLikelihood ratio test= 8.99  on 1 df,   p=0.003\nWald test            = 8.26  on 1 df,   p=0.004\nScore (logrank) test = 9.01  on 1 df,   p=0.003\n\n\n\n\nsummary(cox_res_2)\n\nCall:\ncoxph(formula = surv_obj ~ tx, data = db)\n\n  n= 124, number of events= 34 \n\n        coef exp(coef) se(coef)     z Pr(&gt;|z|)   \ntxnão 1.0787    2.9409   0.3753 2.874  0.00405 **\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n      exp(coef) exp(-coef) lower .95 upper .95\ntxnão     2.941       0.34     1.409     6.136\n\nConcordance= 0.638  (se = 0.04 )\nLikelihood ratio test= 8.99  on 1 df,   p=0.003\nWald test            = 8.26  on 1 df,   p=0.004\nScore (logrank) test = 9.01  on 1 df,   p=0.003\n\n\n\nBoa! Os resultados são idênticos, então podemos manter o padrão de escrevr o modelo utilizando a tábua de vida salva em uma variável.\nEmbora o resultado da função summary() para modelos de Regressão de Cox possa não ser visualmente atraente, ele oferece informações detalhadas sobre como o modelo se ajusta aos dados. Vamos analisar cada componente separadamente:\n\nSumário do Modelo:\n\nCall: Indica a chamada da função utilizada para ajustar o modelo.\nn= 124, number of events= 34: Informa o número total de observações (n) e o número de eventos ocorridos (number of events).\n\nCoeficientes:\n\ncoef: O coeficiente estimado para a variável tx.\nexp(coef): A interpretação deste valor é que, para pessoas do grupo que não fizeram o transplante (txnão), o risco de o evento (morte) ocorrer aumenta em 2.941 vezes.\nse(coef): O erro padrão do coeficiente.\n\nTeste de Hipótese para Coeficientes:\n\nz: O valor z do teste de Wald, indicando quão longe o coeficiente está da média em termos de erros padrão.\nPr(&gt;|z|): O p-valor associado ao teste de Wald. No exemplo, 0.00405 sugere que o efeito da variável tx é estatisticamente significativo.\nSignificância codes: ** indica significância a 0.01.\n\nIntervalo de Confiança para Exp(Coef):\n\nexp(coef) exp(-coef) lower .95 upper .95: O intervalo de confiança de 95% para o efeito da variável tx.\n\nMedidas de Desempenho do Modelo:\n\nConcordance= 0.638: A concordância é uma medida de quão bem o modelo prevê a ordem de eventos.\nLikelihood ratio test= 8.99, p=0.003: O teste de razão de verossimilhança avalia se o modelo é significativamente melhor do que um modelo nulo. O p-valor sugere que o modelo é estatisticamente significativo.\nWald test= 8.26, p=0.004: O teste de Wald também avalia a significância global do modelo.\nScore (logrank) test= 9.01, p=0.003: O teste de log-rank compara as curvas de sobrevivência entre os grupos.\n\n\nE claro que temos formas melhores de visualizar e mostrar os dados mais importantes. Vamos utilizar a função tbl_regression() do pacote gtsummary, que pega um objeto de modelo de regressão e retorna uma tabela formatada pronta para publicação.\n\ntbl_regression(cox_res, exponentiate = TRUE)\n\n\n\n\n\n  \n    \n    \n      Characteristic\n      HR1\n      95% CI1\n      p-value\n    \n  \n  \n    tx\n\n\n\n        sim\n—\n—\n\n        não\n2.94\n1.41, 6.14\n0.004\n  \n  \n  \n    \n      1 HR = Hazard Ratio, CI = Confidence Interval\n    \n  \n\n\n\n\nPra fazer isso aí no word demoraria uns 30 minutos hein? E ficaria feia ainda. Com uma linha de código fizemos miséria!\n\n\nPlots do modelo e do resultado\nTendo ajustado um modelo de Cox aos dados, é possível visualizar a proporção de sobrevivência prevista em qualquer momento para um determinado grupo de risco.\nNeste caso, construímos um novo banco de dados com duas linhas, uma para cada valor de tx.\n\ntx_df &lt;- with(db,\n              data.frame(tx = c(\"sim\", \"não\")\n              )\n)\nkable(tx_df)\n\n\n\n\ntx\n\n\n\n\nsim\n\n\nnão\n\n\n\n\n\n\n\nAgora podemos utilizar o nosso modelo para prever os valores de sobrevida e criar um gráfico da Regressão de Cox.\n\ncox_graph &lt;- survfit(cox_res, newdata = tx_df)\n\nggsurvplot(cox_graph, conf.int = TRUE, legend.labs=c(\"tx=sim\", \"tx=não\"),\n           ggtheme = theme_minimal(),\n           data = db)\n\n\n\n\n\n\n\n\n\n\nCuidado!\n\n\n\nO gráfico do modelo da Regressão de Cox é diferente do gráfico da Kaplan-Meir! O cálculo da regressão distorce os valores e encaixa o modelo aos dados. Observe a diferença!\n\n\n\n# Gráfico da Kaplan-Meir\nfit2_km\n\n\n\n\nNão podemos deixar e fora o gráfico do modelo. Com pouca tinta (e pouco código) vamos mostrar tudo o que a função summary() nos proporcionou. Para isso vamos utilizar a função ggforest() do pacote survminer.\n\nggforest(cox_res, data = db)\n\n\n\n\nSe não escorreu uma lágrima aí do outro lado da tela agora, eu desisto. E olha que utilizamos apenas uma variável independente no modelo!"
  },
  {
    "objectID": "lista_6.html#hazard-ratio-e-risco-relativo-confirmar-o-conteúdo",
    "href": "lista_6.html#hazard-ratio-e-risco-relativo-confirmar-o-conteúdo",
    "title": "6  Lista 6 - Kaplan-Meier e Cox Regression",
    "section": "6.11 Hazard ratio e risco relativo (CONFIRMAR O CONTEÚDO)",
    "text": "6.11 Hazard ratio e risco relativo (CONFIRMAR O CONTEÚDO)\nVocês repararam que tanto na tabela quanto no gráfico com os resultados no modelo aparece o resultado como “Hazard Ratio”… pois bem, isso está errado!\n\n\n\n\n\n\nAtenção!\n\n\n\nO risco relativo compara a probabilidade cumulativa de um evento ocorrer entre dois grupos ao longo de um período específico, enquanto o hazard ratio avalia a razão instantânea de riscos proporcionais entre os grupos, considerando a variação no risco ao longo do tempo. Enquanto o risco relativo se concentra em eventos cumulativos, o hazard ratio destaca as diferenças nas taxas instantâneas de falha, sendo especialmente útil em análises de sobrevida e estudos onde a dinâmica temporal do risco é crucial."
  },
  {
    "objectID": "lista_6.html#d-hazard-ratio",
    "href": "lista_6.html#d-hazard-ratio",
    "title": "6  Lista 6 - Kaplan-Meier e Cox Regression",
    "section": "6.12 d) Hazard Ratio",
    "text": "6.12 d) Hazard Ratio\n\n\n\n\n\n\nExercício\n\n\n\nCompare com base no resultado da Cox, qual seria a diferença na sobrevida (HR) entre uma pessoa que fez e outra que não fez transplante com 50 meses de observação\n\n\nPara de fato calcular o Hazard Ratio precisamos utilizar nosso modelo para prever a sobrevida em um tempo específico de nosso interesse.\nVamos começar salvando nosso modelo em uma variável\n\n# Ajuste do modelo de regressão de Cox\ncox_res &lt;- coxph(Surv(time = t_seg, event = obito) ~ tx, data = db)\n\nAgora vamos criar um conjunto de dados com informações simuladas sobre tempo de seguimento, ocorrência de evento (óbito), e uma variável indicadora de tratamento. Como queremos comparar o tempo de sobrevida entre quem fez ou não o transplante, a única variável que terá valores diferentes será a tx.\n\npred_dat &lt;- data.frame(t_seg = c(41,41),\n                       obito = c(0,0), \n                       tx = c(\"sim\",\"não\")\n                       )\nkable(pred_dat)\n\n\n\n\nt_seg\nobito\ntx\n\n\n\n\n41\n0\nsim\n\n\n41\n0\nnão\n\n\n\n\n\n\n\nA seguir vamos utiliza a função predict() para fazer previsões com base em nosso modelo previamente ajustado (cox_res).\n\npreds &lt;- predict(cox_res, newdata = pred_dat, type = \"survival\", se.fit = TRUE)\n\nSalvamos o resultado da função em uma variável para poder adicionar os resultados das predições em nosso dataframe criado anteriormente (pred_dat). Queremos os resultados da média e do Intervalo de Confiança. Para isso executamos o código a seguir:\n\npred_dat$prob &lt;- preds$fit\npred_dat$lcl &lt;- preds$fit - 1.96*preds$se.fit\npred_dat$ucl &lt;- preds$fit + 1.96*preds$se.fit\nkable(pred_dat)\n\n\n\n\nt_seg\nobito\ntx\nprob\nlcl\nucl\n\n\n\n\n41\n0\nsim\n0.8630231\n0.7805057\n0.9455404\n\n\n41\n0\nnão\n0.6484075\n0.5224067\n0.7744083\n\n\n\n\n\n\n\nPor fim, podemos finalmente verificar o Hazard Ratio no tempo de 41 meses, dividindo a probabilidade de sobrevida do grupo que fez o transplante pela probabilidade de sobrevida do grupo que não fez o transplante.\n\nHR_41 = pred_dat$prob[1] / pred_dat$prob[2] # Diferença na sobrevida (HR) no tempo 41 meses \nHR_41\n\n[1] 1.330989\n\n\n\nTemos que no tempo de 41 meses a probabilidade de sobrevida de quem não fez o transplante é 1.33 menor do que quem fez o transplante.\nCaso tenha interesse em mais pontos, podemos criar vários tempos de interesse em um único dataframe e repetir o código.\n\nmulti_pred_dat &lt;- data.frame(t_seg = c(41,41, 50, 50, 80, 80),\n                       obito = c(0,0,0,0,0,0), \n                       tx = c(\"sim\",\"não\",\"sim\",\"não\",\"sim\",\"não\")\n                       )\n\npreds &lt;- predict(cox_res, newdata = multi_pred_dat, type = \"survival\", se.fit = TRUE)\n\nmulti_pred_dat$prob &lt;- preds$fit\nmulti_pred_dat$lcl &lt;- preds$fit - 1.96*preds$se.fit\nmulti_pred_dat$ucl &lt;- preds$fit + 1.96*preds$se.fit\n\nHR_41 = multi_pred_dat$prob[1] / multi_pred_dat$prob[2] # 41 \nHR_50 = multi_pred_dat$prob[3] / multi_pred_dat$prob[4] # 50 \nHR_80 = multi_pred_dat$prob[5] / multi_pred_dat$prob[6] # 80 \n\ntabela_HR = data.frame(Tempo = c(41, 50, 80),\n                       HR_Não = c(HR_41, HR_50, HR_80))\nkable(tabela_HR)\n\n\n\n\nTempo\nHR_Não\n\n\n\n\n41\n1.330989\n\n\n50\n1.454309\n\n\n80\n1.597592"
  },
  {
    "objectID": "lista_6.html#verificando-os-pressupostos-da-cox-regression",
    "href": "lista_6.html#verificando-os-pressupostos-da-cox-regression",
    "title": "6  Lista 6 - Kaplan-Meier e Cox Regression",
    "section": "6.13 Verificando os pressupostos da Cox regression",
    "text": "6.13 Verificando os pressupostos da Cox regression\nA Regressão de Cox é uma técnica robusta, mas, como qualquer método estatístico, possui alguns pressupostos importantes. Os principais pressupostos da Regressão de Cox são:\n\nProporcionalidade dos Riscos:\n\nO pressuposto fundamental é que os riscos relativos entre dois grupos são constantes ao longo do tempo. Em outras palavras, a razão instantânea de riscos (hazard ratio) entre grupos não muda com o tempo. Este é o pressuposto de proporcionalidade dos riscos.\n\nIndependência Censura:\n\nA censura dos dados deve ser independente da probabilidade de falha. Isso significa que a probabilidade de um evento censurado (ocorrido após o fim do acompanhamento) deve ser a mesma para todos os grupos.\n\nLinearidade no Logaritmo dos Riscos:\n\nA relação entre as variáveis independentes e o logaritmo do risco deve ser linear. Isso é crucial para a interpretação dos coeficientes como log-riscos instantâneos.\n\nAuscência de Colinearidade:\n\nAs variáveis independentes no modelo não devem estar altamente correlacionadas (colinearidade). A colinearidade pode levar a estimativas imprecisas dos coeficientes.\n\nAusência de Efeito de Interferência:\n\nNão deve haver efeito de interferência entre indivíduos, o que significa que o status de um indivíduo não deve influenciar diretamente o tempo de falha de outro indivíduo.\n\nAdequação do Modelo:\n\nO modelo escolhido deve ser apropriado para os dados. Avaliações de adequação, como testes de resíduos, podem ser úteis para verificar a qualidade do ajuste do modelo aos dados.\n\n\nOs pressupostos de 2 a 6 são inerentes ao desenho do experimento e do acompanhamento durante as observações. O único que vamos abordar aqui no tutorial é o de proporcionalidade dos riscos.\n\nProporcionalidade dos riscos\nTemos duas formas de avaliar a proporcionalidade dos riscos\n\n1) Análise do gráfico da Kaplan-Meier\nAo analisar o gráfico de Kaplan-Meier para diferentes grupos, é crucial observar se as curvas de sobrevivência são aproximadamente paralelas ou se cruzam entre si. Se as curvas são paralelas, isso sugere proporcionalidade dos riscos, indicando que as diferenças nas taxas de falha entre os grupos são constantes ao longo do tempo. No entanto, se as curvas se cruzam, isso indica uma possível violação da proporcionalidade dos riscos.\nCruzamentos nas curvas podem indicar mudanças na relação de risco entre os grupos ao longo do tempo. Essa mudança pode ser devido a diferentes dinâmicas de risco em períodos distintos do estudo. Se as curvas se cruzarem, a aplicação da Regressão de Cox não deve ser feita para não gerar interpretações erradas!\n\nfit2_km\n\n\n\n\nPodemos observar que em nosso exemplo as linhas de sobrevida não cruzam, portanto podemos assumir que os riscos são proporcionais pela análise gráfica.\n\n\n2) Resíduos de Schoenfeld\nA segunda forma para se avaliar a suposição de proporcionalidade dos riscos na Regressão de Cox vamos utilizar o teste de Schoenfeld, que verifica se há uma relação sistemática entre os resíduos de Schoenfeld e o tempo, o que indicaria uma violação dessa suposição.\nA ideia central é que, se os resíduos de Schoenfeld não apresentarem uma relação significativa com o tempo, isso sugere que a proporcionalidade dos riscos é razoável. Logo, a hipótese nula é que não há relação entre os resíduos e o tempo, o que indicaria proporcionalidade dos riscos. O teste estatístico avalia se é razoável rejeitar essa hipótese nula.\n\n\n\n\n\n\nImportante!\n\n\n\nVamos torcer para o valor de p ser MAIOR que 0.05!\n\n\nUtilizando a função cox.zph() do pacote survival temos o seguinte código:\n\ntest &lt;- survival::cox.zph(cox_res)\ntest\n\n       chisq df    p\ntx      0.58  1 0.45\nGLOBAL  0.58  1 0.45\n\n\nOk! Temos riscos proporcionais!\nOutra forma de verificar a proporcionalidade dos riscos é com o gráfico dos resíduos de Schoenfeld.\n\n# Plot the Schoenfeld residuals over time for each covariate\nsurvminer::ggcoxzph(test, point.size = 0.1)[1]\n\n$`1`\n\n\n\n\n\nSe os resíduos mostrarem um padrão claro ao longo do tempo, isso pode indicar uma violação da suposição de riscos proporcionais.\nAlgumas dicas para ajudar na interpretação:\n\nSem Padrão (Resíduos Constantes): Se os resíduos aparecerem aleatoriamente espalhados em torno de zero, sem nenhuma tendência ou padrão claro, isso sugere que a suposição de riscos proporcionais é razoável.\nTendência Linear: Uma tendência linear (aumentando ou diminuindo) nos resíduos ao longo do tempo pode sugerir uma violação da suposição de riscos proporcionais. Por exemplo, se os resíduos forem consistentemente positivos ou negativos ao longo do tempo, isso indica um efeito dependente do tempo.\nPadrão Não Linear: Se os resíduos exibirem um padrão não linear ou formatos específicos (por exemplo, formato de U, formato de V), isso pode indicar desvios dos riscos proporcionais.\nParalelismo: Paralelismo significa que a propagação e distribuição dos resíduos são relativamente constantes ao longo do tempo. Se os resíduos aumentarem ou diminuirem ao longo do tempo, isso pode sugerir uma violação da suposição."
  },
  {
    "objectID": "lista_6.html#conlcusões",
    "href": "lista_6.html#conlcusões",
    "title": "6  Lista 6 - Kaplan-Meier e Cox Regression",
    "section": "6.14 Conlcusões",
    "text": "6.14 Conlcusões\nMuito bacana a análise de sobrevida e a Regressão de Cox! Na seção Extras! vamos ver mais algumas formas de plotar os gráficos e avaliar a proporcionalidade dos riscos caso a Variável Independente seja contínua!\nPróximo capitulo: Cox tempo-dependente!"
  },
  {
    "objectID": "lista_6.html#lista-6-resolvida-no-spss",
    "href": "lista_6.html#lista-6-resolvida-no-spss",
    "title": "6  Lista 6 - Kaplan-Meier e Cox Regression",
    "section": "6.15 Lista 6 resolvida no SPSS",
    "text": "6.15 Lista 6 resolvida no SPSS"
  },
  {
    "objectID": "lista_6.html#sec-extrasVI",
    "href": "lista_6.html#sec-extrasVI",
    "title": "6  Lista 6 - Kaplan-Meier e Cox Regression",
    "section": "6.16 Extras!",
    "text": "6.16 Extras!\n\nEvento como fator ou como número\nComo mencionado na seção Section 6.4, o tipo da variável do evento (morte) afeta os resultados tanto da Kaplan-Meir quanto na Regressão de Cox.\nVamos criar alguns modelos utilizando o banco de dados original (variável óbito é um fator) e também o db (variável óbito é binária, 1 e 0).\nVamos começar observando a diferença do tipo da variável nos bancos utilizando a função glimpse():\n\nglimpse(original$obito)\n\n Factor w/ 2 levels \"não\",\"sim\": 1 1 1 1 1 1 1 1 2 1 ...\n\n\n\nglimpse(db$obito)\n\n int [1:124] 0 0 0 0 0 0 0 0 1 0 ...\n\n\nE tem mais! Temos que lembrar que quando deixamos as variáveis como fatores elas sempre possuem um nível de referência. Já verificamos isso em outros exercícios utilizando a função levels().\n\nlevels(original$obito)\n\n[1] \"não\" \"sim\"\n\n\nVeja só! A referência para a variável óbito é o “não”. Para fins didáditcos vamos criar três modelos:\nÓbito como variável binária (banco db) Óbito como fator com nível de referência “não” (banco original) Óbito como fator com nível de referência “sim” (banco original_sim)\n\noriginal_sim = original\noriginal_sim$obito = relevel(original_sim$obito, ref = \"sim\")\n\nAgora vamos repetir todo o procedimento já demonstrado no início das análises, utilizando os três bancos de dados.\n\nsurv_db &lt;- Surv(time = db$t_seg, event = db$obito)\nsurv_oiriginal_não &lt;- Surv(time = original$t_seg, event = original$obito)\nsurv_oiriginal_sim &lt;- Surv(time = original_sim$t_seg, event = original_sim$obito)\n\n\nfit_db &lt;- survfit(surv_db ~ 1, data = db)\nfit_original_não &lt;- survfit(surv_oiriginal_não ~ 1, data = original)\nfit_original_sim &lt;- survfit(surv_oiriginal_sim ~ 1, data = original_sim)\n\n\nplot(fit_db)\n\n\n\nplot(fit_original_não)\n\n\n\nplot(fit_original_sim)\n\n\n\n\n\nggsurvfit(fit_db, linewidth = 1) +\n  ggtitle(\"Binário\") +\n  labs(x = 'Dias', y = 'Overall survival') +\n  add_confidence_interval() +\n    add_risktable() +\n  scale_ggsurvfit() \n\n\n\nggcuminc(fit_original_não, linewidth = 1, type = \"survival\" ) +\n  ggtitle(\"Fator - Lelvel = Não\") +\n  labs(x = 'Dias', y = 'Overall survival') +\n  add_confidence_interval() +\n  add_risktable() +\n  scale_ggsurvfit() \n\nPlotting outcome \"sim\".\n\n\nWarning in ggplot2::geom_step(ggplot2::aes(x = .data$time, y = .data$estimate),\n: Ignoring unknown parameters: `type`\n\n\n\n\nggcuminc(fit_original_sim, linewidth = 1) +\n  ggtitle(\"Fator - Lelvel = Sim\") +\n  labs(x = 'Dias', y = 'Overall survival') +\n  add_confidence_interval() +\n  add_risktable() +\n  scale_ggsurvfit() \n\nPlotting outcome \"não\".\n\n\n\n\n\nComo podemos observar, quando utilizamos a variável de evento como um fator, acabamos analisando o risco cumulativo e não a sobrevida.\n\n\nMais gráficos!\nCom o ggplot2\n\nkm_plot = survfit2(surv_obj ~ tx, data = db) %&gt;%\n  tidy_survfit() %&gt;%\n  ggplot(aes(x = time, y = estimate,\n             min = conf.low, ymax = conf.low,\n             color = strata, fill = strata)) +\n  geom_step()\n\nkm_plot\n\n\n\n\nCom a função ggsurvplot() do pacote survminer.\n\nggsurvplot(fit2, data = db,\n           size = 1,\n           palette = c('#E7B800', '#2e9fdf'),\n           censor.shape = '|', censor.size = 4,\n           conf.int = TRUE,\n           pval = TRUE,\n           risk.table = TRUE,\n           risk.table.col = 'strata',\n           legend.labs = list('0' = 'Transplante = sim', '1' = 'Transplante = não'),\n           risk.table.height = 0.25,\n           ggtheme = theme_bw())\n\n\n\n\nGráficos de proporcionalidade com outras funções\n\nggcoxdiagnostics(cox_res, type = \"dfbeta\", linear.predictions = FALSE)\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\nE um específico para variáveis contínuas.\n\n# Não é importante para variáveis categóricas, mas fica o código para eventual consulta.\nggcoxdiagnostics(cox_res, type = \"deviance\", linear.predictions = FALSE)\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\nPacots alternativos para comparar curvas\n\ngehan.wilcoxon.test(surv_obj ~ tx ,data=db)\n\n\n    Gehan-Wilcoxon\n\ndata:  \n= 9.1531, p-value = 0.002483\nalternative hypothesis: two-sided\n\n\nsurvdiff Com rho = 0 este é o teste log-rank ou Mantel-Haenszel, e com rho = 1 é equivalente à modificação Peto & Peto do teste Gehan-Wilcoxon.\n\nsurvdiff(surv_obj ~ tx, data=db, rho = 2)\n\nCall:\nsurvdiff(formula = surv_obj ~ tx, data = db, rho = 2)\n\n        N Observed Expected (O-E)^2/E (O-E)^2/V\ntx=sim 60      7.4     14.0      3.12      9.19\ntx=não 64     17.9     11.3      3.89      9.19\n\n Chisq= 9.2  on 1 degrees of freedom, p= 0.002 \n\n\n\n\nTabela completa do modelo 2\n\nlife_table2 = survfit2(Surv(time = t_seg, event = obito) ~ tx, data = db) %&gt;%\n  tidy_survfit() \n\nkable(life_table2)\n\n\n\n\ntime\nn.risk\nn.event\nn.censor\ncum.event\ncum.censor\nestimate\nstd.error\nconf.high\nconf.low\nstrata\nestimate_type\nestimate_type_label\nmonotonicity_type\nstrata_label\nconf.level\n\n\n\n\n0\n60\n0\n1\n0\n1\n1.0000000\n0.0000000\n1.0000000\n1.0000000\nsim\nsurvival\nSurvival Probability\ndecreasing\ntx\n0.95\n\n\n3\n59\n1\n0\n1\n1\n0.9830508\n0.0170946\n1.0000000\n0.9506595\nsim\nsurvival\nSurvival Probability\ndecreasing\ntx\n0.95\n\n\n4\n58\n1\n0\n2\n1\n0.9661017\n0.0243866\n1.0000000\n0.9210112\nsim\nsurvival\nSurvival Probability\ndecreasing\ntx\n0.95\n\n\n24\n57\n1\n0\n3\n1\n0.9491525\n0.0301329\n1.0000000\n0.8947194\nsim\nsurvival\nSurvival Probability\ndecreasing\ntx\n0.95\n\n\n26\n56\n1\n0\n4\n1\n0.9322034\n0.0351093\n0.9986097\n0.8702130\nsim\nsurvival\nSurvival Probability\ndecreasing\ntx\n0.95\n\n\n29\n55\n1\n0\n5\n1\n0.9152542\n0.0396152\n0.9891503\n0.8468787\nsim\nsurvival\nSurvival Probability\ndecreasing\ntx\n0.95\n\n\n32\n54\n0\n3\n5\n4\n0.9152542\n0.0396152\n0.9891503\n0.8468787\nsim\nsurvival\nSurvival Probability\ndecreasing\ntx\n0.95\n\n\n34\n51\n0\n1\n5\n5\n0.9152542\n0.0396152\n0.9891503\n0.8468787\nsim\nsurvival\nSurvival Probability\ndecreasing\ntx\n0.95\n\n\n35\n50\n0\n3\n5\n8\n0.9152542\n0.0396152\n0.9891503\n0.8468787\nsim\nsurvival\nSurvival Probability\ndecreasing\ntx\n0.95\n\n\n36\n47\n0\n1\n5\n9\n0.9152542\n0.0396152\n0.9891503\n0.8468787\nsim\nsurvival\nSurvival Probability\ndecreasing\ntx\n0.95\n\n\n37\n46\n0\n2\n5\n11\n0.9152542\n0.0396152\n0.9891503\n0.8468787\nsim\nsurvival\nSurvival Probability\ndecreasing\ntx\n0.95\n\n\n38\n44\n1\n0\n6\n11\n0.8944530\n0.0458029\n0.9784644\n0.8176548\nsim\nsurvival\nSurvival Probability\ndecreasing\ntx\n0.95\n\n\n39\n43\n0\n1\n6\n12\n0.8944530\n0.0458029\n0.9784644\n0.8176548\nsim\nsurvival\nSurvival Probability\ndecreasing\ntx\n0.95\n\n\n40\n42\n0\n1\n6\n13\n0.8944530\n0.0458029\n0.9784644\n0.8176548\nsim\nsurvival\nSurvival Probability\ndecreasing\ntx\n0.95\n\n\n41\n41\n1\n0\n7\n13\n0.8726371\n0.0520352\n0.9663315\n0.7880272\nsim\nsurvival\nSurvival Probability\ndecreasing\ntx\n0.95\n\n\n42\n40\n0\n2\n7\n15\n0.8726371\n0.0520352\n0.9663315\n0.7880272\nsim\nsurvival\nSurvival Probability\ndecreasing\ntx\n0.95\n\n\n44\n38\n0\n1\n7\n16\n0.8726371\n0.0520352\n0.9663315\n0.7880272\nsim\nsurvival\nSurvival Probability\ndecreasing\ntx\n0.95\n\n\n45\n37\n1\n1\n8\n17\n0.8490523\n0.0588083\n0.9527789\n0.7566181\nsim\nsurvival\nSurvival Probability\ndecreasing\ntx\n0.95\n\n\n46\n35\n0\n1\n8\n18\n0.8490523\n0.0588083\n0.9527789\n0.7566181\nsim\nsurvival\nSurvival Probability\ndecreasing\ntx\n0.95\n\n\n48\n34\n0\n2\n8\n20\n0.8490523\n0.0588083\n0.9527789\n0.7566181\nsim\nsurvival\nSurvival Probability\ndecreasing\ntx\n0.95\n\n\n49\n32\n1\n2\n9\n22\n0.8225194\n0.0668317\n0.9376341\n0.7215375\nsim\nsurvival\nSurvival Probability\ndecreasing\ntx\n0.95\n\n\n51\n29\n0\n1\n9\n23\n0.8225194\n0.0668317\n0.9376341\n0.7215375\nsim\nsurvival\nSurvival Probability\ndecreasing\ntx\n0.95\n\n\n52\n28\n0\n1\n9\n24\n0.8225194\n0.0668317\n0.9376341\n0.7215375\nsim\nsurvival\nSurvival Probability\ndecreasing\ntx\n0.95\n\n\n54\n27\n0\n1\n9\n25\n0.8225194\n0.0668317\n0.9376341\n0.7215375\nsim\nsurvival\nSurvival Probability\ndecreasing\ntx\n0.95\n\n\n55\n26\n0\n4\n9\n29\n0.8225194\n0.0668317\n0.9376341\n0.7215375\nsim\nsurvival\nSurvival Probability\ndecreasing\ntx\n0.95\n\n\n57\n22\n0\n1\n9\n30\n0.8225194\n0.0668317\n0.9376341\n0.7215375\nsim\nsurvival\nSurvival Probability\ndecreasing\ntx\n0.95\n\n\n65\n21\n0\n2\n9\n32\n0.8225194\n0.0668317\n0.9376341\n0.7215375\nsim\nsurvival\nSurvival Probability\ndecreasing\ntx\n0.95\n\n\n66\n19\n1\n1\n10\n33\n0.7792289\n0.0859678\n0.9222336\n0.6583990\nsim\nsurvival\nSurvival Probability\ndecreasing\ntx\n0.95\n\n\n67\n17\n0\n1\n10\n34\n0.7792289\n0.0859678\n0.9222336\n0.6583990\nsim\nsurvival\nSurvival Probability\ndecreasing\ntx\n0.95\n\n\n73\n16\n0\n1\n10\n35\n0.7792289\n0.0859678\n0.9222336\n0.6583990\nsim\nsurvival\nSurvival Probability\ndecreasing\ntx\n0.95\n\n\n74\n15\n0\n1\n10\n36\n0.7792289\n0.0859678\n0.9222336\n0.6583990\nsim\nsurvival\nSurvival Probability\ndecreasing\ntx\n0.95\n\n\n75\n14\n0\n1\n10\n37\n0.7792289\n0.0859678\n0.9222336\n0.6583990\nsim\nsurvival\nSurvival Probability\ndecreasing\ntx\n0.95\n\n\n77\n13\n0\n1\n10\n38\n0.7792289\n0.0859678\n0.9222336\n0.6583990\nsim\nsurvival\nSurvival Probability\ndecreasing\ntx\n0.95\n\n\n82\n12\n0\n1\n10\n39\n0.7792289\n0.0859678\n0.9222336\n0.6583990\nsim\nsurvival\nSurvival Probability\ndecreasing\ntx\n0.95\n\n\n83\n11\n0\n2\n10\n41\n0.7792289\n0.0859678\n0.9222336\n0.6583990\nsim\nsurvival\nSurvival Probability\ndecreasing\ntx\n0.95\n\n\n87\n9\n0\n1\n10\n42\n0.7792289\n0.0859678\n0.9222336\n0.6583990\nsim\nsurvival\nSurvival Probability\ndecreasing\ntx\n0.95\n\n\n89\n8\n1\n0\n11\n42\n0.6818253\n0.1588949\n0.9309465\n0.4993689\nsim\nsurvival\nSurvival Probability\ndecreasing\ntx\n0.95\n\n\n90\n7\n0\n1\n11\n43\n0.6818253\n0.1588949\n0.9309465\n0.4993689\nsim\nsurvival\nSurvival Probability\ndecreasing\ntx\n0.95\n\n\n92\n6\n0\n1\n11\n44\n0.6818253\n0.1588949\n0.9309465\n0.4993689\nsim\nsurvival\nSurvival Probability\ndecreasing\ntx\n0.95\n\n\n96\n5\n0\n1\n11\n45\n0.6818253\n0.1588949\n0.9309465\n0.4993689\nsim\nsurvival\nSurvival Probability\ndecreasing\ntx\n0.95\n\n\n97\n4\n0\n2\n11\n47\n0.6818253\n0.1588949\n0.9309465\n0.4993689\nsim\nsurvival\nSurvival Probability\ndecreasing\ntx\n0.95\n\n\n98\n2\n0\n1\n11\n48\n0.6818253\n0.1588949\n0.9309465\n0.4993689\nsim\nsurvival\nSurvival Probability\ndecreasing\ntx\n0.95\n\n\n99\n1\n0\n1\n11\n49\n0.6818253\n0.1588949\n0.9309465\n0.4993689\nsim\nsurvival\nSurvival Probability\ndecreasing\ntx\n0.95\n\n\n0\n64\n2\n0\n2\n0\n0.9687500\n0.0224507\n1.0000000\n0.9270468\nnão\nsurvival\nSurvival Probability\ndecreasing\ntx\n0.95\n\n\n3\n62\n1\n0\n3\n0\n0.9531250\n0.0277208\n1.0000000\n0.9027217\nnão\nsurvival\nSurvival Probability\ndecreasing\ntx\n0.95\n\n\n4\n61\n1\n0\n4\n0\n0.9375000\n0.0322749\n0.9987199\n0.8800328\nnão\nsurvival\nSurvival Probability\ndecreasing\ntx\n0.95\n\n\n6\n60\n1\n0\n5\n0\n0.9218750\n0.0363889\n0.9900254\n0.8584159\nnão\nsurvival\nSurvival Probability\ndecreasing\ntx\n0.95\n\n\n8\n59\n2\n0\n7\n0\n0.8906250\n0.0438048\n0.9704688\n0.8173502\nnão\nsurvival\nSurvival Probability\ndecreasing\ntx\n0.95\n\n\n11\n57\n1\n0\n8\n0\n0.8750000\n0.0472456\n0.9598946\n0.7976136\nnão\nsurvival\nSurvival Probability\ndecreasing\ntx\n0.95\n\n\n13\n56\n1\n0\n9\n0\n0.8593750\n0.0505650\n0.9489071\n0.7782905\nnão\nsurvival\nSurvival Probability\ndecreasing\ntx\n0.95\n\n\n14\n55\n0\n1\n9\n1\n0.8593750\n0.0505650\n0.9489071\n0.7782905\nnão\nsurvival\nSurvival Probability\ndecreasing\ntx\n0.95\n\n\n15\n54\n0\n1\n9\n2\n0.8593750\n0.0505650\n0.9489071\n0.7782905\nnão\nsurvival\nSurvival Probability\ndecreasing\ntx\n0.95\n\n\n16\n53\n1\n0\n10\n2\n0.8431604\n0.0540339\n0.9373546\n0.7584316\nnão\nsurvival\nSurvival Probability\ndecreasing\ntx\n0.95\n\n\n18\n52\n0\n1\n10\n3\n0.8431604\n0.0540339\n0.9373546\n0.7584316\nnão\nsurvival\nSurvival Probability\ndecreasing\ntx\n0.95\n\n\n19\n51\n1\n0\n11\n3\n0.8266278\n0.0575484\n0.9253272\n0.7384562\nnão\nsurvival\nSurvival Probability\ndecreasing\ntx\n0.95\n\n\n22\n50\n0\n1\n11\n4\n0.8266278\n0.0575484\n0.9253272\n0.7384562\nnão\nsurvival\nSurvival Probability\ndecreasing\ntx\n0.95\n\n\n24\n49\n1\n0\n12\n4\n0.8097579\n0.0611309\n0.9128300\n0.7183241\nnão\nsurvival\nSurvival Probability\ndecreasing\ntx\n0.95\n\n\n25\n48\n1\n0\n13\n4\n0.7928879\n0.0646549\n0.9000075\n0.6985178\nnão\nsurvival\nSurvival Probability\ndecreasing\ntx\n0.95\n\n\n27\n47\n1\n0\n14\n4\n0.7760180\n0.0681380\n0.8868924\n0.6790044\nnão\nsurvival\nSurvival Probability\ndecreasing\ntx\n0.95\n\n\n29\n46\n0\n1\n14\n5\n0.7760180\n0.0681380\n0.8868924\n0.6790044\nnão\nsurvival\nSurvival Probability\ndecreasing\ntx\n0.95\n\n\n30\n45\n0\n4\n14\n9\n0.7760180\n0.0681380\n0.8868924\n0.6790044\nnão\nsurvival\nSurvival Probability\ndecreasing\ntx\n0.95\n\n\n31\n41\n0\n1\n14\n10\n0.7760180\n0.0681380\n0.8868924\n0.6790044\nnão\nsurvival\nSurvival Probability\ndecreasing\ntx\n0.95\n\n\n32\n40\n0\n2\n14\n12\n0.7760180\n0.0681380\n0.8868924\n0.6790044\nnão\nsurvival\nSurvival Probability\ndecreasing\ntx\n0.95\n\n\n34\n38\n3\n0\n17\n12\n0.7147534\n0.0830568\n0.8411128\n0.6073768\nnão\nsurvival\nSurvival Probability\ndecreasing\ntx\n0.95\n\n\n36\n35\n1\n5\n18\n17\n0.6943319\n0.0879702\n0.8249877\n0.5843684\nnão\nsurvival\nSurvival Probability\ndecreasing\ntx\n0.95\n\n\n37\n29\n0\n3\n18\n20\n0.6943319\n0.0879702\n0.8249877\n0.5843684\nnão\nsurvival\nSurvival Probability\ndecreasing\ntx\n0.95\n\n\n40\n26\n1\n1\n19\n21\n0.6676268\n0.0963183\n0.8063435\n0.5527738\nnão\nsurvival\nSurvival Probability\ndecreasing\ntx\n0.95\n\n\n41\n24\n1\n0\n20\n21\n0.6398090\n0.1053035\n0.7864748\n0.5204942\nnão\nsurvival\nSurvival Probability\ndecreasing\ntx\n0.95\n\n\n42\n23\n0\n2\n20\n23\n0.6398090\n0.1053035\n0.7864748\n0.5204942\nnão\nsurvival\nSurvival Probability\ndecreasing\ntx\n0.95\n\n\n44\n21\n1\n2\n21\n25\n0.6093419\n0.1160593\n0.7649815\n0.4853680\nnão\nsurvival\nSurvival Probability\ndecreasing\ntx\n0.95\n\n\n46\n18\n1\n2\n22\n27\n0.5754896\n0.1293744\n0.7415854\n0.4465949\nnão\nsurvival\nSurvival Probability\ndecreasing\ntx\n0.95\n\n\n50\n15\n0\n1\n22\n28\n0.5754896\n0.1293744\n0.7415854\n0.4465949\nnão\nsurvival\nSurvival Probability\ndecreasing\ntx\n0.95\n\n\n51\n14\n0\n1\n22\n29\n0.5754896\n0.1293744\n0.7415854\n0.4465949\nnão\nsurvival\nSurvival Probability\ndecreasing\ntx\n0.95\n\n\n54\n13\n0\n1\n22\n30\n0.5754896\n0.1293744\n0.7415854\n0.4465949\nnão\nsurvival\nSurvival Probability\ndecreasing\ntx\n0.95\n\n\n56\n12\n0\n1\n22\n31\n0.5754896\n0.1293744\n0.7415854\n0.4465949\nnão\nsurvival\nSurvival Probability\ndecreasing\ntx\n0.95\n\n\n58\n11\n1\n3\n23\n34\n0.5231723\n0.1607130\n0.7168758\n0.3818086\nnão\nsurvival\nSurvival Probability\ndecreasing\ntx\n0.95\n\n\n60\n7\n0\n1\n23\n35\n0.5231723\n0.1607130\n0.7168758\n0.3818086\nnão\nsurvival\nSurvival Probability\ndecreasing\ntx\n0.95\n\n\n65\n6\n0\n1\n23\n36\n0.5231723\n0.1607130\n0.7168758\n0.3818086\nnão\nsurvival\nSurvival Probability\ndecreasing\ntx\n0.95\n\n\n71\n5\n0\n1\n23\n37\n0.5231723\n0.1607130\n0.7168758\n0.3818086\nnão\nsurvival\nSurvival Probability\ndecreasing\ntx\n0.95\n\n\n77\n4\n0\n1\n23\n38\n0.5231723\n0.1607130\n0.7168758\n0.3818086\nnão\nsurvival\nSurvival Probability\ndecreasing\ntx\n0.95\n\n\n80\n3\n0\n1\n23\n39\n0.5231723\n0.1607130\n0.7168758\n0.3818086\nnão\nsurvival\nSurvival Probability\ndecreasing\ntx\n0.95\n\n\n82\n2\n0\n1\n23\n40\n0.5231723\n0.1607130\n0.7168758\n0.3818086\nnão\nsurvival\nSurvival Probability\ndecreasing\ntx\n0.95\n\n\n97\n1\n0\n1\n23\n41\n0.5231723\n0.1607130\n0.7168758\n0.3818086\nnão\nsurvival\nSurvival Probability\ndecreasing\ntx\n0.95\n\n\n\n\n\n\nsummary(life_table2)\n\n      time           n.risk        n.event          n.censor    \n Min.   : 0.00   Min.   : 1.0   Min.   :0.0000   Min.   :0.000  \n 1st Qu.:28.00   1st Qu.:13.5   1st Qu.:0.0000   1st Qu.:0.000  \n Median :42.00   Median :34.0   Median :0.0000   Median :1.000  \n Mean   :46.25   Mean   :31.9   Mean   :0.4096   Mean   :1.084  \n 3rd Qu.:65.50   3rd Qu.:50.0   3rd Qu.:1.0000   3rd Qu.:1.000  \n Max.   :99.00   Max.   :64.0   Max.   :3.0000   Max.   :5.000  \n   cum.event       cum.censor       estimate        std.error      \n Min.   : 0.00   Min.   : 0.00   Min.   :0.5232   Min.   :0.00000  \n 1st Qu.: 7.00   1st Qu.: 4.00   1st Qu.:0.6818   1st Qu.:0.05056  \n Median :10.00   Median :20.00   Median :0.7929   Median :0.06683  \n Mean   :11.48   Mean   :20.04   Mean   :0.7757   Mean   :0.08234  \n 3rd Qu.:14.00   3rd Qu.:34.50   3rd Qu.:0.8726   3rd Qu.:0.11068  \n Max.   :23.00   Max.   :49.00   Max.   :1.0000   Max.   :0.16071  \n   conf.high         conf.low      strata   estimate_type     \n Min.   :0.7169   Min.   :0.3818   sim:43   Length:83         \n 1st Qu.:0.8869   1st Qu.:0.5099   não:40   Class :character  \n Median :0.9309   Median :0.6985            Mode  :character  \n Mean   :0.9015   Mean   :0.6716                              \n 3rd Qu.:0.9663   3rd Qu.:0.7880                              \n Max.   :1.0000   Max.   :1.0000                              \n estimate_type_label monotonicity_type  strata_label         conf.level  \n Length:83           Length:83          Length:83          Min.   :0.95  \n Class :character    Class :character   Class :character   1st Qu.:0.95  \n Mode  :character    Mode  :character   Mode  :character   Median :0.95  \n                                                           Mean   :0.95  \n                                                           3rd Qu.:0.95  \n                                                           Max.   :0.95  \n\nsummary(life_table2, times = tempos_específicos)\n\n      time           n.risk        n.event          n.censor    \n Min.   : 0.00   Min.   : 1.0   Min.   :0.0000   Min.   :0.000  \n 1st Qu.:28.00   1st Qu.:13.5   1st Qu.:0.0000   1st Qu.:0.000  \n Median :42.00   Median :34.0   Median :0.0000   Median :1.000  \n Mean   :46.25   Mean   :31.9   Mean   :0.4096   Mean   :1.084  \n 3rd Qu.:65.50   3rd Qu.:50.0   3rd Qu.:1.0000   3rd Qu.:1.000  \n Max.   :99.00   Max.   :64.0   Max.   :3.0000   Max.   :5.000  \n   cum.event       cum.censor       estimate        std.error      \n Min.   : 0.00   Min.   : 0.00   Min.   :0.5232   Min.   :0.00000  \n 1st Qu.: 7.00   1st Qu.: 4.00   1st Qu.:0.6818   1st Qu.:0.05056  \n Median :10.00   Median :20.00   Median :0.7929   Median :0.06683  \n Mean   :11.48   Mean   :20.04   Mean   :0.7757   Mean   :0.08234  \n 3rd Qu.:14.00   3rd Qu.:34.50   3rd Qu.:0.8726   3rd Qu.:0.11068  \n Max.   :23.00   Max.   :49.00   Max.   :1.0000   Max.   :0.16071  \n   conf.high         conf.low      strata   estimate_type     \n Min.   :0.7169   Min.   :0.3818   sim:43   Length:83         \n 1st Qu.:0.8869   1st Qu.:0.5099   não:40   Class :character  \n Median :0.9309   Median :0.6985            Mode  :character  \n Mean   :0.9015   Mean   :0.6716                              \n 3rd Qu.:0.9663   3rd Qu.:0.7880                              \n Max.   :1.0000   Max.   :1.0000                              \n estimate_type_label monotonicity_type  strata_label         conf.level  \n Length:83           Length:83          Length:83          Min.   :0.95  \n Class :character    Class :character   Class :character   1st Qu.:0.95  \n Mode  :character    Mode  :character   Mode  :character   Median :0.95  \n                                                           Mean   :0.95  \n                                                           3rd Qu.:0.95  \n                                                           Max.   :0.95  \n\nhead(life_table2)\n\n# A tibble: 6 × 16\n   time n.risk n.event n.censor cum.event cum.censor estimate std.error\n  &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;      &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;\n1     0     60       0        1         0          1    1        0     \n2     3     59       1        0         1          1    0.983    0.0171\n3     4     58       1        0         2          1    0.966    0.0244\n4    24     57       1        0         3          1    0.949    0.0301\n5    26     56       1        0         4          1    0.932    0.0351\n6    29     55       1        0         5          1    0.915    0.0396\n# ℹ 8 more variables: conf.high &lt;dbl&gt;, conf.low &lt;dbl&gt;, strata &lt;fct&gt;,\n#   estimate_type &lt;chr&gt;, estimate_type_label &lt;chr&gt;, monotonicity_type &lt;chr&gt;,\n#   strata_label &lt;chr&gt;, conf.level &lt;dbl&gt;\n\n\n\n\nCódigo não usado\n\n# Create the new data  \nnew_df &lt;- with(db,\n               data.frame(tx = c(\"sim\", \"não\")\n               )\n)\nglimpse(new_df)\n\nRows: 2\nColumns: 1\n$ tx &lt;chr&gt; \"sim\", \"não\"\n\nnew_df$tx = as.factor(new_df$tx)\n\n\n# Survival curves with new data\n#%%%%%%%%%%%%%%%%%%%%%%%%%%%\nfit_cox &lt;- survfit(cox_res, newdata = new_df)\n\n\nggsurvplot(fit_cox, data = db,\n           size = 1,\n           palette = c('#E7B800', '#2e9fdf'),\n           censor.shape = '|', censor.size = 4,\n           conf.int = TRUE,\n           pval = TRUE,\n          # risk.table = TRUE,\n         #  risk.table.col = 'strata',\n           legend.labs = list('0' = 'Transplante = sim', '1' = 'Transplante = não'),\n           risk.table.height = 0.25,\n           ggtheme = theme_bw())\n\nWarning in .pvalue(fit, data = data, method = method, pval = pval, pval.coord = pval.coord, : There are no survival curves to be compared. \n This is a null model.\n\n\n\n\n\n\n\nPara salvar os valores de sobrevida\n\nsurv_fit_cox = survfit(cox_res)\n\n# Extrai os tempos de sobrevida e as estimativas de sobrevida\nsurv_df_cox &lt;- data.frame(time = surv_fit_cox$time, surv = surv_fit_cox$surv)\nsurv_df_cox\n\n   time      surv\n1     0 0.9919270\n2     3 0.9837071\n3     4 0.9754200\n4     6 0.9712508\n5     8 0.9628064\n6    11 0.9585298\n7    13 0.9542158\n8    14 0.9542158\n9    15 0.9542158\n10   16 0.9497436\n11   18 0.9497436\n12   19 0.9451662\n13   22 0.9451662\n14   24 0.9357670\n15   25 0.9310329\n16   26 0.9262516\n17   27 0.9214703\n18   29 0.9166403\n19   30 0.9166403\n20   31 0.9166403\n21   32 0.9166403\n22   34 0.8995899\n23   35 0.8995899\n24   36 0.8936099\n25   37 0.8936099\n26   38 0.8862225\n27   39 0.8862225\n28   40 0.8787730\n29   41 0.8630231\n30   42 0.8630231\n31   44 0.8544152\n32   45 0.8449676\n33   46 0.8354131\n34   48 0.8354131\n35   49 0.8245091\n36   50 0.8245091\n37   51 0.8245091\n38   52 0.8245091\n39   54 0.8245091\n40   55 0.8245091\n41   56 0.8245091\n42   57 0.8245091\n43   58 0.8091983\n44   60 0.8091983\n45   65 0.8091983\n46   66 0.7855423\n47   67 0.7855423\n48   71 0.7855423\n49   73 0.7855423\n50   74 0.7855423\n51   75 0.7855423\n52   77 0.7855423\n53   80 0.7855423\n54   82 0.7855423\n55   83 0.7855423\n56   87 0.7855423\n57   89 0.7169271\n58   90 0.7169271\n59   92 0.7169271\n60   96 0.7169271\n61   97 0.7169271\n62   98 0.7169271\n63   99 0.7169271"
  },
  {
    "objectID": "lista_6.html#referências",
    "href": "lista_6.html#referências",
    "title": "6  Lista 6 - Kaplan-Meier e Cox Regression",
    "section": "6.17 Referências",
    "text": "6.17 Referências\nhttps://bookdown.org/mpfoley1973/survival/semiparametric.html#fitting-the-model-1\nhttps://biostatsquid.com/easy-survival-analysis-r-tutorial/\nhttps://www.youtube.com/watch?v=XrvCCFQRCZE\nhttps://www.youtube.com/watch?v=vX3l36ptrTU&list=PLqzoL9-eJTNDdnKvep_YHIwk2AMqHhuJ0\nhttp://www.sthda.com/english/wiki/cox-proportional-hazards-model"
  },
  {
    "objectID": "lista_6.html#versões-dos-pacotes",
    "href": "lista_6.html#versões-dos-pacotes",
    "title": "6  Lista 6 - Kaplan-Meier e Cox Regression",
    "section": "6.18 Versões dos pacotes",
    "text": "6.18 Versões dos pacotes\n\nreport(sessionInfo())\n\nAnalyses were conducted using the R Statistical language (version 4.3.1; R Core\nTeam, 2023) on Windows 11 x64 (build 22621), using the packages effectsize\n(version 0.8.6; Ben-Shachar MS et al., 2020), lpSolve (version 5.6.19;\nBerkelaar M, others, 2023), survMisc (version 0.5.6; Dardis C, 2022), tm\n(version 0.7.11; Feinerer I, Hornik K, 2023), flexplot (version 0.20.5; Fife D,\n2024), lubridate (version 1.9.3; Grolemund G, Wickham H, 2011), coxphf (version\n1.13.4; Heinze G et al., 2023), NLP (version 0.2.1; Hornik K, 2020), coin\n(version 1.4.3; Hothorn T et al., 2006), ggpubr (version 0.6.0; Kassambara A,\n2023), survminer (version 0.4.9; Kassambara A et al., 2021),\nPHInfiniteEstimates (version 2.9.5; Kolassa JE, Zhang J, 2023), parameters\n(version 0.21.3; Lüdecke D et al., 2020), performance (version 0.10.8; Lüdecke\nD et al., 2021), easystats (version 0.6.0; Lüdecke D et al., 2022), see\n(version 0.8.1; Lüdecke D et al., 2021), insight (version 0.19.6; Lüdecke D et\nal., 2019), bayestestR (version 0.13.1; Makowski D et al., 2019), modelbased\n(version 0.8.6; Makowski D et al., 2020), report (version 0.5.7; Makowski D et\nal., 2023), correlation (version 0.8.4; Makowski D et al., 2022), condSURV\n(version 2.0.4; Meira-Machado L, Sestelo M, 2023), tibble (version 3.2.1;\nMüller K, Wickham H, 2023), datawizard (version 0.9.0; Patil I et al., 2022),\nforeign (version 0.8.85; R Core Team, 2023), nph (version 2.1; Ristl R et al.,\n2021), broom (version 1.0.5; Robinson D et al., 2023), ggsurvfit (version\n1.0.0; Sjoberg D et al., 2023), gtsummary (version 1.7.2; Sjoberg D et al.,\n2021), rempsyc (version 0.1.6; Thériault R, 2023), survival (version 3.5.7;\nTherneau T, 2023), ggplot2 (version 3.4.4; Wickham H, 2016), forcats (version\n1.0.0; Wickham H, 2023), stringr (version 1.5.1; Wickham H, 2023), tidyverse\n(version 2.0.0; Wickham H et al., 2019), dplyr (version 1.1.3; Wickham H et\nal., 2023), purrr (version 1.0.2; Wickham H, Henry L, 2023), readr (version\n2.1.4; Wickham H et al., 2023), tidyr (version 1.3.0; Wickham H et al., 2023)\nand kableExtra (version 1.3.4; Zhu H, 2021).\n\nReferences\n----------\n  - Ben-Shachar MS, Lüdecke D, Makowski D (2020). \"effectsize: Estimation of\nEffect Size Indices and Standardized Parameters.\" _Journal of Open Source\nSoftware_, *5*(56), 2815. doi:10.21105/joss.02815\n&lt;https://doi.org/10.21105/joss.02815&gt;, &lt;https://doi.org/10.21105/joss.02815&gt;.\n  - Berkelaar M, others (2023). _lpSolve: Interface to 'Lp_solve' v. 5.5 to Solve\nLinear/Integer Programs_. R package version 5.6.19,\n&lt;https://CRAN.R-project.org/package=lpSolve&gt;.\n  - Dardis C (2022). _survMisc: Miscellaneous Functions for Survival Data_. R\npackage version 0.5.6, &lt;https://CRAN.R-project.org/package=survMisc&gt;.\n  - Feinerer I, Hornik K (2023). _tm: Text Mining Package_. R package version\n0.7-11, &lt;https://CRAN.R-project.org/package=tm&gt;. Feinerer I, Hornik K, Meyer D\n(2008). \"Text Mining Infrastructure in R.\" _Journal of Statistical Software_,\n*25*(5), 1-54. doi:10.18637/jss.v025.i05\n&lt;https://doi.org/10.18637/jss.v025.i05&gt;.\n  - Fife D (2024). _flexplot: Graphically Based Data Analysis Using 'flexplot'_.\nR package version 0.20.5.\n  - Grolemund G, Wickham H (2011). \"Dates and Times Made Easy with lubridate.\"\n_Journal of Statistical Software_, *40*(3), 1-25.\n&lt;https://www.jstatsoft.org/v40/i03/&gt;.\n  - Heinze G, Ploner M, Jiricka L, Steiner G (2023). _coxphf: Cox Regression with\nFirth's Penalized Likelihood_. R package version 1.13.4,\n&lt;https://CRAN.R-project.org/package=coxphf&gt;.\n  - Hornik K (2020). _NLP: Natural Language Processing Infrastructure_. R package\nversion 0.2-1, &lt;https://CRAN.R-project.org/package=NLP&gt;.\n  - Hothorn T, Hornik K, van de Wiel MA, Zeileis A (2006). \"A Lego system for\nconditional inference.\" _The American Statistician_, *60*(3), 257-263.\ndoi:10.1198/000313006X118430 &lt;https://doi.org/10.1198/000313006X118430&gt;.\nHothorn T, Hornik K, van de Wiel MA, Zeileis A (2008). \"Implementing a class of\npermutation tests: The coin package.\" _Journal of Statistical Software_,\n*28*(8), 1-23. doi:10.18637/jss.v028.i08\n&lt;https://doi.org/10.18637/jss.v028.i08&gt;.\n  - Kassambara A (2023). _ggpubr: 'ggplot2' Based Publication Ready Plots_. R\npackage version 0.6.0, &lt;https://CRAN.R-project.org/package=ggpubr&gt;.\n  - Kassambara A, Kosinski M, Biecek P (2021). _survminer: Drawing Survival\nCurves using 'ggplot2'_. R package version 0.4.9,\n&lt;https://CRAN.R-project.org/package=survminer&gt;.\n  - Kolassa JE, Zhang J (2023). _PHInfiniteEstimates: Tools for Inference in the\nPresence of a Monotone Likelihood_. R package version 2.9.5,\n&lt;https://CRAN.R-project.org/package=PHInfiniteEstimates&gt;.\n  - Lüdecke D, Ben-Shachar M, Patil I, Makowski D (2020). \"Extracting, Computing\nand Exploring the Parameters of Statistical Models using R.\" _Journal of Open\nSource Software_, *5*(53), 2445. doi:10.21105/joss.02445\n&lt;https://doi.org/10.21105/joss.02445&gt;.\n  - Lüdecke D, Ben-Shachar M, Patil I, Waggoner P, Makowski D (2021).\n\"performance: An R Package for Assessment, Comparison and Testing of\nStatistical Models.\" _Journal of Open Source Software_, *6*(60), 3139.\ndoi:10.21105/joss.03139 &lt;https://doi.org/10.21105/joss.03139&gt;.\n  - Lüdecke D, Ben-Shachar M, Patil I, Wiernik B, Makowski D (2022). \"easystats:\nFramework for Easy Statistical Modeling, Visualization, and Reporting.\" _CRAN_.\nR package, &lt;https://easystats.github.io/easystats/&gt;.\n  - Lüdecke D, Patil I, Ben-Shachar M, Wiernik B, Waggoner P, Makowski D (2021).\n\"see: An R Package for Visualizing Statistical Models.\" _Journal of Open Source\nSoftware_, *6*(64), 3393. doi:10.21105/joss.03393\n&lt;https://doi.org/10.21105/joss.03393&gt;.\n  - Lüdecke D, Waggoner P, Makowski D (2019). \"insight: A Unified Interface to\nAccess Information from Model Objects in R.\" _Journal of Open Source Software_,\n*4*(38), 1412. doi:10.21105/joss.01412 &lt;https://doi.org/10.21105/joss.01412&gt;.\n  - Makowski D, Ben-Shachar M, Lüdecke D (2019). \"bayestestR: Describing Effects\nand their Uncertainty, Existence and Significance within the Bayesian\nFramework.\" _Journal of Open Source Software_, *4*(40), 1541.\ndoi:10.21105/joss.01541 &lt;https://doi.org/10.21105/joss.01541&gt;,\n&lt;https://joss.theoj.org/papers/10.21105/joss.01541&gt;.\n  - Makowski D, Ben-Shachar M, Patil I, Lüdecke D (2020). \"Estimation of\nModel-Based Predictions, Contrasts and Means.\" _CRAN_.\n&lt;https://github.com/easystats/modelbased&gt;.\n  - Makowski D, Lüdecke D, Patil I, Thériault R, Ben-Shachar M, Wiernik B (2023).\n\"Automated Results Reporting as a Practical Tool to Improve Reproducibility and\nMethodological Best Practices Adoption.\" _CRAN_.\n&lt;https://easystats.github.io/report/&gt;.\n  - Makowski D, Wiernik B, Patil I, Lüdecke D, Ben-Shachar M (2022).\n\"correlation: Methods for Correlation Analysis.\" Version 0.8.3,\n&lt;https://CRAN.R-project.org/package=correlation&gt;. Makowski D, Ben-Shachar M,\nPatil I, Lüdecke D (2020). \"Methods and Algorithms for Correlation Analysis in\nR.\" _Journal of Open Source Software_, *5*(51), 2306. doi:10.21105/joss.02306\n&lt;https://doi.org/10.21105/joss.02306&gt;,\n&lt;https://joss.theoj.org/papers/10.21105/joss.02306&gt;.\n  - Meira-Machado L, Sestelo M (2023). _condSURV: Estimation of the Conditional\nSurvival Function for Ordered Multivariate Failure Time Data_. R package\nversion 2.0.4, &lt;https://CRAN.R-project.org/package=condSURV&gt;.\n  - Müller K, Wickham H (2023). _tibble: Simple Data Frames_. R package version\n3.2.1, &lt;https://CRAN.R-project.org/package=tibble&gt;.\n  - Patil I, Makowski D, Ben-Shachar M, Wiernik B, Bacher E, Lüdecke D (2022).\n\"datawizard: An R Package for Easy Data Preparation and Statistical\nTransformations.\" _Journal of Open Source Software_, *7*(78), 4684.\ndoi:10.21105/joss.04684 &lt;https://doi.org/10.21105/joss.04684&gt;.\n  - R Core Team (2023). _foreign: Read Data Stored by 'Minitab', 'S', 'SAS',\n'SPSS', 'Stata', 'Systat', 'Weka', 'dBase', ..._. R package version 0.8-85,\n&lt;https://CRAN.R-project.org/package=foreign&gt;.\n  - R Core Team (2023). _R: A Language and Environment for Statistical\nComputing_. R Foundation for Statistical Computing, Vienna, Austria.\n&lt;https://www.R-project.org/&gt;.\n  - Ristl R, Ballarini N, Götte H, Schüler A, Posch M, König F (2021). \"Delayed\ntreatment effects, treatment switching and heterogeneous patient populations:\nHow to design and analyze RCTs in oncology.\" _Pharmaceutical statistics_,\n*20*(1), 129-145.\n  - Robinson D, Hayes A, Couch S (2023). _broom: Convert Statistical Objects into\nTidy Tibbles_. R package version 1.0.5,\n&lt;https://CRAN.R-project.org/package=broom&gt;.\n  - Sjoberg D, Baillie M, Fruechtenicht C, Haesendonckx S, Treis T (2023).\n_ggsurvfit: Flexible Time-to-Event Figures_. R package version 1.0.0,\n&lt;https://CRAN.R-project.org/package=ggsurvfit&gt;.\n  - Sjoberg D, Whiting K, Curry M, Lavery J, Larmarange J (2021). \"Reproducible\nSummary Tables with the gtsummary Package.\" _The R Journal_, *13*, 570-580.\ndoi:10.32614/RJ-2021-053 &lt;https://doi.org/10.32614/RJ-2021-053&gt;,\n&lt;https://doi.org/10.32614/RJ-2021-053&gt;.\n  - Thériault R (2023). \"rempsyc: Convenience functions for psychology.\" _Journal\nof Open Source Software_, *8*(87), 5466. doi:10.21105/joss.05466\n&lt;https://doi.org/10.21105/joss.05466&gt;, &lt;https://doi.org/10.21105/joss.05466&gt;.\n  - Therneau T (2023). _A Package for Survival Analysis in R_. R package version\n3.5-7, &lt;https://CRAN.R-project.org/package=survival&gt;. Terry M. Therneau,\nPatricia M. Grambsch (2000). _Modeling Survival Data: Extending the Cox Model_.\nSpringer, New York. ISBN 0-387-98784-3.\n  - Wickham H (2016). _ggplot2: Elegant Graphics for Data Analysis_.\nSpringer-Verlag New York. ISBN 978-3-319-24277-4,\n&lt;https://ggplot2.tidyverse.org&gt;.\n  - Wickham H (2023). _forcats: Tools for Working with Categorical Variables\n(Factors)_. R package version 1.0.0,\n&lt;https://CRAN.R-project.org/package=forcats&gt;.\n  - Wickham H (2023). _stringr: Simple, Consistent Wrappers for Common String\nOperations_. R package version 1.5.1,\n&lt;https://CRAN.R-project.org/package=stringr&gt;.\n  - Wickham H, Averick M, Bryan J, Chang W, McGowan LD, François R, Grolemund G,\nHayes A, Henry L, Hester J, Kuhn M, Pedersen TL, Miller E, Bache SM, Müller K,\nOoms J, Robinson D, Seidel DP, Spinu V, Takahashi K, Vaughan D, Wilke C, Woo K,\nYutani H (2019). \"Welcome to the tidyverse.\" _Journal of Open Source Software_,\n*4*(43), 1686. doi:10.21105/joss.01686 &lt;https://doi.org/10.21105/joss.01686&gt;.\n  - Wickham H, François R, Henry L, Müller K, Vaughan D (2023). _dplyr: A Grammar\nof Data Manipulation_. R package version 1.1.3,\n&lt;https://CRAN.R-project.org/package=dplyr&gt;.\n  - Wickham H, Henry L (2023). _purrr: Functional Programming Tools_. R package\nversion 1.0.2, &lt;https://CRAN.R-project.org/package=purrr&gt;.\n  - Wickham H, Hester J, Bryan J (2023). _readr: Read Rectangular Text Data_. R\npackage version 2.1.4, &lt;https://CRAN.R-project.org/package=readr&gt;.\n  - Wickham H, Vaughan D, Girlich M (2023). _tidyr: Tidy Messy Data_. R package\nversion 1.3.0, &lt;https://CRAN.R-project.org/package=tidyr&gt;.\n  - Zhu H (2021). _kableExtra: Construct Complex Table with 'kable' and Pipe\nSyntax_. R package version 1.3.4,\n&lt;https://CRAN.R-project.org/package=kableExtra&gt;."
  },
  {
    "objectID": "lista_6_1.html#carregando-pacotes",
    "href": "lista_6_1.html#carregando-pacotes",
    "title": "7  Lista 6.1 - Cox tempo dependente",
    "section": "7.1 Carregando pacotes",
    "text": "7.1 Carregando pacotes\n\nlibrary(tidyverse)\nlibrary(flexplot)\nlibrary(foreign)\nlibrary(dplyr)\nlibrary(tm)\nlibrary(ggplot2)\nlibrary(forcats)\nlibrary(rempsyc)\nlibrary(easystats)\nlibrary(kableExtra)\nlibrary(gtsummary)\n\n#Específicos para survival\nlibrary(survival)\nlibrary(ggsurvfit)\nlibrary(survminer)\nlibrary(broom)\nlibrary(survMisc)\nlibrary(PHInfiniteEstimates)\nlibrary(coin)\nlibrary(condSURV)"
  },
  {
    "objectID": "lista_6_1.html#carregando-os-dados-e-modificando-o-tipo-de-variável",
    "href": "lista_6_1.html#carregando-os-dados-e-modificando-o-tipo-de-variável",
    "title": "7  Lista 6.1 - Cox tempo dependente",
    "section": "7.2 Carregando os dados e modificando o tipo de variável",
    "text": "7.2 Carregando os dados e modificando o tipo de variável\nMantendo as boas práticas das análises, logo após carregar os dados em uma variável, vamos verificar os tipos de variávels que temos em nosso banco.\n\noriginal = read.spss(\"Cox tempo dependente 2_1.sav\", to.data.frame=TRUE)\nglimpse(original)\n\nRows: 628\nColumns: 7\n$ ID            &lt;dbl&gt; 112, 91, 113, 150, 22, 139, 104, 590, 189, 171, 338, 492…\n$ age           &lt;dbl&gt; 35, 33, 35, 31, 33, 43, 25, 35, 29, 27, 35, 23, 24, 23, …\n$ race          &lt;fct&gt; branco, branco, branco, branco, branco, branco, branco, …\n$ treat         &lt;dbl&gt; 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1,…\n$ Tempo_dialise &lt;dbl&gt; 51, 67, 88, 156, 12, 139, 90, 25, 187, 34, 29, 78, 63, 8…\n$ time          &lt;dbl&gt; 1172, 762, 734, 720, 659, 658, 655, 654, 634, 630, 621, …\n$ morte         &lt;fct&gt; Não, Não, Não, Não, Não, Não, Não, Não, Não, Não, Não, N…\n\n\nNovamente podemos observar que o evento de interesse (morte) está como um fator. Vamos modificar como já fizemos a lista 6 e também já vamos ajustar a variável “treat” para que ela seja um fator e não um número.\n\ndb &lt;- original %&gt;%\n  mutate(\n    morte = as.integer(morte == \"Sim\"), # para transformar sim e não em 1 e 0, respectivamente\n    treat = as.factor(treat)\n  )\nglimpse(db)\n\nRows: 628\nColumns: 7\n$ ID            &lt;dbl&gt; 112, 91, 113, 150, 22, 139, 104, 590, 189, 171, 338, 492…\n$ age           &lt;dbl&gt; 35, 33, 35, 31, 33, 43, 25, 35, 29, 27, 35, 23, 24, 23, …\n$ race          &lt;fct&gt; branco, branco, branco, branco, branco, branco, branco, …\n$ treat         &lt;fct&gt; 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1,…\n$ Tempo_dialise &lt;dbl&gt; 51, 67, 88, 156, 12, 139, 90, 25, 187, 34, 29, 78, 63, 8…\n$ time          &lt;dbl&gt; 1172, 762, 734, 720, 659, 658, 655, 654, 634, 630, 621, …\n$ morte         &lt;int&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n\n\nFeito! Vamos também verificar se há presença de dados faltantes e em quais variáveis.\n\n# Verificando NAs\nresumo_nas &lt;- db %&gt;%\n  summarise(\n    nas_age = sum(is.na(age)),\n    nas_race = sum(is.na(race)),\n    nas_treat = sum(is.na(treat)),\n    nas_t_dialise = sum(is.na(Tempo_dialise)),\n    nas_time = sum(is.na(time)),\n    nas_morte = sum(is.na(morte)),\n  )\nkable(resumo_nas)\n\n\n\n\nnas_age\nnas_race\nnas_treat\nnas_t_dialise\nnas_time\nnas_morte\n\n\n\n\n5\n6\n0\n0\n0\n0\n\n\n\n\n\n\n\nAté chegar na Cox tempo dependente, vamos repetir basicamente o que já fizemos no Capítulo 6"
  },
  {
    "objectID": "lista_6_1.html#criando-a-estrutura-de-dados",
    "href": "lista_6_1.html#criando-a-estrutura-de-dados",
    "title": "7  Lista 6.1 - Cox tempo dependente",
    "section": "7.3 Criando a estrutura de dados",
    "text": "7.3 Criando a estrutura de dados\n\n# Create a survival object\nsurv_obj &lt;- Surv(time = db$time, event = db$morte)\n\n\nTábua de vida\n\n# Create survival curve\nfit1 &lt;- survfit(surv_obj ~ treat, data = db)\nkable(head(tidy(fit1)))\n\n\n\n\ntime\nn.risk\nn.event\nn.censor\nestimate\nstd.error\nconf.high\nconf.low\nstrata\n\n\n\n\n3\n320\n2\n0\n0.993750\n0.0044333\n1.0000000\n0.9851526\ntreat=0\n\n\n4\n318\n2\n0\n0.987500\n0.0062894\n0.9997483\n0.9754017\ntreat=0\n\n\n5\n316\n1\n0\n0.984375\n0.0070430\n0.9980575\n0.9708801\ntreat=0\n\n\n6\n315\n2\n0\n0.978125\n0.0083599\n0.9942837\n0.9622289\ntreat=0\n\n\n7\n313\n2\n0\n0.971875\n0.0095097\n0.9901593\n0.9539283\ntreat=0\n\n\n8\n311\n1\n0\n0.968750\n0.0100402\n0.9880024\n0.9498728\ntreat=0\n\n\n\n\n\n\n\n\n\nGráfico Kaplan-Meir\n\nkm_plot = survfit2(surv_obj ~ treat, data = db) %&gt;%\n  tidy_survfit() %&gt;%\n  ggplot(aes(x = time, y = estimate,\n             min = conf.low, ymax = conf.low,\n             color = strata, fill = strata)) +\n  geom_step()\nkm_plot\n\n\n\n\nPodemos ajustar as configurações do eixo X para exibir uma escala temporal com intervalos de 50 unidades.\n\n# km_plot2 = fit1 %&gt;%\n#   tidy_survfit() %&gt;%\n#   ggplot(aes(x = time, y = estimate,\n#              min = conf.low, ymax = conf.low,\n#              color = strata, fill = strata)) +\n#   geom_step()\n\nkm_plot2 = fit1 %&gt;%\n  tidy_survfit() %&gt;%\n  ggplot(aes(x = time, y = estimate,\n             min = conf.low, ymax = conf.low,\n             color = strata, fill = strata)) +\n  geom_step() +\n  scale_x_continuous(breaks = seq(0, max(fit1$time), by = 50))\n\n\nkm_plot2\n\n\n\n\n\n\nTabela com Sobrevida em tempos espcíficos.\n\ntbl_survfit_ex3 &lt;-\n  list(\n    survfit(surv_obj ~ 1, db),\n    survfit(surv_obj ~ treat, db)\n  ) %&gt;%\n  tbl_survfit(times = c(100, 600))\ntbl_survfit_ex3\n\n\n\n\n\n  \n    \n    \n      Characteristic\n      Time 100\n      Time 600\n    \n  \n  \n    Overall\n66% (63%, 70%)\n19% (16%, 22%)\n    treat\n\n\n        0\n61% (56%, 66%)\n16% (13%, 21%)\n        1\n72% (67%, 77%)\n21% (17%, 26%)\n  \n  \n  \n\n\n\n\n\n\nLog-rank\n\ncoin::logrank_test(surv_obj ~ treat, data = db, type = \"logrank\" ) # padrão é o log-rank\n\n\n    Asymptotic Two-Sample Logrank Test\n\ndata:  surv_obj by treat (0, 1)\nZ = -2.5984, p-value = 0.009365\nalternative hypothesis: true theta is not equal to 1\n\n\n\n\nGehan-Breslow\n\ncoin::logrank_test(surv_obj ~ treat ,data = db, type = \"Gehan-Breslow\")\n\n\n    Asymptotic Two-Sample Gehan-Breslow Test\n\ndata:  surv_obj by treat (0, 1)\nZ = -3.0713, p-value = 0.002132\nalternative hypothesis: true theta is not equal to 1\n\n\n\n\nTarone-Ware\n\ncoin::logrank_test(surv_obj ~ treat ,data = db, type = \"Tarone-Ware\")\n\n\n    Asymptotic Two-Sample Tarone-Ware Test\n\ndata:  surv_obj by treat (0, 1)\nZ = -2.9622, p-value = 0.003055\nalternative hypothesis: true theta is not equal to 1\n\n\n\n\nPeto-Peto\n\ncoin::logrank_test(surv_obj ~ treat ,data = db, type = \"Peto-Peto\")\n\n\n    Asymptotic Two-Sample Peto-Peto Test\n\ndata:  surv_obj by treat (0, 1)\nZ = -3.0608, p-value = 0.002207\nalternative hypothesis: true theta is not equal to 1"
  },
  {
    "objectID": "lista_6_1.html#cox-regression",
    "href": "lista_6_1.html#cox-regression",
    "title": "7  Lista 6.1 - Cox tempo dependente",
    "section": "7.4 Cox regression",
    "text": "7.4 Cox regression\n\n# Cox regression ======================================================\n# Fit the model\n\ncox_res &lt;- coxph(Surv(time = db$time, event = db$morte) ~ treat, data = db)\n### Para testar todas as variáveis\n#cox_res &lt;- coxph(Surv(time = db$time, event = db$morte2) ~ treat + age + Tempo_dialise, data = db)\n\ntbl_regression(cox_res, exponentiate = TRUE)\n\n\n\n\n\n  \n    \n    \n      Characteristic\n      HR1\n      95% CI1\n      p-value\n    \n  \n  \n    treat\n\n\n\n        0\n—\n—\n\n        1\n0.79\n0.67, 0.94\n0.009\n  \n  \n  \n    \n      1 HR = Hazard Ratio, CI = Confidence Interval\n    \n  \n\n\n\n\n\nVerificando os pressupostos da Cox regression\nRelembrando a análise dos riscos proporcionais com base nos resíduos de Schoenfeld:\n\np-val &lt; 0,05: há evidências contra a pressuposto de riscos proporcionais, os HRs não são constantes ao longo do tempo\nchisq: quanto maior o valor, mais forte a violação dos pressupostos"
  },
  {
    "objectID": "lista_6_1.html#plot-dos-resíduos-de-schoenfeld",
    "href": "lista_6_1.html#plot-dos-resíduos-de-schoenfeld",
    "title": "7  Lista 6.1 - Cox tempo dependente",
    "section": "7.5 Plot dos resíduos de Schoenfeld",
    "text": "7.5 Plot dos resíduos de Schoenfeld\n\n# Plot the Schoenfeld residuals over time for each covariate\nsurvminer::ggcoxzph(cox.zph(cox_res), point.size = 0.1)\n\n\n\n\nSe os resíduos mostrarem um padrão claro ao longo do tempo, isso pode indicar uma violação da suposição de riscos proporcionais.\nAlgumas dicas para ajudar na interpretação:\n\nSem Padrão (Resíduos Constantes): Se os resíduos aparecerem aleatoriamente espalhados em torno de zero, sem nenhuma tendência ou padrão claro, isso sugere que a suposição de riscos proporcionais é razoável.\nTendência Linear: Uma tendência linear (aumentando ou diminuindo) nos resíduos ao longo do tempo pode sugerir uma violação da suposição de riscos proporcionais. Por exemplo, se os resíduos forem consistentemente positivos ou negativos ao longo do tempo, isso indica um efeito dependente do tempo.\nPadrão Não Linear: Se os resíduos exibirem um padrão não linear ou formatos específicos (por exemplo, formato de U, formato de V), isso pode indicar desvios dos riscos proporcionais.\nParalelismo: Paralelismo significa que a propagação e distribuição dos resíduos são relativamente constantes ao longo do tempo. Se os resíduos aumentarem ou diminuirem ao longo do tempo, isso pode sugerir uma violação da suposição.\n\n\nggcoxdiagnostics(cox_res, type = \"dfbeta\", linear.predictions = FALSE)\n\nWarning: `gather_()` was deprecated in tidyr 1.2.0.\nℹ Please use `gather()` instead.\nℹ The deprecated feature was likely used in the survminer package.\n  Please report the issue at &lt;https://github.com/kassambara/survminer/issues&gt;.\n\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n# Não é importante para variáveis categóricas, mas fica o código para eventual consulta.\nggcoxdiagnostics(cox_res, type = \"deviance\", linear.predictions = FALSE)\n\n`geom_smooth()` using formula = 'y ~ x'"
  },
  {
    "objectID": "lista_6_1.html#plots-do-modelo",
    "href": "lista_6_1.html#plots-do-modelo",
    "title": "7  Lista 6.1 - Cox tempo dependente",
    "section": "7.6 Plots do modelo",
    "text": "7.6 Plots do modelo\n\nForest plot\n\n# Forest plots ================================================================\n# Visualise your Cox model results\nggforest(cox_res, data = db)\n\n\n\n\n\n\nGráfico de sobrevida\nAssim como fizemos no exercício anterior, precisamos criar um novo banco de dados para visualizar o gráfico da Regressão de Cox:\n\n# Precisa ser feito apenas com uma variável\ncox_res2 &lt;- coxph(Surv(time = db$time, event = db$morte) ~ treat, data = db)\n\n# Criando o novo banco de dados\nnew_df &lt;- with(db,\n               data.frame(treat = c(\"0\", \"1\"))\n)\n\nE precisamos transformar a variável treat em um fator.\n\nnew_df$treat = as.factor(new_df$treat)\nkable(new_df)\n\n\n\n\ntreat\n\n\n\n\n0\n\n\n1\n\n\n\n\n\n\n\nCriando os dados com base no modelo e plotando o gráfico.\n\nfit_cox &lt;- survfit(cox_res2, newdata = new_df)\n\nJ = ggsurvplot(fit_cox, conf.int = TRUE, legend.labs=c(\"tx=sim\", \"tx=não\"),\n           ggtheme = theme_minimal(),\n           data = db)\n\nJ$plot = J$plot +\n  scale_x_continuous(breaks = seq(0, 900, 20))\n\nScale for x is already present.\nAdding another scale for x, which will replace the existing scale.\n\nJ\n\n\n\n\nReparem na distorção do gráfico em relação à Kaplan-Meir\n\nkm_plot"
  },
  {
    "objectID": "lista_6_1.html#cox-tempo-dependente",
    "href": "lista_6_1.html#cox-tempo-dependente",
    "title": "7  Lista 6.1 - Cox tempo dependente",
    "section": "7.7 Cox tempo-dependente",
    "text": "7.7 Cox tempo-dependente\nJá vimos que os riscos não são proporcionais neste caso. Porém, nem tudo está perdido. Podemos finalmente agora falar da Cox Tempo-dependente.\nO primeiro passo é identificar um possível fator que esteja afetando a proporcionalidade dos riscos no estudo. Pela literatura tempos que o tempo em diálise afeta os riscos entre pessoas que fizeram ou não o transplante de rim. Daí a importância de entender bem o fenômeno que estamos estudando. Como bons pesquisadores, também coletamos o tempo em diálise e esses dados estão no banco de dados\n\nglimpse(db$Tempo_dialise)\n\n num [1:628] 51 67 88 156 12 139 90 25 187 34 ...\n\n\nA variável é numérica e contínua, logo ela já está formatada para continuarmos com a análise.\nNão existe regras escritas na pedra para contornar o problema de não proporcionalidade. Vamos mostrar uma abordagem aqui. Não deixe de ver as referências para outros casos.\n\nCovariáveis tempo dependente\nNo R, há diversas formas de indicar uma variável como tempo-dependente. A escolha do método dependerá da natureza da variável independente e da sua relação teórica com o evento em estudo. A função coxph() oferece a opção de utilizar o argumento tt(), o qual especifica qual variável independente será considerada uma covariável tempo-dependente e como o coeficiente associado a ela deve ser modificado ao longo do tempo.\nO modelo deve seguir a seguinte estrutura\ncoxph(Surv(time, event) ~ covariavel1 + covariavel2 + tt(covariavel2), data, tt=function(x,t,…) x*t)\nPodemos substituir o Surv(time, event) pela variável que salvamos com o objeto survival, surv_obj.\nA função tt (function(x,t,…)___) pode assumir alguns modelos. A seguir trazemos três exemplos mais utilizados em diversas análises:\n\nx*t permitirá que o coeficiente mude linearmente com o tempo\nx*log(t) permite que o coeficiente mude com o log do tempo\nx*(t&gt;tempo) permite que o coeficiente assuma 2 valores diferentes, um valor quando t&lt;=tempo e outro valor t&gt;tempo\n\nVamos gerar vários modelos e avaliá-los comparando os índices de ajuste e os resultados obtidos.\n\n\nSem variável tempo dependente\n\ndialise &lt;- coxph(surv_obj ~ treat + Tempo_dialise, \n                          data=db) # corte no 660\n\nsummary(dialise)\n\nCall:\ncoxph(formula = surv_obj ~ treat + Tempo_dialise, data = db)\n\n  n= 628, number of events= 508 \n\n                    coef  exp(coef)   se(coef)       z            Pr(&gt;|z|)    \ntreat1         0.0618983  1.0638541  0.0899990   0.688               0.492    \nTempo_dialise -0.0084493  0.9915863  0.0007709 -10.960 &lt;0.0000000000000002 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n              exp(coef) exp(-coef) lower .95 upper .95\ntreat1           1.0639      0.940    0.8918    1.2691\nTempo_dialise    0.9916      1.008    0.9901    0.9931\n\nConcordance= 0.75  (se = 0.012 )\nLikelihood ratio test= 151.4  on 2 df,   p=&lt;0.0000000000000002\nWald test            = 121.2  on 2 df,   p=&lt;0.0000000000000002\nScore (logrank) test = 120.6  on 2 df,   p=&lt;0.0000000000000002\n\n\n\n\nMudança linear\n\ndialise_linear &lt;- coxph(surv_obj ~ treat + Tempo_dialise + tt(Tempo_dialise),\n                        data=db,\n                          tt=function(x,t,...) x*t) \nsummary(dialise_linear)\n\nCall:\ncoxph(formula = surv_obj ~ treat + Tempo_dialise + tt(Tempo_dialise), \n    data = db, tt = function(x, t, ...) x * t)\n\n  n= 628, number of events= 508 \n\n                          coef    exp(coef)     se(coef)       z\ntreat1            -0.016001236  0.984126103  0.091676088  -0.175\nTempo_dialise     -0.023777102  0.976503346  0.001506128 -15.787\ntt(Tempo_dialise)  0.000070699  1.000070701  0.000005184  13.637\n                             Pr(&gt;|z|)    \ntreat1                          0.861    \nTempo_dialise     &lt;0.0000000000000002 ***\ntt(Tempo_dialise) &lt;0.0000000000000002 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n                  exp(coef) exp(-coef) lower .95 upper .95\ntreat1               0.9841     1.0161    0.8223    1.1778\nTempo_dialise        0.9765     1.0241    0.9736    0.9794\ntt(Tempo_dialise)    1.0001     0.9999    1.0001    1.0001\n\nConcordance= 0.761  (se = 0.009 )\nLikelihood ratio test= 337.6  on 3 df,   p=&lt;0.0000000000000002\nWald test            = 249.3  on 3 df,   p=&lt;0.0000000000000002\nScore (logrank) test = 229.1  on 3 df,   p=&lt;0.0000000000000002\n\n\n\n\nModelo log\n\ndialise_log &lt;- coxph(surv_obj ~ treat + Tempo_dialise + tt(Tempo_dialise),\n                          data=db,\n                          tt=function(x,t,...) x*log(t)) \n\nsummary(dialise_log)\n\nCall:\ncoxph(formula = surv_obj ~ treat + Tempo_dialise + tt(Tempo_dialise), \n    data = db, tt = function(x, t, ...) x * log(t))\n\n  n= 628, number of events= 508 \n\n                       coef exp(coef)  se(coef)      z            Pr(&gt;|z|)    \ntreat1            -0.071106  0.931363  0.092369  -0.77               0.441    \nTempo_dialise     -0.097417  0.907178  0.005942 -16.40 &lt;0.0000000000000002 ***\ntt(Tempo_dialise)  0.017178  1.017326  0.001087  15.80 &lt;0.0000000000000002 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n                  exp(coef) exp(-coef) lower .95 upper .95\ntreat1               0.9314      1.074    0.7771    1.1162\nTempo_dialise        0.9072      1.102    0.8967    0.9178\ntt(Tempo_dialise)    1.0173      0.983    1.0152    1.0195\n\nConcordance= 0.759  (se = 0.01 )\nLikelihood ratio test= 461.5  on 3 df,   p=&lt;0.0000000000000002\nWald test            = 284.6  on 3 df,   p=&lt;0.0000000000000002\nScore (logrank) test = 223.9  on 3 df,   p=&lt;0.0000000000000002\n\n\n\n\nModelo temporal\n\ndialise_tempo_650 &lt;- coxph(surv_obj ~ treat + Tempo_dialise + tt(Tempo_dialise),\n                          data=db,\n                          tt=function(x,t,...) x*(t&gt;650))\n\nsummary(dialise_tempo_650)\n\nCall:\ncoxph(formula = surv_obj ~ treat + Tempo_dialise + tt(Tempo_dialise), \n    data = db, tt = function(x, t, ...) x * (t &gt; 650))\n\n  n= 628, number of events= 508 \n\n                        coef  exp(coef)   se(coef)       z            Pr(&gt;|z|)\ntreat1             0.0617615  1.0637086  0.0900051   0.686               0.493\nTempo_dialise     -0.0084524  0.9915832  0.0007713 -10.958 &lt;0.0000000000000002\ntt(Tempo_dialise)  0.0028519  1.0028560  0.0221016   0.129               0.897\n                     \ntreat1               \nTempo_dialise     ***\ntt(Tempo_dialise)    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n                  exp(coef) exp(-coef) lower .95 upper .95\ntreat1               1.0637     0.9401    0.8917    1.2689\nTempo_dialise        0.9916     1.0085    0.9901    0.9931\ntt(Tempo_dialise)    1.0029     0.9972    0.9603    1.0473\n\nConcordance= 0.75  (se = 0.01 )\nLikelihood ratio test= 151.5  on 3 df,   p=&lt;0.0000000000000002\nWald test            = 121.2  on 3 df,   p=&lt;0.0000000000000002\nScore (logrank) test = 120.6  on 3 df,   p=&lt;0.0000000000000002\n\n\n\n\nÍndices de aderência (AIC e BIC)\nPodemos comparar os modelos computando os valores de AIC e BIC\n\ncombined_df &lt;- data.frame(\n  Model = c(\"dialise\", \"dialise_linear\", \"dialise_log\", \"dialise_tempo_650\"),\n  AIC = c(AIC(dialise), AIC(dialise_linear), AIC(dialise_log), AIC(dialise_tempo_650)),\n  BIC = c(BIC(dialise), BIC(dialise_linear), BIC(dialise_log), BIC(dialise_tempo_650))\n)\n\nkable(combined_df)\n\n\n\n\nModel\nAIC\nBIC\n\n\n\n\ndialise\n5771.688\n5780.149\n\n\ndialise_linear\n5587.564\n5600.256\n\n\ndialise_log\n5463.651\n5476.343\n\n\ndialise_tempo_650\n5773.672\n5786.363\n\n\n\n\n\n\n\nPor esse critério, temos que o melhor modelo é o log em seguida o linear.\n\n\nResíduos de Schoenfeld\nAgora vamos analisar mais uma vez os resíduos de Schoenfeld, mas agora variando pelo “Tempo em Diálise”.\n\ncox_res_T_Cov &lt;- coxph(Surv(time = db$time, event = db$morte) ~ treat + Tempo_dialise, data = db)  \nggcoxzph(cox.zph(cox_res_T_Cov), var =\"Tempo_dialise\") \n\n\n\n\nPodemos observar que o Beta do tempo em diálise tem um aumento linear conforme maior o tempo. O resultado pode indicar que o efeito do tempo sobre a o tempo em diálise pode ser linear.\n\n\nInterpretando os resultados.\nA interpretação dos coeficientes da Cox Tempo-dependente é diferente das outras regressõs.\nVamos interpretar o valor do modelo com mudança linear.\n\nsummary(dialise_linear)\n\nCall:\ncoxph(formula = surv_obj ~ treat + Tempo_dialise + tt(Tempo_dialise), \n    data = db, tt = function(x, t, ...) x * t)\n\n  n= 628, number of events= 508 \n\n                          coef    exp(coef)     se(coef)       z\ntreat1            -0.016001236  0.984126103  0.091676088  -0.175\nTempo_dialise     -0.023777102  0.976503346  0.001506128 -15.787\ntt(Tempo_dialise)  0.000070699  1.000070701  0.000005184  13.637\n                             Pr(&gt;|z|)    \ntreat1                          0.861    \nTempo_dialise     &lt;0.0000000000000002 ***\ntt(Tempo_dialise) &lt;0.0000000000000002 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n                  exp(coef) exp(-coef) lower .95 upper .95\ntreat1               0.9841     1.0161    0.8223    1.1778\nTempo_dialise        0.9765     1.0241    0.9736    0.9794\ntt(Tempo_dialise)    1.0001     0.9999    1.0001    1.0001\n\nConcordance= 0.761  (se = 0.009 )\nLikelihood ratio test= 337.6  on 3 df,   p=&lt;0.0000000000000002\nWald test            = 249.3  on 3 df,   p=&lt;0.0000000000000002\nScore (logrank) test = 229.1  on 3 df,   p=&lt;0.0000000000000002\n\n\nO coeficiente Tempo_dialise = -0.023, deve ser interpretado como o efeito do tempo de diálise no tempo zero. Já o coeficiente tt(Tempo_dialise) = deve ser interpretado como o a mudança do efeito do tempo em diálise a cada unidade de tempo a mais.\n\n\nObservações SPSS e R\nNa aula prática o modelo não é feito com o Tempo em Diálise fora da variável tempo dependente. Já na aula teórica do curso II de 2023, o modelo é escrito como foi feito aqui no R, levando em conta o Tempo em Diálise como uma variável tempo dependente e também como covariável no modelo."
  },
  {
    "objectID": "lista_6_1.html#covariando-para-idade-e-raça",
    "href": "lista_6_1.html#covariando-para-idade-e-raça",
    "title": "7  Lista 6.1 - Cox tempo dependente",
    "section": "7.8 Covariando para idade e raça",
    "text": "7.8 Covariando para idade e raça\nO conjunto de dados ainda possui duas variáveis que não foram incluídas no modelo: idade e raça. Conforme o procedimento padrão, vamos examinar a natureza dessas variáveis. Começando com a idade.\n\nglimpse(db)\n\nRows: 628\nColumns: 7\n$ ID            &lt;dbl&gt; 112, 91, 113, 150, 22, 139, 104, 590, 189, 171, 338, 492…\n$ age           &lt;dbl&gt; 35, 33, 35, 31, 33, 43, 25, 35, 29, 27, 35, 23, 24, 23, …\n$ race          &lt;fct&gt; branco, branco, branco, branco, branco, branco, branco, …\n$ treat         &lt;fct&gt; 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1,…\n$ Tempo_dialise &lt;dbl&gt; 51, 67, 88, 156, 12, 139, 90, 25, 187, 34, 29, 78, 63, 8…\n$ time          &lt;dbl&gt; 1172, 762, 734, 720, 659, 658, 655, 654, 634, 630, 621, …\n$ morte         &lt;int&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n\n\nÓtimo, idade já está como uma variável numérica e contínua e raça está como um fator. Por fim, vamos verificar qual o nível de referência da variável “race”.\n\nlevels(db$race)\n\n[1] \"branco\"      \"negro/pardo\"\n\n\nO nível “branco” está como referência, logo, os resultados do modelo mostrarão os valores dos coeficientes do nível “negro/pardo” em relação ao nível “branco”.\nVamos ao modelo completo.\n\nModelo completo Cox tempo dependente\n\ncox_full_model &lt;- coxph(surv_obj ~ age + race + treat + Tempo_dialise + tt(Tempo_dialise),\n                        data=db,\n                          tt=function(x,t,...) x*t) \nsummary(cox_full_model)\n\nCall:\ncoxph(formula = surv_obj ~ age + race + treat + Tempo_dialise + \n    tt(Tempo_dialise), data = db, tt = function(x, t, ...) x * \n    t)\n\n  n= 617, number of events= 500 \n   (11 observations deleted due to missingness)\n\n                          coef    exp(coef)     se(coef)       z\nage               -0.005531327  0.994483942  0.007272881  -0.761\nracenegro/pardo   -0.342009991  0.710341107  0.108147939  -3.162\ntreat1             0.042207387  1.043110784  0.093368582   0.452\nTempo_dialise     -0.023671737  0.976606241  0.001511519 -15.661\ntt(Tempo_dialise)  0.000068807  1.000068809  0.000005196  13.242\n                              Pr(&gt;|z|)    \nage                            0.44693    \nracenegro/pardo                0.00156 ** \ntreat1                         0.65123    \nTempo_dialise     &lt; 0.0000000000000002 ***\ntt(Tempo_dialise) &lt; 0.0000000000000002 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n                  exp(coef) exp(-coef) lower .95 upper .95\nage                  0.9945     1.0055    0.9804    1.0088\nracenegro/pardo      0.7103     1.4078    0.5747    0.8781\ntreat1               1.0431     0.9587    0.8687    1.2526\nTempo_dialise        0.9766     1.0240    0.9737    0.9795\ntt(Tempo_dialise)    1.0001     0.9999    1.0001    1.0001\n\nConcordance= 0.765  (se = 0.009 )\nLikelihood ratio test= 343.2  on 5 df,   p=&lt;0.0000000000000002\nWald test            = 259.4  on 5 df,   p=&lt;0.0000000000000002\nScore (logrank) test = 243.3  on 5 df,   p=&lt;0.0000000000000002\n\n\nAgora temos que a raça tem um efeito significativo no modelo. Seguindo o vídeo da aula prática, podemos segmentar o banco de dados para as duas raças que temos no banco de dados.\n\n\nSegmentando o banco de dados por raça\n\ndb_branco = db %&gt;%\n  filter(race == \"branco\")\n\ndb_pardo_negro = db %&gt;% \n  filter(race == \"negro/pardo\")\n\n\n\nKM por raça = Branco\n\n# Criando um novo objeto Surv\nsurv_obj_branco &lt;- Surv(time = db_branco$time, event = db_branco$morte)\n\nfit_br = survfit(surv_obj_branco ~ treat, data = db_branco)\nggsurvfit(fit_br)\n\n\n\nggsurvfit(fit_br, linewidth = 1) +\n  labs(x = 'Dias', y = 'Overall survival') +\n  add_confidence_interval() +\n # add_risktable() +\n  scale_ggsurvfit() + \n  biostatsquid_theme #+  coord_cartesian(xlim = c(0, 8))\n\n\n\n\n\n\nModelo completo para brancos\n\n# Escrevendo o modelo\n\ncox_full_model_branco &lt;- coxph(surv_obj_branco ~ age + treat + Tempo_dialise + tt(Tempo_dialise),\n                        data=db_branco,\n                          tt=function(x,t,...) x*t) \n\nsummary(cox_full_model_branco)\n\nCall:\ncoxph(formula = surv_obj_branco ~ age + treat + Tempo_dialise + \n    tt(Tempo_dialise), data = db_branco, tt = function(x, t, \n    ...) x * t)\n\n  n= 464, number of events= 385 \n   (3 observations deleted due to missingness)\n\n                          coef    exp(coef)     se(coef)      z\nage               -0.000811624  0.999188705  0.008137628  -0.10\ntreat1             0.028995294  1.029419750  0.107276897   0.27\nTempo_dialise     -0.024166842  0.976122838  0.001707544 -14.15\ntt(Tempo_dialise)  0.000070240  1.000070242  0.000005841  12.03\n                             Pr(&gt;|z|)    \nage                             0.921    \ntreat1                          0.787    \nTempo_dialise     &lt;0.0000000000000002 ***\ntt(Tempo_dialise) &lt;0.0000000000000002 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n                  exp(coef) exp(-coef) lower .95 upper .95\nage                  0.9992     1.0008    0.9834    1.0153\ntreat1               1.0294     0.9714    0.8342    1.2703\nTempo_dialise        0.9761     1.0245    0.9729    0.9794\ntt(Tempo_dialise)    1.0001     0.9999    1.0001    1.0001\n\nConcordance= 0.78  (se = 0.01 )\nLikelihood ratio test= 286.5  on 4 df,   p=&lt;0.0000000000000002\nWald test            = 201.8  on 4 df,   p=&lt;0.0000000000000002\nScore (logrank) test = 185.6  on 4 df,   p=&lt;0.0000000000000002\n\n\n\n\nKM por raça = negro/pardo\n\n# Criando um novo objeto Surv\n\nsurv_obj_pardo_negro&lt;- Surv(time = db_pardo_negro$time, event = db_pardo_negro$morte)\n\nfit_pn = survfit(surv_obj_pardo_negro ~ treat, data = db_pardo_negro)\n\nggsurvfit(fit_pn, linewidth = 1) +\n  labs(x = 'Dias', y = 'Overall survival') +\n  add_confidence_interval() +\n # add_risktable() +\n  scale_ggsurvfit() + \n  biostatsquid_theme #+  coord_cartesian(xlim = c(0, 8))\n\n\n\n\n\n\nModelo completo para pardo/negro\n\n# Escrevendo o modelo\n\ncox_full_model_pardo_negro &lt;- coxph(surv_obj_pardo_negro ~ age + treat + Tempo_dialise + tt(Tempo_dialise),\n                        data=db_pardo_negro,\n                          tt=function(x,t,...) x*t) \n\nsummary(cox_full_model_pardo_negro)\n\nCall:\ncoxph(formula = surv_obj_pardo_negro ~ age + treat + Tempo_dialise + \n    tt(Tempo_dialise), data = db_pardo_negro, tt = function(x, \n    t, ...) x * t)\n\n  n= 153, number of events= 115 \n   (2 observations deleted due to missingness)\n\n                         coef   exp(coef)    se(coef)      z      Pr(&gt;|z|)    \nage               -0.02336224  0.97690855  0.01673857 -1.396         0.163    \ntreat1             0.07806397  1.08119182  0.19431411  0.402         0.688    \nTempo_dialise     -0.02367178  0.97660620  0.00397339 -5.958 0.00000000256 ***\ntt(Tempo_dialise)  0.00007639  1.00007639  0.00001784  4.282 0.00001853157 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n                  exp(coef) exp(-coef) lower .95 upper .95\nage                  0.9769     1.0236    0.9454    1.0095\ntreat1               1.0812     0.9249    0.7388    1.5824\nTempo_dialise        0.9766     1.0240    0.9690    0.9842\ntt(Tempo_dialise)    1.0001     0.9999    1.0000    1.0001\n\nConcordance= 0.696  (se = 0.025 )\nLikelihood ratio test= 48.53  on 4 df,   p=0.0000000007\nWald test            = 39.77  on 4 df,   p=0.00000005\nScore (logrank) test = 42.56  on 4 df,   p=0.00000001"
  },
  {
    "objectID": "lista_6_1.html#lista-6.1-resolvida-no-spss",
    "href": "lista_6_1.html#lista-6.1-resolvida-no-spss",
    "title": "7  Lista 6.1 - Cox tempo dependente",
    "section": "7.9 Lista 6.1 resolvida no SPSS",
    "text": "7.9 Lista 6.1 resolvida no SPSS"
  },
  {
    "objectID": "lista_6_1.html#extras",
    "href": "lista_6_1.html#extras",
    "title": "7  Lista 6.1 - Cox tempo dependente",
    "section": "7.10 Extras",
    "text": "7.10 Extras\n\nMais gráficos\nE utilizar nosso tema para personalizar e padronizar.\n\nfit2_km &lt;- ggsurvfit(fit1, linewidth = 1) +\n  labs(x = 'Dias', y = 'Porcentagem de sobrevida') +\n  add_confidence_interval() +\n # add_risktable() +\n  scale_ggsurvfit() + \n  biostatsquid_theme #+  coord_cartesian(xlim = c(0, 8))\n\nfit2_km\n\n\n\n\nCuidado com o p-value do gráfico a seguir, ele se refere apenas ao Log-rank\n\nggsurvplot(fit1, data = db,\n           size = 1,\n           palette = c('#E7B800', '#2e9fdf'),\n           censor.shape = '|', censor.size = 4,\n           conf.int = TRUE,\n           pval = TRUE, # CUIDADO, apenas log-rank\n          # risk.table = TRUE,\n         #  risk.table.col = 'strata',\n           legend.labs = list('0' = 'Transplante = sim', '1' = 'Transplante = não'),\n           risk.table.height = 0.25,\n           ggtheme = theme_bw())\n\n\n\n\n\n\nCox tempo dependente log\n\ncox_full_model_2 &lt;- coxph(surv_obj ~ age + race + treat + Tempo_dialise + tt(Tempo_dialise),\n                        data=db,\n                          tt=function(x,t,...) x*log(t)) \nsummary(cox_full_model_2)\n\nCall:\ncoxph(formula = surv_obj ~ age + race + treat + Tempo_dialise + \n    tt(Tempo_dialise), data = db, tt = function(x, t, ...) x * \n    log(t))\n\n  n= 617, number of events= 500 \n   (11 observations deleted due to missingness)\n\n                       coef exp(coef)  se(coef)       z             Pr(&gt;|z|)\nage               -0.005656  0.994360  0.007318  -0.773              0.43960\nracenegro/pardo   -0.296846  0.743159  0.108704  -2.731              0.00632\ntreat1            -0.007682  0.992348  0.094183  -0.082              0.93499\nTempo_dialise     -0.096272  0.908217  0.005996 -16.056 &lt; 0.0000000000000002\ntt(Tempo_dialise)  0.016885  1.017028  0.001098  15.383 &lt; 0.0000000000000002\n                     \nage                  \nracenegro/pardo   ** \ntreat1               \nTempo_dialise     ***\ntt(Tempo_dialise) ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n                  exp(coef) exp(-coef) lower .95 upper .95\nage                  0.9944     1.0057    0.9802    1.0087\nracenegro/pardo      0.7432     1.3456    0.6006    0.9196\ntreat1               0.9923     1.0077    0.8251    1.1935\nTempo_dialise        0.9082     1.1011    0.8976    0.9190\ntt(Tempo_dialise)    1.0170     0.9833    1.0148    1.0192\n\nConcordance= 0.764  (se = 0.009 )\nLikelihood ratio test= 459.7  on 5 df,   p=&lt;0.0000000000000002\nWald test            = 290.9  on 5 df,   p=&lt;0.0000000000000002\nScore (logrank) test = 237.8  on 5 df,   p=&lt;0.0000000000000002\n\nAIC(cox_full_model_2)\n\n[1] 5356.724"
  },
  {
    "objectID": "lista_6_1.html#referencias",
    "href": "lista_6_1.html#referencias",
    "title": "7  Lista 6.1 - Cox tempo dependente",
    "section": "7.11 Referencias",
    "text": "7.11 Referencias\nhttps://stats.oarc.ucla.edu/wp-content/uploads/2022/05/survival_r.html#(48)\nhttps://www.youtube.com/watch?v=Y_83HXuHMdc\nhttps://youtu.be/Y_83HXuHMdc?t=9151"
  },
  {
    "objectID": "lista_6_1.html#códigos-não-utilizados",
    "href": "lista_6_1.html#códigos-não-utilizados",
    "title": "7  Lista 6.1 - Cox tempo dependente",
    "section": "7.12 Códigos não utilizados",
    "text": "7.12 Códigos não utilizados\n\n# Ajustando o banco de dados\n\ndb3 = db\n\n\n# db3$time = pmax(0.5, db3$time - 0) caso eu tenha zeros no tempo de morte\n# db3$time660 = as.integer(db3$time660)\n# head(db3)\n\n# db3$time660 = as.integer(db3$time660)\n\ndb3 &lt;- tmerge(\n  data1 = db3,\n  data2 = db3,\n  id = ID,\n # death = event(T1, delta1), caso tenha dois eventos de morte independentes. Duas doenças diferentes, por exemplo\n  death = event(time, morte),\n  T_Cov = tdc(Tempo_dialise) # indicando a covariavel tempo-dependente\n)\n\nhead(db3)\n\n   ID age   race treat Tempo_dialise time morte tstart tstop death T_Cov\n1 112  35 branco     1            51 1172     0      0    51     0     0\n2 112  35 branco     1            51 1172     0     51  1172     0     1\n3  91  33 branco     0            67  762     0      0    67     0     0\n4  91  33 branco     0            67  762     0     67   762     0     1\n5 113  35 branco     0            88  734     0      0    88     0     0\n6 113  35 branco     0            88  734     0     88   734     0     1\n\n\n\n# Duvida para Altay - colocar o evento como morte2 ou death\ncox_model_T_Cov &lt;- coxph(Surv(time = tstart, time2 = tstop, event = morte) ~ treat + T_Cov, data = db3)\n\nsummary(cox_model_T_Cov)\n\nCall:\ncoxph(formula = Surv(time = tstart, time2 = tstop, event = morte) ~ \n    treat + T_Cov, data = db3)\n\n  n= 1174, number of events= 934 \n\n           coef exp(coef) se(coef)      z Pr(&gt;|z|)   \ntreat1 -0.17205   0.84194  0.06668 -2.580  0.00987 **\nT_Cov   0.03829   1.03903  0.08493  0.451  0.65210   \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n       exp(coef) exp(-coef) lower .95 upper .95\ntreat1    0.8419     1.1877    0.7388    0.9595\nT_Cov     1.0390     0.9624    0.8797    1.2272\n\nConcordance= 0.539  (se = 0.01 )\nLikelihood ratio test= 7.53  on 2 df,   p=0.02\nWald test            = 7.53  on 2 df,   p=0.02\nScore (logrank) test = 7.54  on 2 df,   p=0.02\n\ndb3 %&gt;% \n  coxph(Surv(time = tstart, time2 = tstop, event = death) ~ treat + age + race + T_Cov, data = .) %&gt;% \n  gtsummary::tbl_regression(exp = TRUE)\n\n\n\n\n\n  \n    \n    \n      Characteristic\n      HR1\n      95% CI1\n      p-value\n    \n  \n  \n    treat\n\n\n\n        0\n—\n—\n\n        1\n1.05\n0.88, 1.25\n0.6\n    age\n1.00\n0.98, 1.01\n0.5\n    race\n\n\n\n        branco\n—\n—\n\n        negro/pardo\n0.68\n0.55, 0.84\n&lt;0.001\n    T_Cov\n13.6\n10.1, 18.4\n&lt;0.001\n  \n  \n  \n    \n      1 HR = Hazard Ratio, CI = Confidence Interval\n    \n  \n\n\n\n\n\nTempo em diálise como covariante tempo-dependente\n\n# Ajustando o banco de dados\n\ndb2 = db\n\n\n#db2$time = pmax(0.5, db2$time - 0)\n\n\ndb2 &lt;- tmerge(\n  data1 = db,\n  data2 = db,\n  id = ID,\n # death = event(T1, delta1), caso tenha dois eventos de morte independentes. Duas doenças diferentes, por exemplo\n  death = event(time, morte),\n  T_Tempo_dialise = tdc(Tempo_dialise) # indicando a covariavel tempo-dependente\n)\nhead(db2)\n\n   ID age   race treat Tempo_dialise time morte tstart tstop death\n1 112  35 branco     1            51 1172     0      0    51     0\n2 112  35 branco     1            51 1172     0     51  1172     0\n3  91  33 branco     0            67  762     0      0    67     0\n4  91  33 branco     0            67  762     0     67   762     0\n5 113  35 branco     0            88  734     0      0    88     0\n6 113  35 branco     0            88  734     0     88   734     0\n  T_Tempo_dialise\n1               0\n2               1\n3               0\n4               1\n5               0\n6               1\n\n\n\ncox_model_time_dependent &lt;- coxph(Surv(time = tstart, time2 = tstop, event = death) ~ T_Tempo_dialise + treat, data = db2)\n\nsummary(cox_model_time_dependent)\n\nCall:\ncoxph(formula = Surv(time = tstart, time2 = tstop, event = death) ~ \n    T_Tempo_dialise + treat, data = db2)\n\n  n= 1174, number of events= 508 \n\n                     coef exp(coef)  se(coef)      z            Pr(&gt;|z|)    \nT_Tempo_dialise  2.585761 13.273384  0.150925 17.133 &lt;0.0000000000000002 ***\ntreat1          -0.003201  0.996804  0.089471 -0.036               0.971    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n                exp(coef) exp(-coef) lower .95 upper .95\nT_Tempo_dialise   13.2734    0.07534    9.8745    17.842\ntreat1             0.9968    1.00321    0.8365     1.188\n\nConcordance= 0.699  (se = 0.014 )\nLikelihood ratio test= 382.7  on 2 df,   p=&lt;0.0000000000000002\nWald test            = 294.6  on 2 df,   p=&lt;0.0000000000000002\nScore (logrank) test = 354.7  on 2 df,   p=&lt;0.0000000000000002\n\ndb2 %&gt;% \n  coxph(Surv(time = tstart, time2 = tstop, event = death) ~ T_Tempo_dialise * treat, data = .) %&gt;% \n  gtsummary::tbl_regression(exp = TRUE)\n\n\n\n\n\n  \n    \n    \n      Characteristic\n      HR1\n      95% CI1\n      p-value\n    \n  \n  \n    T_Tempo_dialise\n9.78\n6.78, 14.1\n&lt;0.001\n    treat\n\n\n\n        0\n—\n—\n\n        1\n0.59\n0.38, 0.92\n0.020\n    T_Tempo_dialise * treat\n\n\n\n        T_Tempo_dialise * 1\n1.86\n1.15, 3.02\n0.012\n  \n  \n  \n    \n      1 HR = Hazard Ratio, CI = Confidence Interval"
  },
  {
    "objectID": "lista_6_1.html#versões-dos-pacotes",
    "href": "lista_6_1.html#versões-dos-pacotes",
    "title": "7  Lista 6.1 - Cox tempo dependente",
    "section": "7.13 Versões dos pacotes",
    "text": "7.13 Versões dos pacotes\n\nreport(sessionInfo())\n\nAnalyses were conducted using the R Statistical language (version 4.3.1; R Core\nTeam, 2023) on Windows 11 x64 (build 22621), using the packages effectsize\n(version 0.8.6; Ben-Shachar MS et al., 2020), lpSolve (version 5.6.19;\nBerkelaar M, others, 2023), survMisc (version 0.5.6; Dardis C, 2022), tm\n(version 0.7.11; Feinerer I, Hornik K, 2023), flexplot (version 0.20.5; Fife D,\n2024), lubridate (version 1.9.3; Grolemund G, Wickham H, 2011), coxphf (version\n1.13.4; Heinze G et al., 2023), NLP (version 0.2.1; Hornik K, 2020), coin\n(version 1.4.3; Hothorn T et al., 2006), ggpubr (version 0.6.0; Kassambara A,\n2023), survminer (version 0.4.9; Kassambara A et al., 2021),\nPHInfiniteEstimates (version 2.9.5; Kolassa JE, Zhang J, 2023), parameters\n(version 0.21.3; Lüdecke D et al., 2020), performance (version 0.10.8; Lüdecke\nD et al., 2021), easystats (version 0.6.0; Lüdecke D et al., 2022), see\n(version 0.8.1; Lüdecke D et al., 2021), insight (version 0.19.6; Lüdecke D et\nal., 2019), bayestestR (version 0.13.1; Makowski D et al., 2019), modelbased\n(version 0.8.6; Makowski D et al., 2020), report (version 0.5.7; Makowski D et\nal., 2023), correlation (version 0.8.4; Makowski D et al., 2022), condSURV\n(version 2.0.4; Meira-Machado L, Sestelo M, 2023), tibble (version 3.2.1;\nMüller K, Wickham H, 2023), datawizard (version 0.9.0; Patil I et al., 2022),\nforeign (version 0.8.85; R Core Team, 2023), nph (version 2.1; Ristl R et al.,\n2021), broom (version 1.0.5; Robinson D et al., 2023), ggsurvfit (version\n1.0.0; Sjoberg D et al., 2023), gtsummary (version 1.7.2; Sjoberg D et al.,\n2021), rempsyc (version 0.1.6; Thériault R, 2023), survival (version 3.5.7;\nTherneau T, 2023), ggplot2 (version 3.4.4; Wickham H, 2016), forcats (version\n1.0.0; Wickham H, 2023), stringr (version 1.5.1; Wickham H, 2023), tidyverse\n(version 2.0.0; Wickham H et al., 2019), dplyr (version 1.1.3; Wickham H et\nal., 2023), purrr (version 1.0.2; Wickham H, Henry L, 2023), readr (version\n2.1.4; Wickham H et al., 2023), tidyr (version 1.3.0; Wickham H et al., 2023)\nand kableExtra (version 1.3.4; Zhu H, 2021).\n\nReferences\n----------\n  - Ben-Shachar MS, Lüdecke D, Makowski D (2020). \"effectsize: Estimation of\nEffect Size Indices and Standardized Parameters.\" _Journal of Open Source\nSoftware_, *5*(56), 2815. doi:10.21105/joss.02815\n&lt;https://doi.org/10.21105/joss.02815&gt;, &lt;https://doi.org/10.21105/joss.02815&gt;.\n  - Berkelaar M, others (2023). _lpSolve: Interface to 'Lp_solve' v. 5.5 to Solve\nLinear/Integer Programs_. R package version 5.6.19,\n&lt;https://CRAN.R-project.org/package=lpSolve&gt;.\n  - Dardis C (2022). _survMisc: Miscellaneous Functions for Survival Data_. R\npackage version 0.5.6, &lt;https://CRAN.R-project.org/package=survMisc&gt;.\n  - Feinerer I, Hornik K (2023). _tm: Text Mining Package_. R package version\n0.7-11, &lt;https://CRAN.R-project.org/package=tm&gt;. Feinerer I, Hornik K, Meyer D\n(2008). \"Text Mining Infrastructure in R.\" _Journal of Statistical Software_,\n*25*(5), 1-54. doi:10.18637/jss.v025.i05\n&lt;https://doi.org/10.18637/jss.v025.i05&gt;.\n  - Fife D (2024). _flexplot: Graphically Based Data Analysis Using 'flexplot'_.\nR package version 0.20.5.\n  - Grolemund G, Wickham H (2011). \"Dates and Times Made Easy with lubridate.\"\n_Journal of Statistical Software_, *40*(3), 1-25.\n&lt;https://www.jstatsoft.org/v40/i03/&gt;.\n  - Heinze G, Ploner M, Jiricka L, Steiner G (2023). _coxphf: Cox Regression with\nFirth's Penalized Likelihood_. R package version 1.13.4,\n&lt;https://CRAN.R-project.org/package=coxphf&gt;.\n  - Hornik K (2020). _NLP: Natural Language Processing Infrastructure_. R package\nversion 0.2-1, &lt;https://CRAN.R-project.org/package=NLP&gt;.\n  - Hothorn T, Hornik K, van de Wiel MA, Zeileis A (2006). \"A Lego system for\nconditional inference.\" _The American Statistician_, *60*(3), 257-263.\ndoi:10.1198/000313006X118430 &lt;https://doi.org/10.1198/000313006X118430&gt;.\nHothorn T, Hornik K, van de Wiel MA, Zeileis A (2008). \"Implementing a class of\npermutation tests: The coin package.\" _Journal of Statistical Software_,\n*28*(8), 1-23. doi:10.18637/jss.v028.i08\n&lt;https://doi.org/10.18637/jss.v028.i08&gt;.\n  - Kassambara A (2023). _ggpubr: 'ggplot2' Based Publication Ready Plots_. R\npackage version 0.6.0, &lt;https://CRAN.R-project.org/package=ggpubr&gt;.\n  - Kassambara A, Kosinski M, Biecek P (2021). _survminer: Drawing Survival\nCurves using 'ggplot2'_. R package version 0.4.9,\n&lt;https://CRAN.R-project.org/package=survminer&gt;.\n  - Kolassa JE, Zhang J (2023). _PHInfiniteEstimates: Tools for Inference in the\nPresence of a Monotone Likelihood_. R package version 2.9.5,\n&lt;https://CRAN.R-project.org/package=PHInfiniteEstimates&gt;.\n  - Lüdecke D, Ben-Shachar M, Patil I, Makowski D (2020). \"Extracting, Computing\nand Exploring the Parameters of Statistical Models using R.\" _Journal of Open\nSource Software_, *5*(53), 2445. doi:10.21105/joss.02445\n&lt;https://doi.org/10.21105/joss.02445&gt;.\n  - Lüdecke D, Ben-Shachar M, Patil I, Waggoner P, Makowski D (2021).\n\"performance: An R Package for Assessment, Comparison and Testing of\nStatistical Models.\" _Journal of Open Source Software_, *6*(60), 3139.\ndoi:10.21105/joss.03139 &lt;https://doi.org/10.21105/joss.03139&gt;.\n  - Lüdecke D, Ben-Shachar M, Patil I, Wiernik B, Makowski D (2022). \"easystats:\nFramework for Easy Statistical Modeling, Visualization, and Reporting.\" _CRAN_.\nR package, &lt;https://easystats.github.io/easystats/&gt;.\n  - Lüdecke D, Patil I, Ben-Shachar M, Wiernik B, Waggoner P, Makowski D (2021).\n\"see: An R Package for Visualizing Statistical Models.\" _Journal of Open Source\nSoftware_, *6*(64), 3393. doi:10.21105/joss.03393\n&lt;https://doi.org/10.21105/joss.03393&gt;.\n  - Lüdecke D, Waggoner P, Makowski D (2019). \"insight: A Unified Interface to\nAccess Information from Model Objects in R.\" _Journal of Open Source Software_,\n*4*(38), 1412. doi:10.21105/joss.01412 &lt;https://doi.org/10.21105/joss.01412&gt;.\n  - Makowski D, Ben-Shachar M, Lüdecke D (2019). \"bayestestR: Describing Effects\nand their Uncertainty, Existence and Significance within the Bayesian\nFramework.\" _Journal of Open Source Software_, *4*(40), 1541.\ndoi:10.21105/joss.01541 &lt;https://doi.org/10.21105/joss.01541&gt;,\n&lt;https://joss.theoj.org/papers/10.21105/joss.01541&gt;.\n  - Makowski D, Ben-Shachar M, Patil I, Lüdecke D (2020). \"Estimation of\nModel-Based Predictions, Contrasts and Means.\" _CRAN_.\n&lt;https://github.com/easystats/modelbased&gt;.\n  - Makowski D, Lüdecke D, Patil I, Thériault R, Ben-Shachar M, Wiernik B (2023).\n\"Automated Results Reporting as a Practical Tool to Improve Reproducibility and\nMethodological Best Practices Adoption.\" _CRAN_.\n&lt;https://easystats.github.io/report/&gt;.\n  - Makowski D, Wiernik B, Patil I, Lüdecke D, Ben-Shachar M (2022).\n\"correlation: Methods for Correlation Analysis.\" Version 0.8.3,\n&lt;https://CRAN.R-project.org/package=correlation&gt;. Makowski D, Ben-Shachar M,\nPatil I, Lüdecke D (2020). \"Methods and Algorithms for Correlation Analysis in\nR.\" _Journal of Open Source Software_, *5*(51), 2306. doi:10.21105/joss.02306\n&lt;https://doi.org/10.21105/joss.02306&gt;,\n&lt;https://joss.theoj.org/papers/10.21105/joss.02306&gt;.\n  - Meira-Machado L, Sestelo M (2023). _condSURV: Estimation of the Conditional\nSurvival Function for Ordered Multivariate Failure Time Data_. R package\nversion 2.0.4, &lt;https://CRAN.R-project.org/package=condSURV&gt;.\n  - Müller K, Wickham H (2023). _tibble: Simple Data Frames_. R package version\n3.2.1, &lt;https://CRAN.R-project.org/package=tibble&gt;.\n  - Patil I, Makowski D, Ben-Shachar M, Wiernik B, Bacher E, Lüdecke D (2022).\n\"datawizard: An R Package for Easy Data Preparation and Statistical\nTransformations.\" _Journal of Open Source Software_, *7*(78), 4684.\ndoi:10.21105/joss.04684 &lt;https://doi.org/10.21105/joss.04684&gt;.\n  - R Core Team (2023). _foreign: Read Data Stored by 'Minitab', 'S', 'SAS',\n'SPSS', 'Stata', 'Systat', 'Weka', 'dBase', ..._. R package version 0.8-85,\n&lt;https://CRAN.R-project.org/package=foreign&gt;.\n  - R Core Team (2023). _R: A Language and Environment for Statistical\nComputing_. R Foundation for Statistical Computing, Vienna, Austria.\n&lt;https://www.R-project.org/&gt;.\n  - Ristl R, Ballarini N, Götte H, Schüler A, Posch M, König F (2021). \"Delayed\ntreatment effects, treatment switching and heterogeneous patient populations:\nHow to design and analyze RCTs in oncology.\" _Pharmaceutical statistics_,\n*20*(1), 129-145.\n  - Robinson D, Hayes A, Couch S (2023). _broom: Convert Statistical Objects into\nTidy Tibbles_. R package version 1.0.5,\n&lt;https://CRAN.R-project.org/package=broom&gt;.\n  - Sjoberg D, Baillie M, Fruechtenicht C, Haesendonckx S, Treis T (2023).\n_ggsurvfit: Flexible Time-to-Event Figures_. R package version 1.0.0,\n&lt;https://CRAN.R-project.org/package=ggsurvfit&gt;.\n  - Sjoberg D, Whiting K, Curry M, Lavery J, Larmarange J (2021). \"Reproducible\nSummary Tables with the gtsummary Package.\" _The R Journal_, *13*, 570-580.\ndoi:10.32614/RJ-2021-053 &lt;https://doi.org/10.32614/RJ-2021-053&gt;,\n&lt;https://doi.org/10.32614/RJ-2021-053&gt;.\n  - Thériault R (2023). \"rempsyc: Convenience functions for psychology.\" _Journal\nof Open Source Software_, *8*(87), 5466. doi:10.21105/joss.05466\n&lt;https://doi.org/10.21105/joss.05466&gt;, &lt;https://doi.org/10.21105/joss.05466&gt;.\n  - Therneau T (2023). _A Package for Survival Analysis in R_. R package version\n3.5-7, &lt;https://CRAN.R-project.org/package=survival&gt;. Terry M. Therneau,\nPatricia M. Grambsch (2000). _Modeling Survival Data: Extending the Cox Model_.\nSpringer, New York. ISBN 0-387-98784-3.\n  - Wickham H (2016). _ggplot2: Elegant Graphics for Data Analysis_.\nSpringer-Verlag New York. ISBN 978-3-319-24277-4,\n&lt;https://ggplot2.tidyverse.org&gt;.\n  - Wickham H (2023). _forcats: Tools for Working with Categorical Variables\n(Factors)_. R package version 1.0.0,\n&lt;https://CRAN.R-project.org/package=forcats&gt;.\n  - Wickham H (2023). _stringr: Simple, Consistent Wrappers for Common String\nOperations_. R package version 1.5.1,\n&lt;https://CRAN.R-project.org/package=stringr&gt;.\n  - Wickham H, Averick M, Bryan J, Chang W, McGowan LD, François R, Grolemund G,\nHayes A, Henry L, Hester J, Kuhn M, Pedersen TL, Miller E, Bache SM, Müller K,\nOoms J, Robinson D, Seidel DP, Spinu V, Takahashi K, Vaughan D, Wilke C, Woo K,\nYutani H (2019). \"Welcome to the tidyverse.\" _Journal of Open Source Software_,\n*4*(43), 1686. doi:10.21105/joss.01686 &lt;https://doi.org/10.21105/joss.01686&gt;.\n  - Wickham H, François R, Henry L, Müller K, Vaughan D (2023). _dplyr: A Grammar\nof Data Manipulation_. R package version 1.1.3,\n&lt;https://CRAN.R-project.org/package=dplyr&gt;.\n  - Wickham H, Henry L (2023). _purrr: Functional Programming Tools_. R package\nversion 1.0.2, &lt;https://CRAN.R-project.org/package=purrr&gt;.\n  - Wickham H, Hester J, Bryan J (2023). _readr: Read Rectangular Text Data_. R\npackage version 2.1.4, &lt;https://CRAN.R-project.org/package=readr&gt;.\n  - Wickham H, Vaughan D, Girlich M (2023). _tidyr: Tidy Messy Data_. R package\nversion 1.3.0, &lt;https://CRAN.R-project.org/package=tidyr&gt;.\n  - Zhu H (2021). _kableExtra: Construct Complex Table with 'kable' and Pipe\nSyntax_. R package version 1.3.4,\n&lt;https://CRAN.R-project.org/package=kableExtra&gt;."
  },
  {
    "objectID": "ARIMA.html#fundamentos-do-arima",
    "href": "ARIMA.html#fundamentos-do-arima",
    "title": "ARIMA",
    "section": "Fundamentos do ARIMA:",
    "text": "Fundamentos do ARIMA:\nAutoRegressivo (AR): Refere-se à relação entre uma observação atual e suas observações passadas. O termo “AutoRegressivo” destaca a dependência linear de uma observação em relação a suas antecessoras.\nIntegrated (I): Indica o número de diferenciações necessárias para tornar a série temporal estacionária, ou seja, para remover tendências e padrões sistemáticos. A estacionarização é crucial para garantir a estabilidade do modelo.\nMédia Móvel (MA): Considera os erros residuais das observações anteriores para prever a próxima. O componente “Média Móvel” reflete a média dos erros anteriores, incorporando informações sobre o comportamento recente da série.\nNúmero de observações: O número ideal de observações repetidas para uma única unidade de análise é de pelo menos 40, sendo preferível alcançar 50 observações. Não é necessário ter um grande número de pessoas ou unidades de análise; até mesmo com N = 1, você pode obter várias observações do mesmo indivíduo, tornando o ARIMA uma ferramenta eficaz de análise."
  },
  {
    "objectID": "ARIMA.html#condições-e-pressupostos",
    "href": "ARIMA.html#condições-e-pressupostos",
    "title": "ARIMA",
    "section": "Condições e Pressupostos:",
    "text": "Condições e Pressupostos:\nEstacionariedade: O ARIMA assume que a série temporal seja estacionária, o que significa que a média, a variância e a estrutura de autocorrelação não devem variar significativamente ao longo do tempo. Se a série não for estacionária, é necessário aplicar diferenciação até atingir a estacionariedade.\nIdentificação de Ordem: A escolha adequada dos parâmetros p, d, e q (ordens AR, I, e MA) é crucial. Isso geralmente é feito por meio de análise visual, funções de autocorrelação (ACF) e autocorrelação parcial (PACF), bem como métodos estatísticos como o critério de informação de Akaike (AIC).\nRuído Branco: Os resíduos do modelo ARIMA devem se comportar como um “ruído branco”, ou seja, serem independentes, terem média zero e variância constante. Isso garante que não haja padrões significativos nos erros residuais não capturados pelo modelo.\nAlém dos componentes fundamentais, o ARIMA pode ser estendido para lidar com sazonalidade através do SARIMA (Seasonal ARIMA), que incorpora parâmetros adicionais para modelar padrões recorrentes em determinados intervalos de tempo.\nA adequada compreensão dos fundamentos, condições e pressupostos é essencial para explorar todo o potencial desse método e fazer previsões precisas em uma variedade de contextos.",
    "crumbs": [
      "ARIMA"
    ]
  },
  {
    "objectID": "ARIMA.html#passo-a-passo-da-arima",
    "href": "ARIMA.html#passo-a-passo-da-arima",
    "title": "ARIMA",
    "section": "Passo a Passo da ARIMA",
    "text": "Passo a Passo da ARIMA\n\nColeta e Exploração de Dados:\n\nInicie coletando dados temporais relevantes para sua análise.\nExplore graficamente a série temporal para identificar padrões, sazonalidades e tendências.\n\nEstacionarização da Série:\n\nDiferencie a série temporal para torná-la estacionária.\nUtilize gráficos, como sequence charts, para visualizar mudanças ao longo do tempo.\n\nIdentificação dos Parâmetros (p, d, q):\n\nAnalise as funções de autocorrelação (ACF) e autocorrelação parcial (PACF) para determinar os valores ideais de p (ordem AR) e q (ordem MA).\nEstabeleça a ordem de diferenciação d necessária para atingir a estacionariedade.\n\nDivisão dos Dados:\n\nSepare os dados em conjuntos de treinamento e teste para avaliar o desempenho do modelo posteriormente.\n\nAjuste do Modelo ARIMA:\n\nUtilize os parâmetros (p, d, q) identificados para ajustar o modelo ARIMA aos dados de treinamento.\nAjuste também os parâmetros sazonais, se aplicável (SARIMA).\n\nValidação do Modelo:\n\nAvalie a qualidade do modelo usando critérios de informação como AIC (Akaike Information Criterion) e BIC (Bayesian Information Criterion) para modelos com os mesmos valores de p, d, e q.\nCalcule o erro médio quadrático (RMSE) para comparar modelos com diferentes configurações de p, d, e q.\n\nPrevisões e Avaliação:\n\nFaça previsões utilizando o modelo ARIMA ajustado nos dados de teste.\nAvalie a precisão das previsões comparando-as com os valores reais.\n\nAjustes Finais e Refinamentos:\n\nSe necessário, ajuste os parâmetros do modelo com base na análise da qualidade das previsões.\nConsidere iterar nos passos anteriores para melhorar a performance do modelo.\n\nInterpretação e Comunicação dos Resultados:\n\nComunique os resultados do modelo de forma clara, destacando as tendências identificadas e a capacidade de previsão.\n\n\nNa lista prática de exercícios vamos analisar dois bancos de dados, um apenas para verificar se o modelo é estacionário ou não e outro para de fato criar modelos ARIMA.\nPara mais informações sobre os parâmetros p, d, q, consulte as referências",
    "crumbs": [
      "ARIMA"
    ]
  },
  {
    "objectID": "ARIMA.html#referências",
    "href": "ARIMA.html#referências",
    "title": "ARIMA",
    "section": "Referências",
    "text": "Referências\nhttps://people.duke.edu/~rnau/411arim.htm",
    "crumbs": [
      "ARIMA"
    ]
  },
  {
    "objectID": "lista_7.html",
    "href": "lista_7.html",
    "title": "Lista 7: Séries Temporais (ARIMA)",
    "section": "",
    "text": "📦 Pacotes\n✓ Pacotes de séries temporais carregados!",
    "crumbs": [
      "ARIMA",
      "Lista 7: Séries Temporais (ARIMA)"
    ]
  },
  {
    "objectID": "lista_7.html#pacotes",
    "href": "lista_7.html#pacotes",
    "title": "8  Lista 7 - Séries Temporais (ARIMA)",
    "section": "8.1 Pacotes",
    "text": "8.1 Pacotes\n\nlibrary(tidyverse)\nlibrary(flexplot)\nlibrary(foreign)\nlibrary(dplyr)\nlibrary(tm)\nlibrary(ggplot2)\nlibrary(forcats)\nlibrary(rempsyc)\nlibrary(easystats)\nlibrary(kableExtra)\n\n#Específicos para series temporais\nlibrary(prophet)\nlibrary(forecast)\nlibrary(tseries)"
  },
  {
    "objectID": "lista_7.html#limpando-o-ambiente",
    "href": "lista_7.html#limpando-o-ambiente",
    "title": "8  Lista 7 - Séries Temporais (ARIMA)",
    "section": "8.2 Limpando o ambiente",
    "text": "8.2 Limpando o ambiente"
  },
  {
    "objectID": "lista_7.html#carregando-os-dados-e-modificando-o-tipo-de-variável",
    "href": "lista_7.html#carregando-os-dados-e-modificando-o-tipo-de-variável",
    "title": "8  Lista 7 - Séries Temporais (ARIMA)",
    "section": "9.1 Carregando os dados e modificando o tipo de variável",
    "text": "9.1 Carregando os dados e modificando o tipo de variável\n\noriginal = read.spss(\"CigarrosROD_1.sav\", to.data.frame=TRUE)\nglimpse(original)\n\nRows: 20\nColumns: 2\n$ Dia         &lt;dbl&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17,…\n$ cigarrosROD &lt;dbl&gt; 6, 10, 4, 13, 4, 11, 4, 6, 4, 15, 5, 14, 5, 21, 10, 31, 13…\n\ndb = original"
  },
  {
    "objectID": "lista_7.html#verificando-se-os-dados-são-estacionários",
    "href": "lista_7.html#verificando-se-os-dados-são-estacionários",
    "title": "8  Lista 7 - Séries Temporais (ARIMA)",
    "section": "9.2 Verificando se os dados são estacionários",
    "text": "9.2 Verificando se os dados são estacionários\nIniciaremos nossa primeira análise para verificar a estacionaridade dos dados por meio de uma abordagem gráfica. Este gráfico simples exibirá o número de cigarros consumidos ao longo do tempo, apresentando uma linha média que atravessa toda a linha temporal. A ideia é observar se os números de cigarros oscilam próximos à média, proporcionando uma visualização intuitiva da estacionariedade dos dados.\n\n# Plot estilizado\n# media_cigarros &lt;- mean(db$cigarrosROD)\n# \n# # Cria o gráfico com ggplot\n# ggplot(data = data.frame(cigarrosROD = db$cigarrosROD), aes(x = seq_along(cigarrosROD), y = cigarrosROD)) +\n#   geom_line(color = \"black\", size = 1) +\n#   geom_point(color = \"black\", size = 3) +\n#   geom_hline(yintercept = media_cigarros, linetype = \"dashed\", color = \"blue\", size = 1) +  # Adiciona a linha média\n#   labs(x = \"Dias\", y = \"Cigarros por dia\") +\n#   scale_x_continuous(breaks = seq_along(db$cigarrosROD), labels = seq_along(db$cigarrosROD)) +\n#   theme_minimal() +\n#   theme(panel.grid = element_blank(),\n#         axis.ticks = element_line())  # Adiciona ticks nos eixos x e y\n\n\nPlot simples\n\nmedia_cigarros &lt;- mean(db$cigarrosROD)\n\n# plot mais simples\nplot.ts(db$cigarrosROD)\nabline(h = media_cigarros, col = \"blue\", lty = 2, lwd = 2)\naxis(1, at = db$Dia, labels = db$Dia)\n\n\n\n\nClaramente os dados desviam bastante da média, logo essa não é uma série estacionária.\n\n\nAdf teste\nPodemos também utilizar o Augmented Dickey-Fuller (ADF) Test para avaliar a estacionaridade em séries temporais. A função para realizar o teste é a adf.test().\nInterpretação do Resultado:\n\nSe a estatística do teste for menor que o valor crítico (p &lt; 0.05), rejeitamos a hipótese nula e concluímos que a série é estacionária.\nSe a estatística do teste for maior que o valor crítico (p &gt; 0.05), falhamos em rejeitar a hipótese nula, sugerindo que a série é não estacionária.\n\n\n# Adf teste\nadf.test(db$cigarrosROD)\n\n\n    Augmented Dickey-Fuller Test\n\ndata:  db$cigarrosROD\nDickey-Fuller = -0.38979, Lag order = 2, p-value = 0.9797\nalternative hypothesis: stationary\n\n\nCorroborando a análise visual, falhamos em rejeitar a hipótese nula, logo podemos assumir que a série temporal em questão não é estacionária. Em seguida vamos ver como podemos ajustar os dados.\n\n\nAutocorrelação\nA função acf() (AutoCorrelation Function) no R é utilizada para calcular e visualizar os coeficientes de autocorrelação em uma série temporal. A autocorrelação mede a correlação entre uma observação e suas observações anteriores em diferentes defasagens (lags de tempo).\n\n# Calcula as autocorrelações e cria o gráfico\n\nautocorrelacoes = acf(db$cigarrosROD, plot = FALSE)\n\nautoplot(autocorrelacoes)\n\n\n\n\n\nggtsdisplay(db$cigarrosROD)\n\n\n\n\nOs valores de lag que tiveram um AFC além do intervalo de confiança (linha tracejada), são candidatos para utilizarmos em nosso modelo ARIMA. Portanto lag 2 e 4 são candidatos. Além disso podemos basear nossa decisão também o teste de Ljung-Box.\n\n\nTeste Ljung-Box\nO Teste Ljung-Box avalia para cada lag se a séria é estacionária ou não. Podemos testar individualmente para cada lag.\n\n# Teste Ljung-Box com lag 2\nBox.test(autocorrelacoes$acf , lag = 3, type = \"Ljung-Box\")\n\n\n    Box-Ljung test\n\ndata:  autocorrelacoes$acf\nX-squared = 8.5179, df = 3, p-value = 0.03644\n\nlag(db$cigarrosROD,1)\n\n [1] NA  6 10  4 13  4 11  4  6  4 15  5 14  5 21 10 31 13 39 16\n\n\nUma outra forma é criar um dataframe com todos os valores de lags calculados na autocorrelação.\n\n# Obtém o número máximo de lags disponíveis\nmax_lags &lt;- length(autocorrelacoes$acf) - 1\n\n# Inicialize os vetores para armazenar os resultados\nlags &lt;- numeric(max_lags)\np_values &lt;- numeric(max_lags)\n\n# Itere sobre os lags\nfor (lag in 1:max_lags) {\n  # Execute o teste de Ljung-Box para o lag atual\n  resultado_teste &lt;- Box.test(autocorrelacoes$acf, lag = lag, type = \"Ljung-Box\")\n  \n  # Armazene os resultados\n  lags[lag] &lt;- lag\n  p_values[lag] &lt;- resultado_teste$p.value\n}\n\n# Crie um dataframe com os resultados\nresultados_df &lt;- data.frame(Lag = lags, P_Value = p_values)\nkable(resultados_df)\n\n\n\n\nLag\nP_Value\n\n\n\n\n1\n0.9409683\n\n\n2\n0.0166341\n\n\n3\n0.0364377\n\n\n4\n0.0200419\n\n\n5\n0.0236724\n\n\n6\n0.0359384\n\n\n7\n0.0197526\n\n\n8\n0.0337181\n\n\n9\n0.0101406\n\n\n10\n0.0150763\n\n\n11\n0.0030557\n\n\n12\n0.0038952\n\n\n13\n0.0006256\n\n\n\n\n\n\n\nOu ainda\n\ntsdiag(auto.arima(db$cigarrosROD))"
  },
  {
    "objectID": "lista_7.html#transformação-variabilidade-e-estacionária",
    "href": "lista_7.html#transformação-variabilidade-e-estacionária",
    "title": "8  Lista 7 - Séries Temporais (ARIMA)",
    "section": "9.3 Transformação variabilidade e estacionária",
    "text": "9.3 Transformação variabilidade e estacionária\nPrimeiro vamos modificar a série para que tenha variabilidade constante\n\nlambda = BoxCox.lambda(db$cigarrosROD)\nlambda\n\n[1] -0.1713367\n\nvar_const = BoxCox(db$cigarrosROD, lambda = lambda)\n\nggtsdisplay(var_const)\n\n\n\n\nE agora podemos ajustar a serie para que ela fique estacionária.\n\nndiffs(var_const)\n\n[1] 1\n\n\n\nestacio = diff(var_const, 1)\nggtsdisplay(estacio)\n\n\n\n\nDe acordo com os resultados, qualquer lag, a não ser o lag 1, poderá ser utilizado para transformar os dados.\nPara decidir devemos levar em conta tanto a análise gráfica da autocorrelação quanto o teste de Ljung-Box.\nLogo os lags 2 e 4 são bons candidatos. Por parcimônia e sem nenhum critério teórico, vamos optar pelo lag menor, ou seja, lag 2."
  },
  {
    "objectID": "lista_7.html#transformando-os-dados-para-estacionários",
    "href": "lista_7.html#transformando-os-dados-para-estacionários",
    "title": "8  Lista 7 - Séries Temporais (ARIMA)",
    "section": "9.4 Transformando os dados para estacionários",
    "text": "9.4 Transformando os dados para estacionários\nPara modificar nossa série temporal utilizando lag 2 vamos utilizar a função diff().\n\n# Log\nlag_2 = diff(db$cigarrosROD, differences = 2) # posso colocar o log da diferença também caso os valores fiquem muito pequenos.\n\n\nPlot\n\nmedia_lag_2 = mean(lag_2)\nplot.ts(lag_2)\nabline(h = media_lag_2, col = \"blue\", lty = 2, lwd = 2)\naxis(1, at = db$Dia, labels = db$Dia)\n\n\n\n\nPronto! Agora os valores estão ocilando em torno da média. Apenas para confirmar que agora temos uma série temporal estacionária, podemos rodar novamente o adf.test.\n\nadf.test(lag_2) # testar com outros valores de K(lag) para verificar o p-value\n\n\n    Augmented Dickey-Fuller Test\n\ndata:  lag_2\nDickey-Fuller = -4.3237, Lag order = 2, p-value = 0.01196\nalternative hypothesis: stationary\n\n\nEsse banco de dados era apenas para transformar os dados não estacionários para estacionários. Vamos agora carregar outro banco de dados e criar o modelo ARIMA."
  },
  {
    "objectID": "lista_7.html#dados-séries-temporais",
    "href": "lista_7.html#dados-séries-temporais",
    "title": "8  Lista 7 - Séries Temporais (ARIMA)",
    "section": "9.5 Dados séries temporais",
    "text": "9.5 Dados séries temporais\n\noriginal_ts = read.spss(\"dados series temporais.sav\", to.data.frame=TRUE)\n\nre-encoding from CP1252\n\ndb_ts = original_ts\n\nglimpse(db_ts)\n\nRows: 120\nColumns: 11\n$ date         &lt;dbl&gt; 12818995200, 12821673600, 12824092800, 12826771200, 12829…\n$ men          &lt;dbl&gt; 11357.92, 10605.95, 16998.57, 6563.75, 6607.69, 9839.00, …\n$ women        &lt;dbl&gt; 16578.93, 18236.13, 43393.55, 30908.49, 28701.58, 29647.5…\n$ horas        &lt;dbl&gt; 7978, 8290, 8029, 7752, 8685, 7847, 7881, 8121, 7811, 870…\n$ divida       &lt;dbl&gt; 73, 88, 65, 85, 74, 87, 79, 72, 83, 111, 74, 105, 66, 59,…\n$ idade        &lt;dbl&gt; 34, 29, 24, 20, 17, 30, 28, 27, 35, 25, 30, 45, 35, 20, 2…\n$ propaganda   &lt;dbl&gt; 22294.48, 27426.47, 27978.66, 28949.65, 22642.27, 27210.6…\n$ escolaridade &lt;dbl&gt; 20, 20, 26, 22, 21, 23, 22, 20, 15, 20, 16, 29, 22, 28, 2…\n$ YEAR_        &lt;dbl&gt; 1989, 1989, 1989, 1989, 1989, 1989, 1989, 1989, 1989, 198…\n$ MONTH_       &lt;dbl&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 1, 2, 3, 4, 5, 6, …\n$ DATE_        &lt;chr&gt; \"JAN 1989\", \"FEB 1989\", \"MAR 1989\", \"APR 1989\", \"MAY 1989…\n\n\n\nPlot simples\n\nmedia_sal_men &lt;- mean(db_ts$men)\ndb_season = ts(db_ts$men,\n               frequency = 12,\n               start = c(1989, 1))\n\nts.plot(db_season)\nabline(h = media_sal_men, col = \"blue\", lty = 2, lwd = 2)\n\n\n\n\n\nseasonplot(db_season,\n           col = rainbow(12),\n           year.labels = TRUE,\n           type = \"o\",\n           pch = 16)\n\n\n\n\n\nggtsdisplay(db_season)\n\n\n\n\nSemelhante ao ARIMA (0,0,0)\n\n\nAdf teste\n\n# Adf teste\nadf.test(db_ts$men, k =1) #já está no formato estacionário\n\nWarning in adf.test(db_ts$men, k = 1): p-value smaller than printed p-value\n\n\n\n    Augmented Dickey-Fuller Test\n\ndata:  db_ts$men\nDickey-Fuller = -6.1931, Lag order = 1, p-value = 0.01\nalternative hypothesis: stationary\n\n\n\n\nLjung-Box\nDescrever\n\n# Teste Ljung-Box com lag 2\nBox.test(db_ts$men , lag = 1, type = \"Ljung-Box\")\n\n\n    Box-Ljung test\n\ndata:  db_ts$men\nX-squared = 19.742, df = 1, p-value = 0.000008865"
  },
  {
    "objectID": "lista_7.html#modelo-arima-100",
    "href": "lista_7.html#modelo-arima-100",
    "title": "8  Lista 7 - Séries Temporais (ARIMA)",
    "section": "9.6 Modelo ARIMA (1,0,0)",
    "text": "9.6 Modelo ARIMA (1,0,0)\n\nmodelo_sal_men = Arima(db_ts$men, order = c(1,0,0))\n\n\nPlot 1 do modelo (1,0,0)\n\n# Supondo que você tenha as séries temporais 'modelo_sal_men$fitted' e 'db_ts$men'\n\n# Cria o gráfico\nplot(modelo_sal_men$x, type = \"l\", col = \"red\", lty = 1, lwd = 2, xlab = \"Tempo\", ylab = \"Salário\")\nlines(modelo_sal_men$fitted, col = \"blue\", lty = 1, lwd = 2)\n\n# Adiciona uma legenda\nlegend(\"topright\", legend = c(\"Real\", \"Modelo\"), col = c(\"red\", \"blue\"), lty = c(1, 1), lwd = 2)\n\n# Adiciona um título ao gráfico\ntitle(main = \"Valores e Reais e do Modelo ARIMA de Salário para Homens\")"
  },
  {
    "objectID": "lista_7.html#modelo-arima-010",
    "href": "lista_7.html#modelo-arima-010",
    "title": "8  Lista 7 - Séries Temporais (ARIMA)",
    "section": "9.7 Modelo ARIMA (0,1,0)",
    "text": "9.7 Modelo ARIMA (0,1,0)\n\nmodelo2_sal_men = Arima(db_ts$men, order = c(0,1,0))\n\n\nPlot 1 do modelo (0,1,0)\n\n# Supondo que você tenha as séries temporais 'modelo2_sal_men$fitted' e 'db_ts$men'\n\n# Cria o gráfico\nplot(modelo2_sal_men$x, type = \"l\", col = \"red\", lty = 1, lwd = 2, xlab = \"Tempo\", ylab = \"Salário\")\nlines(modelo2_sal_men$fitted, col = \"blue\", lty = 1, lwd = 2)\n\n# Adiciona uma legenda\nlegend(\"topright\", legend = c(\"Real\", \"Modelo\"), col = c(\"red\", \"blue\"), lty = c(1, 1), lwd = 2)\n\n# Adiciona um título ao gráfico\ntitle(main = \"Valores e Reais e do Modelo ARIMA de Salário para Homens\")"
  },
  {
    "objectID": "lista_7.html#modelo-autoarima",
    "href": "lista_7.html#modelo-autoarima",
    "title": "8  Lista 7 - Séries Temporais (ARIMA)",
    "section": "9.8 Modelo autoARIMA",
    "text": "9.8 Modelo autoARIMA\nAssim como o SPSS o R também tem uma função que determina automaticamente os parâmetros p, d, q. Vamos verificar qual modelo a função auto.arima()sugere.\n\n# Para verificar qual o modelo sugerido pela função auto.arima\nauto.arima(db_ts$men, trace = TRUE)\n\n\n ARIMA(2,1,2) with drift         : Inf\n ARIMA(0,1,0) with drift         : 2434.823\n ARIMA(1,1,0) with drift         : 2412.096\n ARIMA(0,1,1) with drift         : Inf\n ARIMA(0,1,0)                    : 2432.897\n ARIMA(2,1,0) with drift         : 2411.86\n ARIMA(3,1,0) with drift         : 2408.495\n ARIMA(4,1,0) with drift         : 2407.461\n ARIMA(5,1,0) with drift         : 2408.674\n ARIMA(4,1,1) with drift         : Inf\n ARIMA(3,1,1) with drift         : Inf\n ARIMA(5,1,1) with drift         : Inf\n ARIMA(4,1,0)                    : 2405.816\n ARIMA(3,1,0)                    : 2406.731\n ARIMA(5,1,0)                    : 2407.075\n ARIMA(4,1,1)                    : 2394.525\n ARIMA(3,1,1)                    : 2392.515\n ARIMA(2,1,1)                    : 2392.416\n ARIMA(1,1,1)                    : 2391.073\n ARIMA(0,1,1)                    : 2393.07\n ARIMA(1,1,0)                    : 2410.255\n ARIMA(1,1,2)                    : 2392.894\n ARIMA(0,1,2)                    : 2391.92\n ARIMA(2,1,0)                    : 2410.02\n ARIMA(2,1,2)                    : Inf\n ARIMA(1,1,1) with drift         : Inf\n\n Best model: ARIMA(1,1,1)                    \n\n\nSeries: db_ts$men \nARIMA(1,1,1) \n\nCoefficients:\n         ar1      ma1\n      0.2036  -0.9139\ns.e.  0.1002   0.0347\n\nsigma^2 = 29737029:  log likelihood = -1192.43\nAIC=2390.86   AICc=2391.07   BIC=2399.2\n\n\nA função sugeriu o modelo 1, 1, 1. Vamos verificar os resultados.\n\nmodelo_auto_sal_men = Arima(db_ts$men, order = c(1,1,1))\n\n\nPlot 1 do modelo (1,1,1)\n\n# Supondo que você tenha as séries temporais 'modelo_atuo_sal_men$fitted' e 'db_ts$men'\n\n# Cria o gráfico\nplot(modelo_auto_sal_men$x, type = \"l\", col = \"red\", lty = 1, lwd = 2, xlab = \"Tempo\", ylab = \"Salário\")\nlines(modelo_auto_sal_men$fitted, col = \"blue\", lty = 1, lwd = 2)\n\n# Adiciona uma legenda\nlegend(\"topright\", legend = c(\"Real\", \"Modelo\"), col = c(\"red\", \"blue\"), lty = c(1, 1), lwd = 2)\n\n# Adiciona um título ao gráfico\ntitle(main = \"Valores e Reais e do Modelo ARIMA de Salário para Homens\")"
  },
  {
    "objectID": "lista_7.html#homens---modelo-com-variáveis-independentes",
    "href": "lista_7.html#homens---modelo-com-variáveis-independentes",
    "title": "8  Lista 7 - Séries Temporais (ARIMA)",
    "section": "9.9 Homens - Modelo com variáveis independentes",
    "text": "9.9 Homens - Modelo com variáveis independentes\n\n\n\n\n\n\nAtenção!\n\n\n\nAinda falta modificar os índices p, d, q das variáveis indepentendes como foi feito no SPSS.\n\n\n\nAuto arima\n\n# Defina as variáveis independentes originais\nnomes_variaveis &lt;- c(\"horas\", \"divida\", \"idade\", \"propaganda\", \"escolaridade\")\n\n# Crie a matriz de covariáveis\ncovars &lt;- as.matrix(db_ts[, nomes_variaveis, drop = FALSE])\n\n\n\n# Atribua os nomes diretamente à matriz de covariáveis\ncolnames(covars) &lt;- nomes_variaveis\n\n\n# \n# covars &lt;- cbind(\n#   db_ts$horas,\n#   db_ts$divida,\n#   db_ts$idade,\n#   db_ts$propaganda,\n#   db_ts$escolaridade\n# )\n\nauto.arima(db_ts$men, xreg = covars)\n\nSeries: db_ts$men \nRegression with ARIMA(1,0,0) errors \n\nCoefficients:\n         ar1   intercept   horas   divida     idade  propaganda  escolaridade\n      0.1968  -23753.966  2.0271  34.5286  342.9908      0.2046      -30.3841\ns.e.  0.1000    2752.767  0.2204  20.1900   43.9319      0.0733       41.3101\n\nsigma^2 = 8316739:  log likelihood = -1122.71\nAIC=2261.43   AICc=2262.72   BIC=2283.73\n\n\nModelo sugerido é o c(1,0,0)\n\n# Ajuste o modelo ARIMA com covariáveis\nmodelo_completo = Arima(\n  db_ts$men,\n  order = c(1, 0, 0),\n  xreg = covars, \n)\n\n\n# Defina as variáveis independentes originais\nnomes_variaveis &lt;- c(\"horas\", \"divida\", \"idade\", \"propaganda\", \"escolaridade\")\n\n# Inicialize uma lista para armazenar os modelos ajustados para cada VI\nmodelos_vi &lt;- list()\n\n# Loop através das variáveis independentes\nfor (variavel in nomes_variaveis) {\n  \n  # Selecione a VI específica\n  variavel_ts &lt;- db_ts[, variavel, drop = FALSE]\n  \n  # Ajuste as ordens p, d, q para a VI específica\n  ordens_vi &lt;- c(1, 0, 0)  # p, d, q\n  \n  # Ajuste o modelo ARIMA para a VI específica\n  modelo_vi &lt;- Arima(\n    variavel_ts,\n    order = ordens_vi,\n    include.mean = TRUE,\n    transform.pars = TRUE,\n    fixed = NULL,\n    include.drift = FALSE,\n    method = \"ML\",  # Mude conforme necessário\n    optim.control = list(trace = FALSE, REPORT = 1),\n    kappa = 1\n  )\n  \n  # Adicione o modelo ao vetor de modelos\n  modelos_vi[[variavel]] &lt;- modelo_vi\n}\n\n# Agora, você tem modelos ajustados para cada VI na lista modelos_vi\n\n# Combine os modelos ARIMA para as VI em uma única matriz\ncovars &lt;- cbind(\n  modelos_vi$horas$fitted, \n  modelos_vi$divida$fitted, \n  modelos_vi$idade$fitted, \n  modelos_vi$propaganda$fitted, \n  modelos_vi$escolaridade$fitted\n)\n\n# Ajuste o modelo ARIMA principal com as covariáveis\nmodelo_completo &lt;- Arima(\n  db_ts$men,\n  order = c(1, 0, 0),\n  xreg = covars,\n  seasonal = list(order = c(0, 0, 0)),  # Adapte conforme necessário\n  include.mean = TRUE,\n  transform.pars = TRUE,\n  fixed = NULL,\n  include.drift = FALSE,\n  method = \"ML\",  # Mude conforme necessário\n  optim.control = list(trace = FALSE, REPORT = 1),\n  kappa = 1\n)\n\n\n\nPlot do modelo com VIs\n\n# Criar um dataframe com as séries temporais\ndf_full &lt;- data.frame(\n  Tempo = seq_along(modelo_completo$fitted),\n  Ajustado = modelo_completo$fitted,\n  Real = modelo_completo$x\n)\n\n# Criar o gráfico com ggplot2\nggplot(df_full, aes(x = Tempo)) +\n  geom_line(aes(y = Ajustado, color = \"Ajustado\"), size = 1) +\n  geom_line(aes(y = Real, color = \"Real\"), size = 1) +\n  labs(x = \"Tempo\", y = \"Salário\", title = \"Valores Ajustados e Reais de Salário para Homens ao Longo do Tempo\") +\n  scale_color_manual(values = c(\"Ajustado\" = \"blue\", \"Real\" = \"red\"), guide = \"legend\") +\n  theme_minimal()\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead.\n\n\nDon't know how to automatically pick scale for object of type &lt;ts&gt;. Defaulting\nto continuous.\n\n\n\n\n\n\n\nAIC, BIC e RMSE\n\nperformance(modelo_completo)\n\n# Indices of model performance\n\nAIC      |     AICc |      BIC | R2.modelos_vi$horas$fitted | R2.modelos_vi$divida$fitted | R2.modelos_vi$idade$fitted | R2.modelos_vi$propaganda$fitted | R2.modelos_vi$escolaridade$fitted |     RMSE |    Sigma\n------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n2421.052 | 6925.052 | 2443.352 |                      0.397 |                       0.213 |                      0.722 |                       5.366e-04 |                             0.656 | 5442.460 | 5633.481\n\n\n\n\nResultados\n\n# Visualize o resumo do modelo\nsummary(modelo_completo)\n\nSeries: db_ts$men \nRegression with ARIMA(1,0,0) errors \n\nCoefficients:\n          ar1  intercept  modelos_vi$horas$fitted  modelos_vi$divida$fitted\n      -0.1727   34621.57                   0.7594                 -607.0271\ns.e.   0.1639   40027.85                   1.3741                  316.5860\n      modelos_vi$idade$fitted  modelos_vi$propaganda$fitted\n                     371.3498                        0.1770\ns.e.                 127.6716                        1.0677\n      modelos_vi$escolaridade$fitted\n                            135.8938\ns.e.                         81.0383\n\nsigma^2 = 31455262:  log likelihood = -1202.53\nAIC=2421.05   AICc=2422.35   BIC=2443.35\n\nTraining set error measures:\n                   ME    RMSE      MAE       MPE     MAPE     MASE        ACF1\nTraining set -5.05266 5442.46 3863.789 -11.92625 27.46778 0.826093 0.002906111\n\n# db_ts$horas,       xreg1    \n# db_ts$divida  ,    xreg2\n# db_ts$idade,       xreg3\n# db_ts$propaganda,  xreg4    \n# db_ts$escolaridade xreg5\n\n\nCoeficientes e valores de p\n\nlibrary(lmtest) # pacote para calcular os estimates e valores de p\n\nWarning: package 'lmtest' was built under R version 4.3.2\n\n\nCarregando pacotes exigidos: zoo\n\n\n\nAttaching package: 'zoo'\n\n\nThe following objects are masked from 'package:base':\n\n    as.Date, as.Date.numeric\n\n# Use a função coeftest para obter coeficientes e p-valores\ntest_coef &lt;- coeftest(modelo_completo)\n\n# Acesse os coeficientes estimados e os p-valores\ncoeficientes &lt;- round(test_coef[, \"Estimate\"], 3)\np_valores &lt;- round(test_coef[, \"Pr(&gt;|z|)\"], 3)\n\n# Crie uma nova coluna com asteriscos para valores de p significativos\ntest_coef$Significativo &lt;- ifelse(p_valores &lt; 0.05, \"*\", \"\")\n\nWarning in test_coef$Significativo &lt;- ifelse(p_valores &lt; 0.05, \"*\", \"\"):\nRealizando coerção de LHD para uma lista\n\n# Exiba os resultados\nresultados &lt;- data.frame(Coeficientes = coeficientes, p_valores = paste0(format(p_valores, digits = 3), test_coef$Significativo))\nprint(resultados)\n\n                               Coeficientes p_valores\nar1                                  -0.173     0.292\nintercept                         34621.566     0.387\nmodelos_vi$horas$fitted               0.759     0.581\nmodelos_vi$divida$fitted           -607.027     0.055\nmodelos_vi$idade$fitted             371.350    0.004*\nmodelos_vi$propaganda$fitted          0.177     0.868\nmodelos_vi$escolaridade$fitted      135.894     0.094\n\n\n\n\n\nMulheres - Modelo com variáveis independentes para\n\nVerificar qual o melhor modelo utilizando as VIs no auto.arima\n\n# Supondo que você tenha um dataframe 'db_ts' com as variáveis mencionadas\n\n# Defina as variáveis independentes originais\nnomes_variaveis &lt;- c(\"horas\", \"divida\", \"idade\", \"propaganda\", \"escolaridade\")\n\n# Crie a matriz de covariáveis\ncovars &lt;- as.matrix(db_ts[, nomes_variaveis, drop = FALSE])\n\n# Atribua os nomes diretamente à matriz de covariáveis\ncolnames(covars) &lt;- nomes_variaveis\n\n\n# \n# covars &lt;- cbind(\n#   db_ts$horas,\n#   db_ts$divida,\n#   db_ts$idade,\n#   db_ts$propaganda,\n#   db_ts$escolaridade\n# )\n\nauto.arima(db_ts$women, xreg = covars)\n\nSeries: db_ts$women \nRegression with ARIMA(0,0,1) errors \n\nCoefficients:\n         ma1   intercept   horas   divida     idade  propaganda  escolaridade\n      0.3351  -37941.151  2.6828  90.5433    1.6294      0.9805      445.6786\ns.e.  0.1096    6458.967  0.5145  52.4388  110.2176      0.1693      102.0171\n\nsigma^2 = 49641429:  log likelihood = -1229.95\nAIC=2475.89   AICc=2477.19   BIC=2498.19\n\n\nModelo sugerido é o c(0,0,1)\n\n# Ajuste o modelo ARIMA com covariáveis\nmodelo_completo_women = Arima(\n  db_ts$women,\n  order = c(0, 0, 1),\n  xreg = covars\n)\n\n\n\n# Visualize o resumo do modelo\nsummary(modelo_completo_women)\n\nSeries: db_ts$women \nRegression with ARIMA(0,0,1) errors \n\nCoefficients:\n         ma1   intercept   horas   divida     idade  propaganda  escolaridade\n      0.3351  -37941.151  2.6828  90.5433    1.6294      0.9805      445.6786\ns.e.  0.1096    6458.967  0.5145  52.4388  110.2176      0.1693      102.0171\n\nsigma^2 = 49641429:  log likelihood = -1229.95\nAIC=2475.89   AICc=2477.19   BIC=2498.19\n\nTraining set error measures:\n                     ME     RMSE  MAE       MPE    MAPE      MASE        ACF1\nTraining set -0.1962005 6837.081 4889 -3.414187 14.6811 0.5114592 -0.01923702\n\n\n\n# db_ts$horas,       xreg1    \n# db_ts$divida  ,    xreg2\n# db_ts$idade,       xreg3\n# db_ts$propaganda,  xreg4    \n# db_ts$escolaridade xreg5\n\ncheckresiduals(modelo_completo_women)\n\n\n\n\n\n    Ljung-Box test\n\ndata:  Residuals from Regression with ARIMA(0,0,1) errors\nQ* = 10.048, df = 9, p-value = 0.3466\n\nModel df: 1.   Total lags used: 10\n\n\n\n\nPlot do modelo com VIs\n\n# Criar um dataframe com as séries temporais\ndf_full_women &lt;- data.frame(\n  Tempo = seq_along(modelo_completo_women$fitted),\n  Ajustado = modelo_completo_women$fitted,\n  Real = modelo_completo_women$x\n)\n\n# Criar o gráfico com ggplot2\nggplot(df_full_women, aes(x = Tempo)) +\n  geom_line(aes(y = Ajustado, color = \"Ajustado\"), size = 1) +\n  geom_line(aes(y = Real, color = \"Real\"), size = 1) +\n  labs(x = \"Tempo\", y = \"Salário\", title = \"Valores Ajustados e Reais de Salário para Mulheres ao Longo do Tempo\") +\n  scale_color_manual(values = c(\"Ajustado\" = \"red\", \"Real\" = \"blue\"), guide = \"legend\") +\n  theme_minimal()\n\nDon't know how to automatically pick scale for object of type &lt;ts&gt;. Defaulting\nto continuous.\n\n\n\n\n\n\n\nCoeficientes e valores de p\n\nlibrary(lmtest) # pacote para calcular os estimates e valores de p\n\n\n# Use a função coeftest para obter coeficientes e p-valores\ntest_coef_women &lt;- coeftest(modelo_completo_women)\n\n# Acesse os coeficientes estimados e os p-valores\ncoeficientes_women &lt;- round(test_coef_women[, \"Estimate\"], 3)\np_valores_women &lt;- round(test_coef_women[, \"Pr(&gt;|z|)\"], 3)\n\n# Crie uma nova coluna com asteriscos para valores de p significativos\ntest_coef_women$Significativo &lt;- ifelse(p_valores_women &lt; 0.05, \"*\", \"\")\n\nWarning in test_coef_women$Significativo &lt;- ifelse(p_valores_women &lt; 0.05, :\nRealizando coerção de LHD para uma lista\n\n# Exiba os resultados\nresultados_women &lt;- data.frame(Coeficientes = coeficientes_women, Pvalores = paste0(format(p_valores_women, digits = 3), test_coef_women$Significativo))\nprint(resultados_women)\n\n             Coeficientes Pvalores\nma1                 0.335   0.002*\nintercept      -37941.151   0.000*\nhoras               2.683   0.000*\ndivida             90.543    0.084\nidade               1.629    0.988\npropaganda          0.981   0.000*\nescolaridade      445.679   0.000*"
  },
  {
    "objectID": "lista_7.html#forecast-previsões",
    "href": "lista_7.html#forecast-previsões",
    "title": "8  Lista 7 - Séries Temporais (ARIMA)",
    "section": "9.10 Forecast (previsões)",
    "text": "9.10 Forecast (previsões)\n\nMulheres - 50 anos\n\nwomen_salary_ts = ts(db_ts$women,\n               frequency = 12,\n               start = c(1989, 1))\n\n\nfit_arima_women = auto.arima(women_salary_ts)\n\nfcast_women = forecast(fit_arima_women, h=50)\nautoplot(fcast_women)\n\n\n\n\n\n\nHomens - 50 anos\n\nmen_salary_ts = ts(db_ts$men,\n               frequency = 12,\n               start = c(1989, 1))\n\n\nfit_arima_men = auto.arima(men_salary_ts)\n\nfcast_men = forecast(fit_arima_men, h=50)\nautoplot(fcast_men)"
  },
  {
    "objectID": "lista_7.html#extras",
    "href": "lista_7.html#extras",
    "title": "8  Lista 7 - Séries Temporais (ARIMA)",
    "section": "9.11 Extras",
    "text": "9.11 Extras\n\nMais gráficos\n\nPlot 2 do modelo (1,0,0)\n\nmodelo_sal_men = Arima(db_ts$men, order = c(1,0,0))\n\n# Criar um dataframe com as séries temporais\ndf_100 &lt;- data.frame(\n  Tempo = seq_along(modelo_sal_men$fitted),\n  Ajustado = modelo_sal_men$fitted,\n  Real = modelo_sal_men$x\n)\n\n# Criar o gráfico com ggplot2\nggplot(df_100, aes(x = Tempo)) +\n  geom_line(aes(y = Ajustado, color = \"Ajustado\"), size = 1) +\n  geom_line(aes(y = Real, color = \"Real\"), size = 1) +\n  labs(x = \"Tempo\", y = \"Salário\", title = \"Valores Ajustados e Reais de Salário para Homens ao Longo do Tempo\") +\n  scale_color_manual(values = c(\"Ajustado\" = \"red\", \"Real\" = \"blue\"), guide = \"legend\") +\n  theme_minimal()\n\nDon't know how to automatically pick scale for object of type &lt;ts&gt;. Defaulting\nto continuous.\n\n\n\n\n\n\n\nPlot 2 do modelo (0,1,0)\n\n# Criar um dataframe com as séries temporais\ndf_010 &lt;- data.frame(\n  Tempo = seq_along(modelo2_sal_men$fitted),\n  Ajustado = modelo2_sal_men$fitted,\n  Real = modelo2_sal_men$x\n)\n\n# Criar o gráfico com ggplot2\nggplot(df_010, aes(x = Tempo)) +\n  geom_line(aes(y = Ajustado, color = \"Ajustado\"), size = 1) +\n  geom_line(aes(y = Real, color = \"Real\"), size = 1) +\n  labs(x = \"Tempo\", y = \"Salário\", title = \"Valores Ajustados e Reais de Salário para Homens ao Longo do Tempo\") +\n  scale_color_manual(values = c(\"Ajustado\" = \"red\", \"Real\" = \"blue\"), guide = \"legend\") +\n  theme_minimal()\n\nDon't know how to automatically pick scale for object of type &lt;ts&gt;. Defaulting\nto continuous.\n\n\n\n\n\n\n\nPlot 2 do modelo (1,1,1)\n\nmodelo_atuo_sal_men = Arima(db_ts$men, order = c(1,1,1))\n\n# Criar um dataframe com as séries temporais\ndf_111 &lt;- data.frame(\n  Tempo = seq_along(modelo_atuo_sal_men$fitted),\n  Ajustado = modelo_atuo_sal_men$fitted,\n  Real = modelo_atuo_sal_men$x\n)\n\n# Criar o gráfico com ggplot2\nggplot(df_111, aes(x = Tempo)) +\n  geom_line(aes(y = Ajustado, color = \"Ajustado\"), size = 1) +\n  geom_line(aes(y = Real, color = \"Real\"), size = 1) +\n  labs(x = \"Tempo\", y = \"Salário\", title = \"Valores Ajustados e Reais de Salário para Homens ao Longo do Tempo\") +\n  scale_color_manual(values = c(\"Ajustado\" = \"red\", \"Real\" = \"blue\"), guide = \"legend\") +\n  theme_minimal()\n\nDon't know how to automatically pick scale for object of type &lt;ts&gt;. Defaulting\nto continuous."
  },
  {
    "objectID": "lista_7.html#verificando-resíduos",
    "href": "lista_7.html#verificando-resíduos",
    "title": "8  Lista 7 - Séries Temporais (ARIMA)",
    "section": "9.12 Verificando resíduos",
    "text": "9.12 Verificando resíduos\n\ncheckresiduals(modelo_auto_sal_men)\n\n\n\n\n\n    Ljung-Box test\n\ndata:  Residuals from ARIMA(1,1,1)\nQ* = 10.891, df = 8, p-value = 0.208\n\nModel df: 2.   Total lags used: 10\n\nsummary(modelo_auto_sal_men)\n\nSeries: db_ts$men \nARIMA(1,1,1) \n\nCoefficients:\n         ar1      ma1\n      0.2036  -0.9139\ns.e.  0.1002   0.0347\n\nsigma^2 = 29737029:  log likelihood = -1192.43\nAIC=2390.86   AICc=2391.07   BIC=2399.2\n\nTraining set error measures:\n                   ME     RMSE      MAE       MPE     MAPE      MASE\nTraining set 915.6723 5384.571 3662.003 -5.571742 25.15003 0.7829504\n                    ACF1\nTraining set -0.04692903"
  },
  {
    "objectID": "lista_7.html#lista-7-resolvida-no-spss",
    "href": "lista_7.html#lista-7-resolvida-no-spss",
    "title": "8  Lista 7 - Séries Temporais (ARIMA)",
    "section": "9.13 Lista 7 resolvida no SPSS",
    "text": "9.13 Lista 7 resolvida no SPSS"
  },
  {
    "objectID": "lista_7.html#referências",
    "href": "lista_7.html#referências",
    "title": "8  Lista 7 - Séries Temporais (ARIMA)",
    "section": "9.14 Referências",
    "text": "9.14 Referências\nhttps://facebook.github.io/prophet/docs/installation.html#r\nhttps://rpubs.com/mpleo/timeseries_prophet\nhttps://www.youtube.com/watch?v=ny3gRhfVsi4&t=10s\nhttps://www.youtube.com/watch?v=Txuo9JQjnKE ótima ref em PT-BR\nhttps://www.youtube.com/watch?v=RJzmHkGWCxs&list=PLEuzmtv9IuT_vg5oE0lQyZR-wgbVeGztt"
  },
  {
    "objectID": "lista_7.html#versões-dos-pacotes",
    "href": "lista_7.html#versões-dos-pacotes",
    "title": "8  Lista 7 - Séries Temporais (ARIMA)",
    "section": "9.15 Versões dos pacotes",
    "text": "9.15 Versões dos pacotes\n\nreport(sessionInfo())\n\nAnalyses were conducted using the R Statistical language (version 4.3.1; R Core\nTeam, 2023) on Windows 11 x64 (build 22621), using the packages effectsize\n(version 0.8.6; Ben-Shachar MS et al., 2020), Rcpp (version 1.0.11;\nEddelbuettel D et al., 2023), tm (version 0.7.11; Feinerer I, Hornik K, 2023),\nflexplot (version 0.20.5; Fife D, 2024), lubridate (version 1.9.3; Grolemund G,\nWickham H, 2011), rlang (version 1.1.1; Henry L, Wickham H, 2023), NLP (version\n0.2.1; Hornik K, 2020), forecast (version 8.21.1; Hyndman R et al., 2023),\nparameters (version 0.21.3; Lüdecke D et al., 2020), performance (version\n0.10.8; Lüdecke D et al., 2021), easystats (version 0.6.0; Lüdecke D et al.,\n2022), see (version 0.8.1; Lüdecke D et al., 2021), insight (version 0.19.6;\nLüdecke D et al., 2019), bayestestR (version 0.13.1; Makowski D et al., 2019),\nmodelbased (version 0.8.6; Makowski D et al., 2020), report (version 0.5.7;\nMakowski D et al., 2023), correlation (version 0.8.4; Makowski D et al., 2022),\ntibble (version 3.2.1; Müller K, Wickham H, 2023), datawizard (version 0.9.0;\nPatil I et al., 2022), foreign (version 0.8.85; R Core Team, 2023), prophet\n(version 1.0; Taylor S, Letham B, 2021), rempsyc (version 0.1.6; Thériault R,\n2023), tseries (version 0.10.55; Trapletti A, Hornik K, 2023), ggplot2 (version\n3.4.4; Wickham H, 2016), forcats (version 1.0.0; Wickham H, 2023), stringr\n(version 1.5.1; Wickham H, 2023), tidyverse (version 2.0.0; Wickham H et al.,\n2019), dplyr (version 1.1.3; Wickham H et al., 2023), purrr (version 1.0.2;\nWickham H, Henry L, 2023), readr (version 2.1.4; Wickham H et al., 2023), tidyr\n(version 1.3.0; Wickham H et al., 2023), zoo (version 1.8.12; Zeileis A,\nGrothendieck G, 2005), lmtest (version 0.9.40; Zeileis A, Hothorn T, 2002) and\nkableExtra (version 1.3.4; Zhu H, 2021).\n\nReferences\n----------\n  - Ben-Shachar MS, Lüdecke D, Makowski D (2020). \"effectsize: Estimation of\nEffect Size Indices and Standardized Parameters.\" _Journal of Open Source\nSoftware_, *5*(56), 2815. doi:10.21105/joss.02815\n&lt;https://doi.org/10.21105/joss.02815&gt;, &lt;https://doi.org/10.21105/joss.02815&gt;.\n  - Eddelbuettel D, Francois R, Allaire J, Ushey K, Kou Q, Russell N, Ucar I,\nBates D, Chambers J (2023). _Rcpp: Seamless R and C++ Integration_. R package\nversion 1.0.11, &lt;https://CRAN.R-project.org/package=Rcpp&gt;. Eddelbuettel D,\nFrançois R (2011). \"Rcpp: Seamless R and C++ Integration.\" _Journal of\nStatistical Software_, *40*(8), 1-18. doi:10.18637/jss.v040.i08\n&lt;https://doi.org/10.18637/jss.v040.i08&gt;. Eddelbuettel D (2013). _Seamless R and\nC++ Integration with Rcpp_. Springer, New York. doi:10.1007/978-1-4614-6868-4\n&lt;https://doi.org/10.1007/978-1-4614-6868-4&gt;, ISBN 978-1-4614-6867-7.\nEddelbuettel D, Balamuta J (2018). \"Extending R with C++: A Brief Introduction\nto Rcpp.\" _The American Statistician_, *72*(1), 28-36.\ndoi:10.1080/00031305.2017.1375990\n&lt;https://doi.org/10.1080/00031305.2017.1375990&gt;.\n  - Feinerer I, Hornik K (2023). _tm: Text Mining Package_. R package version\n0.7-11, &lt;https://CRAN.R-project.org/package=tm&gt;. Feinerer I, Hornik K, Meyer D\n(2008). \"Text Mining Infrastructure in R.\" _Journal of Statistical Software_,\n*25*(5), 1-54. doi:10.18637/jss.v025.i05\n&lt;https://doi.org/10.18637/jss.v025.i05&gt;.\n  - Fife D (2024). _flexplot: Graphically Based Data Analysis Using 'flexplot'_.\nR package version 0.20.5.\n  - Grolemund G, Wickham H (2011). \"Dates and Times Made Easy with lubridate.\"\n_Journal of Statistical Software_, *40*(3), 1-25.\n&lt;https://www.jstatsoft.org/v40/i03/&gt;.\n  - Henry L, Wickham H (2023). _rlang: Functions for Base Types and Core R and\n'Tidyverse' Features_. R package version 1.1.1,\n&lt;https://CRAN.R-project.org/package=rlang&gt;.\n  - Hornik K (2020). _NLP: Natural Language Processing Infrastructure_. R package\nversion 0.2-1, &lt;https://CRAN.R-project.org/package=NLP&gt;.\n  - Hyndman R, Athanasopoulos G, Bergmeir C, Caceres G, Chhay L, O'Hara-Wild M,\nPetropoulos F, Razbash S, Wang E, Yasmeen F (2023). _forecast: Forecasting\nfunctions for time series and linear models_. R package version 8.21.1,\n&lt;https://pkg.robjhyndman.com/forecast/&gt;. Hyndman RJ, Khandakar Y (2008).\n\"Automatic time series forecasting: the forecast package for R.\" _Journal of\nStatistical Software_, *26*(3), 1-22. doi:10.18637/jss.v027.i03\n&lt;https://doi.org/10.18637/jss.v027.i03&gt;.\n  - Lüdecke D, Ben-Shachar M, Patil I, Makowski D (2020). \"Extracting, Computing\nand Exploring the Parameters of Statistical Models using R.\" _Journal of Open\nSource Software_, *5*(53), 2445. doi:10.21105/joss.02445\n&lt;https://doi.org/10.21105/joss.02445&gt;.\n  - Lüdecke D, Ben-Shachar M, Patil I, Waggoner P, Makowski D (2021).\n\"performance: An R Package for Assessment, Comparison and Testing of\nStatistical Models.\" _Journal of Open Source Software_, *6*(60), 3139.\ndoi:10.21105/joss.03139 &lt;https://doi.org/10.21105/joss.03139&gt;.\n  - Lüdecke D, Ben-Shachar M, Patil I, Wiernik B, Makowski D (2022). \"easystats:\nFramework for Easy Statistical Modeling, Visualization, and Reporting.\" _CRAN_.\nR package, &lt;https://easystats.github.io/easystats/&gt;.\n  - Lüdecke D, Patil I, Ben-Shachar M, Wiernik B, Waggoner P, Makowski D (2021).\n\"see: An R Package for Visualizing Statistical Models.\" _Journal of Open Source\nSoftware_, *6*(64), 3393. doi:10.21105/joss.03393\n&lt;https://doi.org/10.21105/joss.03393&gt;.\n  - Lüdecke D, Waggoner P, Makowski D (2019). \"insight: A Unified Interface to\nAccess Information from Model Objects in R.\" _Journal of Open Source Software_,\n*4*(38), 1412. doi:10.21105/joss.01412 &lt;https://doi.org/10.21105/joss.01412&gt;.\n  - Makowski D, Ben-Shachar M, Lüdecke D (2019). \"bayestestR: Describing Effects\nand their Uncertainty, Existence and Significance within the Bayesian\nFramework.\" _Journal of Open Source Software_, *4*(40), 1541.\ndoi:10.21105/joss.01541 &lt;https://doi.org/10.21105/joss.01541&gt;,\n&lt;https://joss.theoj.org/papers/10.21105/joss.01541&gt;.\n  - Makowski D, Ben-Shachar M, Patil I, Lüdecke D (2020). \"Estimation of\nModel-Based Predictions, Contrasts and Means.\" _CRAN_.\n&lt;https://github.com/easystats/modelbased&gt;.\n  - Makowski D, Lüdecke D, Patil I, Thériault R, Ben-Shachar M, Wiernik B (2023).\n\"Automated Results Reporting as a Practical Tool to Improve Reproducibility and\nMethodological Best Practices Adoption.\" _CRAN_.\n&lt;https://easystats.github.io/report/&gt;.\n  - Makowski D, Wiernik B, Patil I, Lüdecke D, Ben-Shachar M (2022).\n\"correlation: Methods for Correlation Analysis.\" Version 0.8.3,\n&lt;https://CRAN.R-project.org/package=correlation&gt;. Makowski D, Ben-Shachar M,\nPatil I, Lüdecke D (2020). \"Methods and Algorithms for Correlation Analysis in\nR.\" _Journal of Open Source Software_, *5*(51), 2306. doi:10.21105/joss.02306\n&lt;https://doi.org/10.21105/joss.02306&gt;,\n&lt;https://joss.theoj.org/papers/10.21105/joss.02306&gt;.\n  - Müller K, Wickham H (2023). _tibble: Simple Data Frames_. R package version\n3.2.1, &lt;https://CRAN.R-project.org/package=tibble&gt;.\n  - Patil I, Makowski D, Ben-Shachar M, Wiernik B, Bacher E, Lüdecke D (2022).\n\"datawizard: An R Package for Easy Data Preparation and Statistical\nTransformations.\" _Journal of Open Source Software_, *7*(78), 4684.\ndoi:10.21105/joss.04684 &lt;https://doi.org/10.21105/joss.04684&gt;.\n  - R Core Team (2023). _foreign: Read Data Stored by 'Minitab', 'S', 'SAS',\n'SPSS', 'Stata', 'Systat', 'Weka', 'dBase', ..._. R package version 0.8-85,\n&lt;https://CRAN.R-project.org/package=foreign&gt;.\n  - R Core Team (2023). _R: A Language and Environment for Statistical\nComputing_. R Foundation for Statistical Computing, Vienna, Austria.\n&lt;https://www.R-project.org/&gt;.\n  - Taylor S, Letham B (2021). _prophet: Automatic Forecasting Procedure_. R\npackage version 1.0, &lt;https://CRAN.R-project.org/package=prophet&gt;.\n  - Thériault R (2023). \"rempsyc: Convenience functions for psychology.\" _Journal\nof Open Source Software_, *8*(87), 5466. doi:10.21105/joss.05466\n&lt;https://doi.org/10.21105/joss.05466&gt;, &lt;https://doi.org/10.21105/joss.05466&gt;.\n  - Trapletti A, Hornik K (2023). _tseries: Time Series Analysis and\nComputational Finance_. R package version 0.10-55,\n&lt;https://CRAN.R-project.org/package=tseries&gt;.\n  - Wickham H (2016). _ggplot2: Elegant Graphics for Data Analysis_.\nSpringer-Verlag New York. ISBN 978-3-319-24277-4,\n&lt;https://ggplot2.tidyverse.org&gt;.\n  - Wickham H (2023). _forcats: Tools for Working with Categorical Variables\n(Factors)_. R package version 1.0.0,\n&lt;https://CRAN.R-project.org/package=forcats&gt;.\n  - Wickham H (2023). _stringr: Simple, Consistent Wrappers for Common String\nOperations_. R package version 1.5.1,\n&lt;https://CRAN.R-project.org/package=stringr&gt;.\n  - Wickham H, Averick M, Bryan J, Chang W, McGowan LD, François R, Grolemund G,\nHayes A, Henry L, Hester J, Kuhn M, Pedersen TL, Miller E, Bache SM, Müller K,\nOoms J, Robinson D, Seidel DP, Spinu V, Takahashi K, Vaughan D, Wilke C, Woo K,\nYutani H (2019). \"Welcome to the tidyverse.\" _Journal of Open Source Software_,\n*4*(43), 1686. doi:10.21105/joss.01686 &lt;https://doi.org/10.21105/joss.01686&gt;.\n  - Wickham H, François R, Henry L, Müller K, Vaughan D (2023). _dplyr: A Grammar\nof Data Manipulation_. R package version 1.1.3,\n&lt;https://CRAN.R-project.org/package=dplyr&gt;.\n  - Wickham H, Henry L (2023). _purrr: Functional Programming Tools_. R package\nversion 1.0.2, &lt;https://CRAN.R-project.org/package=purrr&gt;.\n  - Wickham H, Hester J, Bryan J (2023). _readr: Read Rectangular Text Data_. R\npackage version 2.1.4, &lt;https://CRAN.R-project.org/package=readr&gt;.\n  - Wickham H, Vaughan D, Girlich M (2023). _tidyr: Tidy Messy Data_. R package\nversion 1.3.0, &lt;https://CRAN.R-project.org/package=tidyr&gt;.\n  - Zeileis A, Grothendieck G (2005). \"zoo: S3 Infrastructure for Regular and\nIrregular Time Series.\" _Journal of Statistical Software_, *14*(6), 1-27.\ndoi:10.18637/jss.v014.i06 &lt;https://doi.org/10.18637/jss.v014.i06&gt;.\n  - Zeileis A, Hothorn T (2002). \"Diagnostic Checking in Regression\nRelationships.\" _R News_, *2*(3), 7-10.\n&lt;https://CRAN.R-project.org/doc/Rnews/&gt;.\n  - Zhu H (2021). _kableExtra: Construct Complex Table with 'kable' and Pipe\nSyntax_. R package version 1.3.4,\n&lt;https://CRAN.R-project.org/package=kableExtra&gt;."
  },
  {
    "objectID": "SEM.html#referências",
    "href": "SEM.html#referências",
    "title": "SEM",
    "section": "Referências",
    "text": "Referências\nhttps://repositorio.ufba.br/bitstream/ri/17684/1/ebook_SEM_2012.pdf\nhttps://statplace.com.br/blog/modelagem-de-equacoes-estruturais/",
    "crumbs": [
      "SEM"
    ]
  },
  {
    "objectID": "lista_8.html#a-regressão-linear",
    "href": "lista_8.html#a-regressão-linear",
    "title": "9  Lista 8 - CFA e Path Analysis",
    "section": "9.1 a) Regressão linear",
    "text": "9.1 a) Regressão linear\n\n\n\n\n\n\nExercício\n\n\n\nVeja o banco de dados DADOSPATH.sav. Nele temos os dados de Idade, IMC, numero de treinos e sociabilidade (questionario) de um grupo de 94 pessoas. Faca um modelo de regressao linear tendo como variavel dependente o numero de Treinos e as demais variaveis como independentes.\n\n\n\noriginal = read.spss(\"DADOS PATH.sav\", to.data.frame=TRUE)\nmodelo_1 = lm(Treinos ~ Idade + IMC1 + Sociabilidade, data = original)\n\nModelo:\n\\[\nY \\sim \\beta_0 + \\beta_1*idade + \\beta_2*IMC1 + \\beta_3*Sociabilidade + \\epsilon\n\\]\n\nResultados\n\nkable(summary(modelo_1)$coef)\n\n\n\n\n\nEstimate\nStd. Error\nt value\nPr(&gt;|t|)\n\n\n\n\n(Intercept)\n78.0103771\n33.1315541\n2.3545644\n0.0207191\n\n\nIdade\n1.9071028\n0.5479748\n3.4802749\n0.0007745\n\n\nIMC1\n-2.8021799\n1.1809989\n-2.3727202\n0.0197865\n\n\nSociabilidade\n0.5177685\n0.5903261\n0.8770889\n0.3827736\n\n\n\n\n\n\n\nUm modelo linear (estimado usando Mínimos Quadrados Ordinários - OLS) foi utilizado para prever a variável Treinos com base nas variáveis Idade, IMC1 e Sociabilidade. O modelo explica uma proporção estatisticamente significativa e moderada da variância (R² = 0,14, F(3, 90) = 5,06, p = 0,003, R² ajustado = 0,12). Dentro desse modelo: • O efeito da Idade é estatisticamente significativo e positivo (beta = 1,91, IC 95% [0,82, 3,00], t(90) = 3,48, p &lt; 0,001; Beta padronizado = 0,35, IC 95% [0,15, 0,56]) • O efeito do IMC1 é estatisticamente significativo e negativo (beta = -2,80, IC 95% [-5,15, -0,46], t(90) = -2,37, p = 0,020; Beta padronizado = -0,24, IC 95% [-0,44, -0,04]) • O efeito da Sociabilidade é estatisticamente não significativo e positivo (beta = 0,52, IC 95% [-0,66, 1,69], t(90) = 0,88, p = 0,383; Beta padronizado = 0,09, IC 95% [-0,11, 0,28]) Parâmetros padronizados foram obtidos ajustando o modelo a uma versão padronizada do conjunto de dados. Intervalos de Confiança (ICs) de 95% e valores-p foram calculados usando uma aproximação da distribuição t de Wald."
  },
  {
    "objectID": "lista_8.html#b-path-analysis",
    "href": "lista_8.html#b-path-analysis",
    "title": "9  Lista 8 - CFA e Path Analysis",
    "section": "9.2 b) Path Analysis",
    "text": "9.2 b) Path Analysis\n\n\n\n\n\n\nExercício\n\n\n\nCom base no mesmo banco acima faça uma Path Analysis e monte um diagrama no AMOS R. Compare os resultados com os dados encontrados na regressão linear.\n\n\n\npath_1 = \"Treinos ~ Idade + IMC1 + Sociabilidade\"\n\n\npath_model_1 = sem(\n  model = path_1,\n  data = original,\n)\n\n\nTabela com os resultados\nComo sempre, podemos utilizar a função summary() para retornar um resumo com os resultados do modelo\n\nsummary(path_model_1) # posso colocar o parametro fit.measures = TRUE para obter os valores de aderência do modelo\n\nlavaan 0.6.16 ended normally after 1 iteration\n\n  Estimator                                         ML\n  Optimization method                           NLMINB\n  Number of model parameters                         4\n\n  Number of observations                            94\n\nModel Test User Model:\n                                                      \n  Test statistic                                 0.000\n  Degrees of freedom                                 0\n\nParameter Estimates:\n\n  Standard errors                             Standard\n  Information                                 Expected\n  Information saturated (h1) model          Structured\n\nRegressions:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n  Treinos ~                                           \n    Idade             1.907    0.536    3.557    0.000\n    IMC1             -2.802    1.156   -2.425    0.015\n    Sociabilidade     0.518    0.578    0.896    0.370\n\nVariances:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n   .Treinos        2050.999  299.169    6.856    0.000\n\n\nNo caso da path analisys recomendamos utilizar a função parameterEstimates() do pacote lavaan para ter uma tabela mais direta com os resultados dos estimadores.\n\nkable(parameterEstimates(path_model_1))\n\n\n\n\nlhs\nop\nrhs\nest\nse\nz\npvalue\nci.lower\nci.upper\n\n\n\n\nTreinos\n~\nIdade\n1.9071028\n0.5361890\n3.5567736\n0.0003754\n0.8561917\n2.9580139\n\n\nTreinos\n~\nIMC1\n-2.8021799\n1.1555981\n-2.4248741\n0.0153137\n-5.0671106\n-0.5372493\n\n\nTreinos\n~\nSociabilidade\n0.5177685\n0.5776294\n0.8963679\n0.3700563\n-0.6143644\n1.6499014\n\n\nTreinos\n~~\nTreinos\n2050.9987436\n299.1689143\n6.8556546\n0.0000000\n1464.6384463\n2637.3590409\n\n\nIdade\n~~\nIdade\n82.5840878\n0.0000000\nNA\nNA\n82.5840878\n82.5840878\n\n\nIdade\n~~\nIMC1\n10.7872961\n0.0000000\nNA\nNA\n10.7872961\n10.7872961\n\n\nIdade\n~~\nSociabilidade\n3.7635808\n0.0000000\nNA\nNA\n3.7635808\n3.7635808\n\n\nIMC1\n~~\nIMC1\n17.7567863\n0.0000000\nNA\nNA\n17.7567863\n17.7567863\n\n\nIMC1\n~~\nSociabilidade\n1.2498636\n0.0000000\nNA\nNA\n1.2498636\n1.2498636\n\n\nSociabilidade\n~~\nSociabilidade\n65.6008375\n0.0000000\nNA\nNA\n65.6008375\n65.6008375\n\n\n\n\n\n\n\nOs resultados foram os mesmos obtidos tanto pela path analysis quanto pela regressão linear simples.\n\n\nIndices de qualidade do modelo\n\nmodel_performance(path_model_1, metrics = c(\"Chi2\", \"Chi2_df\", \"NFI\", \"NNFI\", \"CFI\", \"RMSEA\", \"AIC\", \"BIC\"))\n\n# Indices of model performance\n\nChi2(0) |   NFI |  NNFI |   CFI | RMSEA |     AIC |      BIC\n------------------------------------------------------------\n0.000   | 1.000 | 1.000 | 1.000 | 0.000 | 991.612 | 1001.785\n\nAIC(path_model_1)\n\n[1] 991.6122\n\n\n\n\nDiagrama da path analysis\n\nP &lt;- semPaths(\n          object = path_model_1,\n          what = \"path\",\n          whatLabels = \"par\",\n          style = \"ram\",\n          layout = \"tree\",\n          rotation = 2,\n          sizeMan = 7,\n          sizeLat = 7,\n          color = \"lightgray\",\n          edge.label.cex = 1.2,\n          label.cex = 1.3\n)"
  },
  {
    "objectID": "lista_8.html#c-cfa",
    "href": "lista_8.html#c-cfa",
    "title": "9  Lista 8 - CFA e Path Analysis",
    "section": "9.3 c) CFA",
    "text": "9.3 c) CFA\n\n\n\n\n\n\nExercício\n\n\n\nVeja o banco de dados Fatorial escala.sav. Faça uma Análise fatorial confirmatória (CFA) gerando os seguintes fatores com base no questionário de apego a amigos (IAA).\n\n\nSegundo a teoria esperada, os fatores teriam o seguinte agrupamento: a. Confianca – Q13 Q14 Q15 b. Alienacao – Q1 Q2 Q3 Monte o diagrama e discuta a qualidade do modelo e suas limitações caso existam.\nEquação do Modelo 1:\ncfa_eq = \" Alienação =~ IAa1 + IAa2 + IAa3 Confiança =~ IAa13 + IAa14 + IAa15  \"\nAnálise Fatorial Confirmatória do modelo 1\ncfa_modelo = cfa(   model = cfa_eq,   data = dados_CFA,   std.lv = TRUE  )\n\ndados_CFA = read.spss(\"fatorial CFA.sav\", to.data.frame=TRUE)\n\n\ncfa_eq = \"\nAlienação =~ IAa1 + IAa2 + IAa3\nConfiança =~ IAa13 + IAa14 + IAa15\n\n\"\n\n\ncfa_modelo = cfa(\n  model = cfa_eq,\n  data = dados_CFA,\n  std.lv = TRUE #If TRUE, the metric of each latent variable is determined by fixing their (residual) variances to 1.0. If FALSE, the metric of each latent variable is determined by fixing the factor loading of the first indicator to 1.0.\n  \n)\n\n\nResultados do modelo sem covariâncias entre os resíduos (modelo 1)\n\nsummary(cfa_modelo) # posso colocar no summary o parametro fit.measures = TRUE\n\nlavaan 0.6.16 ended normally after 18 iterations\n\n  Estimator                                         ML\n  Optimization method                           NLMINB\n  Number of model parameters                        13\n\n                                                  Used       Total\n  Number of observations                           347         348\n\nModel Test User Model:\n                                                      \n  Test statistic                                39.166\n  Degrees of freedom                                 8\n  P-value (Chi-square)                           0.000\n\nParameter Estimates:\n\n  Standard errors                             Standard\n  Information                                 Expected\n  Information saturated (h1) model          Structured\n\nLatent Variables:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n  Alienação =~                                        \n    IAa1              0.578    0.069    8.408    0.000\n    IAa2              0.842    0.069   12.135    0.000\n    IAa3              0.423    0.051    8.278    0.000\n  Confiança =~                                        \n    IAa13             0.580    0.044   13.279    0.000\n    IAa14             0.660    0.052   12.652    0.000\n    IAa15             0.586    0.053   11.105    0.000\n\nCovariances:\n                  Estimate  Std.Err  z-value  P(&gt;|z|)\n  Alienação ~~                                       \n    Confiança        0.865    0.051   16.807    0.000\n\nVariances:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n   .IAa1              1.023    0.088   11.607    0.000\n   .IAa2              0.676    0.089    7.627    0.000\n   .IAa3              0.568    0.049   11.667    0.000\n   .IAa13             0.316    0.036    8.898    0.000\n   .IAa14             0.485    0.051    9.564    0.000\n   .IAa15             0.564    0.052   10.767    0.000\n    Alienação         1.000                           \n    Confiança         1.000                           \n\n\n\nkable(parameterEstimates(cfa_modelo))\n\n\n\n\nlhs\nop\nrhs\nest\nse\nz\npvalue\nci.lower\nci.upper\n\n\n\n\nAlienação\n=~\nIAa1\n0.5783085\n0.0687768\n8.408481\n0\n0.4435084\n0.7131086\n\n\nAlienação\n=~\nIAa2\n0.8419500\n0.0693835\n12.134735\n0\n0.7059609\n0.9779391\n\n\nAlienação\n=~\nIAa3\n0.4226729\n0.0510624\n8.277581\n0\n0.3225925\n0.5227533\n\n\nConfiança\n=~\nIAa13\n0.5796173\n0.0436497\n13.278840\n0\n0.4940655\n0.6651691\n\n\nConfiança\n=~\nIAa14\n0.6603480\n0.0521921\n12.652247\n0\n0.5580533\n0.7626427\n\n\nConfiança\n=~\nIAa15\n0.5856667\n0.0527386\n11.105077\n0\n0.4823008\n0.6890325\n\n\nIAa1\n~~\nIAa1\n1.0234312\n0.0881741\n11.606933\n0\n0.8506131\n1.1962493\n\n\nIAa2\n~~\nIAa2\n0.6763156\n0.0886784\n7.626611\n0\n0.5025092\n0.8501221\n\n\nIAa3\n~~\nIAa3\n0.5677370\n0.0486609\n11.667220\n0\n0.4723635\n0.6631105\n\n\nIAa13\n~~\nIAa13\n0.3160382\n0.0355192\n8.897671\n0\n0.2464219\n0.3856546\n\n\nIAa14\n~~\nIAa14\n0.4851673\n0.0507280\n9.564088\n0\n0.3857422\n0.5845925\n\n\nIAa15\n~~\nIAa15\n0.5636709\n0.0523500\n10.767362\n0\n0.4610669\n0.6662750\n\n\nAlienação\n~~\nAlienação\n1.0000000\n0.0000000\nNA\nNA\n1.0000000\n1.0000000\n\n\nConfiança\n~~\nConfiança\n1.0000000\n0.0000000\nNA\nNA\n1.0000000\n1.0000000\n\n\nAlienação\n~~\nConfiança\n0.8646695\n0.0514471\n16.806951\n0\n0.7638349\n0.9655040\n\n\n\n\n\n\n\nOs resultados da análise de equações estruturais indicam que o modelo ajustado apresenta um bom ajuste aos dados observados (χ² = 39,166, df = 8, p &lt; 0,001). O modelo envolve duas variáveis latentes, “Alienação” e “Confiança”, e suas variáveis observadas.\nOs coeficientes de carga (estimates) indicam que as perguntas associadas a “Alienação” (IAa1, IAa2, IAa3) e “Confiança” (IAa13, IAa14, IAa15) têm influências positivas significativas em suas respectivas variáveis latentes.\nAlém disso, a covariância entre “Alienação” e “Confiança” é estatisticamente significativa (estimate = 0,865, p &lt; 0,001), sugerindo uma relação entre essas duas dimensões.\nEsses resultados fornecem evidências de que o modelo proposto é estatisticamente significativo.\n\n\nÍndices de qualidade do modelo 1\n\nmodel_performance(cfa_modelo, metrics = c(\"Chi2\", \"Chi2_df\", \"NFI\", \"CFI\", \"RMSEA\", \"p_RMSEA\", \"AIC\", \"BIC\", \"NNFI\") )\n\n# Indices of model performance\n\nChi2(8) |   NFI |   CFI | RMSEA | p (RMSEA) |      AIC |      BIC |  NNFI\n-------------------------------------------------------------------------\n39.166  | 0.918 | 0.933 | 0.106 |     0.003 | 5402.476 | 5452.517 | 0.874\n\n\nOs resultados dos índices de qualidade indicam que o modelo apresenta uma adequada qualidade de aderência aos dados observados, conforme evidenciado pelos índices de ajuste (NFI, CFI) acima de 0.9. Apenas o NNFI (ou TFI) está abaixo de 0.9, indicando um bom ajuste relativo.\nNo entanto, o valor do RMSEA é alto (10%), indicando que o modelo pode ser aprimorado.\nOs valores de AIC e BIC serão utilizados para efeito de comparação com os modelos a seguir.\n\n\nDiagrama da CFA com o modelo 1\n\nplot_CFA &lt;- semPaths(\n          object = cfa_modelo,\n          what = \"path\",\n          whatLabels = \"par\",\n          style = \"ram\",\n          layout = \"tree\",\n          rotation = 2,\n          sizeMan = 7,\n          sizeLat = 7,\n          color = \"lightgray\",\n          edge.label.cex = 1.2,\n          label.cex = 1.3\n)\n\n\n\n\n\n\nVerificar os índices de modificações do modelo 1\nOs índices de modificação podem ser obtidos utilizando a função modindices(). Por padrão, os índices de modificação são impressos para cada parâmetro não livre (ou fixado como zero). Os índices de modificação são complementados pelos valores de mudança esperada nos parâmetros (EPC) (coluna epc). As últimas três colunas contêm os valores padronizados de EPC (sepc.lv: padronização apenas das variáveis latentes; sepc.all: padronização de todas as variáveis; sepc.nox: padronização de todas, exceto variáveis observadas exógenas).\n\nkable(modificationindices(cfa_modelo, sort = TRUE, minimum.value = 5))\n\n\n\n\n\nlhs\nop\nrhs\nmi\nepc\nsepc.lv\nsepc.all\nsepc.nox\n\n\n\n\n34\nIAa13\n~~\nIAa14\n18.245523\n0.1825252\n0.1825252\n0.4661302\n0.4661302\n\n\n18\nAlienação\n=~\nIAa15\n18.245517\n0.9569991\n0.9569991\n1.0050447\n1.0050447\n\n\n29\nIAa2\n~~\nIAa14\n17.160433\n-0.2043919\n-0.2043919\n-0.3568151\n-0.3568151\n\n\n30\nIAa2\n~~\nIAa15\n10.461405\n0.1539148\n0.1539148\n0.2492832\n0.2492832\n\n\n20\nConfiança\n=~\nIAa2\n8.403845\n-1.6415789\n-1.6415789\n-1.3947817\n-1.3947817\n\n\n23\nIAa1\n~~\nIAa3\n8.403843\n-0.1390871\n-0.1390871\n-0.1824669\n-0.1824669\n\n\n35\nIAa13\n~~\nIAa15\n5.006171\n-0.0840609\n-0.0840609\n-0.1991642\n-0.1991642\n\n\n17\nAlienação\n=~\nIAa14\n5.006165\n-0.5603084\n-0.5603084\n-0.5837728\n-0.5837728\n\n\n\n\n\n\n\n\n\nNovo modelo com a covariância dos resíduos (modelo 2)\n\ncfa_eq_2 = \"\nAlienação =~ IAa1 + IAa2 + IAa3\nConfiança =~ IAa13 + IAa14 + IAa15\n\n# Covariancia dos resíduos\nIAa1 ~~ IAa3\nIAa13 ~~ IAa14\nIAa13 ~~ IAa15\n\n\"\n\n\ncfa_modelo_2 = cfa(\n  model = cfa_eq_2,\n  data = dados_CFA,\n  std.lv = TRUE\n)\n\nEquação do Modelo 2:\ncfa_eq_2 = \" Alienação =~ IAa1 + IAa2 + IAa3 Confiança =~ IAa13 + IAa14 + IAa15  # Covariancia dos resíduos IAa1 ~~ IAa3  IAa13 ~~ IAa14 IAa13 ~~ IAa15  \"\nAnálise Fatorial Confirmatória do modelo 2\ncfa_modelo_2 = cfa(   model = cfa_eq_2,   data = dados_CFA,   std.lv = TRUE    )\n\n\nResultados modelo 2\n\nsummary(cfa_modelo_2) # posso colocar no summary o parametro fit.measures = TRUE\n\nlavaan 0.6.16 ended normally after 24 iterations\n\n  Estimator                                         ML\n  Optimization method                           NLMINB\n  Number of model parameters                        16\n\n                                                  Used       Total\n  Number of observations                           347         348\n\nModel Test User Model:\n                                                      \n  Test statistic                                14.194\n  Degrees of freedom                                 5\n  P-value (Chi-square)                           0.014\n\nParameter Estimates:\n\n  Standard errors                             Standard\n  Information                                 Expected\n  Information saturated (h1) model          Structured\n\nLatent Variables:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n  Alienação =~                                        \n    IAa1              0.625    0.069    9.009    0.000\n    IAa2              0.844    0.066   12.774    0.000\n    IAa3              0.440    0.052    8.484    0.000\n  Confiança =~                                        \n    IAa13             0.486    0.054    9.010    0.000\n    IAa14             0.558    0.057    9.744    0.000\n    IAa15             0.627    0.058   10.741    0.000\n\nCovariances:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n .IAa1 ~~                                             \n   .IAa3             -0.131    0.047   -2.812    0.005\n .IAa13 ~~                                            \n   .IAa14             0.156    0.042    3.700    0.000\n   .IAa15             0.005    0.037    0.123    0.902\n  Alienação ~~                                        \n    Confiança         0.945    0.063   15.041    0.000\n\nVariances:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n   .IAa1              0.968    0.088   11.049    0.000\n   .IAa2              0.674    0.081    8.299    0.000\n   .IAa3              0.553    0.049   11.303    0.000\n   .IAa13             0.416    0.048    8.717    0.000\n   .IAa14             0.609    0.059   10.323    0.000\n   .IAa15             0.514    0.060    8.497    0.000\n    Alienação         1.000                           \n    Confiança         1.000                           \n\n\n\nkable(parameterEstimates(cfa_modelo_2))\n\n\n\n\nlhs\nop\nrhs\nest\nse\nz\npvalue\nci.lower\nci.upper\n\n\n\n\nAlienação\n=~\nIAa1\n0.6246375\n0.0693348\n9.0090043\n0.0000000\n0.4887438\n0.7605313\n\n\nAlienação\n=~\nIAa2\n0.8436173\n0.0660435\n12.7736683\n0.0000000\n0.7141745\n0.9730601\n\n\nAlienação\n=~\nIAa3\n0.4398298\n0.0518412\n8.4841676\n0.0000000\n0.3382228\n0.5414367\n\n\nConfiança\n=~\nIAa13\n0.4855333\n0.0538885\n9.0099663\n0.0000000\n0.3799138\n0.5911527\n\n\nConfiança\n=~\nIAa14\n0.5583551\n0.0573047\n9.7436136\n0.0000000\n0.4460399\n0.6706703\n\n\nConfiança\n=~\nIAa15\n0.6267943\n0.0583571\n10.7406769\n0.0000000\n0.5124166\n0.7411721\n\n\nIAa1\n~~\nIAa3\n-0.1314725\n0.0467540\n-2.8120052\n0.0049234\n-0.2231086\n-0.0398363\n\n\nIAa13\n~~\nIAa14\n0.1558199\n0.0421126\n3.7000779\n0.0002155\n0.0732807\n0.2383591\n\n\nIAa13\n~~\nIAa15\n0.0045594\n0.0370060\n0.1232056\n0.9019443\n-0.0679712\n0.0770899\n\n\nIAa1\n~~\nIAa1\n0.9676998\n0.0875801\n11.0493149\n0.0000000\n0.7960460\n1.1393536\n\n\nIAa2\n~~\nIAa2\n0.6735053\n0.0811578\n8.2987178\n0.0000000\n0.5144390\n0.8325716\n\n\nIAa3\n~~\nIAa3\n0.5529392\n0.0489190\n11.3031626\n0.0000000\n0.4570597\n0.6488186\n\n\nIAa13\n~~\nIAa13\n0.4162519\n0.0477495\n8.7174157\n0.0000000\n0.3226647\n0.5098391\n\n\nIAa14\n~~\nIAa14\n0.6094664\n0.0590382\n10.3232593\n0.0000000\n0.4937537\n0.7251790\n\n\nIAa15\n~~\nIAa15\n0.5138053\n0.0604718\n8.4966149\n0.0000000\n0.3952828\n0.6323277\n\n\nAlienação\n~~\nAlienação\n1.0000000\n0.0000000\nNA\nNA\n1.0000000\n1.0000000\n\n\nConfiança\n~~\nConfiança\n1.0000000\n0.0000000\nNA\nNA\n1.0000000\n1.0000000\n\n\nAlienação\n~~\nConfiança\n0.9447949\n0.0628146\n15.0410074\n0.0000000\n0.8216805\n1.0679092\n\n\n\n\n\n\n\nOs resultados da análise indicam que o modelo apresenta um razoável ajuste aos dados observados, conforme evidenciado pelos índices de ajuste, embora o teste qui-quadrado seja estatisticamente significativo (χ² = 14.194, df = 5, p = 0.014), indicando diferenças entre o modelo e os dados.\nAs cargas fatoriais para os indicadores associados às variáveis latentes “Alienação” e “Confiança” são todas estatisticamente significativas (p &lt; 0.001), indicando que esses indicadores têm uma relação com suas respectivas variáveis latentes.\n\n\nÍndices de qualidade do modelo 2\n\nmodel_performance(cfa_modelo_2, metrics = c(\"Chi2\", \"Chi2_df\", \"NFI\", \"CFI\", \"RMSEA\", \"p_RMSEA\", \"AIC\", \"BIC\", \"NNFI\"))\n\n# Indices of model performance\n\nChi2(5) |   NFI |   CFI | RMSEA | p (RMSEA) |      AIC |      BIC |  NNFI\n-------------------------------------------------------------------------\n14.194  | 0.970 | 0.980 | 0.073 |     0.165 | 5383.504 | 5445.093 | 0.940\n\n\nOs resultados dos índices de qualidade indicam que o modelo apresenta uma adequada qualidade de aderência aos dados observados, conforme evidenciado pelos índices de ajuste (NFI, CFI e NNFI) acima de 0.9.\nNo entanto, o valor do RMSEA é moderado (7%), indicando que o modelo pode ser aprimorado.\nOs valores de AIC e BIC serão utilizados para efeito de comparação com os modelos a seguir.\n\n\nDiagrama do modelo 2\n\nplot_CFA &lt;- semPaths(\n          object = cfa_modelo_2,\n          what = \"path\",\n          whatLabels = \"par\",\n          style = \"ram\",\n          layout = \"tree\",\n          rotation = 2,\n          sizeMan = 7,\n          sizeLat = 7,\n          color = \"lightgray\",\n          edge.label.cex = 1.2,\n          label.cex = 1.3\n)\n\n\n\n\n\n\nComparação entre os modelos\n\ncompare_performance(cfa_modelo, cfa_modelo_2, \n                    metrics = c(\"NFI\", \"CFI\", \"RMSEA\", \"p_RMSEA\", \"AIC\", \"BIC\", \"NNFI\"),\n                    rank = TRUE, verbose = F)\n\n# Comparison of Model Performance Indices\n\nName         |  Model |   NFI |   CFI | RMSEA | p (RMSEA) |  NNFI | AIC weights | BIC weights | Performance-Score\n-----------------------------------------------------------------------------------------------------------------\ncfa_modelo_2 | lavaan | 0.970 | 0.980 | 0.073 |     0.165 | 0.940 |       1.000 |       0.976 |            85.71%\ncfa_modelo   | lavaan | 0.918 | 0.933 | 0.106 |     0.003 | 0.874 |    7.59e-05 |       0.024 |            14.29%\n\n\nO modelo_2 demonstra superioridade em relação ao modelo_1 com base nos critérios de ajuste avaliados."
  },
  {
    "objectID": "lista_8.html#complementar-modelo-com-apenas-um-fator-latente-modelo-3",
    "href": "lista_8.html#complementar-modelo-com-apenas-um-fator-latente-modelo-3",
    "title": "9  Lista 8 - CFA e Path Analysis",
    "section": "9.4 Complementar: Modelo com apenas um fator latente (modelo 3)",
    "text": "9.4 Complementar: Modelo com apenas um fator latente (modelo 3)\n\ncfa_eq_3 = \"\nF1 =~ IAa1 + IAa2 + IAa3 + IAa13 + IAa14 + IAa15\n\"\n\n\ncfa_modelo_3 = cfa(\n  model = cfa_eq_3,\n  data = dados_CFA,\n  std.lv = TRUE\n)\n\nEquação do modelo 3:\ncfa_eq_3 = \" F1 =~ IAa1 + IAa2 + IAa3 + IAa13 + IAa14 + IAa15 \"\nAnálise Fatorial Confirmatória do modelo 2\ncfa_modelo_3 = cfa(   model = cfa_eq_3,   data = dados_CFA,   std.lv = TRUE    )\n\nResultados do modelo 3\n\nkable(parameterEstimates(cfa_modelo_3))\n\n\n\n\nlhs\nop\nrhs\nest\nse\nz\npvalue\nci.lower\nci.upper\n\n\n\n\nF1\n=~\nIAa1\n0.5580340\n0.0664300\n8.400335\n0\n0.4278336\n0.6882343\n\n\nF1\n=~\nIAa2\n0.7651182\n0.0637750\n11.997154\n0\n0.6401216\n0.8901149\n\n\nF1\n=~\nIAa3\n0.4044799\n0.0493864\n8.190103\n0\n0.3076843\n0.5012755\n\n\nF1\n=~\nIAa13\n0.5564023\n0.0432259\n12.871965\n0\n0.4716811\n0.6411235\n\n\nF1\n=~\nIAa14\n0.6400430\n0.0517363\n12.371268\n0\n0.5386419\n0.7414442\n\n\nF1\n=~\nIAa15\n0.5959511\n0.0519930\n11.462144\n0\n0.4940467\n0.6978555\n\n\nIAa1\n~~\nIAa1\n1.0464704\n0.0865635\n12.089050\n0\n0.8768091\n1.2161317\n\n\nIAa2\n~~\nIAa2\n0.7997900\n0.0764096\n10.467135\n0\n0.6500299\n0.9495502\n\n\nIAa3\n~~\nIAa3\n0.5827853\n0.0479619\n12.151008\n0\n0.4887817\n0.6767889\n\n\nIAa13\n~~\nIAa13\n0.3424110\n0.0348598\n9.822517\n0\n0.2740870\n0.4107349\n\n\nIAa14\n~~\nIAa14\n0.5115718\n0.0501136\n10.208248\n0\n0.4133510\n0.6097926\n\n\nIAa15\n~~\nIAa15\n0.5515190\n0.0510740\n10.798424\n0\n0.4514157\n0.6516222\n\n\nF1\n~~\nF1\n1.0000000\n0.0000000\nNA\nNA\n1.0000000\n1.0000000\n\n\n\n\n\n\n\nO modelo de uma única variável latente “F1” apresenta um ajuste geral adequado aos dados, conforme indicado pelo teste qui-quadrado significativo (χ² = 45.034, df = 9, p = 0.000).\nAs cargas fatoriais dos indicadores para “F1” são todas estatisticamente significativas (p &lt; 0.001), indicando que essas variáveis observadas têm uma relação com a variável latente “F1”.\n\n\nÍndices de qualidade do modelo 3\n\nmodel_performance(cfa_modelo_3, metrics = c(\"Chi2\", \"Chi2_df\", \"NFI\", \"CFI\", \"RMSEA\", \"p_RMSEA\", \"AIC\", \"BIC\", \"NNFI\") )\n\n# Indices of model performance\n\nChi2(9) |   NFI |   CFI | RMSEA | p (RMSEA) |      AIC |      BIC |  NNFI\n-------------------------------------------------------------------------\n45.034  | 0.906 | 0.922 | 0.107 |     0.001 | 5406.344 | 5452.536 | 0.870\n\n\n\n\nDiagrama do modelo 3\n\nplot_CFA &lt;- semPaths(\n          object = cfa_modelo_3,\n          what = \"path\",\n          whatLabels = \"par\",\n          style = \"ram\",\n          layout = \"tree\",\n          rotation = 2,\n          sizeMan = 7,\n          sizeLat = 7,\n          color = \"lightgray\",\n          edge.label.cex = 1.2,\n          label.cex = 1.3\n)\n\n\n\n\n\n\nÍndices de modificação para o modelo\n\nkable(modificationindices(cfa_modelo_3, standardized = FALSE, minimum.value = 5))\n\n\n\n\n\nlhs\nop\nrhs\nmi\nepc\n\n\n\n\n16\nIAa1\n~~\nIAa13\n6.419170\n-0.1034145\n\n\n19\nIAa2\n~~\nIAa3\n5.260435\n0.1017547\n\n\n21\nIAa2\n~~\nIAa14\n19.900038\n-0.2224777\n\n\n22\nIAa2\n~~\nIAa15\n6.284104\n0.1223301\n\n\n26\nIAa13\n~~\nIAa14\n24.013115\n0.1712177"
  },
  {
    "objectID": "lista_8.html#modelo-4-com-covariância-entre-os-resíduos",
    "href": "lista_8.html#modelo-4-com-covariância-entre-os-resíduos",
    "title": "9  Lista 8 - CFA e Path Analysis",
    "section": "9.5 Modelo 4 com covariância entre os resíduos",
    "text": "9.5 Modelo 4 com covariância entre os resíduos\n\ncfa_eq_4 = \"\nF1 =~ IAa1 + IAa2 + IAa3 + IAa13 + IAa14 + IAa15\n\n#Covariância dos resíduos\nIAa2    ~~  IAa14\nIAa13   ~~  IAa14\n\"\n\nAnálise Fatorial Confirmatória do modelo 4\n\ncfa_modelo_4 = cfa(\n  model = cfa_eq_4,\n  data = dados_CFA,\n  std.lv = TRUE\n)\n\n\nResultados do modelo 4\n\nkable(parameterEstimates(cfa_modelo_4))\n\n\n\n\nlhs\nop\nrhs\nest\nse\nz\npvalue\nci.lower\nci.upper\n\n\n\n\nF1\n=~\nIAa1\n0.5755782\n0.0658579\n8.739696\n0.0000000\n0.4464990\n0.7046573\n\n\nF1\n=~\nIAa2\n0.8812882\n0.0659778\n13.357336\n0.0000000\n0.7519740\n1.0106024\n\n\nF1\n=~\nIAa3\n0.4106200\n0.0490163\n8.377216\n0.0000000\n0.3145499\n0.5066902\n\n\nF1\n=~\nIAa13\n0.4773285\n0.0461558\n10.341675\n0.0000000\n0.3868648\n0.5677923\n\n\nF1\n=~\nIAa14\n0.6235655\n0.0604044\n10.323181\n0.0000000\n0.5051751\n0.7419560\n\n\nF1\n=~\nIAa15\n0.5905868\n0.0525289\n11.243084\n0.0000000\n0.4876320\n0.6935415\n\n\nIAa2\n~~\nIAa14\n-0.1604716\n0.0490176\n-3.273757\n0.0010613\n-0.2565442\n-0.0643989\n\n\nIAa13\n~~\nIAa14\n0.1249518\n0.0402391\n3.105235\n0.0019013\n0.0460846\n0.2038189\n\n\nIAa1\n~~\nIAa1\n1.0265817\n0.0852570\n12.041031\n0.0000000\n0.8594811\n1.1936823\n\n\nIAa2\n~~\nIAa2\n0.6085266\n0.0820552\n7.416062\n0.0000000\n0.4477013\n0.7693519\n\n\nIAa3\n~~\nIAa3\n0.5777805\n0.0475147\n12.160028\n0.0000000\n0.4846534\n0.6709077\n\n\nIAa13\n~~\nIAa13\n0.4241519\n0.0395633\n10.720852\n0.0000000\n0.3466093\n0.5016945\n\n\nIAa14\n~~\nIAa14\n0.5298461\n0.0642606\n8.245273\n0.0000000\n0.4038976\n0.6557945\n\n\nIAa15\n~~\nIAa15\n0.5578837\n0.0519546\n10.737912\n0.0000000\n0.4560546\n0.6597128\n\n\nF1\n~~\nF1\n1.0000000\n0.0000000\nNA\nNA\n1.0000000\n1.0000000\n\n\n\n\n\n\n\nOs resultados do modelo sugerem que o ajuste do modelo aos dados é razoável, conforme indicado pelo teste qui-quadrado (χ² = 12.216, df = 7, p = 0.094). O modelo envolve uma única variável latente “F1,” e por seis variáveis observadas (IAa1, IAa2, IAa3, IAa13, IAa14, IAa15). As cargas fatoriais associadas a cada indicador são todas estatisticamente significativas (p &lt; 0.001), indicando uma relação entre esses indicadores e a variável latente “F1”. As variâncias dos indicadores também são significativas, sugerindo que cada indicador contribui para a variabilidade total da variável latente “F1”.\nAlém disso, há duas covariâncias estimadas entre os indicadores: uma entre IAa2 e IAa14, e outra entre IAa13 e IAa14. Essas covariâncias indicam associações adicionais entre os indicadores além daquelas explicadas pelas relações com a variável latente “F1”.\n\n\nÍndices de qualidade do modelo 4\n\nmodel_performance(cfa_modelo_4, metrics = c(\"Chi2\", \"Chi2_df\", \"NFI\", \"CFI\", \"RMSEA\", \"p_RMSEA\", \"AIC\", \"BIC\", \"NNFI\"))\n\n# Indices of model performance\n\nChi2(7) |   NFI |   CFI | RMSEA | p (RMSEA) |      AIC |      BIC |  NNFI\n-------------------------------------------------------------------------\n12.216  | 0.974 | 0.989 | 0.046 |     0.498 | 5377.526 | 5431.416 | 0.976\n\n\nO modelo apresenta índices NFI (0.974), CFI (0.989) e NNFI (0.976) próximos de 1, indicando um bom ajuste. O RMSEA (0.046) é baixo, sugerindo uma adequada aproximação do modelo aos dados.\n\n\nDiagrama do modelo 4\n\nplot_CFA &lt;- semPaths(\n          object = cfa_modelo_4,\n          what = \"path\",\n          whatLabels = \"par\",\n          style = \"ram\",\n          layout = \"tree\",\n          rotation = 2,\n          sizeMan = 7,\n          sizeLat = 7,\n          color = \"lightgray\",\n          edge.label.cex = 1.2,\n          label.cex = 1.3\n)\n\n\n\n\n\n\nComparação entre os modelos\n\ncompare_performance(cfa_modelo, cfa_modelo_2, cfa_modelo_3, cfa_modelo_4,\n                    metrics = c(\"NFI\", \"CFI\", \"RMSEA\", \"p_RMSEA\", \"AIC\", \"BIC\", \"NNFI\"),\n                    rank = TRUE, verbose = F)\n\n# Comparison of Model Performance Indices\n\nName         |  Model |   NFI |   CFI | RMSEA | p (RMSEA) |  NNFI | AIC weights | BIC weights | Performance-Score\n-----------------------------------------------------------------------------------------------------------------\ncfa_modelo_4 | lavaan | 0.974 | 0.989 | 0.046 |     0.498 | 0.976 |       0.952 |       0.999 |            85.71%\ncfa_modelo_2 | lavaan | 0.970 | 0.980 | 0.073 |     0.165 | 0.940 |       0.048 |       0.001 |            47.00%\ncfa_modelo   | lavaan | 0.918 | 0.933 | 0.106 |     0.003 | 0.874 |    3.64e-06 |    2.62e-05 |            19.27%\ncfa_modelo_3 | lavaan | 0.906 | 0.922 | 0.107 |     0.001 | 0.870 |    5.26e-07 |    2.59e-05 |            14.29%\n\n\nO modelo_4 demonstra superioridade em relação aos demais modelos com base nos critérios de ajuste avaliados.\n\n# Links de referência\n\n# https://rdrr.io/cran/performance/man/model_performance.lavaan.html\n# https://methodenlehre.github.io/SGSCLM-R-course/cfa-and-sem-with-lavaan.html#structural-equation-modelling-sem"
  },
  {
    "objectID": "lista_8.html#lista-8-resolvida-no-spss",
    "href": "lista_8.html#lista-8-resolvida-no-spss",
    "title": "9  Lista 8 - CFA e Path Analysis",
    "section": "9.6 Lista 8 resolvida no SPSS",
    "text": "9.6 Lista 8 resolvida no SPSS"
  },
  {
    "objectID": "lista_8.html#extras",
    "href": "lista_8.html#extras",
    "title": "9  Lista 8 - CFA e Path Analysis",
    "section": "9.7 Extras!",
    "text": "9.7 Extras!\n\nMais gráficos\n\nsemPaths(cfa_modelo, \"std\", weighted = FALSE, nCharNodes = 7, shapeMan = \"rectangle\",\n         sizeMan = 8, sizeMan2 = 5)"
  },
  {
    "objectID": "lista_8.html#referências",
    "href": "lista_8.html#referências",
    "title": "9  Lista 8 - CFA e Path Analysis",
    "section": "9.8 Referências",
    "text": "9.8 Referências\nhttps://www.jstatsoft.org/article/view/v048i02\nhttps://lavaan.ugent.be/tutorial/inspect.html"
  },
  {
    "objectID": "lista_8.html#versões-dos-pacotes",
    "href": "lista_8.html#versões-dos-pacotes",
    "title": "9  Lista 8 - CFA e Path Analysis",
    "section": "9.9 Versões dos pacotes",
    "text": "9.9 Versões dos pacotes\n\nreport(sessionInfo())\n\nAnalyses were conducted using the R Statistical language (version 4.3.1; R Core\nTeam, 2023) on Windows 11 x64 (build 22621), using the packages effectsize\n(version 0.8.6; Ben-Shachar MS et al., 2020), semPlot (version 1.1.6; Epskamp\nS, 2022), lubridate (version 1.9.3; Grolemund G, Wickham H, 2011), parameters\n(version 0.21.3; Lüdecke D et al., 2020), performance (version 0.10.8; Lüdecke\nD et al., 2021), easystats (version 0.6.0; Lüdecke D et al., 2022), see\n(version 0.8.1; Lüdecke D et al., 2021), insight (version 0.19.6; Lüdecke D et\nal., 2019), bayestestR (version 0.13.1; Makowski D et al., 2019), modelbased\n(version 0.8.6; Makowski D et al., 2020), report (version 0.5.7; Makowski D et\nal., 2023), correlation (version 0.8.4; Makowski D et al., 2022), tibble\n(version 3.2.1; Müller K, Wickham H, 2023), datawizard (version 0.9.0; Patil I\net al., 2022), foreign (version 0.8.85; R Core Team, 2023), lavaan (version\n0.6.16; Rosseel Y, 2012), ggplot2 (version 3.4.4; Wickham H, 2016), forcats\n(version 1.0.0; Wickham H, 2023), stringr (version 1.5.1; Wickham H, 2023),\ntidyverse (version 2.0.0; Wickham H et al., 2019), dplyr (version 1.1.3;\nWickham H et al., 2023), purrr (version 1.0.2; Wickham H, Henry L, 2023), readr\n(version 2.1.4; Wickham H et al., 2023), tidyr (version 1.3.0; Wickham H et\nal., 2023) and kableExtra (version 1.3.4; Zhu H, 2021).\n\nReferences\n----------\n  - Ben-Shachar MS, Lüdecke D, Makowski D (2020). \"effectsize: Estimation of\nEffect Size Indices and Standardized Parameters.\" _Journal of Open Source\nSoftware_, *5*(56), 2815. doi:10.21105/joss.02815\n&lt;https://doi.org/10.21105/joss.02815&gt;, &lt;https://doi.org/10.21105/joss.02815&gt;.\n  - Epskamp S (2022). _semPlot: Path Diagrams and Visual Analysis of Various SEM\nPackages' Output_. R package version 1.1.6,\n&lt;https://CRAN.R-project.org/package=semPlot&gt;.\n  - Grolemund G, Wickham H (2011). \"Dates and Times Made Easy with lubridate.\"\n_Journal of Statistical Software_, *40*(3), 1-25.\n&lt;https://www.jstatsoft.org/v40/i03/&gt;.\n  - Lüdecke D, Ben-Shachar M, Patil I, Makowski D (2020). \"Extracting, Computing\nand Exploring the Parameters of Statistical Models using R.\" _Journal of Open\nSource Software_, *5*(53), 2445. doi:10.21105/joss.02445\n&lt;https://doi.org/10.21105/joss.02445&gt;.\n  - Lüdecke D, Ben-Shachar M, Patil I, Waggoner P, Makowski D (2021).\n\"performance: An R Package for Assessment, Comparison and Testing of\nStatistical Models.\" _Journal of Open Source Software_, *6*(60), 3139.\ndoi:10.21105/joss.03139 &lt;https://doi.org/10.21105/joss.03139&gt;.\n  - Lüdecke D, Ben-Shachar M, Patil I, Wiernik B, Makowski D (2022). \"easystats:\nFramework for Easy Statistical Modeling, Visualization, and Reporting.\" _CRAN_.\nR package, &lt;https://easystats.github.io/easystats/&gt;.\n  - Lüdecke D, Patil I, Ben-Shachar M, Wiernik B, Waggoner P, Makowski D (2021).\n\"see: An R Package for Visualizing Statistical Models.\" _Journal of Open Source\nSoftware_, *6*(64), 3393. doi:10.21105/joss.03393\n&lt;https://doi.org/10.21105/joss.03393&gt;.\n  - Lüdecke D, Waggoner P, Makowski D (2019). \"insight: A Unified Interface to\nAccess Information from Model Objects in R.\" _Journal of Open Source Software_,\n*4*(38), 1412. doi:10.21105/joss.01412 &lt;https://doi.org/10.21105/joss.01412&gt;.\n  - Makowski D, Ben-Shachar M, Lüdecke D (2019). \"bayestestR: Describing Effects\nand their Uncertainty, Existence and Significance within the Bayesian\nFramework.\" _Journal of Open Source Software_, *4*(40), 1541.\ndoi:10.21105/joss.01541 &lt;https://doi.org/10.21105/joss.01541&gt;,\n&lt;https://joss.theoj.org/papers/10.21105/joss.01541&gt;.\n  - Makowski D, Ben-Shachar M, Patil I, Lüdecke D (2020). \"Estimation of\nModel-Based Predictions, Contrasts and Means.\" _CRAN_.\n&lt;https://github.com/easystats/modelbased&gt;.\n  - Makowski D, Lüdecke D, Patil I, Thériault R, Ben-Shachar M, Wiernik B (2023).\n\"Automated Results Reporting as a Practical Tool to Improve Reproducibility and\nMethodological Best Practices Adoption.\" _CRAN_.\n&lt;https://easystats.github.io/report/&gt;.\n  - Makowski D, Wiernik B, Patil I, Lüdecke D, Ben-Shachar M (2022).\n\"correlation: Methods for Correlation Analysis.\" Version 0.8.3,\n&lt;https://CRAN.R-project.org/package=correlation&gt;. Makowski D, Ben-Shachar M,\nPatil I, Lüdecke D (2020). \"Methods and Algorithms for Correlation Analysis in\nR.\" _Journal of Open Source Software_, *5*(51), 2306. doi:10.21105/joss.02306\n&lt;https://doi.org/10.21105/joss.02306&gt;,\n&lt;https://joss.theoj.org/papers/10.21105/joss.02306&gt;.\n  - Müller K, Wickham H (2023). _tibble: Simple Data Frames_. R package version\n3.2.1, &lt;https://CRAN.R-project.org/package=tibble&gt;.\n  - Patil I, Makowski D, Ben-Shachar M, Wiernik B, Bacher E, Lüdecke D (2022).\n\"datawizard: An R Package for Easy Data Preparation and Statistical\nTransformations.\" _Journal of Open Source Software_, *7*(78), 4684.\ndoi:10.21105/joss.04684 &lt;https://doi.org/10.21105/joss.04684&gt;.\n  - R Core Team (2023). _foreign: Read Data Stored by 'Minitab', 'S', 'SAS',\n'SPSS', 'Stata', 'Systat', 'Weka', 'dBase', ..._. R package version 0.8-85,\n&lt;https://CRAN.R-project.org/package=foreign&gt;.\n  - R Core Team (2023). _R: A Language and Environment for Statistical\nComputing_. R Foundation for Statistical Computing, Vienna, Austria.\n&lt;https://www.R-project.org/&gt;.\n  - Rosseel Y (2012). \"lavaan: An R Package for Structural Equation Modeling.\"\n_Journal of Statistical Software_, *48*(2), 1-36. doi:10.18637/jss.v048.i02\n&lt;https://doi.org/10.18637/jss.v048.i02&gt;.\n  - Wickham H (2016). _ggplot2: Elegant Graphics for Data Analysis_.\nSpringer-Verlag New York. ISBN 978-3-319-24277-4,\n&lt;https://ggplot2.tidyverse.org&gt;.\n  - Wickham H (2023). _forcats: Tools for Working with Categorical Variables\n(Factors)_. R package version 1.0.0,\n&lt;https://CRAN.R-project.org/package=forcats&gt;.\n  - Wickham H (2023). _stringr: Simple, Consistent Wrappers for Common String\nOperations_. R package version 1.5.1,\n&lt;https://CRAN.R-project.org/package=stringr&gt;.\n  - Wickham H, Averick M, Bryan J, Chang W, McGowan LD, François R, Grolemund G,\nHayes A, Henry L, Hester J, Kuhn M, Pedersen TL, Miller E, Bache SM, Müller K,\nOoms J, Robinson D, Seidel DP, Spinu V, Takahashi K, Vaughan D, Wilke C, Woo K,\nYutani H (2019). \"Welcome to the tidyverse.\" _Journal of Open Source Software_,\n*4*(43), 1686. doi:10.21105/joss.01686 &lt;https://doi.org/10.21105/joss.01686&gt;.\n  - Wickham H, François R, Henry L, Müller K, Vaughan D (2023). _dplyr: A Grammar\nof Data Manipulation_. R package version 1.1.3,\n&lt;https://CRAN.R-project.org/package=dplyr&gt;.\n  - Wickham H, Henry L (2023). _purrr: Functional Programming Tools_. R package\nversion 1.0.2, &lt;https://CRAN.R-project.org/package=purrr&gt;.\n  - Wickham H, Hester J, Bryan J (2023). _readr: Read Rectangular Text Data_. R\npackage version 2.1.4, &lt;https://CRAN.R-project.org/package=readr&gt;.\n  - Wickham H, Vaughan D, Girlich M (2023). _tidyr: Tidy Messy Data_. R package\nversion 1.3.0, &lt;https://CRAN.R-project.org/package=tidyr&gt;.\n  - Zhu H (2021). _kableExtra: Construct Complex Table with 'kable' and Pipe\nSyntax_. R package version 1.3.4,\n&lt;https://CRAN.R-project.org/package=kableExtra&gt;."
  },
  {
    "objectID": "lista_8_1.html#a-modelo-causal-teórico",
    "href": "lista_8_1.html#a-modelo-causal-teórico",
    "title": "1  Lista 8.1 - Moderação e Mediação",
    "section": "",
    "text": "Exercício\n\n\n\nVerifique esse modelo causal teórico e veja se ele faz sentido, utilizando um modelo SEM com mediação. Avalie os efeitos diretos e indiretos e decida se esse modelo teórico faz sentido, utilizando o AMOS e o Process.\n\n\n\n\n\n\n\n\nResultados\n\nRegressões:\n\n\nO coeficiente estimado para a relação entre Sociabilidae e Treinos é 0.605, mas não é estatisticamente significativo (p = 0.360).\nO coeficiente estimado para a relação entre IMC e Treinos é -1.650, indicando uma relação negativa. No entanto, esse coeficiente também não é estatisticamente significativo (p = 0.100).\nO coeficiente estimado para a relação entre Sociabilidae e IMC é 0.019 e não é estatisticamente significativo (p = 0.693).\n\n\nParâmetros Definidos:\n\n\nO efeito indireto é estimado como -0.031, mas não é estatisticamente significativo (p = 0.717). Isso sugere que a variável IMC não medeia significativamente a relação entre Sociabilidae e Treinos.\nO efeito direto da Sociabilidade no Treino é estimado como 0.574 e também não é estatisticamente significativo (p = 0.386).\n\nCom base nos resultados, podemos concluir que o modelo teórico não se sustenta, pois não há evidência estatística significativa para sugerir relações entre as variáveis Sociabilidae , IMC e Treinos.",
    "crumbs": [
      "SEM",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Lista 8.1 - Moderação e Mediação</span>"
    ]
  },
  {
    "objectID": "lista_8_1.html#b-mediação-vs-regressões-lineares",
    "href": "lista_8_1.html#b-mediação-vs-regressões-lineares",
    "title": "1  Lista 8.1 - Moderação e Mediação",
    "section": "1.2 b) Mediação vs Regressões lineares",
    "text": "1.2 b) Mediação vs Regressões lineares\n\n\n\n\n\n\nExercício\n\n\n\nCompare os dados encontrados com aqueles realizados por um conjunto de regressões lineares (OLS). Fazer esta análise de mediação por regressão linear e utilizando o AMOS+Process é a mesma coisa? Coloque também o diagrama gerado aqui.\n\n\n\nValor de “c”\n\nsoc_treinos = lm(Treinos ~ Sociabilidade, data = original) #valor de c\nkable(summary(soc_treinos)$coef)\n\n\n\n\n\nEstimate\nStd. Error\nt value\nPr(&gt;|t|)\n\n\n\n\n(Intercept)\n69.4395522\n14.1638541\n4.9025888\n0.0000041\n\n\nSociabilidade\n0.5737921\n0.6273496\n0.9146289\n0.3627775\n\n\n\n\n\n\n\nValor de a\n\nsoc_imc = lm(IMC1 ~ Sociabilidade, data = original) \nkable(summary(soc_imc)$coef)\n\n\n\n\n\nEstimate\nStd. Error\nt value\nPr(&gt;|t|)\n\n\n\n\n(Intercept)\n25.3971491\n1.2238100\n20.7525264\n0.0000000\n\n\nSociabilidade\n0.0190526\n0.0542054\n0.3514884\n0.7260257\n\n\n\n\n\n\n\nvalor de b e de c’\n\nsoc_E_imc_treinos = lm(Treinos ~ IMC1 + Sociabilidade, data = original) \nkable(summary(soc_E_imc_treinos)$coef)\n\n\n\n\n\n\n\n\n\n\n\n\nEstimate\nStd. Error\nt value\nPr(&gt;|t|)\n\n\n\n\n(Intercept)\n111.3388945\n33.5981763\n3.3138374\n0.0013220\n\n\nIMC1\n-1.6497656\n1.2008507\n-1.3738307\n0.1728690\n\n\nSociabilidade\n0.6052243\n0.6247647\n0.9687235\n0.3352508\n\n\n\n\n\nOs resultados são diferentes. As mediações apenas por regressão linear não apresentam o resultado do efeito indireto, mostrado no resultado do exercício anterior\n\n\nDiagrama do modelo\n\ndiagrama_1 &lt;- semPaths(\n          object = fit_1,\n          what = \"path\",\n          whatLabels = \"par\",\n          style = \"ram\",\n          layout = \"tree\",\n          rotation = 2,\n          sizeMan = 7,\n          sizeLat = 7,\n          color = \"lightgray\",\n          edge.label.cex = 1.2,\n          label.cex = 1.3\n)",
    "crumbs": [
      "SEM",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Lista 8.1 - Moderação e Mediação</span>"
    ]
  },
  {
    "objectID": "lista_8_1.html#modelo-2-opcional-1",
    "href": "lista_8_1.html#modelo-2-opcional-1",
    "title": "1  Lista 8.1 - Moderação e Mediação",
    "section": "1.3 Modelo 2 (Opcional 1)",
    "text": "1.3 Modelo 2 (Opcional 1)\nRefaça o modelo tendo a variável Idade como mediador.\n\nmodelo_2 = \"Treinos ~ c_*Sociabilidade + b*Idade \n            Idade ~ a*Sociabilidade\n            Indireto := a*b\n            Total_direto_C := a*b + c_\"\n\n\nfit_2 = sem(modelo_2, original, se = \"bootstrap\", bootstrap = 500)\n\nkable(parameterEstimates(fit_2)) # parâmetros adicionais summary(fit_1, fit.measures = TRUE, standardized = TRUE, rsquare = TRUE) \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nlhs\nop\nrhs\nlabel\nest\nse\nz\npvalue\nci.lower\nci.upper\n\n\n\n\nTreinos\n~\nSociabilidade\nc_\n0.4852942\n0.6167360\n0.7868750\n0.4313550\n-0.6313123\n1.8748063\n\n\nTreinos\n~\nIdade\nb\n1.5425565\n0.4809015\n3.2076354\n0.0013383\n0.4986601\n2.3565724\n\n\nIdade\n~\nSociabilidade\na\n0.0573709\n0.1077544\n0.5324230\n0.5944331\n-0.1782322\n0.2349021\n\n\nTreinos\n~~\nTreinos\n\n2179.2955768\n199.1324397\n10.9439506\n0.0000000\n1729.4483713\n2505.5122758\n\n\nIdade\n~~\nIdade\n\n82.3681677\n10.0791038\n8.1721718\n0.0000000\n60.3094976\n101.2515923\n\n\nSociabilidade\n~~\nSociabilidade\n\n65.6008375\n0.0000000\nNA\nNA\n65.6008375\n65.6008375\n\n\nIndireto\n:=\na*b\nIndireto\n0.0884979\n0.1668425\n0.5304278\n0.5958154\n-0.2675616\n0.4045438\n\n\nTotal_direto_C\n:=\na*b+c_\nTotal_direto_C\n0.5737921\n0.6720495\n0.8537943\n0.3932190\n-0.7060400\n2.0018306\n\n\n\n\n\n\nResultados\n\nRegressões:\n\nA relação estimada entre Sociabilidade e Treinos é 0.485, mas não é estatisticamente significativa (p = 0.384).\nA relação estimada entre Idade e Treinos é 1.543, indicando uma relação positiva e significativa (p = 0.001).\nA relação estimada entre Sociabldd e Idade é 0.057 e não é estatisticamente significativa (p = 0.592).\n\nParâmetros Definidos:\n\nO efeito Indireto é estimado como 0.088, mas não é estatisticamente significativo (p = 0.605). Isso sugere que a variável Idade não medeia significativamente a relação entre Sociabilidade e Treinos.\nO efeito total direto da Sociabilidae nos Treinos é estimado como 0.574 e não é estatisticamente significativo (p = 0.345).\n\n\nOs resultados sugerem que a variável Idade está significativamente relacionada à variável Treinos, enquanto a variável Sociabilidade não tem uma relação significativa com Treinos. O efeito indireto através de Idade não é estatisticamente significativo, e o efeito total direto também não é significativo.\n\n\nDiagrama do modelo 2\n\ndiagrama_2 &lt;- semPaths(\n          object = fit_2,\n          what = \"path\",\n          whatLabels = \"par\",\n          style = \"ram\",\n          layout = \"tree\",\n          rotation = 2,\n          sizeMan = 7,\n          sizeLat = 7,\n          color = \"lightgray\",\n          edge.label.cex = 1.2,\n          label.cex = 1.3\n)\n\n\n\n\n\n\n\n\n\nmediation_model_2 = lm(Idade ~ Sociabilidade, data = original)\nkable(summary(mediation_model_2)$coef)\n\n\n\n\n\nEstimate\nStd. Error\nt value\nPr(&gt;|t|)\n\n\n\n\n(Intercept)\n32.8228531\n2.6375635\n12.4443843\n0.0000000\n\n\nSociabilidade\n0.0573709\n0.1168237\n0.4910896\n0.6245325\n\n\n\n\n# library(flexplot)\n# visualize(mediation_model_2) análise gráfica do modelo\n\n\nfull_model_2 = lm(Treinos ~ Idade + Sociabilidade, data = original)\nkable(summary(full_model_2)$coef)\n\n\n\n\n\nEstimate\nStd. Error\nt value\nPr(&gt;|t|)\n\n\n\n\n(Intercept)\n18.8084463\n22.3454098\n0.8417141\n0.4021546\n\n\nIdade\n1.5425565\n0.5392097\n2.8607731\n0.0052418\n\n\nSociabilidade\n0.4852942\n0.6049941\n0.8021469\n0.4245578\n\n\n\n\n#visualize(full_model_2) análise gráfica do modelo\n\n\nresults_2 = mediate(mediation_model_2, full_model_2,\n                  treat = \"Sociabilidade\",\n                  mediator = \"Idade\",\n                  boot = TRUE,\n                  sims = 500)\n\nsummary(results_2)\n\n\nCausal Mediation Analysis \n\nNonparametric Bootstrap Confidence Intervals with the Percentile Method\n\n                Estimate 95% CI Lower 95% CI Upper p-value\nACME            0.088498    -0.221887     0.463128   0.584\nADE             0.485294    -0.528174     1.721350   0.380\nTotal Effect    0.573792    -0.560848     1.984330   0.344\nProp. Mediated  0.154233    -1.465826     1.856289   0.560\n\nSample Size Used: 94 \n\n\nSimulations: 500 \n\n\n\nmediate_plot(Treinos ~ Idade  + Sociabilidade  , data = original)",
    "crumbs": [
      "SEM",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Lista 8.1 - Moderação e Mediação</span>"
    ]
  },
  {
    "objectID": "lista_8_1.html#modelo-3-opcional-2",
    "href": "lista_8_1.html#modelo-3-opcional-2",
    "title": "1  Lista 8.1 - Moderação e Mediação",
    "section": "1.4 Modelo 3 (Opcional 2)",
    "text": "1.4 Modelo 3 (Opcional 2)\nTestando outros modelos, foi possível observar que o efeito do IMC sobre o treinamento é mediado pela Idade\n\nmodelo_3 = \"Treinos ~ c_*IMC1 + b*Idade \n            Idade ~ a*IMC1\n            Indireto := a*b\n            Total_direto_C := a*b + c_\"\n\n\nfit_3 = sem(modelo_3, original, se = \"bootstrap\", bootstrap = 500) #demora um tempo para executar\n\n\nkable(parameterEstimates(fit_3)) # parâmetros adicionais summary(fit_1, fit.measures = TRUE, standardized = TRUE, rsquare = TRUE)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nlhs\nop\nrhs\nlabel\nest\nse\nz\npvalue\nci.lower\nci.upper\n\n\n\n\nTreinos\n~\nIMC1\nc_\n-2.7781642\n0.9505827\n-2.922591\n0.0034713\n-4.5313054\n-0.8983049\n\n\nTreinos\n~\nIdade\nb\n1.9275620\n0.4570572\n4.217332\n0.0000247\n1.0249570\n2.8415207\n\n\nIdade\n~\nIMC1\na\n0.6075027\n0.2236498\n2.716313\n0.0066014\n0.1872942\n1.0855955\n\n\nTreinos\n~~\nTreinos\n\n2068.5298836\n196.3987428\n10.532297\n0.0000000\n1616.6433067\n2400.6574044\n\n\nIdade\n~~\nIdade\n\n76.0307760\n10.0047653\n7.599456\n0.0000000\n56.0333506\n94.1240338\n\n\nIMC1\n~~\nIMC1\n\n17.7567863\n0.0000000\nNA\nNA\n17.7567863\n17.7567863\n\n\nIndireto\n:=\na*b\nIndireto\n1.1709992\n0.5250816\n2.230128\n0.0257389\n0.3217028\n2.4318595\n\n\nTotal_direto_C\n:=\na*b+c_\nTotal_direto_C\n-1.6071651\n1.0118606\n-1.588326\n0.1122125\n-3.3648125\n0.5045181\n\n\n\n\n\n\nResultados\n\nRegressões:\n\nA relação estimada entre IMC1 (Índice de Massa Corporal) e Treinos é -2.778, indicando uma relação negativa e significativa (p = 0.006).\nA relação estimada entre Idade e Treinos é 1.928, indicando uma relação positiva e significativa (p = 0.000).\nA relação estimada entre IMC e Idade é 0.608 e é estatisticamente significativa (p = 0.005).\n\nParâmetros Definidos:\n\nO efeito Indireto é estimado como 1.171 e é estatisticamente significativo (p = 0.030). Isso sugere que a variável Idade medeia significativamente a relação entre IMC e Treinos.\nO efeito total direto de IMC nos Treinos é estimado como -1.607, mas não é estatisticamente significativo (p = 0.114).\n\n\nOs resultados indicam que a variável IMC está significativamente relacionada negativamente à variável Treinos. A variável Idade atua como mediadora nessa relação. O efeito indireto é estimado como 1.171 (p = 0.030), indicando que a inclusão de Idade no modelo altera a relação entre IMC1 e Treinos, tornando-a mais negativa do que a relação direta.",
    "crumbs": [
      "SEM",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Lista 8.1 - Moderação e Mediação</span>"
    ]
  },
  {
    "objectID": "lista_8_1.html#diagrama-do-modelo-3",
    "href": "lista_8_1.html#diagrama-do-modelo-3",
    "title": "1  Lista 8.1 - Moderação e Mediação",
    "section": "1.5 Diagrama do modelo 3",
    "text": "1.5 Diagrama do modelo 3\n\ndiagrama_3 &lt;- semPaths(\n          object = fit_3,\n          what = \"path\",\n          whatLabels = \"par\",\n          style = \"ram\",\n          layout = \"tree\",\n          rotation = 2,\n          sizeMan = 7,\n          sizeLat = 7,\n          color = \"lightgray\",\n          edge.label.cex = 1.2,\n          label.cex = 1.3\n)\n\n\n\n\n\n\n\n\n\nmediation_model_3 = lm(Idade ~ IMC1, data = original)\nsummary(mediation_model_3)$coef\n\n              Estimate Std. Error  t value    Pr(&gt;|t|)\n(Intercept) 18.3591515   5.639405 3.255512 0.001584908\nIMC1         0.6075027   0.215734 2.815980 0.005949584\n\nvisualize(mediation_model_3) \n\n\n\n\n\n\n\n\n\nfull_model_3 = lm(Treinos ~ Idade + IMC1, data = original)\nsummary(full_model_3)$coef\n\n             Estimate Std. Error   t value     Pr(&gt;|t|)\n(Intercept) 87.606237 31.2333809  2.804891 0.0061538896\nIdade        1.927562  0.5467836  3.525274 0.0006645242\nIMC1        -2.778164  1.1791838 -2.356006 0.0206193649\n\nvisualize(full_model_3)\n\n\n\n\n\n\n\n\n\nresults_3 = mediate(mediation_model_3, full_model_3,\n                  treat = \"IMC1\",\n                  mediator = \"Idade\",\n                  boot = TRUE,\n                  sims = 500)\n\nsummary(results_3)\n\n\nCausal Mediation Analysis \n\nNonparametric Bootstrap Confidence Intervals with the Percentile Method\n\n               Estimate 95% CI Lower 95% CI Upper p-value  \nACME            1.17100      0.23780      2.20968   0.012 *\nADE            -2.77816     -4.40516     -0.48847   0.016 *\nTotal Effect   -1.60717     -3.42511      0.84391   0.148  \nProp. Mediated -0.72861     -6.25079      3.86477   0.160  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nSample Size Used: 94 \n\n\nSimulations: 500 \n\n\n\nmediate_plot(Treinos ~ Idade  + IMC1  , data = original)",
    "crumbs": [
      "SEM",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Lista 8.1 - Moderação e Mediação</span>"
    ]
  },
  {
    "objectID": "lista_8_1.html#lista-8.1-resolvida-no-spss",
    "href": "lista_8_1.html#lista-8.1-resolvida-no-spss",
    "title": "1  Lista 8.1 - Moderação e Mediação",
    "section": "1.6 Lista 8.1 resolvida no SPSS",
    "text": "1.6 Lista 8.1 resolvida no SPSS",
    "crumbs": [
      "SEM",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Lista 8.1 - Moderação e Mediação</span>"
    ]
  },
  {
    "objectID": "lista_8_1.html#extras",
    "href": "lista_8_1.html#extras",
    "title": "1  Lista 8.1 - Moderação e Mediação",
    "section": "1.7 Extras!",
    "text": "1.7 Extras!\nOutro tipo de resolução baseada no vídeo do Dustin Fife (How to do a mediation analysis in R…with visuals!)\n\n# Mediação com visualização\nlibrary(mediation)\nlibrary(flexplot)\n\n\nmediation_model = lm(IMC1 ~ Sociabilidade, data = original)\nsummary(mediation_model)\n\n\nCall:\nlm(formula = IMC1 ~ Sociabilidade, data = original)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-7.3645 -2.8931 -0.4598  2.7881 14.5354 \n\nCoefficients:\n              Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)   25.39715    1.22381  20.753   &lt;2e-16 ***\nSociabilidade  0.01905    0.05421   0.351    0.726    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 4.257 on 92 degrees of freedom\nMultiple R-squared:  0.001341,  Adjusted R-squared:  -0.009514 \nF-statistic: 0.1235 on 1 and 92 DF,  p-value: 0.726\n\n\n\nvisualize(mediation_model, plot = \"model\")\n\n\n\n\n\n\n\n\n\nfull_model = lm(Treinos ~ IMC1 + Sociabilidade, data = original)\nsummary(full_model)\n\n\nCall:\nlm(formula = Treinos ~ IMC1 + Sociabilidade, data = original)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-85.683 -42.165   2.807  47.623  69.596 \n\nCoefficients:\n              Estimate Std. Error t value Pr(&gt;|t|)   \n(Intercept)   111.3389    33.5982   3.314  0.00132 **\nIMC1           -1.6498     1.2009  -1.374  0.17287   \nSociabilidade   0.6052     0.6248   0.969  0.33525   \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 49.03 on 91 degrees of freedom\nMultiple R-squared:  0.02915,   Adjusted R-squared:  0.00781 \nF-statistic: 1.366 on 2 and 91 DF,  p-value: 0.2603\n\n\n\nvisualize(full_model)\n\n\n\n\n\n\n\n\n\nresults = mediate(mediation_model, full_model,\n                  treat = \"Sociabilidade\",\n                  mediator = \"IMC1\",\n                  boot = TRUE,\n                  sims = 500)\n\n\nsummary(results)\n\n\nCausal Mediation Analysis \n\nNonparametric Bootstrap Confidence Intervals with the Percentile Method\n\n                Estimate 95% CI Lower 95% CI Upper p-value\nACME           -0.031432    -0.208155     0.220546   0.748\nADE             0.605224    -0.581768     2.016734   0.324\nTotal Effect    0.573792    -0.626790     2.042318   0.324\nProp. Mediated -0.054780    -0.897646     1.226252   0.944\n\nSample Size Used: 94 \n\n\nSimulations: 500 \n\n\n\nmediate_plot(Treinos ~ IMC1 +  Sociabilidade, data = original) # Ordem em que aparece as variáveis é muito importante. A última variável será sempre a variável DEPENDENTE (X). Todas as outras que vierem antes dela, serão tratadas como MEDIADORAS (no caso IMC1)",
    "crumbs": [
      "SEM",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Lista 8.1 - Moderação e Mediação</span>"
    ]
  },
  {
    "objectID": "lista_8_1.html#referências",
    "href": "lista_8_1.html#referências",
    "title": "1  Lista 8.1 - Moderação e Mediação",
    "section": "1.8 Referências",
    "text": "1.8 Referências\nhttps://www.youtube.com/watch?v=_4Fu8SZID2k",
    "crumbs": [
      "SEM",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Lista 8.1 - Moderação e Mediação</span>"
    ]
  },
  {
    "objectID": "lista_8_1.html#versões-dos-pacotes",
    "href": "lista_8_1.html#versões-dos-pacotes",
    "title": "1  Lista 8.1 - Moderação e Mediação",
    "section": "1.9 Versões dos pacotes",
    "text": "1.9 Versões dos pacotes\n\nreport(sessionInfo())\n\nAnalyses were conducted using the R Statistical language (version 4.4.2; R Core\nTeam, 2024) on Windows 11 x64 (build 26100), using the packages Matrix (version\n1.7.1; Bates D et al., 2024), effectsize (version 1.0.1; Ben-Shachar MS et al.,\n2020), semPlot (version 1.1.6; Epskamp S, 2022), flexplot (version 0.24.3;\nFife, D, 2022), mvtnorm (version 1.3.3; Genz A, Bretz F, 2009), lubridate\n(version 1.9.4; Grolemund G, Wickham H, 2011), semTools (version 0.5.7;\nJorgensen TD et al., 2025), parameters (version 0.28.3; Lüdecke D et al.,\n2020), performance (version 0.15.2; Lüdecke D et al., 2021), easystats (version\n0.7.5; Lüdecke D et al., 2022), see (version 0.12.0; Lüdecke D et al., 2021),\ninsight (version 1.4.4; Lüdecke D et al., 2019), bayestestR (version 0.17.0;\nMakowski D et al., 2019), modelbased (version 0.13.1; Makowski D et al., 2025),\nreport (version 0.6.3; Makowski D et al., 2023), correlation (version 0.8.8;\nMakowski D et al., 2022), tibble (version 3.3.1; Müller K, Wickham H, 2026),\ndatawizard (version 1.3.0; Patil I et al., 2022), foreign (version 0.8.87; R\nCore Team, 2024), lavaan (version 0.6.19; Rosseel Y, 2012), mediation (version\n4.5.1; Tingley D et al., 2014), MASS (version 7.3.61; Venables WN, Ripley BD,\n2002), ggplot2 (version 4.0.1; Wickham H, 2016), forcats (version 1.0.0;\nWickham H, 2023), stringr (version 1.5.1; Wickham H, 2023), tidyverse (version\n2.0.0; Wickham H et al., 2019), dplyr (version 1.1.4; Wickham H et al., 2023),\npurrr (version 1.0.4; Wickham H, Henry L, 2025), readr (version 2.1.5; Wickham\nH et al., 2024), tidyr (version 1.3.1; Wickham H et al., 2024), sandwich\n(version 3.1.1; Zeileis A et al., 2020) and kableExtra (version 1.4.0; Zhu H,\n2024).\n\nReferences\n----------\n  - Bates D, Maechler M, Jagan M (2024). _Matrix: Sparse and Dense Matrix Classes\nand Methods_. R package version 1.7-1,\n&lt;https://CRAN.R-project.org/package=Matrix&gt;.\n  - Ben-Shachar MS, Lüdecke D, Makowski D (2020). \"effectsize: Estimation of\nEffect Size Indices and Standardized Parameters.\" _Journal of Open Source\nSoftware_, *5*(56), 2815. doi:10.21105/joss.02815\n&lt;https://doi.org/10.21105/joss.02815&gt;, &lt;https://doi.org/10.21105/joss.02815&gt;.\n  - Epskamp S (2022). _semPlot: Path Diagrams and Visual Analysis of Various SEM\nPackages' Output_. R package version 1.1.6,\n&lt;https://CRAN.R-project.org/package=semPlot&gt;.\n  - Fife, A. D (2022). \"Flexplot: Graphically-based data analysis.\"\n_Psychological Methods_, *27*(4), -19. &lt;doi.org/10.1037/met0000424&gt;.\n  - Genz A, Bretz F (2009). _Computation of Multivariate Normal and t\nProbabilities_, series Lecture Notes in Statistics. Springer-Verlag,\nHeidelberg. ISBN 978-3-642-01688-2.\n  - Grolemund G, Wickham H (2011). \"Dates and Times Made Easy with lubridate.\"\n_Journal of Statistical Software_, *40*(3), 1-25.\n&lt;https://www.jstatsoft.org/v40/i03/&gt;.\n  - Jorgensen TD, Pornprasertmanit S, Schoemann AM, Rosseel Y (2025).\n_\\texttt{semTools}: Useful tools for structural equation modeling_. R package\nversion 0.5-7, &lt;https://CRAN.R-project.org/package=semTools&gt;.\n  - Lüdecke D, Ben-Shachar M, Patil I, Makowski D (2020). \"Extracting, Computing\nand Exploring the Parameters of Statistical Models using R.\" _Journal of Open\nSource Software_, *5*(53), 2445. doi:10.21105/joss.02445\n&lt;https://doi.org/10.21105/joss.02445&gt;.\n  - Lüdecke D, Ben-Shachar M, Patil I, Waggoner P, Makowski D (2021).\n\"performance: An R Package for Assessment, Comparison and Testing of\nStatistical Models.\" _Journal of Open Source Software_, *6*(60), 3139.\ndoi:10.21105/joss.03139 &lt;https://doi.org/10.21105/joss.03139&gt;.\n  - Lüdecke D, Ben-Shachar M, Patil I, Wiernik B, Bacher E, Thériault R, Makowski\nD (2022). \"easystats: Framework for Easy Statistical Modeling, Visualization,\nand Reporting.\" _CRAN_. doi:10.32614/CRAN.package.easystats\n&lt;https://doi.org/10.32614/CRAN.package.easystats&gt;, R package,\n&lt;https://easystats.github.io/easystats/&gt;.\n  - Lüdecke D, Patil I, Ben-Shachar M, Wiernik B, Waggoner P, Makowski D (2021).\n\"see: An R Package for Visualizing Statistical Models.\" _Journal of Open Source\nSoftware_, *6*(64), 3393. doi:10.21105/joss.03393\n&lt;https://doi.org/10.21105/joss.03393&gt;.\n  - Lüdecke D, Waggoner P, Makowski D (2019). \"insight: A Unified Interface to\nAccess Information from Model Objects in R.\" _Journal of Open Source Software_,\n*4*(38), 1412. doi:10.21105/joss.01412 &lt;https://doi.org/10.21105/joss.01412&gt;.\n  - Makowski D, Ben-Shachar M, Lüdecke D (2019). \"bayestestR: Describing Effects\nand their Uncertainty, Existence and Significance within the Bayesian\nFramework.\" _Journal of Open Source Software_, *4*(40), 1541.\ndoi:10.21105/joss.01541 &lt;https://doi.org/10.21105/joss.01541&gt;,\n&lt;https://joss.theoj.org/papers/10.21105/joss.01541&gt;.\n  - Makowski D, Ben-Shachar M, Wiernik B, Patil I, Thériault R, Lüdecke D (2025).\n\"modelbased: An R package to make the most out of your statistical models\nthrough marginal means, marginal effects, and model predictions.\" _Journal of\nOpen Source Software_, *10*(109), 7969. doi:10.21105/joss.07969\n&lt;https://doi.org/10.21105/joss.07969&gt;,\n&lt;https://joss.theoj.org/papers/10.21105/joss.07969&gt;.\n  - Makowski D, Lüdecke D, Patil I, Thériault R, Ben-Shachar M, Wiernik B (2023).\n\"Automated Results Reporting as a Practical Tool to Improve Reproducibility and\nMethodological Best Practices Adoption.\" _CRAN_.\ndoi:10.32614/CRAN.package.report\n&lt;https://doi.org/10.32614/CRAN.package.report&gt;,\n&lt;https://easystats.github.io/report/&gt;.\n  - Makowski D, Wiernik B, Patil I, Lüdecke D, Ben-Shachar M (2022).\n\"correlation: Methods for Correlation Analysis.\" Version 0.8.3,\n&lt;https://CRAN.R-project.org/package=correlation&gt;. Makowski D, Ben-Shachar M,\nPatil I, Lüdecke D (2020). \"Methods and Algorithms for Correlation Analysis in\nR.\" _Journal of Open Source Software_, *5*(51), 2306. doi:10.21105/joss.02306\n&lt;https://doi.org/10.21105/joss.02306&gt;,\n&lt;https://joss.theoj.org/papers/10.21105/joss.02306&gt;.\n  - Müller K, Wickham H (2026). _tibble: Simple Data Frames_. R package version\n3.3.1, &lt;https://CRAN.R-project.org/package=tibble&gt;.\n  - Patil I, Makowski D, Ben-Shachar M, Wiernik B, Bacher E, Lüdecke D (2022).\n\"datawizard: An R Package for Easy Data Preparation and Statistical\nTransformations.\" _Journal of Open Source Software_, *7*(78), 4684.\ndoi:10.21105/joss.04684 &lt;https://doi.org/10.21105/joss.04684&gt;.\n  - R Core Team (2024). _foreign: Read Data Stored by 'Minitab', 'S', 'SAS',\n'SPSS', 'Stata', 'Systat', 'Weka', 'dBase', ..._. R package version 0.8-87,\n&lt;https://CRAN.R-project.org/package=foreign&gt;.\n  - R Core Team (2024). _R: A Language and Environment for Statistical\nComputing_. R Foundation for Statistical Computing, Vienna, Austria.\n&lt;https://www.R-project.org/&gt;.\n  - Rosseel Y (2012). \"lavaan: An R Package for Structural Equation Modeling.\"\n_Journal of Statistical Software_, *48*(2), 1-36. doi:10.18637/jss.v048.i02\n&lt;https://doi.org/10.18637/jss.v048.i02&gt;.\n  - Tingley D, Yamamoto T, Hirose K, Keele L, Imai K (2014). \"mediation: R\nPackage for Causal Mediation Analysis.\" _Journal of Statistical Software_,\n*59*(5), 1-38. &lt;https://www.jstatsoft.org/v59/i05/&gt;. Imai K, Keele L, Yamamoto\nT (2010). \"Identification, Inference, and Sensitivity Analysis for Causal\nMediation Effects.\" _Statistical Science_, *25*(1), 51-71.\n&lt;https://imai.fas.harvard.edu/research/mediation.html&gt;. Imai K, Keele L,\nTingley D (2010). \"A General Approach to Causal Mediation Analysis.\"\n_Psychological Methods_, *15*(4), 309-334.\n&lt;https://imai.fas.harvard.edu/research/BaronKenny.html&gt;. Imai K, Keele L,\nTingley D, Yamamoto T (2011). \"Unpacking the Black Box of Causality: Learning\nabout Causal Mechanisms from Experimental and Observational Studies.\" _American\nPolitical Science Review_, *105*(4), 765-789.\n&lt;https://imai.fas.harvard.edu/research/mediationP.html&gt;. Imai K, Yamamoto T\n(2013). \"Identification and Sensitivity Analysis for Multiple Causal\nMechanisms: Revisiting Evidence from Framing Experiments.\" _Political\nAnalysis_, *21*(2), 141-171.\n&lt;https://imai.fas.harvard.edu/research/medsens.html&gt;. Imai K, Keele L, Tingley\nD, Yamamoto T (2010). \"Causal Mediation Analysis Using R.\" In Vinod HD (ed.),\n_Advances in Social Science Research Using R_. Springer-Verlag, New York.\n  - Venables WN, Ripley BD (2002). _Modern Applied Statistics with S_, Fourth\nedition. Springer, New York. ISBN 0-387-95457-0,\n&lt;https://www.stats.ox.ac.uk/pub/MASS4/&gt;.\n  - Wickham H (2016). _ggplot2: Elegant Graphics for Data Analysis_.\nSpringer-Verlag New York. ISBN 978-3-319-24277-4,\n&lt;https://ggplot2.tidyverse.org&gt;.\n  - Wickham H (2023). _forcats: Tools for Working with Categorical Variables\n(Factors)_. R package version 1.0.0,\n&lt;https://CRAN.R-project.org/package=forcats&gt;.\n  - Wickham H (2023). _stringr: Simple, Consistent Wrappers for Common String\nOperations_. R package version 1.5.1,\n&lt;https://CRAN.R-project.org/package=stringr&gt;.\n  - Wickham H, Averick M, Bryan J, Chang W, McGowan LD, François R, Grolemund G,\nHayes A, Henry L, Hester J, Kuhn M, Pedersen TL, Miller E, Bache SM, Müller K,\nOoms J, Robinson D, Seidel DP, Spinu V, Takahashi K, Vaughan D, Wilke C, Woo K,\nYutani H (2019). \"Welcome to the tidyverse.\" _Journal of Open Source Software_,\n*4*(43), 1686. doi:10.21105/joss.01686 &lt;https://doi.org/10.21105/joss.01686&gt;.\n  - Wickham H, François R, Henry L, Müller K, Vaughan D (2023). _dplyr: A Grammar\nof Data Manipulation_. R package version 1.1.4,\n&lt;https://CRAN.R-project.org/package=dplyr&gt;.\n  - Wickham H, Henry L (2025). _purrr: Functional Programming Tools_. R package\nversion 1.0.4, &lt;https://CRAN.R-project.org/package=purrr&gt;.\n  - Wickham H, Hester J, Bryan J (2024). _readr: Read Rectangular Text Data_. R\npackage version 2.1.5, &lt;https://CRAN.R-project.org/package=readr&gt;.\n  - Wickham H, Vaughan D, Girlich M (2024). _tidyr: Tidy Messy Data_. R package\nversion 1.3.1, &lt;https://CRAN.R-project.org/package=tidyr&gt;.\n  - Zeileis A, Köll S, Graham N (2020). \"Various Versatile Variances: An\nObject-Oriented Implementation of Clustered Covariances in R.\" _Journal of\nStatistical Software_, *95*(1), 1-36. doi:10.18637/jss.v095.i01\n&lt;https://doi.org/10.18637/jss.v095.i01&gt;. Zeileis A (2004). \"Econometric\nComputing with HC and HAC Covariance Matrix Estimators.\" _Journal of\nStatistical Software_, *11*(10), 1-17. doi:10.18637/jss.v011.i10\n&lt;https://doi.org/10.18637/jss.v011.i10&gt;. Zeileis A (2006). \"Object-Oriented\nComputation of Sandwich Estimators.\" _Journal of Statistical Software_,\n*16*(9), 1-16. doi:10.18637/jss.v016.i09\n&lt;https://doi.org/10.18637/jss.v016.i09&gt;.\n  - Zhu H (2024). _kableExtra: Construct Complex Table with 'kable' and Pipe\nSyntax_. R package version 1.4.0,\n&lt;https://CRAN.R-project.org/package=kableExtra&gt;.",
    "crumbs": [
      "SEM",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Lista 8.1 - Moderação e Mediação</span>"
    ]
  },
  {
    "objectID": "lista_2.html",
    "href": "lista_2.html",
    "title": "Lista 2: GEE Avançado",
    "section": "",
    "text": "📦 Pacotes Necessários\n# Lista completa de pacotes\npacotes &lt;- c(\n  \"emmeans\", \"lme4\", \"nlme\", \"flexplot\", \"foreign\",\n  \"tidyr\", \"dplyr\", \"multcomp\", \"effects\", \"sjstats\",\n  \"car\", \"rstatix\", \"geepack\", \"performance\", \"see\",\n  \"rempsyc\", \"easystats\", \"GGally\", \"gee\", \"tweedie\",\n  \"stats\", \"statmod\", \"fitdistrplus\", \"ggplot2\"\n)\n\n# Verificar e instalar faltantes\npacotes_faltantes &lt;- pacotes[!pacotes %in% installed.packages()[, \"Package\"]]\nif (length(pacotes_faltantes) &gt; 0) {\n  cat(\"Instalando:\", paste(pacotes_faltantes, collapse = \", \"), \"\\n\")\n  install.packages(pacotes_faltantes, dependencies = TRUE)\n}\n\n# Carregar silenciosamente\ninvisible(lapply(pacotes, library, character.only = TRUE))\ncat(\"✓ Pacotes carregados!\\n\")\n\n✓ Pacotes carregados!",
    "crumbs": [
      "Modelos Lineares",
      "Lista 2: GEE Avançado"
    ]
  },
  {
    "objectID": "lista_2.html#exercícios",
    "href": "lista_2.html#exercícios",
    "title": "2  Lista 2 - GEE",
    "section": "2.2 Exercícios",
    "text": "2.2 Exercícios\n\na) GEE com a VD “Pulse”\nUtilize um GEE para verificar o efeito de tempo e grupo sobre os resultados de resp e pulse. Faça 3 modelos para cada variável dependente (com as distribuições Normal, Gamma e Tweedie) e cole aqui apenas as tabelas relevantes para a análise.\n\nDistribuição normal\n\nCriando o modelo\n\nmodel_gee_tweedie &lt;- glmmTMB::glmmTMB(formula = resp ~ Tempo*drug + us(1 + Tempo | ID),\n                                      family = gaussian(),# tweedie(var.power = 1.5, link.power = 0),  # Definindo a família Tweedie\n                                      data = bd_long  # Seu conjunto de dados\n  #corstr = \"exchangeable\"  # Estrutura de correlação (pode ser \"independence\", \"exchangeable\", etc.)\n)\n\nWarning in finalizeTMB(TMBStruc, obj, fit, h, data.tmb.old): Model convergence\nproblem; non-positive-definite Hessian matrix. See vignette('troubleshooting')\n\nAIC(model_gee_tweedie)\n\n[1] NA\n\nrm(model_gee_tweedie)\n\n\nmodelo_gee_pulse_normal &lt;- geeglm(pulse ~ drug + Tempo + drug*Tempo, \n                           data = bd_long,         \n                           id = ID,                 \n                           family = gaussian, #Distribuição normal      \n                           corstr = \"unstructured\")\n\n\n\nResumo do modelo e contrastes\n\nsummary(modelo_gee_pulse_normal)\n\n\nCall:\ngeeglm(formula = pulse ~ drug + Tempo + drug * Tempo, family = gaussian, \n    data = bd_long, id = ID, corstr = \"unstructured\")\n\n Coefficients:\n                   Estimate Std.err     Wald Pr(&gt;|W|)    \n(Intercept)         2.20000 0.04082 2904.000  &lt; 2e-16 ***\ndrugPlacebo         0.46667 0.05092   84.000  &lt; 2e-16 ***\nTempo2              0.01667 0.03664    0.207  0.64921    \nTempo3              0.08333 0.06838    1.485  0.22297    \ndrugPlacebo:Tempo2  0.13333 0.04194   10.105  0.00148 ** \ndrugPlacebo:Tempo3  0.03333 0.08767    0.145  0.70377    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nCorrelation structure = unstructured \nEstimated Scale Parameters:\n\n            Estimate  Std.err\n(Intercept)  0.00963 0.001676\n  Link = identity \n\nEstimated Correlation Parameters:\n          Estimate Std.err\nalpha.1:2   0.7212  0.1690\nalpha.1:3  -0.2885  0.2076\nalpha.2:3   0.1154  0.2665\nNumber of clusters:   12  Maximum cluster size: 3 \n\nemmeans(modelo_gee_pulse_normal, pairwise ~ drug*Tempo)\n\n$emmeans\n drug     Tempo emmean     SE df lower.CL upper.CL\n New Drug 1       2.20 0.0408 30     2.12     2.28\n Placebo  1       2.67 0.0304 30     2.60     2.73\n New Drug 2       2.22 0.0549 30     2.10     2.33\n Placebo  2       2.82 0.0280 30     2.76     2.87\n New Drug 3       2.28 0.0436 30     2.19     2.37\n Placebo  3       2.78 0.0366 30     2.71     2.86\n\nCovariance estimate used: vbeta \nConfidence level used: 0.95 \n\n$contrasts\n contrast                          estimate     SE df t.ratio p.value\n New Drug Tempo1 - Placebo Tempo1   -0.4667 0.0509 30  -9.165  &lt;.0001\n New Drug Tempo1 - New Drug Tempo2  -0.0167 0.0366 30  -0.455  0.9973\n New Drug Tempo1 - Placebo Tempo2   -0.6167 0.0495 30 -12.449  &lt;.0001\n New Drug Tempo1 - New Drug Tempo3  -0.0833 0.0684 30  -1.219  0.8244\n New Drug Tempo1 - Placebo Tempo3   -0.5833 0.0549 30 -10.634  &lt;.0001\n Placebo Tempo1 - New Drug Tempo2    0.4500 0.0627 30   7.173  &lt;.0001\n Placebo Tempo1 - Placebo Tempo2    -0.1500 0.0204 30  -7.348  &lt;.0001\n Placebo Tempo1 - New Drug Tempo3    0.3833 0.0531 30   7.213  &lt;.0001\n Placebo Tempo1 - Placebo Tempo3    -0.1167 0.0549 30  -2.127  0.3013\n New Drug Tempo2 - Placebo Tempo2   -0.6000 0.0616 30  -9.738  &lt;.0001\n New Drug Tempo2 - New Drug Tempo3  -0.0667 0.0609 30  -1.095  0.8793\n New Drug Tempo2 - Placebo Tempo3   -0.5667 0.0660 30  -8.590  &lt;.0001\n Placebo Tempo2 - New Drug Tempo3    0.5333 0.0518 30  10.292  &lt;.0001\n Placebo Tempo2 - Placebo Tempo3     0.0333 0.0509 30   0.655  0.9855\n New Drug Tempo3 - Placebo Tempo3   -0.5000 0.0569 30  -8.783  &lt;.0001\n\nP value adjustment: tukey method for comparing a family of 6 estimates \n\n\n\n\nVerificando os pressupostos\n\n# Plotar o diagnóstico do modelo GEE para a variável 'pulse'\n\ncheck_model(modelo_gee_pulse_normal)\n\nConverting missing values (`NA`) into regular values currently not\n  possible for variables of class `NULL`.\n\n\nFailed to compute posterior predictive checks with `re_formula=NULL`.\n  Trying again with `re_formula=NA` now.\n\n\n\n\n\n\n\n\n\n\n\nPlot dos resultados\n\n# Salvando os resultados do modelo em uma variável\n\nmeans_ci_normal = emmeans(modelo_gee_pulse_normal, specs = ~drug:Tempo)\n\n\n# Plotar as médias e intervalos de confiança\n\nggplot(as.data.frame(means_ci_normal), aes(x = Tempo, y = emmean, color = drug)) +\n  geom_errorbar(aes(ymin = lower.CL, ymax = upper.CL), width = 0.2, position = position_dodge(0.8)) +\n  geom_point(position = position_dodge(0.8), size = 3) +\n  labs(title = \"Distribuição Normal\",\n       x = \"Tempo\",\n       y = \"Pulse\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\n\n\n\nDistribuição gamma\n\nCriando o modelo\n\nmodelo_gee_pulse_gamma &lt;- geeglm(pulse ~ drug + Tempo + drug*Tempo, \n                           data = bd_long,         \n                           id = ID,                 \n                           family = Gamma(link = \"identity\"), #Distribuição Gamma      \n                           corstr = \"unstructured\")\n\n\n\nResumo do modelo e contrastes\n\nsummary(modelo_gee_pulse_gamma)\n\n\nCall:\ngeeglm(formula = pulse ~ drug + Tempo + drug * Tempo, family = Gamma(link = \"identity\"), \n    data = bd_long, id = ID, corstr = \"unstructured\")\n\n Coefficients:\n                   Estimate Std.err    Wald Pr(&gt;|W|)    \n(Intercept)          2.2000  0.0408 2904.00   &lt;2e-16 ***\ndrugPlacebo          0.4667  0.0509   84.00   &lt;2e-16 ***\nTempo2               0.0167  0.0366    0.21   0.6492    \nTempo3               0.0833  0.0684    1.49   0.2230    \ndrugPlacebo:Tempo2   0.1333  0.0419   10.11   0.0015 ** \ndrugPlacebo:Tempo3   0.0333  0.0877    0.14   0.7038    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nCorrelation structure = unstructured \nEstimated Scale Parameters:\n\n            Estimate  Std.err\n(Intercept)  0.00172 0.000372\n  Link = identity \n\nEstimated Correlation Parameters:\n          Estimate Std.err\nalpha.1:2    0.745   0.178\nalpha.1:3   -0.279   0.208\nalpha.2:3    0.156   0.279\nNumber of clusters:   12  Maximum cluster size: 3 \n\nemmeans(modelo_gee_pulse_gamma, pairwise ~ drug*Tempo)\n\n$emmeans\n drug     Tempo emmean     SE df lower.CL upper.CL\n New Drug 1       2.20 0.0408 30     2.12     2.28\n Placebo  1       2.67 0.0304 30     2.60     2.73\n New Drug 2       2.22 0.0549 30     2.10     2.33\n Placebo  2       2.82 0.0281 30     2.76     2.87\n New Drug 3       2.28 0.0436 30     2.19     2.37\n Placebo  3       2.78 0.0366 30     2.71     2.86\n\nCovariance estimate used: vbeta \nConfidence level used: 0.95 \n\n$contrasts\n contrast                          estimate     SE df t.ratio p.value\n New Drug Tempo1 - Placebo Tempo1    -0.467 0.0509 30  -9.170  &lt;.0001\n New Drug Tempo1 - New Drug Tempo2   -0.017 0.0366 30  -0.450  0.9970\n New Drug Tempo1 - Placebo Tempo2    -0.617 0.0495 30 -12.450  &lt;.0001\n New Drug Tempo1 - New Drug Tempo3   -0.083 0.0684 30  -1.220  0.8240\n New Drug Tempo1 - Placebo Tempo3    -0.583 0.0549 30 -10.630  &lt;.0001\n Placebo Tempo1 - New Drug Tempo2     0.450 0.0627 30   7.170  &lt;.0001\n Placebo Tempo1 - Placebo Tempo2     -0.150 0.0204 30  -7.350  &lt;.0001\n Placebo Tempo1 - New Drug Tempo3     0.383 0.0531 30   7.210  &lt;.0001\n Placebo Tempo1 - Placebo Tempo3     -0.117 0.0549 30  -2.130  0.3010\n New Drug Tempo2 - Placebo Tempo2    -0.600 0.0616 30  -9.740  &lt;.0001\n New Drug Tempo2 - New Drug Tempo3   -0.067 0.0609 30  -1.100  0.8790\n New Drug Tempo2 - Placebo Tempo3    -0.567 0.0660 30  -8.590  &lt;.0001\n Placebo Tempo2 - New Drug Tempo3     0.533 0.0518 30  10.290  &lt;.0001\n Placebo Tempo2 - Placebo Tempo3      0.033 0.0509 30   0.650  0.9860\n New Drug Tempo3 - Placebo Tempo3    -0.500 0.0569 30  -8.780  &lt;.0001\n\nP value adjustment: tukey method for comparing a family of 6 estimates \n\n\n\n\nVerificando os pressupostos\n\n# Plotar o diagnóstico do modelo GEE para a variável 'pulse'\n\ncheck_model(modelo_gee_pulse_gamma)\n\nConverting missing values (`NA`) into regular values currently not\n  possible for variables of class `NULL`.\n\n\nFailed to compute posterior predictive checks with `re_formula=NULL`.\n  Trying again with `re_formula=NA` now.\n\n\nCannot simulate residuals for models of class `geeglm`. Please try\n  `check_model(..., residual_type = \"normal\")` instead.\n\n\n\n\n\n\n\n\n\n\n\nPlot dos resultados\n\n# Salvando os resultados do modelo em uma variável\n\nmeans_ci_gamma = emmeans(modelo_gee_pulse_gamma, specs = ~drug:Tempo)\n\n\n# Plotar as médias e intervalos de confiança\n\nggplot(as.data.frame(means_ci_gamma), aes(x = Tempo, y = emmean, color = drug)) +\n  geom_errorbar(aes(ymin = lower.CL, ymax = upper.CL), width = 0.2, position = position_dodge(0.8)) +\n  geom_point(position = position_dodge(0.8), size = 3) +\n  labs(title = \"Distribuição Gamma\",\n       x = \"Tempo\",\n       y = \"Pulse\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\n\n\n\nDistribuição tweedie\n\nCriando o modelo\n\nmodelo_gee_pulse_tweedie &lt;- glm(pulse ~ drug + Tempo + drug*Tempo, \n                           data = bd_long,\n                          # id = ID, \n                           family = tweedie(var.power=2, link.power = 0),\n                          contrasts = )\n\n\n\n\n\n\n\nAviso!\n\n\n\nUtilizamos a função glm para criar o modelo Tweedie. Estamos trabalhando para criar o modelo com a função GEE. Por hora utilize o SPSS🤮.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nResumo do modelo e contrastes\n\nsummary(modelo_gee_pulse_tweedie)\n\n\nCall:\nglm(formula = pulse ~ drug + Tempo + drug * Tempo, family = tweedie(var.power = 2, \n    link.power = 0), data = bd_long)\n\nCoefficients:\n                   Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)         0.78846    0.01857   42.47  &lt; 2e-16 ***\ndrugPlacebo         0.19237    0.02626    7.33  3.7e-08 ***\nTempo2              0.00755    0.02626    0.29     0.78    \nTempo3              0.03718    0.02626    1.42     0.17    \ndrugPlacebo:Tempo2  0.04718    0.03713    1.27     0.21    \ndrugPlacebo:Tempo3  0.00564    0.03713    0.15     0.88    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for Tweedie family taken to be 0.00207)\n\n    Null deviance: 0.473395  on 35  degrees of freedom\nResidual deviance: 0.062212  on 30  degrees of freedom\nAIC: NA\n\nNumber of Fisher Scoring iterations: 3\n\nemmeans(modelo_gee_pulse_tweedie, pairwise ~ drug*Tempo)\n\n$emmeans\n drug     Tempo emmean     SE  df asymp.LCL asymp.UCL\n New Drug 1      0.788 0.0186 Inf     0.752     0.825\n Placebo  1      0.981 0.0186 Inf     0.944     1.017\n New Drug 2      0.796 0.0186 Inf     0.760     0.832\n Placebo  2      1.036 0.0186 Inf     0.999     1.072\n New Drug 3      0.826 0.0186 Inf     0.789     0.862\n Placebo  3      1.024 0.0186 Inf     0.987     1.060\n\nResults are given on the mu^0 (not the response) scale. \nConfidence level used: 0.95 \n\n$contrasts\n contrast                          estimate     SE  df z.ratio p.value\n New Drug Tempo1 - Placebo Tempo1   -0.1924 0.0263 Inf  -7.330  &lt;.0001\n New Drug Tempo1 - New Drug Tempo2  -0.0075 0.0263 Inf  -0.290  1.0000\n New Drug Tempo1 - Placebo Tempo2   -0.2471 0.0263 Inf  -9.410  &lt;.0001\n New Drug Tempo1 - New Drug Tempo3  -0.0372 0.0263 Inf  -1.420  0.7170\n New Drug Tempo1 - Placebo Tempo3   -0.2352 0.0263 Inf  -8.960  &lt;.0001\n Placebo Tempo1 - New Drug Tempo2    0.1848 0.0263 Inf   7.040  &lt;.0001\n Placebo Tempo1 - Placebo Tempo2    -0.0547 0.0263 Inf  -2.080  0.2950\n Placebo Tempo1 - New Drug Tempo3    0.1552 0.0263 Inf   5.910  &lt;.0001\n Placebo Tempo1 - Placebo Tempo3    -0.0428 0.0263 Inf  -1.630  0.5780\n New Drug Tempo2 - Placebo Tempo2   -0.2395 0.0263 Inf  -9.120  &lt;.0001\n New Drug Tempo2 - New Drug Tempo3  -0.0296 0.0263 Inf  -1.130  0.8700\n New Drug Tempo2 - Placebo Tempo3   -0.2276 0.0263 Inf  -8.670  &lt;.0001\n Placebo Tempo2 - New Drug Tempo3    0.2099 0.0263 Inf   7.990  &lt;.0001\n Placebo Tempo2 - Placebo Tempo3     0.0119 0.0263 Inf   0.450  0.9980\n New Drug Tempo3 - Placebo Tempo3   -0.1980 0.0263 Inf  -7.540  &lt;.0001\n\nNote: contrasts are still on the mu^0 scale. Consider using\n      regrid() if you want contrasts of back-transformed estimates. \nP value adjustment: tukey method for comparing a family of 6 estimates \n\n\n\n\nVerificando os pressupostos\n\n# Plotar o diagnóstico do modelo GEE para a variável 'pulse'\n\ncheck_model(modelo_gee_pulse_tweedie)\n\nCannot simulate residuals for models of class `glm`. Please try\n  `check_model(..., residual_type = \"normal\")` instead.\n\n\n\n\n\n\n\n\n\n\n\nPlot dos resultados\n\n# Salvando os resultados do modelo em uma variável\n\nmeans_ci_tweedie = emmeans(modelo_gee_pulse_tweedie, specs = ~drug:Tempo)\n\n\n# Plotar as médias e intervalos de confiança\n\nggplot(as.data.frame(means_ci_tweedie), aes(x = Tempo, y = emmean, color = drug)) +\n  geom_errorbar(aes(ymin = asymp.LCL, ymax = asymp.UCL), width = 0.2, position = position_dodge(0.8)) +\n  geom_point(position = position_dodge(0.8), size = 3) +\n  labs(title = \"Distribuição Tweedie\",\n       x = \"Tempo\",\n       y = \"Pulse\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\n\n\n\n\nb) QIC\nCompare cada um dos modelos com diferentes distribuições utilizando o QIC (Quasi Likehood Independence Criterion). Os modelos têm diferença entre si nos resultados?\n\n\n\n\n\n\nNota\n\n\n\nA função QIC() não funciona para modelos gerados com as funções glm e lm, apenas com o GEE. Resolveremos em breve! Por hora utilize o SPSS🤮.\n\n\n\nQIC(modelo_gee_pulse_normal)\n\n      QIC      QICu Quasi Lik       CIC    params      QICC \n   12.347    12.347    -0.173     6.000     6.000   102.347 \n\nQIC(modelo_gee_pulse_gamma)\n\n      QIC      QICu Quasi Lik       CIC    params      QICC \n    125.2     125.2     -56.6       6.0       6.0     215.2 \n\n#QIC(modelo_gee_pulse_tweedie)\n\n\n\nc) Sumarizando os resultados\n\n\n\n\n\n\nNota\n\n\n\nA função report() não funciona para modelos gerados com as funções GEE. Aproveite para treinar a escrita no formato de uma publicação acadêmica.\n\n\n\nResutados com distribuição Tweedie\n\nreport(modelo_gee_pulse_tweedie)\n\nWe fitted a general linear model (Tweedie family with a mu^0 link) (estimated\nusing ML) to predict pulse with drug and Tempo (formula: pulse ~ drug + Tempo +\ndrug * Tempo). The model's explanatory power is substantial (Nagelkerke's R2 =\n0.87). The model's intercept, corresponding to drug = New Drug and Tempo = 1,\nis at 0.79 (95% CI [0.75, 0.83], p &lt; .001). Within this model:\n\n  - The effect of drug [Placebo] is statistically significant and positive (beta\n= 0.19, 95% CI [0.14, 0.24], p &lt; .001; Std. beta = 0.19, 95% CI [0.14, 0.24])\n  - The effect of Tempo [2] is statistically non-significant and positive (beta =\n7.55e-03, 95% CI [-0.04, 0.06], p = 0.774; Std. beta = 7.55e-03, 95% CI [-0.04,\n0.06])\n  - The effect of Tempo [3] is statistically non-significant and positive (beta =\n0.04, 95% CI [-0.01, 0.09], p = 0.157; Std. beta = 0.04, 95% CI [-0.01, 0.09])\n  - The effect of drug [Placebo] × Tempo [2] is statistically non-significant and\npositive (beta = 0.05, 95% CI [-0.03, 0.12], p = 0.204; Std. beta = 0.05, 95%\nCI [-0.03, 0.12])\n  - The effect of drug [Placebo] × Tempo [3] is statistically non-significant and\npositive (beta = 5.64e-03, 95% CI [-0.07, 0.08], p = 0.879; Std. beta =\n5.64e-03, 95% CI [-0.07, 0.08])\n\nStandardized parameters were obtained by fitting the model on a standardized\nversion of the dataset. 95% Confidence Intervals (CIs) and p-values were\ncomputed using a Wald z-distribution approximation.",
    "crumbs": [
      "GLM, GEE, GMM, GzLM",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Lista 2 - GEE</span>"
    ]
  },
  {
    "objectID": "lista_2.html#considerações-finais",
    "href": "lista_2.html#considerações-finais",
    "title": "2  Lista 2 - GEE",
    "section": "2.3 Considerações finais",
    "text": "2.3 Considerações finais\nRealizamos todas as análises para a VD Pulse! Agora faça as análises para a variável Reps!\n\n\n\n\n\n\nDica!\n\n\n\nNão faça apenas um copy/paste dos scripts! Treine escrever os códigos e lembre-se de mudar o nome das variáveis do modelo para que não ocorra nenhum conflito! Compare seus resultados com os da aula prática.",
    "crumbs": [
      "GLM, GEE, GMM, GzLM",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Lista 2 - GEE</span>"
    ]
  },
  {
    "objectID": "lista_2.html#lista-2-resolvida-no-spss",
    "href": "lista_2.html#lista-2-resolvida-no-spss",
    "title": "2  Lista 2 - GEE",
    "section": "2.4 Lista 2 resolvida no SPSS",
    "text": "2.4 Lista 2 resolvida no SPSS",
    "crumbs": [
      "GLM, GEE, GMM, GzLM",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Lista 2 - GEE</span>"
    ]
  },
  {
    "objectID": "lista_2.html#referências",
    "href": "lista_2.html#referências",
    "title": "2  Lista 2 - GEE",
    "section": "2.5 Referências",
    "text": "2.5 Referências",
    "crumbs": [
      "GLM, GEE, GMM, GzLM",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Lista 2 - GEE</span>"
    ]
  },
  {
    "objectID": "lista_2.html#versões-dos-pacotes",
    "href": "lista_2.html#versões-dos-pacotes",
    "title": "2  Lista 2 - GEE",
    "section": "2.6 Versões dos pacotes",
    "text": "2.6 Versões dos pacotes\n\nreport(sessionInfo())\n\nAnalyses were conducted using the R Statistical language (version 4.3.3; R Core\nTeam, 2024) on Windows 11 x64 (build 22631), using the packages lme4 (version\n1.1.35.5; Bates D et al., 2015), Matrix (version 1.6.5; Bates D et al., 2024),\neffectsize (version 0.8.9; Ben-Shachar MS et al., 2020), gee (version 4.13.27;\nCarey VJ, 2024), pwr (version 1.3.0; Champely S, 2020), htmltools (version\n0.5.8.1; Cheng J et al., 2024), fitdistrplus (version 1.2.1; Delignette-Muller\nML, Dutang C, 2015), tweedie (version 2.3.5; Dunn PK, Smyth GK, 2005), tm\n(version 0.7.14; Feinerer I, Hornik K, 2024), flexplot (version 0.21.2; Fife,\nD, 2022), effects (version 4.2.2; Fox J, Weisberg S, 2019), car (version 3.1.3;\nFox J, Weisberg S, 2019), carData (version 3.0.5; Fox J et al., 2022), mvtnorm\n(version 1.3.2; Genz A, Bretz F, 2009), statmod (version 1.5.0; Giner G, Smyth\nGK, 2016), geepack (version 1.3.11; Halekoh U et al., 2006), NLP (version\n0.3.0; Hornik K, 2024), TH.data (version 1.1.2; Hothorn T, 2023), multcomp\n(version 1.4.26; Hothorn T et al., 2008), rstatix (version 0.7.2; Kassambara A,\n2023), emmeans (version 1.10.5; Lenth R, 2024), sjstats (version 0.19.0;\nLüdecke D, 2024), parameters (version 0.23.0; Lüdecke D et al., 2020),\nperformance (version 0.12.4; Lüdecke D et al., 2021), easystats (version 0.7.3;\nLüdecke D et al., 2022), see (version 0.8.5; Lüdecke D et al., 2021), insight\n(version 0.20.5; Lüdecke D et al., 2019), survey (version 4.4.2; Lumley T,\n2024), bayestestR (version 0.15.0; Makowski D et al., 2019), modelbased\n(version 0.8.8; Makowski D et al., 2020), report (version 0.5.9; Makowski D et\nal., 2023), correlation (version 0.8.5; Makowski D et al., 2022), datawizard\n(version 0.13.0; Patil I et al., 2022), nlme (version 3.1.166; Pinheiro J et\nal., 2024), foreign (version 0.8.87; R Core Team, 2024), GGally (version 2.2.1;\nSchloerke B et al., 2024), rempsyc (version 0.1.8; Thériault R, 2023), survival\n(version 3.7.0; Therneau T, 2024), MASS (version 7.3.60.0.1; Venables WN,\nRipley BD, 2002), ggplot2 (version 3.5.1; Wickham H, 2016), dplyr (version\n1.1.4; Wickham H et al., 2023), tidyr (version 1.3.1; Wickham H et al., 2024)\nand mime (version 0.12; Xie Y, 2021).\n\nReferences\n----------\n  - Bates D, Mächler M, Bolker B, Walker S (2015). \"Fitting Linear Mixed-Effects\nModels Using lme4.\" _Journal of Statistical Software_, *67*(1), 1-48.\ndoi:10.18637/jss.v067.i01 &lt;https://doi.org/10.18637/jss.v067.i01&gt;.\n  - Bates D, Maechler M, Jagan M (2024). _Matrix: Sparse and Dense Matrix Classes\nand Methods_. R package version 1.6-5,\n&lt;https://CRAN.R-project.org/package=Matrix&gt;.\n  - Ben-Shachar MS, Lüdecke D, Makowski D (2020). \"effectsize: Estimation of\nEffect Size Indices and Standardized Parameters.\" _Journal of Open Source\nSoftware_, *5*(56), 2815. doi:10.21105/joss.02815\n&lt;https://doi.org/10.21105/joss.02815&gt;, &lt;https://doi.org/10.21105/joss.02815&gt;.\n  - Carey VJ (2024). _gee: Generalized Estimation Equation Solver_. R package\nversion 4.13-27, &lt;https://CRAN.R-project.org/package=gee&gt;.\n  - Champely S (2020). _pwr: Basic Functions for Power Analysis_. R package\nversion 1.3-0, &lt;https://CRAN.R-project.org/package=pwr&gt;.\n  - Cheng J, Sievert C, Schloerke B, Chang W, Xie Y, Allen J (2024). _htmltools:\nTools for HTML_. R package version 0.5.8.1,\n&lt;https://CRAN.R-project.org/package=htmltools&gt;.\n  - Delignette-Muller ML, Dutang C (2015). \"fitdistrplus: An R Package for\nFitting Distributions.\" _Journal of Statistical Software_, *64*(4), 1-34.\ndoi:10.18637/jss.v064.i04 &lt;https://doi.org/10.18637/jss.v064.i04&gt;.\n  - Dunn PK, Smyth GK (2005). \"Series evaluation of Tweedie exponential\ndispersion models.\" _Statistics and Computing_, *15*(4), 267-280. Dunn PK,\nSmyth GK (2008). \"Evaluation of Tweedie exponential dispersion models using\nFourier inversion.\" _Statistics and Computing_, *18*(1), 73-86. Dunn PK (2022).\n_Tweedie: Evaluation of Tweedie Exponential Family Models_. R package version\n2.3.5.\n  - Feinerer I, Hornik K (2024). _tm: Text Mining Package_. R package version\n0.7-14, &lt;https://CRAN.R-project.org/package=tm&gt;. Feinerer I, Hornik K, Meyer D\n(2008). \"Text Mining Infrastructure in R.\" _Journal of Statistical Software_,\n*25*(5), 1-54. doi:10.18637/jss.v025.i05\n&lt;https://doi.org/10.18637/jss.v025.i05&gt;.\n  - Fife, A. D (2022). \"Flexplot: Graphically-based data analysis.\"\n_Psychological Methods_, *27*(4), -19. &lt;doi.org/10.1037/met0000424&gt;.\n  - Fox J, Weisberg S (2019). _An R Companion to Applied Regression_, 3rd\nedition. Sage, Thousand Oaks CA.\n&lt;https://socialsciences.mcmaster.ca/jfox/Books/Companion/index.html&gt;. Fox J,\nWeisberg S (2018). \"Visualizing Fit and Lack of Fit in Complex Regression\nModels with Predictor Effect Plots and Partial Residuals.\" _Journal of\nStatistical Software_, *87*(9), 1-27. doi:10.18637/jss.v087.i09\n&lt;https://doi.org/10.18637/jss.v087.i09&gt;. Fox J (2003). \"Effect Displays in R\nfor Generalised Linear Models.\" _Journal of Statistical Software_, *8*(15),\n1-27. doi:10.18637/jss.v008.i15 &lt;https://doi.org/10.18637/jss.v008.i15&gt;. Fox J,\nHong J (2009). \"Effect Displays in R for Multinomial and Proportional-Odds\nLogit Models: Extensions to the effects Package.\" _Journal of Statistical\nSoftware_, *32*(1), 1-24. doi:10.18637/jss.v032.i01\n&lt;https://doi.org/10.18637/jss.v032.i01&gt;.\n  - Fox J, Weisberg S (2019). _An R Companion to Applied Regression_, Third\nedition. Sage, Thousand Oaks CA. &lt;https://www.john-fox.ca/Companion/&gt;.\n  - Fox J, Weisberg S, Price B (2022). _carData: Companion to Applied Regression\nData Sets_. R package version 3.0-5,\n&lt;https://CRAN.R-project.org/package=carData&gt;.\n  - Genz A, Bretz F (2009). _Computation of Multivariate Normal and t\nProbabilities_, series Lecture Notes in Statistics. Springer-Verlag,\nHeidelberg. ISBN 978-3-642-01688-2.\n  - Giner G, Smyth GK (2016). \"statmod: probability calculations for the inverse\nGaussian distribution.\" _R Journal_, *8*(1), 339-351. Phipson B, Smyth GK\n(2010). \"Permutation p-values should never be zero: calculating exact p-values\nwhen permutations are randomly drawn.\" _Statistical Applications in Genetics\nand Molecular Biology_, *9*(1), Article 39. Hu Y, Smyth GK (2009). \"ELDA:\nextreme limiting dilution analysis for comparing depleted and enriched\npopulations in stem cell and other assays.\" _Journal of Immunological Methods_,\n*347*(1), 70-78. Smyth GK (2005). \"Optimization and nonlinear equations.\"\n_Encyclopedia of Biostatistics_, 3088-3095. Smyth GK (2005). \"Numerical\nintegration.\" _Encyclopedia of Biostatistics_, 3088-3095. Smyth GK (2002). \"An\nefficient algorithm for REML in heteroscedastic regression.\" _Journal of\nComputational and Graphical Statistics_, *11*, 836-847. Dunn PK, Smyth GK\n(1996). \"Randomized quantile residuals.\" _J. Comput. Graph. Statist_, *5*,\n236-244.\n  - Halekoh U, Højsgaard S, Yan J (2006). \"The R Package geepack for Generalized\nEstimating Equations.\" _Journal of Statistical Software_, *15/2*, 1-11. Yan J,\nFine JP (2004). \"Estimating Equations for Association Structures.\" _Statistics\nin Medicine_, *23*, 859-880. Yan J (2002). \"geepack: Yet Another Package for\nGeneralized Estimating Equations.\" _R-News_, *2/3*, 12-14.\n  - Hornik K (2024). _NLP: Natural Language Processing Infrastructure_. R package\nversion 0.3-0, &lt;https://CRAN.R-project.org/package=NLP&gt;.\n  - Hothorn T (2023). _TH.data: TH's Data Archive_. R package version 1.1-2,\n&lt;https://CRAN.R-project.org/package=TH.data&gt;.\n  - Hothorn T, Bretz F, Westfall P (2008). \"Simultaneous Inference in General\nParametric Models.\" _Biometrical Journal_, *50*(3), 346-363.\n  - Kassambara A (2023). _rstatix: Pipe-Friendly Framework for Basic Statistical\nTests_. R package version 0.7.2, &lt;https://CRAN.R-project.org/package=rstatix&gt;.\n  - Lenth R (2024). _emmeans: Estimated Marginal Means, aka Least-Squares Means_.\nR package version 1.10.5, &lt;https://CRAN.R-project.org/package=emmeans&gt;.\n  - Lüdecke D (2024). _sjstats: Statistical Functions for Regression Models\n(Version 0.19.0)_. doi:10.5281/zenodo.1284472\n&lt;https://doi.org/10.5281/zenodo.1284472&gt;,\n&lt;https://CRAN.R-project.org/package=sjstats&gt;.\n  - Lüdecke D, Ben-Shachar M, Patil I, Makowski D (2020). \"Extracting, Computing\nand Exploring the Parameters of Statistical Models using R.\" _Journal of Open\nSource Software_, *5*(53), 2445. doi:10.21105/joss.02445\n&lt;https://doi.org/10.21105/joss.02445&gt;.\n  - Lüdecke D, Ben-Shachar M, Patil I, Waggoner P, Makowski D (2021).\n\"performance: An R Package for Assessment, Comparison and Testing of\nStatistical Models.\" _Journal of Open Source Software_, *6*(60), 3139.\ndoi:10.21105/joss.03139 &lt;https://doi.org/10.21105/joss.03139&gt;.\n  - Lüdecke D, Ben-Shachar M, Patil I, Wiernik B, Bacher E, Thériault R, Makowski\nD (2022). \"easystats: Framework for Easy Statistical Modeling, Visualization,\nand Reporting.\" _CRAN_. doi:10.32614/CRAN.package.easystats\n&lt;https://doi.org/10.32614/CRAN.package.easystats&gt;, R package,\n&lt;https://easystats.github.io/easystats/&gt;.\n  - Lüdecke D, Patil I, Ben-Shachar M, Wiernik B, Waggoner P, Makowski D (2021).\n\"see: An R Package for Visualizing Statistical Models.\" _Journal of Open Source\nSoftware_, *6*(64), 3393. doi:10.21105/joss.03393\n&lt;https://doi.org/10.21105/joss.03393&gt;.\n  - Lüdecke D, Waggoner P, Makowski D (2019). \"insight: A Unified Interface to\nAccess Information from Model Objects in R.\" _Journal of Open Source Software_,\n*4*(38), 1412. doi:10.21105/joss.01412 &lt;https://doi.org/10.21105/joss.01412&gt;.\n  - Lumley T (2024). \"survey: analysis of complex survey samples.\" R package\nversion 4.4. Lumley T (2004). \"Analysis of Complex Survey Samples.\" _Journal of\nStatistical Software_, *9*(1), 1-19. R package verson 2.2. Lumley T (2010).\n_Complex Surveys: A Guide to Analysis Using R: A Guide to Analysis Using R_.\nJohn Wiley and Sons.\n  - Makowski D, Ben-Shachar M, Lüdecke D (2019). \"bayestestR: Describing Effects\nand their Uncertainty, Existence and Significance within the Bayesian\nFramework.\" _Journal of Open Source Software_, *4*(40), 1541.\ndoi:10.21105/joss.01541 &lt;https://doi.org/10.21105/joss.01541&gt;,\n&lt;https://joss.theoj.org/papers/10.21105/joss.01541&gt;.\n  - Makowski D, Ben-Shachar M, Patil I, Lüdecke D (2020). \"Estimation of\nModel-Based Predictions, Contrasts and Means.\" _CRAN_.\n&lt;https://github.com/easystats/modelbased&gt;.\n  - Makowski D, Lüdecke D, Patil I, Thériault R, Ben-Shachar M, Wiernik B (2023).\n\"Automated Results Reporting as a Practical Tool to Improve Reproducibility and\nMethodological Best Practices Adoption.\" _CRAN_.\n&lt;https://easystats.github.io/report/&gt;.\n  - Makowski D, Wiernik B, Patil I, Lüdecke D, Ben-Shachar M (2022).\n\"correlation: Methods for Correlation Analysis.\" Version 0.8.3,\n&lt;https://CRAN.R-project.org/package=correlation&gt;. Makowski D, Ben-Shachar M,\nPatil I, Lüdecke D (2020). \"Methods and Algorithms for Correlation Analysis in\nR.\" _Journal of Open Source Software_, *5*(51), 2306. doi:10.21105/joss.02306\n&lt;https://doi.org/10.21105/joss.02306&gt;,\n&lt;https://joss.theoj.org/papers/10.21105/joss.02306&gt;.\n  - Patil I, Makowski D, Ben-Shachar M, Wiernik B, Bacher E, Lüdecke D (2022).\n\"datawizard: An R Package for Easy Data Preparation and Statistical\nTransformations.\" _Journal of Open Source Software_, *7*(78), 4684.\ndoi:10.21105/joss.04684 &lt;https://doi.org/10.21105/joss.04684&gt;.\n  - Pinheiro J, Bates D, R Core Team (2024). _nlme: Linear and Nonlinear Mixed\nEffects Models_. R package version 3.1-166,\n&lt;https://CRAN.R-project.org/package=nlme&gt;. Pinheiro JC, Bates DM (2000).\n_Mixed-Effects Models in S and S-PLUS_. Springer, New York. doi:10.1007/b98882\n&lt;https://doi.org/10.1007/b98882&gt;.\n  - R Core Team (2024). _foreign: Read Data Stored by 'Minitab', 'S', 'SAS',\n'SPSS', 'Stata', 'Systat', 'Weka', 'dBase', ..._. R package version 0.8-87,\n&lt;https://CRAN.R-project.org/package=foreign&gt;.\n  - R Core Team (2024). _R: A Language and Environment for Statistical\nComputing_. R Foundation for Statistical Computing, Vienna, Austria.\n&lt;https://www.R-project.org/&gt;.\n  - Schloerke B, Cook D, Larmarange J, Briatte F, Marbach M, Thoen E, Elberg A,\nCrowley J (2024). _GGally: Extension to 'ggplot2'_. R package version 2.2.1,\n&lt;https://CRAN.R-project.org/package=GGally&gt;.\n  - Thériault R (2023). \"rempsyc: Convenience functions for psychology.\" _Journal\nof Open Source Software_, *8*(87), 5466. doi:10.21105/joss.05466\n&lt;https://doi.org/10.21105/joss.05466&gt;, &lt;https://doi.org/10.21105/joss.05466&gt;.\n  - Therneau T (2024). _A Package for Survival Analysis in R_. R package version\n3.7-0, &lt;https://CRAN.R-project.org/package=survival&gt;. Terry M. Therneau,\nPatricia M. Grambsch (2000). _Modeling Survival Data: Extending the Cox Model_.\nSpringer, New York. ISBN 0-387-98784-3.\n  - Venables WN, Ripley BD (2002). _Modern Applied Statistics with S_, Fourth\nedition. Springer, New York. ISBN 0-387-95457-0,\n&lt;https://www.stats.ox.ac.uk/pub/MASS4/&gt;.\n  - Wickham H (2016). _ggplot2: Elegant Graphics for Data Analysis_.\nSpringer-Verlag New York. ISBN 978-3-319-24277-4,\n&lt;https://ggplot2.tidyverse.org&gt;.\n  - Wickham H, François R, Henry L, Müller K, Vaughan D (2023). _dplyr: A Grammar\nof Data Manipulation_. R package version 1.1.4,\n&lt;https://CRAN.R-project.org/package=dplyr&gt;.\n  - Wickham H, Vaughan D, Girlich M (2024). _tidyr: Tidy Messy Data_. R package\nversion 1.3.1, &lt;https://CRAN.R-project.org/package=tidyr&gt;.\n  - Xie Y (2021). _mime: Map Filenames to MIME Types_. R package version 0.12,\n&lt;https://CRAN.R-project.org/package=mime&gt;.",
    "crumbs": [
      "GLM, GEE, GMM, GzLM",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Lista 2 - GEE</span>"
    ]
  },
  {
    "objectID": "ARIMA.html",
    "href": "ARIMA.html",
    "title": "ARIMA",
    "section": "",
    "text": "Fundamentos do ARIMA:\nAutoRegressivo (AR): Refere-se à relação entre uma observação atual e suas observações passadas. O termo “AutoRegressivo” destaca a dependência linear de uma observação em relação a suas antecessoras.\nIntegrated (I): Indica o número de diferenciações necessárias para tornar a série temporal estacionária, ou seja, para remover tendências e padrões sistemáticos. A estacionarização é crucial para garantir a estabilidade do modelo.\nMédia Móvel (MA): Considera os erros residuais das observações anteriores para prever a próxima. O componente “Média Móvel” reflete a média dos erros anteriores, incorporando informações sobre o comportamento recente da série.\nNúmero de observações: O número ideal de observações repetidas para uma única unidade de análise é de pelo menos 40, sendo preferível alcançar 50 observações. Não é necessário ter um grande número de pessoas ou unidades de análise; até mesmo com N = 1, você pode obter várias observações do mesmo indivíduo, tornando o ARIMA uma ferramenta eficaz de análise.",
    "crumbs": [
      "ARIMA"
    ]
  },
  {
    "objectID": "SEM.html",
    "href": "SEM.html",
    "title": "SEM",
    "section": "",
    "text": "Análise Fatorial Confirmatória (CFA)\nA Análise de Fator Confirmatória é uma técnica estatística utilizada para avaliar a validade de uma estrutura teórica subjacente a um conjunto de dados. Especificamente, ela é empregada para testar e confirmar a consistência entre os dados observados e a estrutura de fatores previamente proposta. Neste método, um modelo teórico é formulado com fatores latentes e suas respectivas variáveis observadas, e as relações entre eles são testadas em relação aos dados observados. A CFA é comumente utilizada em pesquisas nas áreas de psicologia, educação e ciências sociais para validar construtos teóricos e entender a relação entre variáveis latentes.\nDesenho de Estudo Sugerido: Uma pesquisa que busca validar um modelo teórico de construtos psicológicos, educacionais ou sociais por meio de dados observados em um conjunto de participantes.\nExemplo: Avaliação da validade de um modelo teórico que postula a relação entre variáveis como autoestima, motivação e desempenho acadêmico em estudantes universitários, utilizando a Análise de Fator Confirmatória para testar a consistência dos dados observados com a estrutura proposta.",
    "crumbs": [
      "SEM"
    ]
  },
  {
    "objectID": "SEM.html#análise-de-caminhos-path-analysis",
    "href": "SEM.html#análise-de-caminhos-path-analysis",
    "title": "SEM",
    "section": "Análise de Caminhos (Path Analysis)",
    "text": "Análise de Caminhos (Path Analysis)\nAnálise de Caminhos é uma técnica estatística utilizada para examinar as relações causais entre variáveis em um modelo teórico complexo. Esta abordagem permite explorar e quantificar as vias diretas e indiretas entre diferentes variáveis, identificando assim o impacto de cada componente no modelo. A análise de caminhos é frequentemente empregada em pesquisas nas áreas de psicologia, sociologia e ciências sociais, proporcionando insights sobre como variáveis interagem e contribuem para um fenômeno específico.\nDesenho de Estudo Sugerido: Um estudo que investiga as relações causais entre múltiplas variáveis por meio de um modelo teórico, utilizando dados observados para testar as conexões propostas.\nExemplo: Exame das interações entre variáveis como ambiente familiar, apoio social e desempenho acadêmico em adolescentes, por meio de um modelo de análise de caminhos. A pesquisa busca compreender como fatores familiares e sociais influenciam diretamente ou indiretamente o sucesso acadêmico dos jovens.",
    "crumbs": [
      "SEM"
    ]
  },
  {
    "objectID": "survival.html",
    "href": "survival.html",
    "title": "SURVIVAL",
    "section": "",
    "text": "Pressupostos da Cox regression\nA Regressão de Cox é uma técnica robusta, mas, como qualquer método estatístico, possui alguns pressupostos importantes. Os principais pressupostos da Regressão de Cox são:\nOs pressupostos de 2 a 6 são inerentes ao desenho do experimento e do acompanhamento durante as observações. O único que vamos abordar aqui no tutorial é o de proporcionalidade dos riscos.",
    "crumbs": [
      "SURVIVAL"
    ]
  },
  {
    "objectID": "index.html#origem-do-conteúdo",
    "href": "index.html#origem-do-conteúdo",
    "title": "Técnicas e Métodos de Pesquisa no R",
    "section": "📚 Origem do Conteúdo",
    "text": "📚 Origem do Conteúdo\nAs aulas são disponibilizadas gratuitamente através de lives no canal Cientística & Podcast Naruhodo do YouTube. Você pode acessar a playlist completa das aulas práticas e a playlist da disciplina completa.\n\n\n\n\n\n\nAgradecimento Especial\n\n\n\n\n\nAgradecimento especial à Professora Maria Lucia Oliveira De Souza Formigoni por tornar possível a realização desta disciplina.",
    "crumbs": [
      "Bem-vindo"
    ]
  },
  {
    "objectID": "index.html#o-que-você-vai-aprender",
    "href": "index.html#o-que-você-vai-aprender",
    "title": "Técnicas e Métodos de Pesquisa no R",
    "section": "🎯 O que Você Vai Aprender",
    "text": "🎯 O que Você Vai Aprender\nEste tutorial cobre análises estatísticas avançadas organizadas nos seguintes módulos:\n\nPreparação de DadosModelos LinearesAnálise de SobrevidaAnálises Avançadas\n\n\n\nTransformação e manipulação de dados\nBoas práticas de organização\n\n\n\n\nGLM - Modelo Linear Geral de medidas repetidas\nGEE - Equações de Estimação Generalizadas\nGMM - Modelos Mistos e Hierárquicos\nGzLM - Modelos Lineares Generalizados\n\n\n\n\nKaplan-Meier\nRegressão de Cox\nCox com covariáveis tempo-dependentes\n\n\n\n\nSéries Temporais - Modelos ARIMA\nSEM - Modelagem de Equações Estruturais\n\nPath Analysis\nAnálise Fatorial Confirmatória (CFA)\nModeração e Mediação\n\n\n\n\n\n\n\n\n\n\n\nSeção “Extras”\n\n\n\nAo final de cada capítulo, você encontrará a seção Extras com dicas sobre pacotes úteis que não estão disponíveis no SPSS ou Jamovi.",
    "crumbs": [
      "Bem-vindo"
    ]
  },
  {
    "objectID": "index.html#pré-requisitos",
    "href": "index.html#pré-requisitos",
    "title": "Técnicas e Métodos de Pesquisa no R",
    "section": "⚠️ Pré-requisitos",
    "text": "⚠️ Pré-requisitos\n\n\n\n\n\n\nImportante!\n\n\n\nEste material é complementar às aulas teóricas e práticas. É fundamental que você:\n\nAssista às aulas correspondentes antes de trabalhar com os exercícios\nTenha conhecimento básico em estatística (preferencialmente Estatística Aplicada a Psicobiologia I)\nPossua familiaridade mínima com o ambiente R",
    "crumbs": [
      "Bem-vindo"
    ]
  },
  {
    "objectID": "index.html#configurando-seu-ambiente",
    "href": "index.html#configurando-seu-ambiente",
    "title": "Técnicas e Métodos de Pesquisa no R",
    "section": "🛠️ Configurando seu Ambiente",
    "text": "🛠️ Configurando seu Ambiente\n\nInstalando R e RStudio\nEmbora as aulas originais utilizem SPSS, este tutorial replica todas as análises no R — que é gratuito e open source!\n\n\nR (Base)\n\n📥 Download do R\n\n\nRStudio (IDE)\n\n📥 Download do RStudio\n\n\n\n\nEstrutura Recomendada de Projeto\nOrganizar seus projetos adequadamente facilita a reprodutibilidade e colaboração:\nmeu_projeto/\n├── meu_projeto.Rproj\n├── dados/\n│   ├── raw/          # Dados originais (não modificar)\n│   └── processed/    # Dados processados\n├── scripts/\n│   └── analises.R\n├── outputs/\n│   ├── figuras/\n│   └── tabelas/\n└── README.md\n\n\n\n\n\n\nComo Criar um Projeto no RStudio\n\n\n\n\n\n\nAbra o RStudio\nVá em File → New Project\nEscolha New Directory → New Project\nDefina o nome e localização do projeto\nClique em Create Project\n\nVantagens: - Caminhos relativos automáticos - Facilita compartilhamento - Mantém ambiente organizado - Evita conflitos entre projetos",
    "crumbs": [
      "Bem-vindo"
    ]
  },
  {
    "objectID": "index.html#gerenciamento-de-pacotes",
    "href": "index.html#gerenciamento-de-pacotes",
    "title": "Técnicas e Métodos de Pesquisa no R",
    "section": "📦 Gerenciamento de Pacotes",
    "text": "📦 Gerenciamento de Pacotes\n\nInstalação (apenas uma vez)\n\n# Instalar um pacote\ninstall.packages(\"tidyverse\")\n\n# Instalar múltiplos pacotes\npacotes &lt;- c(\"dplyr\", \"ggplot2\", \"lme4\")\ninstall.packages(pacotes)\n\n\n\nCarregamento (a cada sessão)\n\n# Carregar biblioteca\nlibrary(tidyverse)\n\n\n\n\n\n\n\n💡 Analogia\n\n\n\nPense nos pacotes como livros em uma biblioteca:\n\ninstall.packages() = Comprar/adquirir o livro\nlibrary() = Pegar o livro da prateleira para usar\n\n\n\n\n\nLista de Pacotes Principais\nNo início de cada capítulo, você encontrará uma lista específica dos pacotes necessários. Aqui está uma visão geral dos principais:\n\nManipulaçãoVisualizaçãoModelagemEstatísticas\n\n\n\nlibrary(dplyr)      # Manipulação de dados\nlibrary(tidyr)      # Organização de dados\nlibrary(foreign)    # Importação de dados\n\n\n\n\nlibrary(ggplot2)    # Gráficos elegantes\nlibrary(flexplot)   # Visualização flexível\nlibrary(effects)    # Efeitos de modelos\n\n\n\n\nlibrary(lme4)       # Modelos mistos\nlibrary(nlme)       # Modelos não-lineares\nlibrary(geepack)    # GEE\nlibrary(car)        # Análise de regressão\n\n\n\n\nlibrary(emmeans)    # Médias estimadas\nlibrary(multcomp)   # Comparações múltiplas\nlibrary(rstatix)    # Análises simplificadas\nlibrary(easystats)  # Suite completa",
    "crumbs": [
      "Bem-vindo"
    ]
  },
  {
    "objectID": "index.html#material-de-apoio",
    "href": "index.html#material-de-apoio",
    "title": "Técnicas e Métodos de Pesquisa no R",
    "section": "📹 Material de Apoio",
    "text": "📹 Material de Apoio\n\n\n\n\n\n\nAulas em Vídeo\n\n\n\nOs vídeos das aulas práticas no SPSS estão disponíveis ao final de cada capítulo para referência.\nNota: Pequenas diferenças nos resultados entre SPSS e R podem ocorrer devido a algoritmos diferentes de estimação. O importante é sempre documentar seu método de análise.",
    "crumbs": [
      "Bem-vindo"
    ]
  },
  {
    "objectID": "index.html#boas-práticas-de-reprodutibilidade",
    "href": "index.html#boas-práticas-de-reprodutibilidade",
    "title": "Técnicas e Métodos de Pesquisa no R",
    "section": "🤝 Boas Práticas de Reprodutibilidade",
    "text": "🤝 Boas Práticas de Reprodutibilidade\n\n\n\n\n\n\nChecklist para Análises Reproduzíveis\n\n\n\n\nUse projetos do RStudio\nDocumente versões de pacotes (sessionInfo())\nComente seu código adequadamente\nNunca modifique dados originais\nUse caminhos relativos (não absolutos)\nCompartilhe código e dados quando possível\nReporte métodos detalhadamente",
    "crumbs": [
      "Bem-vindo"
    ]
  },
  {
    "objectID": "index.html#recursos-adicionais",
    "href": "index.html#recursos-adicionais",
    "title": "Técnicas e Métodos de Pesquisa no R",
    "section": "📚 Recursos Adicionais",
    "text": "📚 Recursos Adicionais\nPara aprofundar seus conhecimentos:\n\nR for Data Science - Livro gratuito online\nQuarto Documentation - Documentação oficial\nRStudio Cheatsheets - Guias de referência rápida\n\n\n\n\n\n\n\n\nPronto para Começar?\n\n\n\nAgora que seu ambiente está configurado, você está pronto para explorar os próximos capítulos! Cada um apresenta análises específicas com exemplos práticos e exercícios.\nDica: Trabalhe ativamente com os códigos — não apenas leia, execute e experimente!",
    "crumbs": [
      "Bem-vindo"
    ]
  },
  {
    "objectID": "lms.html",
    "href": "lms.html",
    "title": "Modelos Lineares",
    "section": "",
    "text": "📊 Os Quatro Modelos",
    "crumbs": [
      "Modelos Lineares"
    ]
  },
  {
    "objectID": "lms.html#os-quatro-modelos",
    "href": "lms.html#os-quatro-modelos",
    "title": "Modelos Lineares",
    "section": "",
    "text": "GLM - Medidas RepetidasGEE - Equações EstimadasGMM - Modelos MistosGzLM - Lineares Generalizados\n\n\nModelo Linear Geral de Medidas Repetidas\nExtensão do modelo linear tradicional projetado especificamente para dados com observações correlacionadas ao longo do tempo.\nQuando usar: - Estudos longitudinais com medições repetidas - Mesmos participantes avaliados em múltiplos momentos - Necessidade de modelar estrutura de covariância entre medições\nExemplo prático: Acompanhamento de pacientes em tratamento médico, medindo regularmente biomarcadores para observar mudanças ao longo do tempo.\n\n\nGeneralized Estimated Equations\nAbordagem robusta para dados longitudinais que fornece estimativas eficientes mesmo quando a especificação da covariância não é perfeita.\nQuando usar: - Estudos observacionais longitudinais - Ensaios clínicos com medições correlacionadas - Estudos epidemiológicos multicêntricos\nExemplo prático: Investigação da eficácia de programa de intervenção em saúde onde observações estão correlacionadas dentro de grupos de participantes.\n\n\nModelos Mistos e Hierárquicos\nCombinam componentes fixos e aleatórios, ideais para dados com estrutura hierárquica ou multicêntrica.\nQuando usar: - Dados com estrutura hierárquica - Estudos multicêntricos - Observações agrupadas em diferentes níveis\nExemplo prático: Avaliação de desempenho acadêmico onde alunos (nível 1) estão agrupados em salas (nível 2) e escolas (nível 3), considerando efeitos individuais e contextuais.\n\n\nGeneralized Linear Models\nExtensão dos modelos lineares para variáveis resposta não-normais, permitindo diferentes distribuições e funções de ligação.\nQuando usar: - Dados de contagem (Poisson) - Dados binários (Logística) - Dados com distribuição não-normal\nExemplo prático: Análise de número de eventos adversos (contagem) em ensaio clínico ou modelagem de probabilidade de sucesso em tratamento (binário).",
    "crumbs": [
      "Modelos Lineares"
    ]
  },
  {
    "objectID": "lms.html#por-que-usar-modelos-de-medidas-repetidas",
    "href": "lms.html#por-que-usar-modelos-de-medidas-repetidas",
    "title": "Modelos Lineares",
    "section": "🎯 Por que usar Modelos de Medidas Repetidas?",
    "text": "🎯 Por que usar Modelos de Medidas Repetidas?\n\n\n\n\n\n\nVantagens sobre ANOVA Tradicional\n\n\n\nOs modelos lineares modernos oferecem melhorias substanciais sobre a ANOVA clássica:\n\nModelagem Flexível\n\nMúltiplos fatores independentes em um único modelo\nAnálise de interações complexas\nEstruturas de covariância personalizadas\n\nRobustez a Violações\n\nDados desequilibrados\nHeterogeneidade de variâncias\nDesvios da normalidade\n\nControle Estatístico\n\nInclusão de covariáveis\nAjuste para variáveis confundidoras\nMaior precisão nas estimativas\n\nPoder Estatístico\n\nAproveitamento da correlação entre medidas\nDetecção de efeitos com amostras menores\nAnálise eficiente de designs complexos\n\nVersatilidade\n\nVariáveis dependentes contínuas ou categóricas\nDiferentes distribuições de probabilidade\nEstruturas temporais variadas",
    "crumbs": [
      "Modelos Lineares"
    ]
  },
  {
    "objectID": "lms.html#pacotes-necessários",
    "href": "lms.html#pacotes-necessários",
    "title": "Modelos Lineares",
    "section": "📦 Pacotes Necessários",
    "text": "📦 Pacotes Necessários\n\n# Modelagem e análise\nlibrary(lme4)        # Modelos lineares mistos\nlibrary(nlme)        # Modelos não-lineares mistos\nlibrary(geepack)     # Equações de estimação generalizadas\n\n# Médias e comparações\nlibrary(emmeans)     # Médias estimadas marginais\nlibrary(multcomp)    # Comparações múltiplas\nlibrary(effects)     # Visualização de efeitos\n\n# Estatísticas e diagnósticos\nlibrary(performance) # Diagnósticos de modelos\nlibrary(sjstats)     # Estatísticas descritivas\nlibrary(rstatix)     # Análises simplificadas\nlibrary(car)         # Testes complementares\n\n# Manipulação de dados\nlibrary(dplyr)       # Transformação de dados\nlibrary(tidyr)       # Organização de dados\nlibrary(foreign)     # Importação SPSS/Stata\n\n# Visualização\nlibrary(flexplot)    # Gráficos flexíveis\nlibrary(see)         # Visualizações do easystats\n\n# Suites integradas\nlibrary(easystats)   # Suite completa de análise\nlibrary(rempsyc)     # Métodos psicométricos",
    "crumbs": [
      "Modelos Lineares"
    ]
  },
  {
    "objectID": "lms.html#materiais-para-download",
    "href": "lms.html#materiais-para-download",
    "title": "Modelos Lineares",
    "section": "📥 Materiais para Download",
    "text": "📥 Materiais para Download\n\n\n\n\n\n\nArquivos Necessários\n\n\n\nFaça o download do pacote completo abaixo e descompacte todos os arquivos na pasta do seu projeto.\nConteúdo do pacote:\n\nbd_New drug_respiratory&pulse.sav - Banco de dados principal\nLista 1.R - Script parcialmente preenchido para prática\nlista_1.docx - Exercícios para resolução",
    "crumbs": [
      "Modelos Lineares"
    ]
  },
  {
    "objectID": "lms.html#preparação-dos-dados",
    "href": "lms.html#preparação-dos-dados",
    "title": "Modelos Lineares",
    "section": "🔄 Preparação dos Dados",
    "text": "🔄 Preparação dos Dados\n\nCarregamento Inicial\n\n# Importar dados do SPSS\noriginal_wide &lt;- read.spss(\"bd_New drug_respiratory&pulse.sav\", \n                           to.data.frame = TRUE)\n\n# Visualizar estrutura\nhead(original_wide)\n\n      drug resp1 resp2 resp3 pulse1 pulse2 pulse3\n1 New Drug   3.4   3.3   3.3    2.2    2.1    2.1\n2 New Drug   3.4   3.4   3.3    2.2    2.1    2.2\n3 New Drug   3.3   3.4   3.4    2.3    2.4    2.3\n4 New Drug   3.4   3.4   3.4    2.3    2.4    2.3\n5 New Drug   3.3   3.4   3.3    2.2    2.2    2.4\n6 New Drug   3.3   3.3   3.3    2.0    2.1    2.4\n\n\n\n\n\n\n\n\nSobre a função read.spss()\n\n\n\n\n\n\nOrigem: Pacote foreign\nParâmetro to.data.frame = TRUE: Converte para data frame do R\nAlternativa: Pacote haven com read_sav() (mais moderno)\n\n\n\n\n\n\n\nTransformação Wide → Long\nPara análises de medidas repetidas, precisamos converter os dados de formato wide (uma linha por sujeito) para long (uma linha por observação).\n\nPasso 1: Renomear Colunas\n\nbd &lt;- original_wide %&gt;%\n  rename_with(~gsub(\"(resp|pulse)(\\\\d+)\", \"\\\\1_\\\\2\", .), -drug) %&gt;%\n  mutate(ID = row_number()) %&gt;%\n  select(ID, everything())\n\nhead(bd)\n\n  ID     drug resp_1 resp_2 resp_3 pulse_1 pulse_2 pulse_3\n1  1 New Drug    3.4    3.3    3.3     2.2     2.1     2.1\n2  2 New Drug    3.4    3.4    3.3     2.2     2.1     2.2\n3  3 New Drug    3.3    3.4    3.4     2.3     2.4     2.3\n4  4 New Drug    3.4    3.4    3.4     2.3     2.4     2.3\n5  5 New Drug    3.3    3.4    3.3     2.2     2.2     2.4\n6  6 New Drug    3.3    3.3    3.3     2.0     2.1     2.4\n\n\n\n\n\n\n\n\n🔍 Entendendo a Expressão Regular\n\n\n\n\n\nA regex (resp|pulse)(\\\\d+) funciona assim:\n\n(resp|pulse) - Captura “resp” OU “pulse”\n(\\\\d+) - Captura um ou mais dígitos\n\nTransformação: - resp1 → resp_1 - pulse2 → pulse_2\nIsso facilita a separação posterior em variável e tempo!\n\n\n\n\n\nPasso 2: Pivotar para Formato Long\n\nbd_long &lt;- pivot_longer(\n  bd,\n  cols = resp_1:pulse_3,\n  names_to = c(\".value\", \"Tempo\"),\n  names_pattern = \"(.+)_(.+)\"\n)\n\nhead(bd_long)\n\n# A tibble: 6 × 5\n     ID drug     Tempo  resp pulse\n  &lt;int&gt; &lt;fct&gt;    &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt;\n1     1 New Drug 1       3.4   2.2\n2     1 New Drug 2       3.3   2.1\n3     1 New Drug 3       3.3   2.1\n4     2 New Drug 1       3.4   2.2\n5     2 New Drug 2       3.4   2.1\n6     2 New Drug 3       3.3   2.2\n\n\n\n\n\n\n\n\nEstrutura do pivot_longer()\n\n\n\n\ncols: Colunas a transformar\n.value: Nome da coluna vem da primeira parte\nTempo: Criada da segunda parte do nome\nnames_pattern: Regex para dividir nomes\n\n\n\n\n\nPasso 3: Converter Tempo em Fator\n\nbd_long$Tempo &lt;- factor(bd_long$Tempo)",
    "crumbs": [
      "Modelos Lineares"
    ]
  },
  {
    "objectID": "lms.html#verificação-de-pressupostos",
    "href": "lms.html#verificação-de-pressupostos",
    "title": "Modelos Lineares",
    "section": "✅ Verificação de Pressupostos",
    "text": "✅ Verificação de Pressupostos\n\nNormalidade da Variável Dependente\nA distribuição normal é pressuposto fundamental em muitos testes estatísticos.\n\nDistribuição NormalDistribuição Não-Normal\n\n\n\nset.seed(123)\ndados_normais &lt;- rnorm(1000, mean = 0, sd = 1)\n\n# Criar visualizações\npar(mfrow = c(1, 2))\n\n# Histograma\nhist(dados_normais, \n     main = \"Distribuição Normal\",\n     col = \"lightblue\", \n     border = \"black\")\n\n# Q-Q Plot\nqqnorm(dados_normais, main = \"Q-Q Plot - Normal\")\nqqline(dados_normais, col = \"red\", lwd = 2)\n\n\n\n\n\n\n\npar(mfrow = c(1, 1))\n\nCaracterísticas: - Histograma em forma de sino - Q-Q plot segue linha diagonal - Simetria em torno da média\n\n\n\nset.seed(123)\ndados_nao_normais &lt;- abs(rnorm(1000, mean = 0, sd = 1))\n\npar(mfrow = c(1, 2))\n\nhist(dados_nao_normais,\n     main = \"Distribuição Assimétrica\",\n     col = \"lightcoral\",\n     border = \"black\")\n\nqqnorm(dados_nao_normais, main = \"Q-Q Plot - Não Normal\")\nqqline(dados_nao_normais, col = \"red\", lwd = 2)\n\n\n\n\n\n\n\npar(mfrow = c(1, 1))\n\nCaracterísticas: - Assimetria evidente - Desvios da linha no Q-Q plot - Concentração em uma região\n\n\n\n\n\n\nTeste de Shapiro-Wilk\n\n\n\n\n\n\nHipóteses do Teste\n\n\n\nH₀: Os dados seguem distribuição normal\nH₁: Os dados NÃO seguem distribuição normal\nDecisão: - p &gt; 0,05 → Não rejeita H₀ (assume normalidade) - p &lt; 0,05 → Rejeita H₀ (evidência de não-normalidade)\n⚠️ Atenção: Com amostras muito grandes, pequenos desvios podem ser significativos.\n\n\nExemplo com dados normais:\n\nshapiro.test(dados_normais)\n\n\n    Shapiro-Wilk normality test\n\ndata:  dados_normais\nW = 0.99838, p-value = 0.4765\n\n\nExemplo com dados não-normais:\n\nshapiro.test(dados_nao_normais)\n\n\n    Shapiro-Wilk normality test\n\ndata:  dados_nao_normais\nW = 0.92344, p-value &lt; 2.2e-16\n\n\n\n\n\nNormalidade das Variáveis do Estudo\n\nVariável “Pulse”\n\n# Visualização combinada\nnice_normality(\n  data = bd_long,\n  variable = \"pulse\",\n  histogram = TRUE\n)\n\n\n\n\n\n\n\n# Teste formal\nshapiro.test(bd_long$pulse)\n\n\n    Shapiro-Wilk normality test\n\ndata:  bd_long$pulse\nW = 0.90791, p-value = 0.005655\n\n\n\n\n\n\n\n\nInterpretação\n\n\n\nTanto a análise gráfica quanto o teste de Shapiro-Wilk indicam que pulse não possui distribuição normal.",
    "crumbs": [
      "Modelos Lineares"
    ]
  },
  {
    "objectID": "lms.html#esfericidade-medidas-repetidas",
    "href": "lms.html#esfericidade-medidas-repetidas",
    "title": "Modelos Lineares",
    "section": "🔄 Esfericidade (Medidas Repetidas)",
    "text": "🔄 Esfericidade (Medidas Repetidas)\n\n\n\n\n\n\nO que é Esfericidade?\n\n\n\nA esfericidade avalia se as variâncias das diferenças entre todos os pares de medidas repetidas são homogêneas.\nViolação de esfericidade: - Infla erro Tipo I (falsos positivos) - Requer correções nos graus de liberdade - Comum em medidas repetidas\n\n\n\nTeste de Mauchly para “Pulse”\n\npulse_mauchly &lt;- anova_test(\n  data = bd_long,\n  dv = pulse,\n  wid = ID,\n  within = Tempo\n)\n\npulse_mauchly\n\nANOVA Table (type III tests)\n\n$ANOVA\n  Effect DFn DFd    F     p p&lt;.05   ges\n1  Tempo   2  22 3.48 0.049     * 0.024\n\n$`Mauchly's Test for Sphericity`\n  Effect     W    p p&lt;.05\n1  Tempo 0.781 0.29      \n\n$`Sphericity Corrections`\n  Effect  GGe      DF[GG] p[GG] p[GG]&lt;.05   HFe      DF[HF] p[HF] p[HF]&lt;.05\n1  Tempo 0.82 1.64, 18.04 0.061           0.945 1.89, 20.78 0.052          \n\n\n\n\n\n\n\n\n📊 Interpretando os Resultados\n\n\n\n\n\nANOVA Table: - F = 3,48, p = 0,049 → Efeito significativo de Tempo - ges = medida de tamanho de efeito\nTeste de Mauchly: - W = 0,781, p = 0,29 → Esfericidade NÃO violada\nCorreções (quando necessárias): - GGe = 0,82 → Correção de Greenhouse-Geisser - HFe = 0,945 → Correção de Huynh-Feldt\n\n\n\n\n\n\nTeste de Mauchly para “Resp”\n\nresp_mauchly &lt;- anova_test(\n  data = bd_long,\n  dv = resp,\n  wid = ID,\n  within = Tempo\n)\n\nresp_mauchly\n\nANOVA Table (type III tests)\n\n$ANOVA\n  Effect DFn DFd     F     p p&lt;.05  ges\n1  Tempo   2  22 0.344 0.713       0.01\n\n$`Mauchly's Test for Sphericity`\n  Effect     W     p p&lt;.05\n1  Tempo 0.501 0.032     *\n\n$`Sphericity Corrections`\n  Effect   GGe      DF[GG] p[GG] p[GG]&lt;.05   HFe      DF[HF] p[HF] p[HF]&lt;.05\n1  Tempo 0.667 1.33, 14.68 0.629           0.725 1.45, 15.94 0.646          \n\n\n\n\n\n\n\n\n⚠️ Esfericidade Violada!\n\n\n\nTeste de Mauchly: - W = 0,501, p &lt; 0,05 → Esfericidade VIOLADA\nImplicações: - Graus de liberdade devem ser corrigidos - Usar valores p corrigidos (GGe ou HFe) - GGe = 0,667 (redução de ~33%) - HFe = 0,725 (redução de ~27,5%)\nResultado após correção: - Efeito de Tempo permanece não-significativo",
    "crumbs": [
      "Modelos Lineares"
    ]
  },
  {
    "objectID": "lms.html#coeficientes-de-correção",
    "href": "lms.html#coeficientes-de-correção",
    "title": "Modelos Lineares",
    "section": "🔧 Coeficientes de Correção",
    "text": "🔧 Coeficientes de Correção\n\nGreenhouse-Geisser (GGe)Huynh-Feldt (HFe)Quando Usar Qual?\n\n\nCaracterísticas: - Correção mais conservadora - Recomendado quando GGe &lt; 0,75 - Reduz graus de liberdade proporcionalmente\nInterpretação: - GGe próximo de 1 → Pouca violação - GGe &lt; 0,75 → Violação substancial\nExemplo (Resp): - GGe = 0,667 → Redução de 33% nos GL\n\n\nCaracterísticas: - Menos conservador que GGe - Melhor para amostras pequenas - Pode exceder 1 (truncado em 1)\nInterpretação: - HFe próximo de 1 → Pouca violação - Diferença com GGe indica severidade\nExemplo (Resp): - HFe = 0,725 → Redução de 27,5% nos GL\n\n\n\n\n\nSituação\nRecomendação\n\n\n\n\nGGe &gt; 0,75\nQualquer correção\n\n\nGGe &lt; 0,75\nPreferir GGe\n\n\nAmostra pequena\nConsiderar HFe\n\n\np próximo de 0,05\nComparar ambos",
    "crumbs": [
      "Modelos Lineares"
    ]
  },
  {
    "objectID": "lms.html#resumo-dos-pressupostos",
    "href": "lms.html#resumo-dos-pressupostos",
    "title": "Modelos Lineares",
    "section": "🎓 Resumo dos Pressupostos",
    "text": "🎓 Resumo dos Pressupostos\n\n\n\n\n\n\nChecklist de Verificação\n\n\n\n\n\n\n\n\n\n\n\n\nPressuposto\nPulse\nResp\nAção\n\n\n\n\nNormalidade\n❌ Violado\n-\nConsiderar transformação ou GLM robusto\n\n\nEsfericidade\n✅ OK\n❌ Violado\nUsar correções GGe/HFe\n\n\nHomogeneidade\n-\n-\nVerificar com Levene (próximo capítulo)\n\n\n\nPróximos passos: Agora que verificamos os pressupostos, podemos prosseguir para as análises GLM, GEE e GMM!",
    "crumbs": [
      "Modelos Lineares"
    ]
  },
  {
    "objectID": "lms.html#conceitos-chave",
    "href": "lms.html#conceitos-chave",
    "title": "Modelos Lineares",
    "section": "📚 Conceitos-Chave",
    "text": "📚 Conceitos-Chave\n\n\n\n\n\n\nGlossário Rápido\n\n\n\n\n\nWide vs Long: - Wide: Uma linha por sujeito, múltiplas colunas de tempo - Long: Uma linha por observação, coluna de tempo\nEsfericidade: - Homogeneidade das variâncias das diferenças - Crítico para ANOVA de medidas repetidas\nGGe/HFe: - Correções para violação de esfericidade - Ajustam graus de liberdade\nQ-Q Plot: - Quantis observados vs esperados - Linha diagonal = normalidade perfeita\n\n\n\n\n\n\n\n\n\n\n🚀 Pronto para Análises!\n\n\n\nCom os dados preparados e pressupostos verificados, você está pronto para explorar:\n\nGLM - Modelo Linear Geral\nGEE - Equações de Estimação Generalizadas\n\nGMM - Modelos Mistos\nGzLM - Modelos Lineares Generalizados\n\nSiga para os próximos capítulos onde implementaremos cada modelo em detalhe!",
    "crumbs": [
      "Modelos Lineares"
    ]
  },
  {
    "objectID": "lista_1.html",
    "href": "lista_1.html",
    "title": "1  Lista 1: GLM, GEE e GMM",
    "section": "",
    "text": "1.1 📥 Dados e Materiais",
    "crumbs": [
      "Modelos Lineares",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Lista 1: GLM, GEE e GMM</span>"
    ]
  },
  {
    "objectID": "lista_1.html#dados-e-materiais",
    "href": "lista_1.html#dados-e-materiais",
    "title": "1  Lista 1: GLM, GEE e GMM",
    "section": "",
    "text": "Download Necessário\n\n\n\nFaça o download do banco de dados “new drug respiratory&pulse” e salve na pasta do seu projeto.",
    "crumbs": [
      "Modelos Lineares",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Lista 1: GLM, GEE e GMM</span>"
    ]
  },
  {
    "objectID": "lista_1.html#parte-1-glm-modelo-linear-geral",
    "href": "lista_1.html#parte-1-glm-modelo-linear-geral",
    "title": "1  Lista 1: GLM, GEE e GMM",
    "section": "1.2 📊 Parte 1: GLM (Modelo Linear Geral)",
    "text": "1.2 📊 Parte 1: GLM (Modelo Linear Geral)\n\nModelo para “Resp”\nVamos ajustar um modelo de medidas repetidas para a variável respiratória:\n\\[\n\\text{resp} = \\beta_0 + \\beta_1\\text{drug} + \\beta_2\\text{Tempo} + \\beta_3\\text{drug} \\times \\text{Tempo} + \\varepsilon\n\\]\n\nmodelo1_resp &lt;- lm(resp ~ drug + Tempo + drug*Tempo, \n                   data = bd_long)\n\nsummary(modelo1_resp)\n\n\nCall:\nlm(formula = resp ~ drug + Tempo + drug * Tempo, data = bd_long)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.15000 -0.05000 -0.03333  0.05000  0.15000 \n\nCoefficients:\n                     Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)         3.350e+00  2.635e-02 127.124  &lt; 2e-16 ***\ndrugPlacebo        -1.167e-01  3.727e-02  -3.130  0.00387 ** \nTempo2              1.667e-02  3.727e-02   0.447  0.65793    \nTempo3             -1.667e-02  3.727e-02  -0.447  0.65793    \ndrugPlacebo:Tempo2  1.904e-15  5.270e-02   0.000  1.00000    \ndrugPlacebo:Tempo3  3.333e-02  5.270e-02   0.632  0.53188    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.06455 on 30 degrees of freedom\nMultiple R-squared:  0.4559,    Adjusted R-squared:  0.3652 \nF-statistic: 5.027 on 5 and 30 DF,  p-value: 0.001836\n\n\n\n\n\n\n\n\n📖 Interpretando os Coeficientes\n\n\n\n\n\n\nIntercept: Valor médio de resp no grupo referência (placebo) no tempo 1\ndrug: Diferença entre tratamento e placebo no tempo 1\nTempo: Mudança ao longo do tempo no grupo placebo\ndrug:Tempo: Como o efeito da droga muda ao longo do tempo (interação)\n\nSignificância estatística é indicada pelos valores-p na coluna Pr(&gt;|t|).\n\n\n\n\n\nDiagnóstico do Modelo\n\nPredição e LinearidadeHomogeneidade e OutliersColinearidade e Normalidade\n\n\n\ncheck_model(modelo1_resp, \n            check = c(\"pp_check\", \"linearity\"))\n\n\n\n\n\n\n\n\nPosterior Predictive Check: Compara dados observados (verde) com simulações do modelo (azul). Boa sobreposição indica ajuste adequado.\nLinearidade: Linha horizontal sugere relação linear apropriada. Padrões em U indicam necessidade de termos quadráticos.\n\n\n\ncheck_model(modelo1_resp, \n            check = c(\"homogeneity\", \"outliers\"))\n\n\n\n\n\n\n\n\nHomogeneidade: Pontos devem se distribuir uniformemente. Padrões (cone, curva) indicam heterocedasticidade.\nObservações Influentes: Pontos fora das linhas tracejadas (Distância de Cook) são observações influentes que merecem investigação.\n\n\n\ncheck_model(modelo1_resp, \n            check = c(\"vif\", \"normality\"))\n\n\n\n\n\n\n\n\nVIF (Variance Inflation Factor): - VIF &lt; 5: Sem problemas - VIF 5-10: Colinearidade moderada - VIF &gt; 10: Colinearidade severa\nNormalidade dos Resíduos: Pontos devem seguir a linha diagonal. Desvios nas caudas indicam problemas de predição nesses extremos.\n\n\n\n\n\n\n\n\n\n⚠️ Avaliação dos Pressupostos\n\n\n\nEste modelo apresenta violações em diversos pressupostos. Veja a seção de soluções ao final deste capítulo para estratégias de correção.\n\n\n\n\n\nVisualização Completa\n\n\n\n\n\n\n💡 Painel Completo de Diagnósticos\n\n\n\nUse check_model() sem especificar check para ver todos os diagnósticos em um único painel:\n\n\n\ncheck_model(modelo1_resp)\n\n\n\n\n\n\n\n\n\n\n\nVisualização do Modelo\n\nvisualize(modelo1_resp, plot = \"model\")\n\n\n\n\n\n\n\n\n\n\n\nRelatório Automatizado\n\n\n\n\n\n\n⚡ Poder do report()\n\n\n\nA função report() do pacote easystats gera texto formatado para publicação em inglês, reduzindo erros de digitação e aumentando reprodutibilidade.\nImportante: Use com sabedoria! Sempre revise e compreenda os resultados antes de usar em publicações.\n\n\n\nreport(modelo1_resp)\n\nWe fitted a linear model (estimated using OLS) to predict resp with drug and\nTempo (formula: resp ~ drug + Tempo + drug * Tempo). The model explains a\nstatistically significant and substantial proportion of variance (R2 = 0.46,\nF(5, 30) = 5.03, p = 0.002, adj. R2 = 0.37). The model's intercept,\ncorresponding to drug = New Drug and Tempo = 1, is at 3.35 (95% CI [3.30,\n3.40], t(30) = 127.12, p &lt; .001). Within this model:\n\n  - The effect of drug [Placebo] is statistically significant and negative (beta\n= -0.12, 95% CI [-0.19, -0.04], t(30) = -3.13, p = 0.004; Std. beta = -1.44,\n95% CI [-2.38, -0.50])\n  - The effect of Tempo [2] is statistically non-significant and positive (beta =\n0.02, 95% CI [-0.06, 0.09], t(30) = 0.45, p = 0.658; Std. beta = 0.21, 95% CI\n[-0.73, 1.15])\n  - The effect of Tempo [3] is statistically non-significant and negative (beta =\n-0.02, 95% CI [-0.09, 0.06], t(30) = -0.45, p = 0.658; Std. beta = -0.21, 95%\nCI [-1.15, 0.73])\n  - The effect of drug [Placebo] × Tempo [2] is statistically non-significant and\npositive (beta = 1.90e-15, 95% CI [-0.11, 0.11], t(30) = 3.61e-14, p &gt; .999;\nStd. beta = -1.65e-15, 95% CI [-1.33, 1.33])\n  - The effect of drug [Placebo] × Tempo [3] is statistically non-significant and\npositive (beta = 0.03, 95% CI [-0.07, 0.14], t(30) = 0.63, p = 0.532; Std. beta\n= 0.41, 95% CI [-0.92, 1.74])\n\nStandardized parameters were obtained by fitting the model on a standardized\nversion of the dataset. 95% Confidence Intervals (CIs) and p-values were\ncomputed using a Wald t-distribution approximation.\n\n\n\n\n\n\nModelo para “Pulse”\nAgora ajustaremos o mesmo modelo para a variável de pulso:\n\\[\n\\text{pulse} = \\beta_0 + \\beta_1\\text{drug} + \\beta_2\\text{Tempo} + \\beta_3\\text{drug} \\times \\text{Tempo} + \\varepsilon\n\\]\n\nmodelo1_pulse &lt;- lm(pulse ~ drug + Tempo + drug*Tempo, \n                    data = bd_long)\n\nsummary(modelo1_pulse)\n\n\nCall:\nlm(formula = pulse ~ drug + Tempo + drug * Tempo, data = bd_long)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.20000 -0.08333  0.00000  0.08750  0.18333 \n\nCoefficients:\n                   Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)         2.20000    0.04389  50.131  &lt; 2e-16 ***\ndrugPlacebo         0.46667    0.06206   7.519 2.21e-08 ***\nTempo2              0.01667    0.06206   0.269    0.790    \nTempo3              0.08333    0.06206   1.343    0.189    \ndrugPlacebo:Tempo2  0.13333    0.08777   1.519    0.139    \ndrugPlacebo:Tempo3  0.03333    0.08777   0.380    0.707    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.1075 on 30 degrees of freedom\nMultiple R-squared:  0.8804,    Adjusted R-squared:  0.8605 \nF-statistic: 44.17 on 5 and 30 DF,  p-value: 6.029e-13\n\n\n\n\nDiagnóstico do Modelo\n\nPredição e LinearidadeHomogeneidade e OutliersColinearidade e Normalidade\n\n\n\ncheck_model(modelo1_pulse, \n            check = c(\"pp_check\", \"linearity\"))\n\n\n\n\n\n\n\n\n\n\n\ncheck_model(modelo1_pulse, \n            check = c(\"homogeneity\", \"outliers\"))\n\n\n\n\n\n\n\n\n\n\n\ncheck_model(modelo1_pulse, \n            check = c(\"vif\", \"normality\"))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVisualização do Modelo\n\nvisualize(modelo1_pulse, plot = \"model\")\n\n\n\n\n\n\n\n\n\n\nRelatório Automatizado\n\nreport(modelo1_pulse)\n\nWe fitted a linear model (estimated using OLS) to predict pulse with drug and\nTempo (formula: pulse ~ drug + Tempo + drug * Tempo). The model explains a\nstatistically significant and substantial proportion of variance (R2 = 0.88,\nF(5, 30) = 44.17, p &lt; .001, adj. R2 = 0.86). The model's intercept,\ncorresponding to drug = New Drug and Tempo = 1, is at 2.20 (95% CI [2.11,\n2.29], t(30) = 50.13, p &lt; .001). Within this model:\n\n  - The effect of drug [Placebo] is statistically significant and positive (beta\n= 0.47, 95% CI [0.34, 0.59], t(30) = 7.52, p &lt; .001; Std. beta = 1.62, 95% CI\n[1.18, 2.06])\n  - The effect of Tempo [2] is statistically non-significant and positive (beta =\n0.02, 95% CI [-0.11, 0.14], t(30) = 0.27, p = 0.790; Std. beta = 0.06, 95% CI\n[-0.38, 0.50])\n  - The effect of Tempo [3] is statistically non-significant and positive (beta =\n0.08, 95% CI [-0.04, 0.21], t(30) = 1.34, p = 0.189; Std. beta = 0.29, 95% CI\n[-0.15, 0.73])\n  - The effect of drug [Placebo] × Tempo [2] is statistically non-significant and\npositive (beta = 0.13, 95% CI [-0.05, 0.31], t(30) = 1.52, p = 0.139; Std. beta\n= 0.46, 95% CI [-0.16, 1.09])\n  - The effect of drug [Placebo] × Tempo [3] is statistically non-significant and\npositive (beta = 0.03, 95% CI [-0.15, 0.21], t(30) = 0.38, p = 0.707; Std. beta\n= 0.12, 95% CI [-0.51, 0.74])\n\nStandardized parameters were obtained by fitting the model on a standardized\nversion of the dataset. 95% Confidence Intervals (CIs) and p-values were\ncomputed using a Wald t-distribution approximation.",
    "crumbs": [
      "Modelos Lineares",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Lista 1: GLM, GEE e GMM</span>"
    ]
  },
  {
    "objectID": "lista_1.html#parte-2-gee-equações-de-estimação-generalizadas",
    "href": "lista_1.html#parte-2-gee-equações-de-estimação-generalizadas",
    "title": "1  Lista 1: GLM, GEE e GMM",
    "section": "1.3 📊 Parte 2: GEE (Equações de Estimação Generalizadas)",
    "text": "1.3 📊 Parte 2: GEE (Equações de Estimação Generalizadas)\n\nModelo GEE para “Resp”\nGEE oferece estimativas robustas mesmo quando a estrutura de correlação não é perfeitamente especificada.\n\nmodelo_gee_resp &lt;- geeglm(\n  resp ~ drug + Tempo + drug*Tempo,\n  data = bd_long,\n  id = ID,\n  family = gaussian,\n  corstr = \"unstructured\"\n)\n\nsummary(modelo_gee_resp)\n\n\nCall:\ngeeglm(formula = resp ~ drug + Tempo + drug * Tempo, family = gaussian, \n    data = bd_long, id = ID, corstr = \"unstructured\")\n\n Coefficients:\n                     Estimate    Std.err      Wald Pr(&gt;|W|)    \n(Intercept)         3.350e+00  2.041e-02 26934.000  &lt; 2e-16 ***\ndrugPlacebo        -1.167e-01  2.805e-02    17.294  3.2e-05 ***\nTempo2              1.667e-02  2.805e-02     0.353    0.552    \nTempo3             -1.667e-02  2.805e-02     0.353    0.552    \ndrugPlacebo:Tempo2  4.022e-18  3.967e-02     0.000    1.000    \ndrugPlacebo:Tempo3  3.333e-02  5.693e-02     0.343    0.558    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nCorrelation structure = unstructured \nEstimated Scale Parameters:\n\n            Estimate   Std.err\n(Intercept) 0.003472 0.0007618\n  Link = identity \n\nEstimated Correlation Parameters:\n            Estimate Std.err\nalpha.1:2 -9.252e-18 0.19596\nalpha.1:3 -2.400e-01 0.27321\nalpha.2:3  7.600e-01 0.09074\nNumber of clusters:   12  Maximum cluster size: 3 \n\n\n\n\n\n\n\n\n🔍 Parâmetros do GEE\n\n\n\n\n\n\nid: Identificador do sujeito (observações repetidas)\nfamily: Distribuição da variável resposta (gaussian, binomial, poisson)\ncorstr: Estrutura de correlação\n\n\"independence\": Sem correlação\n\"exchangeable\": Correlação constante\n\"ar1\": Autorregressiva de ordem 1\n\"unstructured\": Sem restrições (mais flexível)\n\n\n\n\n\n\n\nDiagnóstico do Modelo GEE\n\ncheck_model(modelo_gee_resp)\n\n\n\n\n\n\n\n\n\n\nVisualização do Modelo\n\nvisualize(modelo_gee_resp, plot = \"model\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n⚠️ Limitação do report()\n\n\n\nA função report() não funciona para modelos GEE. Pratique escrever seus resultados manualmente!\n\n\n\n\n\n\nModelo GEE para “Pulse”\n\nmodelo_gee_pulse &lt;- geeglm(\n  pulse ~ drug + Tempo + drug*Tempo,\n  data = bd_long,\n  id = ID,\n  family = gaussian,\n  corstr = \"unstructured\"\n)\n\nsummary(modelo_gee_pulse)\n\n\nCall:\ngeeglm(formula = pulse ~ drug + Tempo + drug * Tempo, family = gaussian, \n    data = bd_long, id = ID, corstr = \"unstructured\")\n\n Coefficients:\n                   Estimate Std.err    Wald Pr(&gt;|W|)    \n(Intercept)          2.2000  0.0408 2904.00   &lt;2e-16 ***\ndrugPlacebo          0.4667  0.0509   84.00   &lt;2e-16 ***\nTempo2               0.0167  0.0366    0.21   0.6492    \nTempo3               0.0833  0.0684    1.49   0.2230    \ndrugPlacebo:Tempo2   0.1333  0.0419   10.11   0.0015 ** \ndrugPlacebo:Tempo3   0.0333  0.0877    0.14   0.7038    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nCorrelation structure = unstructured \nEstimated Scale Parameters:\n\n            Estimate Std.err\n(Intercept)  0.00963 0.00168\n  Link = identity \n\nEstimated Correlation Parameters:\n          Estimate Std.err\nalpha.1:2    0.721   0.169\nalpha.1:3   -0.288   0.208\nalpha.2:3    0.115   0.267\nNumber of clusters:   12  Maximum cluster size: 3 \n\n\n\n\nDiagnóstico do Modelo\n\ncheck_model(modelo_gee_pulse)\n\n\n\n\n\n\n\n\n\n\nVisualização do Modelo\n\nvisualize(modelo_gee_pulse, plot = \"model\")",
    "crumbs": [
      "Modelos Lineares",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Lista 1: GLM, GEE e GMM</span>"
    ]
  },
  {
    "objectID": "lista_1.html#parte-3-gmm-modelos-mistos-generalizados",
    "href": "lista_1.html#parte-3-gmm-modelos-mistos-generalizados",
    "title": "1  Lista 1: GLM, GEE e GMM",
    "section": "1.4 📊 Parte 3: GMM (Modelos Mistos Generalizados)",
    "text": "1.4 📊 Parte 3: GMM (Modelos Mistos Generalizados)\n\nModelo GMM para “Resp”\nModelos mistos incorporam efeitos fixos e aleatórios, capturando variabilidade entre e dentro de sujeitos.\n\nmodelo_gmm_resp &lt;- lme(\n  fixed = resp ~ drug + Tempo + drug*Tempo,\n  random = ~1|ID,\n  data = bd_long\n)\n\nsummary(modelo_gmm_resp)\n\nLinear mixed-effects model fit by REML\n  Data: bd_long \n    AIC   BIC logLik\n  -53.4 -42.2   34.7\n\nRandom effects:\n Formula: ~1 | ID\n        (Intercept) Residual\nStdDev:      0.0269   0.0587\n\nFixed effects:  resp ~ drug + Tempo + drug * Tempo \n                   Value Std.Error DF t-value p-value\n(Intercept)         3.35    0.0264 20   127.1  0.0000\ndrugPlacebo        -0.12    0.0373 10    -3.1  0.0107\nTempo2              0.02    0.0339 20     0.5  0.6282\nTempo3             -0.02    0.0339 20    -0.5  0.6282\ndrugPlacebo:Tempo2  0.00    0.0479 20     0.0  1.0000\ndrugPlacebo:Tempo3  0.03    0.0479 20     0.7  0.4947\n Correlation: \n                   (Intr) drgPlc Tempo2 Tempo3 drP:T2\ndrugPlacebo        -0.707                            \nTempo2             -0.643  0.455                     \nTempo3             -0.643  0.455  0.500              \ndrugPlacebo:Tempo2  0.455 -0.643 -0.707 -0.354       \ndrugPlacebo:Tempo3  0.455 -0.643 -0.354 -0.707  0.500\n\nStandardized Within-Group Residuals:\n   Min     Q1    Med     Q3    Max \n-2.263 -0.560 -0.257  0.685  2.190 \n\nNumber of Observations: 36\nNumber of Groups: 12 \n\n\n\n\n\n\n\n\n🔍 Estrutura do Modelo Misto\n\n\n\n\n\n\nfixed: Efeitos fixos (mesmos do GLM)\nrandom = ~1|ID: Intercepto aleatório por sujeito\n\nCaptura variabilidade baseline entre indivíduos\n~1 indica apenas intercepto aleatório\n|ID agrupa por sujeito\n\n\nEstruturas mais complexas: - ~Tempo|ID: Intercepto e slope aleatórios - ~1|Escola/Sala: Hierarquia aninhada\n\n\n\n\n\nDiagnóstico do Modelo\n\ncheck_model(modelo_gmm_resp)\n\n\n\n\n\n\n\n\n\n\n\nVisualização do Modelo\n\n\n\n\n\n\n💡 Visualização Manual com ggplot2\n\n\n\nA função visualize() nem sempre funciona com modelos complexos. Vamos criar gráficos manualmente com ggplot2:\n\n\n\n# Calcular médias marginais estimadas\nmeans_ci_gmm_resp &lt;- emmeans(modelo_gmm_resp, \n                              specs = ~drug:Tempo)\n\n# Criar gráfico\nggplot(as.data.frame(means_ci_gmm_resp), \n       aes(x = Tempo, y = emmean, color = drug, group = drug)) +\n  geom_errorbar(aes(ymin = lower.CL, ymax = upper.CL),\n                width = 0.2,\n                position = position_dodge(0.1)) +\n  geom_point(position = position_dodge(0.1), \n             size = 3) +\n  geom_line(position = position_dodge(0.1)) +\n  labs(\n    title = \"Efeito da Droga na Respiração ao Longo do Tempo\",\n    subtitle = \"Médias marginais estimadas com IC 95%\",\n    x = \"Tempo\",\n    y = \"Respiração (Resp)\",\n    color = \"Tratamento\"\n  ) +\n  theme_minimal() +\n  theme(\n    legend.position = \"bottom\",\n    plot.title = element_text(face = \"bold\")\n  )\n\n\n\n\n\n\n\n\n\n\nRelatório Automatizado\n\nreport(modelo_gmm_resp)\n\nWe fitted a linear mixed model (estimated using REML and nlminb optimizer) to\npredict resp with drug and Tempo (formula: resp ~ drug + Tempo + drug * Tempo).\nThe model included ID as random effect (formula: ~1 | ID). The model's total\nexplanatory power is substantial (conditional R2 = 0.52) and the part related\nto the fixed effects alone (marginal R2) is of 0.42. The model's intercept,\ncorresponding to drug = New Drug and Tempo = 1, is at 3.35 (95% CI [3.30,\n3.40], t(20) = 127.12, p &lt; .001). Within this model:\n\n  - The effect of drug [Placebo] is statistically significant and negative (beta\n= -0.12, 95% CI [-0.20, -0.03], t(10) = -3.13, p = 0.011; Std. beta = -1.44,\n95% CI [-2.47, -0.42])\n  - The effect of Tempo [2] is statistically non-significant and positive (beta =\n0.02, 95% CI [-0.05, 0.09], t(20) = 0.49, p = 0.628; Std. beta = 0.21, 95% CI\n[-0.67, 1.08])\n  - The effect of Tempo [3] is statistically non-significant and negative (beta =\n-0.02, 95% CI [-0.09, 0.05], t(20) = -0.49, p = 0.628; Std. beta = -0.21, 95%\nCI [-1.08, 0.67])\n  - The effect of drug [Placebo] × Tempo [2] is statistically non-significant and\nnegative (beta = -6.16e-16, 95% CI [-0.10, 0.10], t(20) = -1.29e-14, p &gt; .999;\nStd. beta = -3.14e-16, 95% CI [-1.23, 1.23])\n  - The effect of drug [Placebo] × Tempo [3] is statistically non-significant and\npositive (beta = 0.03, 95% CI [-0.07, 0.13], t(20) = 0.70, p = 0.495; Std. beta\n= 0.41, 95% CI [-0.82, 1.65])\n\nStandardized parameters were obtained by fitting the model on a standardized\nversion of the dataset. 95% Confidence Intervals (CIs) and p-values were\ncomputed using a Wald t-distribution approximation.\n\n\n\n\n\n\nModelo GMM para “Pulse”\n\nmodelo_gmm_pulse &lt;- lme(\n  fixed = pulse ~ drug + Tempo + drug*Tempo,\n  random = ~1|ID,\n  data = bd_long\n)\n\nsummary(modelo_gmm_pulse)\n\nLinear mixed-effects model fit by REML\n  Data: bd_long \n    AIC   BIC logLik\n  -22.9 -11.6   19.4\n\nRandom effects:\n Formula: ~1 | ID\n        (Intercept) Residual\nStdDev:      0.0459   0.0972\n\nFixed effects:  pulse ~ drug + Tempo + drug * Tempo \n                   Value Std.Error DF t-value p-value\n(Intercept)        2.200    0.0439 20    50.1   0.000\ndrugPlacebo        0.467    0.0621 10     7.5   0.000\nTempo2             0.017    0.0561 20     0.3   0.769\nTempo3             0.083    0.0561 20     1.5   0.153\ndrugPlacebo:Tempo2 0.133    0.0793 20     1.7   0.108\ndrugPlacebo:Tempo3 0.033    0.0793 20     0.4   0.679\n Correlation: \n                   (Intr) drgPlc Tempo2 Tempo3 drP:T2\ndrugPlacebo        -0.707                            \nTempo2             -0.639  0.452                     \nTempo3             -0.639  0.452  0.500              \ndrugPlacebo:Tempo2  0.452 -0.639 -0.707 -0.354       \ndrugPlacebo:Tempo3  0.452 -0.639 -0.354 -0.707  0.500\n\nStandardized Within-Group Residuals:\n   Min     Q1    Med     Q3    Max \n-1.783 -0.629 -0.178  0.630  1.476 \n\nNumber of Observations: 36\nNumber of Groups: 12 \n\n\n\n\nDiagnóstico do Modelo\n\ncheck_model(modelo_gmm_pulse)\n\n\n\n\n\n\n\n\n\n\n\nVisualização do Modelo\n\n# Calcular médias marginais\nmeans_ci_gmm_pulse &lt;- emmeans(modelo_gmm_pulse, \n                               specs = ~drug:Tempo)\n\n# Criar gráfico\nggplot(as.data.frame(means_ci_gmm_pulse),\n       aes(x = Tempo, y = emmean, color = drug, group = drug)) +\n  geom_errorbar(aes(ymin = lower.CL, ymax = upper.CL),\n                width = 0.2,\n                position = position_dodge(0.1)) +\n  geom_point(position = position_dodge(0.1),\n             size = 3) +\n  geom_line(position = position_dodge(0.1)) +\n  labs(\n    title = \"Efeito da Droga no Pulso ao Longo do Tempo\",\n    subtitle = \"Médias marginais estimadas com IC 95%\",\n    x = \"Tempo\",\n    y = \"Pulso (Pulse)\",\n    color = \"Tratamento\"\n  ) +\n  theme_minimal() +\n  theme(\n    legend.position = \"bottom\",\n    plot.title = element_text(face = \"bold\")\n  )\n\n\n\n\n\n\n\n\n\n\nRelatório Automatizado\n\nreport(modelo_gmm_pulse)\n\nWe fitted a linear mixed model (estimated using REML and nlminb optimizer) to\npredict pulse with drug and Tempo (formula: pulse ~ drug + Tempo + drug *\nTempo). The model included ID as random effect (formula: ~1 | ID). The model's\ntotal explanatory power is substantial (conditional R2 = 0.89) and the part\nrelated to the fixed effects alone (marginal R2) is of 0.86. The model's\nintercept, corresponding to drug = New Drug and Tempo = 1, is at 2.20 (95% CI\n[2.11, 2.29], t(20) = 50.13, p &lt; .001). Within this model:\n\n  - The effect of drug [Placebo] is statistically significant and positive (beta\n= 0.47, 95% CI [0.33, 0.60], t(10) = 7.52, p &lt; .001; Std. beta = 1.62, 95% CI\n[1.14, 2.10])\n  - The effect of Tempo [2] is statistically non-significant and positive (beta =\n0.02, 95% CI [-0.10, 0.13], t(20) = 0.30, p = 0.769; Std. beta = 0.06, 95% CI\n[-0.35, 0.46])\n  - The effect of Tempo [3] is statistically non-significant and positive (beta =\n0.08, 95% CI [-0.03, 0.20], t(20) = 1.49, p = 0.153; Std. beta = 0.29, 95% CI\n[-0.12, 0.70])\n  - The effect of drug [Placebo] × Tempo [2] is statistically non-significant and\npositive (beta = 0.13, 95% CI [-0.03, 0.30], t(20) = 1.68, p = 0.108; Std. beta\n= 0.46, 95% CI [-0.11, 1.04])\n  - The effect of drug [Placebo] × Tempo [3] is statistically non-significant and\npositive (beta = 0.03, 95% CI [-0.13, 0.20], t(20) = 0.42, p = 0.679; Std. beta\n= 0.12, 95% CI [-0.46, 0.69])\n\nStandardized parameters were obtained by fitting the model on a standardized\nversion of the dataset. 95% Confidence Intervals (CIs) and p-values were\ncomputed using a Wald t-distribution approximation.",
    "crumbs": [
      "Modelos Lineares",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Lista 1: GLM, GEE e GMM</span>"
    ]
  },
  {
    "objectID": "lista_1.html#sec-violacoes",
    "href": "lista_1.html#sec-violacoes",
    "title": "1  Lista 1: GLM, GEE e GMM",
    "section": "1.5 🔧 Violação dos Pressupostos: O Que Fazer?",
    "text": "1.5 🔧 Violação dos Pressupostos: O Que Fazer?\n\n\n\n\n\n\nGuia de Soluções para Violações\n\n\n\nQuando seu modelo viola pressupostos, considere as seguintes estratégias:\n\n\n\nMulticolinearidadeNormalidadeHomogeneidadeOutliersLinearidadeAjuste Global\n\n\nProblema: Preditores altamente correlacionados entre si (VIF &gt; 10)\nSoluções:\n\nIdentificar correlações\n\ncor(bd_long[, c(\"var1\", \"var2\", \"var3\")])\n\nRemover variável redundante\n\nManter a mais teoricamente relevante\nOu a com maior poder explicativo\n\nCriar índices compostos\n\nMédia ou soma ponderada de variáveis correlacionadas\nAnálise de componentes principais (PCA)\n\nCentralizar variáveis\n\nbd_long$var_centered &lt;- scale(bd_long$var, scale = FALSE)\n\n\n\n\nProblema: Resíduos não seguem distribuição normal\nSoluções:\n\nTransformações de dados\n\n# Logarítmica\nbd_long$resp_log &lt;- log(bd_long$resp + 1)\n\n# Raiz quadrada\nbd_long$resp_sqrt &lt;- sqrt(bd_long$resp)\n\n# Box-Cox\nlibrary(MASS)\nbc &lt;- boxcox(modelo1_resp)\nlambda &lt;- bc$x[which.max(bc$y)]\n\nModelos robustos\n\nlibrary(robustbase)\nmodelo_robusto &lt;- lmrob(resp ~ drug + Tempo, data = bd_long)\n\nModelos generalizados (GzLM)\n\nUse distribuições mais apropriadas (Gamma, Poisson)\n\n\n\n\nProblema: Variância não constante dos resíduos\nSoluções:\n\nTransformação da variável resposta\n\nMesmas transformações da normalidade\n\nPesos heterocedásticos\n\nlibrary(nlme)\nmodelo_hetero &lt;- gls(\n  resp ~ drug + Tempo,\n  weights = varIdent(form = ~1|drug),\n  data = bd_long\n)\n\nErros-padrão robustos\n\nlibrary(sandwich)\nlibrary(lmtest)\ncoeftest(modelo1_resp, vcov = vcovHC(modelo1_resp, type = \"HC3\"))\n\n\n\n\nProblema: Observações extremamente influentes\nSoluções:\n\nInvestigar outliers\n\n# Identificar outliers\noutliers &lt;- which(cooks.distance(modelo1_resp) &gt; 4/nrow(bd_long))\nbd_long[outliers, ]\n\nAnálise de sensibilidade\n\nRefazer análise com e sem outliers\nReportar ambos os resultados\n\nModelos robustos\n\nMenos sensíveis a outliers\n\nTransformações\n\nReduzir impacto de valores extremos\n\n\n\n\nProblema: Relação não-linear entre preditores e resposta\nSoluções:\n\nTermos polinomiais\n\nmodelo_quad &lt;- lm(resp ~ drug + Tempo + I(Tempo^2), \n                  data = bd_long)\n\nSplines\n\nlibrary(splines)\nmodelo_spline &lt;- lm(resp ~ drug + bs(Tempo, df = 3), \n                    data = bd_long)\n\nModelos aditivos generalizados (GAM)\n\nlibrary(mgcv)\nmodelo_gam &lt;- gam(resp ~ drug + s(Tempo), \n                  data = bd_long)\n\n\n\n\nProblema: Modelo não se ajusta bem aos dados (Posterior Predictive)\nSoluções:\n\nRevisar especificação do modelo\n\nAdicionar interações relevantes\nIncluir preditores omitidos\n\nMudar distribuição\n\nDe gaussian para Gamma, Poisson, etc.\n\nConsiderar não-linearidades\n\nGAM, splines, polinômios\n\nModelos mais flexíveis\n\nRandom forests, boosting (exploratório)\n\n\n\n\n\n\n\n\n\n\n\n💡 Estratégia Geral\n\n\n\n\nIdentifique todas as violações\nPriorize as mais severas\nAplique soluções sequencialmente\nReavalie após cada mudança\nDocumente todas as tentativas\nSe tudo falhar, reconheça limitações do modelo",
    "crumbs": [
      "Modelos Lineares",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Lista 1: GLM, GEE e GMM</span>"
    ]
  },
  {
    "objectID": "lista_1.html#conclusão",
    "href": "lista_1.html#conclusão",
    "title": "1  Lista 1: GLM, GEE e GMM",
    "section": "1.6 📝 Conclusão",
    "text": "1.6 📝 Conclusão\n\n\n\n\n\n\nResumo da Lista\n\n\n\nNeste tutorial, exploramos três abordagens complementares para análise de medidas repetidas:\nGLM: Abordagem clássica, pressupõe esfericidade\nGEE: Robusto à especificação de correlação, foco em efeitos populacionais\nGMM: Modela variabilidade individual, permite estruturas hierárquicas\nCada método tem vantagens específicas. A escolha depende de: - Estrutura dos dados - Pergunta de pesquisa - Pressupostos atendidos - Interpretação desejada\nPróximos passos: Listas subsequentes compararão estes métodos em diferentes cenários.",
    "crumbs": [
      "Modelos Lineares",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Lista 1: GLM, GEE e GMM</span>"
    ]
  },
  {
    "objectID": "lista_1.html#recursos-complementares",
    "href": "lista_1.html#recursos-complementares",
    "title": "1  Lista 1: GLM, GEE e GMM",
    "section": "1.7 📚 Recursos Complementares",
    "text": "1.7 📚 Recursos Complementares\n\nAula em Vídeo (SPSS)\n\n\n\n\nReferências Recomendadas\n\n\n\n\n\n\n📖 Leituras Complementares\n\n\n\n\n\nTestes e pressupostos: - Mauchly’s Test of Sphericity in R\nManipulação de dados: - Pivoting multiple variables - YouTube - Wide to long format part 2 - YouTube\nModelos avançados: - Pinheiro & Bates (2000). Mixed-Effects Models in S and S-PLUS - Fitzmaurice et al. (2011). Applied Longitudinal Analysis - West et al. (2014). Linear Mixed Models: A Practical Guide",
    "crumbs": [
      "Modelos Lineares",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Lista 1: GLM, GEE e GMM</span>"
    ]
  },
  {
    "objectID": "lista_1.html#informações-de-sessão",
    "href": "lista_1.html#informações-de-sessão",
    "title": "1  Lista 1: GLM, GEE e GMM",
    "section": "1.8 🔧 Informações de Sessão",
    "text": "1.8 🔧 Informações de Sessão\n\nreport(sessionInfo())\n\nAnalyses were conducted using the R Statistical language (version 4.4.2; R Core\nTeam, 2024) on Windows 11 x64 (build 26100), using the packages lme4 (version\n1.1.37; Bates D et al., 2015), Matrix (version 1.7.1; Bates D et al., 2024),\neffectsize (version 1.0.1; Ben-Shachar MS et al., 2020), flexplot (version\n0.24.3; Fife, D, 2022), effects (version 4.2.4; Fox J, Weisberg S, 2019),\ncarData (version 3.0.5; Fox J et al., 2022), mvtnorm (version 1.3.3; Genz A,\nBretz F, 2009), geepack (version 1.3.13; Halekoh U et al., 2006), TH.data\n(version 1.1.3; Hothorn T, 2025), multcomp (version 1.4.28; Hothorn T et al.,\n2008), rstatix (version 0.7.2; Kassambara A, 2023), emmeans (version 1.11.0;\nLenth R, 2025), sjstats (version 0.19.1; Lüdecke D, 2025), parameters (version\n0.28.3; Lüdecke D et al., 2020), performance (version 0.15.2; Lüdecke D et al.,\n2021), easystats (version 0.7.5; Lüdecke D et al., 2022), see (version 0.12.0;\nLüdecke D et al., 2021), insight (version 1.4.4; Lüdecke D et al., 2019),\nbayestestR (version 0.17.0; Makowski D et al., 2019), modelbased (version\n0.13.1; Makowski D et al., 2025), report (version 0.6.3; Makowski D et al.,\n2023), correlation (version 0.8.8; Makowski D et al., 2022), datawizard\n(version 1.3.0; Patil I et al., 2022), nlme (version 3.1.166; Pinheiro J et\nal., 2024), foreign (version 0.8.87; R Core Team, 2024), rempsyc (version\n0.2.0; Thériault R, 2023), survival (version 3.7.0; Therneau T, 2024), MASS\n(version 7.3.61; Venables WN, Ripley BD, 2002), ggplot2 (version 4.0.1; Wickham\nH, 2016), dplyr (version 1.1.4; Wickham H et al., 2023) and tidyr (version\n1.3.1; Wickham H et al., 2024).\n\nReferences\n----------\n  - Bates D, Mächler M, Bolker B, Walker S (2015). \"Fitting Linear Mixed-Effects\nModels Using lme4.\" _Journal of Statistical Software_, *67*(1), 1-48.\ndoi:10.18637/jss.v067.i01 &lt;https://doi.org/10.18637/jss.v067.i01&gt;.\n  - Bates D, Maechler M, Jagan M (2024). _Matrix: Sparse and Dense Matrix Classes\nand Methods_. R package version 1.7-1,\n&lt;https://CRAN.R-project.org/package=Matrix&gt;.\n  - Ben-Shachar MS, Lüdecke D, Makowski D (2020). \"effectsize: Estimation of\nEffect Size Indices and Standardized Parameters.\" _Journal of Open Source\nSoftware_, *5*(56), 2815. doi:10.21105/joss.02815\n&lt;https://doi.org/10.21105/joss.02815&gt;, &lt;https://doi.org/10.21105/joss.02815&gt;.\n  - Fife, A. D (2022). \"Flexplot: Graphically-based data analysis.\"\n_Psychological Methods_, *27*(4), -19. &lt;doi.org/10.1037/met0000424&gt;.\n  - Fox J, Weisberg S (2019). _An R Companion to Applied Regression_, 3rd\nedition. Sage, Thousand Oaks CA.\n&lt;https://www.john-fox.ca/Companion/index.html&gt;. Fox J, Weisberg S (2018).\n\"Visualizing Fit and Lack of Fit in Complex Regression Models with Predictor\nEffect Plots and Partial Residuals.\" _Journal of Statistical Software_,\n*87*(9), 1-27. doi:10.18637/jss.v087.i09\n&lt;https://doi.org/10.18637/jss.v087.i09&gt;. Fox J (2003). \"Effect Displays in R\nfor Generalised Linear Models.\" _Journal of Statistical Software_, *8*(15),\n1-27. doi:10.18637/jss.v008.i15 &lt;https://doi.org/10.18637/jss.v008.i15&gt;. Fox J,\nHong J (2009). \"Effect Displays in R for Multinomial and Proportional-Odds\nLogit Models: Extensions to the effects Package.\" _Journal of Statistical\nSoftware_, *32*(1), 1-24. doi:10.18637/jss.v032.i01\n&lt;https://doi.org/10.18637/jss.v032.i01&gt;.\n  - Fox J, Weisberg S, Price B (2022). _carData: Companion to Applied Regression\nData Sets_. R package version 3.0-5,\n&lt;https://CRAN.R-project.org/package=carData&gt;.\n  - Genz A, Bretz F (2009). _Computation of Multivariate Normal and t\nProbabilities_, series Lecture Notes in Statistics. Springer-Verlag,\nHeidelberg. ISBN 978-3-642-01688-2.\n  - Halekoh U, Højsgaard S, Yan J (2006). \"The R Package geepack for Generalized\nEstimating Equations.\" _Journal of Statistical Software_, *15/2*, 1-11. Yan J,\nFine JP (2004). \"Estimating Equations for Association Structures.\" _Statistics\nin Medicine_, *23*, 859-880. Yan J (2002). \"geepack: Yet Another Package for\nGeneralized Estimating Equations.\" _R-News_, *2/3*, 12-14. Xu, Z., Fine, P. J,\nSong, W., Yan, J. (2025). \"On GEE for mean-variance-correlation models:\nVariance estimation and model selection.\" _Statistics in Medicine_, *44*, 1-2.\n  - Hothorn T (2025). _TH.data: TH's Data Archive_. R package version 1.1-3,\n&lt;https://CRAN.R-project.org/package=TH.data&gt;.\n  - Hothorn T, Bretz F, Westfall P (2008). \"Simultaneous Inference in General\nParametric Models.\" _Biometrical Journal_, *50*(3), 346-363.\n  - Kassambara A (2023). _rstatix: Pipe-Friendly Framework for Basic Statistical\nTests_. R package version 0.7.2, &lt;https://CRAN.R-project.org/package=rstatix&gt;.\n  - Lenth R (2025). _emmeans: Estimated Marginal Means, aka Least-Squares Means_.\nR package version 1.11.0, &lt;https://CRAN.R-project.org/package=emmeans&gt;.\n  - Lüdecke D (2025). _sjstats: Statistical Functions for Regression Models\n(Version 0.19.1)_. doi:10.5281/zenodo.1284472\n&lt;https://doi.org/10.5281/zenodo.1284472&gt;,\n&lt;https://CRAN.R-project.org/package=sjstats&gt;.\n  - Lüdecke D, Ben-Shachar M, Patil I, Makowski D (2020). \"Extracting, Computing\nand Exploring the Parameters of Statistical Models using R.\" _Journal of Open\nSource Software_, *5*(53), 2445. doi:10.21105/joss.02445\n&lt;https://doi.org/10.21105/joss.02445&gt;.\n  - Lüdecke D, Ben-Shachar M, Patil I, Waggoner P, Makowski D (2021).\n\"performance: An R Package for Assessment, Comparison and Testing of\nStatistical Models.\" _Journal of Open Source Software_, *6*(60), 3139.\ndoi:10.21105/joss.03139 &lt;https://doi.org/10.21105/joss.03139&gt;.\n  - Lüdecke D, Ben-Shachar M, Patil I, Wiernik B, Bacher E, Thériault R, Makowski\nD (2022). \"easystats: Framework for Easy Statistical Modeling, Visualization,\nand Reporting.\" _CRAN_. doi:10.32614/CRAN.package.easystats\n&lt;https://doi.org/10.32614/CRAN.package.easystats&gt;, R package,\n&lt;https://easystats.github.io/easystats/&gt;.\n  - Lüdecke D, Patil I, Ben-Shachar M, Wiernik B, Waggoner P, Makowski D (2021).\n\"see: An R Package for Visualizing Statistical Models.\" _Journal of Open Source\nSoftware_, *6*(64), 3393. doi:10.21105/joss.03393\n&lt;https://doi.org/10.21105/joss.03393&gt;.\n  - Lüdecke D, Waggoner P, Makowski D (2019). \"insight: A Unified Interface to\nAccess Information from Model Objects in R.\" _Journal of Open Source Software_,\n*4*(38), 1412. doi:10.21105/joss.01412 &lt;https://doi.org/10.21105/joss.01412&gt;.\n  - Makowski D, Ben-Shachar M, Lüdecke D (2019). \"bayestestR: Describing Effects\nand their Uncertainty, Existence and Significance within the Bayesian\nFramework.\" _Journal of Open Source Software_, *4*(40), 1541.\ndoi:10.21105/joss.01541 &lt;https://doi.org/10.21105/joss.01541&gt;,\n&lt;https://joss.theoj.org/papers/10.21105/joss.01541&gt;.\n  - Makowski D, Ben-Shachar M, Wiernik B, Patil I, Thériault R, Lüdecke D (2025).\n\"modelbased: An R package to make the most out of your statistical models\nthrough marginal means, marginal effects, and model predictions.\" _Journal of\nOpen Source Software_, *10*(109), 7969. doi:10.21105/joss.07969\n&lt;https://doi.org/10.21105/joss.07969&gt;,\n&lt;https://joss.theoj.org/papers/10.21105/joss.07969&gt;.\n  - Makowski D, Lüdecke D, Patil I, Thériault R, Ben-Shachar M, Wiernik B (2023).\n\"Automated Results Reporting as a Practical Tool to Improve Reproducibility and\nMethodological Best Practices Adoption.\" _CRAN_.\ndoi:10.32614/CRAN.package.report\n&lt;https://doi.org/10.32614/CRAN.package.report&gt;,\n&lt;https://easystats.github.io/report/&gt;.\n  - Makowski D, Wiernik B, Patil I, Lüdecke D, Ben-Shachar M (2022).\n\"correlation: Methods for Correlation Analysis.\" Version 0.8.3,\n&lt;https://CRAN.R-project.org/package=correlation&gt;. Makowski D, Ben-Shachar M,\nPatil I, Lüdecke D (2020). \"Methods and Algorithms for Correlation Analysis in\nR.\" _Journal of Open Source Software_, *5*(51), 2306. doi:10.21105/joss.02306\n&lt;https://doi.org/10.21105/joss.02306&gt;,\n&lt;https://joss.theoj.org/papers/10.21105/joss.02306&gt;.\n  - Patil I, Makowski D, Ben-Shachar M, Wiernik B, Bacher E, Lüdecke D (2022).\n\"datawizard: An R Package for Easy Data Preparation and Statistical\nTransformations.\" _Journal of Open Source Software_, *7*(78), 4684.\ndoi:10.21105/joss.04684 &lt;https://doi.org/10.21105/joss.04684&gt;.\n  - Pinheiro J, Bates D, R Core Team (2024). _nlme: Linear and Nonlinear Mixed\nEffects Models_. R package version 3.1-166,\n&lt;https://CRAN.R-project.org/package=nlme&gt;. Pinheiro JC, Bates DM (2000).\n_Mixed-Effects Models in S and S-PLUS_. Springer, New York. doi:10.1007/b98882\n&lt;https://doi.org/10.1007/b98882&gt;.\n  - R Core Team (2024). _foreign: Read Data Stored by 'Minitab', 'S', 'SAS',\n'SPSS', 'Stata', 'Systat', 'Weka', 'dBase', ..._. R package version 0.8-87,\n&lt;https://CRAN.R-project.org/package=foreign&gt;.\n  - R Core Team (2024). _R: A Language and Environment for Statistical\nComputing_. R Foundation for Statistical Computing, Vienna, Austria.\n&lt;https://www.R-project.org/&gt;.\n  - Thériault R (2023). \"rempsyc: Convenience functions for psychology.\" _Journal\nof Open Source Software_, *8*(87), 5466. doi:10.21105/joss.05466\n&lt;https://doi.org/10.21105/joss.05466&gt;, &lt;https://doi.org/10.21105/joss.05466&gt;.\n  - Therneau T (2024). _A Package for Survival Analysis in R_. R package version\n3.7-0, &lt;https://CRAN.R-project.org/package=survival&gt;. Terry M. Therneau,\nPatricia M. Grambsch (2000). _Modeling Survival Data: Extending the Cox Model_.\nSpringer, New York. ISBN 0-387-98784-3.\n  - Venables WN, Ripley BD (2002). _Modern Applied Statistics with S_, Fourth\nedition. Springer, New York. ISBN 0-387-95457-0,\n&lt;https://www.stats.ox.ac.uk/pub/MASS4/&gt;.\n  - Wickham H (2016). _ggplot2: Elegant Graphics for Data Analysis_.\nSpringer-Verlag New York. ISBN 978-3-319-24277-4,\n&lt;https://ggplot2.tidyverse.org&gt;.\n  - Wickham H, François R, Henry L, Müller K, Vaughan D (2023). _dplyr: A Grammar\nof Data Manipulation_. R package version 1.1.4,\n&lt;https://CRAN.R-project.org/package=dplyr&gt;.\n  - Wickham H, Vaughan D, Girlich M (2024). _tidyr: Tidy Messy Data_. R package\nversion 1.3.1, &lt;https://CRAN.R-project.org/package=tidyr&gt;.\n\n\n\n\n\n\n\n\n💡 Reprodutibilidade\n\n\n\nSempre inclua sessionInfo() ao final de suas análises para documentar versões de pacotes e garantir reprodutibilidade!",
    "crumbs": [
      "Modelos Lineares",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Lista 1: GLM, GEE e GMM</span>"
    ]
  },
  {
    "objectID": "lista_2.html#preparação-dos-dados",
    "href": "lista_2.html#preparação-dos-dados",
    "title": "Lista 2: GEE Avançado",
    "section": "📥 Preparação dos Dados",
    "text": "📥 Preparação dos Dados\n\n\n\n\n\n\nDownload Necessário\n\n\n\nUse o mesmo banco “New Drug” da Lista 1.\n\n\n\nCarregamento e Transformação\n\n# 1. Carregar dados originais\noriginal_wide &lt;- read.spss(\"bd_New drug_respiratory&pulse.sav\", \n                           to.data.frame = TRUE)\n\n# 2. Renomear colunas\nbd &lt;- original_wide %&gt;%\n  rename_with(~gsub(\"(resp|pulse)(\\\\d+)\", \"\\\\1_\\\\2\", .), -drug) %&gt;%\n  mutate(ID = row_number()) %&gt;%\n  select(ID, everything())\n\n# 3. Converter para formato long\nbd_long &lt;- pivot_longer(\n  bd,\n  cols = resp_1:pulse_3,\n  names_to = c(\".value\", \"Tempo\"),\n  names_pattern = \"(.+)_(.+)\"\n)\n\n# 4. Converter para fatores\nbd_long$ID &lt;- factor(bd_long$ID)\nbd_long$Tempo &lt;- factor(bd_long$Tempo)\n\n# Visualizar estrutura\nhead(bd_long)\n\n# A tibble: 6 × 5\n  ID    drug     Tempo  resp pulse\n  &lt;fct&gt; &lt;fct&gt;    &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 1     New Drug 1       3.4   2.2\n2 1     New Drug 2       3.3   2.1\n3 1     New Drug 3       3.3   2.1\n4 2     New Drug 1       3.4   2.2\n5 2     New Drug 2       3.4   2.1\n6 2     New Drug 3       3.3   2.2",
    "crumbs": [
      "Modelos Lineares",
      "Lista 2: GEE Avançado"
    ]
  },
  {
    "objectID": "lista_2.html#parte-a-modelos-gee-com-diferentes-distribuições",
    "href": "lista_2.html#parte-a-modelos-gee-com-diferentes-distribuições",
    "title": "Lista 2: GEE Avançado",
    "section": "🎯 Parte A: Modelos GEE com Diferentes Distribuições",
    "text": "🎯 Parte A: Modelos GEE com Diferentes Distribuições\n\n\n\n\n\n\nPor que Testar Diferentes Distribuições?\n\n\n\nA escolha da distribuição afeta: - Ajuste do modelo aos dados - Interpretação dos coeficientes - Precisão das predições - Validade das inferências\nTestar múltiplas distribuições ajuda a identificar qual melhor representa seus dados.\n\n\n\n\nModelo 1: Distribuição Normal (Gaussian)\n\nAjuste do Modelo\n\nmodelo_gee_pulse_normal &lt;- geeglm(\n  pulse ~ drug + Tempo + drug*Tempo,\n  data = bd_long,\n  id = ID,\n  family = gaussian,\n  corstr = \"unstructured\"\n)\n\n\n\n\n\n\n\n📊 Quando Usar Distribuição Normal?\n\n\n\n\n\nAdequada para: - Variáveis contínuas - Distribuição simétrica - Sem limite inferior ou superior rígido\nCaracterísticas: - Link: identidade (padrão) - Variância: constante - Suporte: \\((-\\infty, +\\infty)\\)\n\n\n\n\n\n\nResultados e Contrastes\n\nsummary(modelo_gee_pulse_normal)\n\n\nCall:\ngeeglm(formula = pulse ~ drug + Tempo + drug * Tempo, family = gaussian, \n    data = bd_long, id = ID, corstr = \"unstructured\")\n\n Coefficients:\n                   Estimate Std.err     Wald Pr(&gt;|W|)    \n(Intercept)         2.20000 0.04082 2904.000  &lt; 2e-16 ***\ndrugPlacebo         0.46667 0.05092   84.000  &lt; 2e-16 ***\nTempo2              0.01667 0.03664    0.207  0.64921    \nTempo3              0.08333 0.06838    1.485  0.22297    \ndrugPlacebo:Tempo2  0.13333 0.04194   10.105  0.00148 ** \ndrugPlacebo:Tempo3  0.03333 0.08767    0.145  0.70377    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nCorrelation structure = unstructured \nEstimated Scale Parameters:\n\n            Estimate  Std.err\n(Intercept)  0.00963 0.001676\n  Link = identity \n\nEstimated Correlation Parameters:\n          Estimate Std.err\nalpha.1:2   0.7212  0.1690\nalpha.1:3  -0.2885  0.2076\nalpha.2:3   0.1154  0.2665\nNumber of clusters:   12  Maximum cluster size: 3 \n\n\n\nMédias MarginaisComparações Par-a-Par\n\n\n\nemmeans(modelo_gee_pulse_normal, \n        specs = ~drug*Tempo)\n\n drug     Tempo emmean     SE df lower.CL upper.CL\n New Drug 1       2.20 0.0408 30     2.12     2.28\n Placebo  1       2.67 0.0304 30     2.60     2.73\n New Drug 2       2.22 0.0549 30     2.10     2.33\n Placebo  2       2.82 0.0280 30     2.76     2.87\n New Drug 3       2.28 0.0436 30     2.19     2.37\n Placebo  3       2.78 0.0366 30     2.71     2.86\n\nCovariance estimate used: vbeta \nConfidence level used: 0.95 \n\n\n\n\n\nemmeans(modelo_gee_pulse_normal, \n        pairwise ~ drug*Tempo)\n\n$emmeans\n drug     Tempo emmean     SE df lower.CL upper.CL\n New Drug 1       2.20 0.0408 30     2.12     2.28\n Placebo  1       2.67 0.0304 30     2.60     2.73\n New Drug 2       2.22 0.0549 30     2.10     2.33\n Placebo  2       2.82 0.0280 30     2.76     2.87\n New Drug 3       2.28 0.0436 30     2.19     2.37\n Placebo  3       2.78 0.0366 30     2.71     2.86\n\nCovariance estimate used: vbeta \nConfidence level used: 0.95 \n\n$contrasts\n contrast                          estimate     SE df t.ratio p.value\n New Drug Tempo1 - Placebo Tempo1   -0.4667 0.0509 30  -9.165  &lt;.0001\n New Drug Tempo1 - New Drug Tempo2  -0.0167 0.0366 30  -0.455  0.9973\n New Drug Tempo1 - Placebo Tempo2   -0.6167 0.0495 30 -12.449  &lt;.0001\n New Drug Tempo1 - New Drug Tempo3  -0.0833 0.0684 30  -1.219  0.8244\n New Drug Tempo1 - Placebo Tempo3   -0.5833 0.0549 30 -10.634  &lt;.0001\n Placebo Tempo1 - New Drug Tempo2    0.4500 0.0627 30   7.173  &lt;.0001\n Placebo Tempo1 - Placebo Tempo2    -0.1500 0.0204 30  -7.348  &lt;.0001\n Placebo Tempo1 - New Drug Tempo3    0.3833 0.0531 30   7.213  &lt;.0001\n Placebo Tempo1 - Placebo Tempo3    -0.1167 0.0549 30  -2.127  0.3013\n New Drug Tempo2 - Placebo Tempo2   -0.6000 0.0616 30  -9.738  &lt;.0001\n New Drug Tempo2 - New Drug Tempo3  -0.0667 0.0609 30  -1.095  0.8793\n New Drug Tempo2 - Placebo Tempo3   -0.5667 0.0660 30  -8.590  &lt;.0001\n Placebo Tempo2 - New Drug Tempo3    0.5333 0.0518 30  10.292  &lt;.0001\n Placebo Tempo2 - Placebo Tempo3     0.0333 0.0509 30   0.655  0.9855\n New Drug Tempo3 - Placebo Tempo3   -0.5000 0.0569 30  -8.783  &lt;.0001\n\nP value adjustment: tukey method for comparing a family of 6 estimates \n\n\n\n\n\n\n\n\nDiagnóstico do Modelo\n\ncheck_model(modelo_gee_pulse_normal)\n\n\n\n\n\n\n\n\n\n\n\nVisualização dos Resultados\n\n# Calcular médias marginais\nmeans_ci_normal &lt;- emmeans(modelo_gee_pulse_normal, \n                           specs = ~drug:Tempo)\n\n# Criar gráfico elegante\nggplot(as.data.frame(means_ci_normal), \n       aes(x = Tempo, y = emmean, color = drug, group = drug)) +\n  geom_errorbar(\n    aes(ymin = lower.CL, ymax = upper.CL),\n    width = 0.2,\n    position = position_dodge(0.1)\n  ) +\n  geom_point(\n    position = position_dodge(0.1),\n    size = 4\n  ) +\n  geom_line(\n    position = position_dodge(0.1),\n    linewidth = 1\n  ) +\n  labs(\n    title = \"GEE com Distribuição Normal\",\n    subtitle = \"Médias marginais estimadas com IC 95%\",\n    x = \"Tempo\",\n    y = \"Pulso (bpm)\",\n    color = \"Tratamento\"\n  ) +\n  theme_minimal(base_size = 13) +\n  theme(\n    legend.position = \"bottom\",\n    plot.title = element_text(face = \"bold\", size = 15),\n    panel.grid.minor = element_blank()\n  ) +\n  scale_color_brewer(palette = \"Set1\")\n\n\n\n\n\n\n\n\n\n\n\n\nModelo 2: Distribuição Gamma\n\nAjuste do Modelo\n\nmodelo_gee_pulse_gamma &lt;- geeglm(\n  pulse ~ drug + Tempo + drug*Tempo,\n  data = bd_long,\n  id = ID,\n  family = Gamma(link = \"identity\"),\n  corstr = \"unstructured\"\n)\n\n\n\n\n\n\n\n📊 Quando Usar Distribuição Gamma?\n\n\n\n\n\nAdequada para: - Variáveis contínuas positivas - Distribuição assimétrica à direita - Variância proporcional à média\nCaracterísticas: - Link comum: log ou identity - Variância: aumenta com a média - Suporte: \\((0, +\\infty)\\)\nExemplos: - Tempo de reação - Tempo de sobrevida - Concentrações biomarcadores\n\n\n\n\n\n\nResultados e Contrastes\n\nsummary(modelo_gee_pulse_gamma)\n\n\nCall:\ngeeglm(formula = pulse ~ drug + Tempo + drug * Tempo, family = Gamma(link = \"identity\"), \n    data = bd_long, id = ID, corstr = \"unstructured\")\n\n Coefficients:\n                   Estimate Std.err    Wald Pr(&gt;|W|)    \n(Intercept)          2.2000  0.0408 2904.00   &lt;2e-16 ***\ndrugPlacebo          0.4667  0.0509   84.00   &lt;2e-16 ***\nTempo2               0.0167  0.0366    0.21   0.6492    \nTempo3               0.0833  0.0684    1.49   0.2230    \ndrugPlacebo:Tempo2   0.1333  0.0419   10.11   0.0015 ** \ndrugPlacebo:Tempo3   0.0333  0.0877    0.14   0.7038    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nCorrelation structure = unstructured \nEstimated Scale Parameters:\n\n            Estimate  Std.err\n(Intercept)  0.00172 0.000372\n  Link = identity \n\nEstimated Correlation Parameters:\n          Estimate Std.err\nalpha.1:2    0.745   0.178\nalpha.1:3   -0.279   0.208\nalpha.2:3    0.156   0.279\nNumber of clusters:   12  Maximum cluster size: 3 \n\n\n\nMédias MarginaisComparações Par-a-Par\n\n\n\nemmeans(modelo_gee_pulse_gamma, \n        specs = ~drug*Tempo)\n\n drug     Tempo emmean     SE df lower.CL upper.CL\n New Drug 1       2.20 0.0408 30     2.12     2.28\n Placebo  1       2.67 0.0304 30     2.60     2.73\n New Drug 2       2.22 0.0549 30     2.10     2.33\n Placebo  2       2.82 0.0281 30     2.76     2.87\n New Drug 3       2.28 0.0436 30     2.19     2.37\n Placebo  3       2.78 0.0366 30     2.71     2.86\n\nCovariance estimate used: vbeta \nConfidence level used: 0.95 \n\n\n\n\n\nemmeans(modelo_gee_pulse_gamma, \n        pairwise ~ drug*Tempo)\n\n$emmeans\n drug     Tempo emmean     SE df lower.CL upper.CL\n New Drug 1       2.20 0.0408 30     2.12     2.28\n Placebo  1       2.67 0.0304 30     2.60     2.73\n New Drug 2       2.22 0.0549 30     2.10     2.33\n Placebo  2       2.82 0.0281 30     2.76     2.87\n New Drug 3       2.28 0.0436 30     2.19     2.37\n Placebo  3       2.78 0.0366 30     2.71     2.86\n\nCovariance estimate used: vbeta \nConfidence level used: 0.95 \n\n$contrasts\n contrast                          estimate     SE df t.ratio p.value\n New Drug Tempo1 - Placebo Tempo1    -0.467 0.0509 30  -9.170  &lt;.0001\n New Drug Tempo1 - New Drug Tempo2   -0.017 0.0366 30  -0.450  0.9970\n New Drug Tempo1 - Placebo Tempo2    -0.617 0.0495 30 -12.450  &lt;.0001\n New Drug Tempo1 - New Drug Tempo3   -0.083 0.0684 30  -1.220  0.8240\n New Drug Tempo1 - Placebo Tempo3    -0.583 0.0549 30 -10.630  &lt;.0001\n Placebo Tempo1 - New Drug Tempo2     0.450 0.0627 30   7.170  &lt;.0001\n Placebo Tempo1 - Placebo Tempo2     -0.150 0.0204 30  -7.350  &lt;.0001\n Placebo Tempo1 - New Drug Tempo3     0.383 0.0531 30   7.210  &lt;.0001\n Placebo Tempo1 - Placebo Tempo3     -0.117 0.0549 30  -2.130  0.3010\n New Drug Tempo2 - Placebo Tempo2    -0.600 0.0616 30  -9.740  &lt;.0001\n New Drug Tempo2 - New Drug Tempo3   -0.067 0.0609 30  -1.100  0.8790\n New Drug Tempo2 - Placebo Tempo3    -0.567 0.0660 30  -8.590  &lt;.0001\n Placebo Tempo2 - New Drug Tempo3     0.533 0.0518 30  10.290  &lt;.0001\n Placebo Tempo2 - Placebo Tempo3      0.033 0.0509 30   0.650  0.9860\n New Drug Tempo3 - Placebo Tempo3    -0.500 0.0569 30  -8.780  &lt;.0001\n\nP value adjustment: tukey method for comparing a family of 6 estimates \n\n\n\n\n\n\n\n\nDiagnóstico do Modelo\n\ncheck_model(modelo_gee_pulse_gamma)\n\n\n\n\n\n\n\n\n\n\n\nVisualização dos Resultados\n\n# Calcular médias marginais\nmeans_ci_gamma &lt;- emmeans(modelo_gee_pulse_gamma, \n                          specs = ~drug:Tempo)\n\n# Criar gráfico\nggplot(as.data.frame(means_ci_gamma),\n       aes(x = Tempo, y = emmean, color = drug, group = drug)) +\n  geom_errorbar(\n    aes(ymin = lower.CL, ymax = upper.CL),\n    width = 0.2,\n    position = position_dodge(0.1)\n  ) +\n  geom_point(\n    position = position_dodge(0.1),\n    size = 4\n  ) +\n  geom_line(\n    position = position_dodge(0.1),\n    linewidth = 1\n  ) +\n  labs(\n    title = \"GEE com Distribuição Gamma\",\n    subtitle = \"Médias marginais estimadas com IC 95%\",\n    x = \"Tempo\",\n    y = \"Pulso (bpm)\",\n    color = \"Tratamento\"\n  ) +\n  theme_minimal(base_size = 13) +\n  theme(\n    legend.position = \"bottom\",\n    plot.title = element_text(face = \"bold\", size = 15),\n    panel.grid.minor = element_blank()\n  ) +\n  scale_color_brewer(palette = \"Set1\")\n\n\n\n\n\n\n\n\n\n\n\n\nModelo 3: Distribuição Tweedie\n\n\n\n\n\n\n⚠️ Implementação Limitada\n\n\n\nAtualmente, a função geeglm() não suporta nativamente a família Tweedie. Estamos usando glm() como alternativa, mas isso não captura a estrutura de correlação das medidas repetidas.\nRecomendações: - Para análises definitivas, use SPSS ou SAS que implementam GEE-Tweedie - Considere glmmTMB::glmmTMB() como alternativa (modelo misto) - Aguarde atualizações do pacote geepack\n\n\n\nAjuste do Modelo (Limitado)\n\nmodelo_gee_pulse_tweedie &lt;- glm(\n  pulse ~ drug + Tempo + drug*Tempo,\n  data = bd_long,\n  family = tweedie(var.power = 2, link.power = 0)\n)\n\n\n\n\n\n\n\n📊 Quando Usar Distribuição Tweedie?\n\n\n\n\n\nAdequada para: - Dados com excesso de zeros - Distribuição assimétrica - Variância aumenta com a média\nCaracterísticas: - Parâmetro var.power: - 0 = Normal - 1 = Poisson - 2 = Gamma - 1-2 = Distribuições compostas - Flexível para diferentes tipos de assimetria\nExemplos: - Custos médicos (muitos zeros) - Precipitação pluviométrica - Dados de contagem inflados de zeros\n\n\n\n\n\n\nResultados e Contrastes\n\nsummary(modelo_gee_pulse_tweedie)\n\n\nCall:\nglm(formula = pulse ~ drug + Tempo + drug * Tempo, family = tweedie(var.power = 2, \n    link.power = 0), data = bd_long)\n\nCoefficients:\n                   Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)         0.78846    0.01857   42.47  &lt; 2e-16 ***\ndrugPlacebo         0.19237    0.02626    7.33  3.7e-08 ***\nTempo2              0.00755    0.02626    0.29     0.78    \nTempo3              0.03718    0.02626    1.42     0.17    \ndrugPlacebo:Tempo2  0.04718    0.03713    1.27     0.21    \ndrugPlacebo:Tempo3  0.00564    0.03713    0.15     0.88    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for Tweedie family taken to be 0.00207)\n\n    Null deviance: 0.473395  on 35  degrees of freedom\nResidual deviance: 0.062212  on 30  degrees of freedom\nAIC: NA\n\nNumber of Fisher Scoring iterations: 3\n\n\n\nMédias MarginaisComparações Par-a-Par\n\n\n\nemmeans(modelo_gee_pulse_tweedie, \n        specs = ~drug*Tempo)\n\n drug     Tempo emmean     SE  df asymp.LCL asymp.UCL\n New Drug 1      0.788 0.0186 Inf     0.752     0.825\n Placebo  1      0.981 0.0186 Inf     0.944     1.017\n New Drug 2      0.796 0.0186 Inf     0.760     0.832\n Placebo  2      1.036 0.0186 Inf     0.999     1.072\n New Drug 3      0.826 0.0186 Inf     0.789     0.862\n Placebo  3      1.024 0.0186 Inf     0.987     1.060\n\nResults are given on the mu^0 (not the response) scale. \nConfidence level used: 0.95 \n\n\n\n\n\nemmeans(modelo_gee_pulse_tweedie, \n        pairwise ~ drug*Tempo)\n\n$emmeans\n drug     Tempo emmean     SE  df asymp.LCL asymp.UCL\n New Drug 1      0.788 0.0186 Inf     0.752     0.825\n Placebo  1      0.981 0.0186 Inf     0.944     1.017\n New Drug 2      0.796 0.0186 Inf     0.760     0.832\n Placebo  2      1.036 0.0186 Inf     0.999     1.072\n New Drug 3      0.826 0.0186 Inf     0.789     0.862\n Placebo  3      1.024 0.0186 Inf     0.987     1.060\n\nResults are given on the mu^0 (not the response) scale. \nConfidence level used: 0.95 \n\n$contrasts\n contrast                          estimate     SE  df z.ratio p.value\n New Drug Tempo1 - Placebo Tempo1   -0.1924 0.0263 Inf  -7.330  &lt;.0001\n New Drug Tempo1 - New Drug Tempo2  -0.0075 0.0263 Inf  -0.290  1.0000\n New Drug Tempo1 - Placebo Tempo2   -0.2471 0.0263 Inf  -9.410  &lt;.0001\n New Drug Tempo1 - New Drug Tempo3  -0.0372 0.0263 Inf  -1.420  0.7170\n New Drug Tempo1 - Placebo Tempo3   -0.2352 0.0263 Inf  -8.960  &lt;.0001\n Placebo Tempo1 - New Drug Tempo2    0.1848 0.0263 Inf   7.040  &lt;.0001\n Placebo Tempo1 - Placebo Tempo2    -0.0547 0.0263 Inf  -2.080  0.2950\n Placebo Tempo1 - New Drug Tempo3    0.1552 0.0263 Inf   5.910  &lt;.0001\n Placebo Tempo1 - Placebo Tempo3    -0.0428 0.0263 Inf  -1.630  0.5780\n New Drug Tempo2 - Placebo Tempo2   -0.2395 0.0263 Inf  -9.120  &lt;.0001\n New Drug Tempo2 - New Drug Tempo3  -0.0296 0.0263 Inf  -1.130  0.8700\n New Drug Tempo2 - Placebo Tempo3   -0.2276 0.0263 Inf  -8.670  &lt;.0001\n Placebo Tempo2 - New Drug Tempo3    0.2099 0.0263 Inf   7.990  &lt;.0001\n Placebo Tempo2 - Placebo Tempo3     0.0119 0.0263 Inf   0.450  0.9980\n New Drug Tempo3 - Placebo Tempo3   -0.1980 0.0263 Inf  -7.540  &lt;.0001\n\nNote: contrasts are still on the mu^0 scale. Consider using\n      regrid() if you want contrasts of back-transformed estimates. \nP value adjustment: tukey method for comparing a family of 6 estimates \n\n\n\n\n\n\n\n\nDiagnóstico do Modelo\n\ncheck_model(modelo_gee_pulse_tweedie)\n\n\n\n\n\n\n\n\n\n\n\nVisualização dos Resultados\n\n# Calcular médias marginais\nmeans_ci_tweedie &lt;- emmeans(modelo_gee_pulse_tweedie, \n                            specs = ~drug:Tempo)\n\n# Criar gráfico\nggplot(as.data.frame(means_ci_tweedie),\n       aes(x = Tempo, y = emmean, color = drug, group = drug)) +\n  geom_errorbar(\n    aes(ymin = asymp.LCL, ymax = asymp.UCL),\n    width = 0.2,\n    position = position_dodge(0.1)\n  ) +\n  geom_point(\n    position = position_dodge(0.1),\n    size = 4\n  ) +\n  geom_line(\n    position = position_dodge(0.1),\n    linewidth = 1\n  ) +\n  labs(\n    title = \"GLM com Distribuição Tweedie\",\n    subtitle = \"Médias marginais estimadas com IC 95% (sem estrutura de correlação)\",\n    x = \"Tempo\",\n    y = \"Pulso (bpm)\",\n    color = \"Tratamento\",\n    caption = \"Nota: Modelo não captura correlação entre medidas repetidas\"\n  ) +\n  theme_minimal(base_size = 13) +\n  theme(\n    legend.position = \"bottom\",\n    plot.title = element_text(face = \"bold\", size = 15),\n    panel.grid.minor = element_blank(),\n    plot.caption = element_text(face = \"italic\", hjust = 0)\n  ) +\n  scale_color_brewer(palette = \"Set1\")",
    "crumbs": [
      "Modelos Lineares",
      "Lista 2: GEE Avançado"
    ]
  },
  {
    "objectID": "lista_2.html#parte-b-comparação-de-modelos-com-qic",
    "href": "lista_2.html#parte-b-comparação-de-modelos-com-qic",
    "title": "Lista 2: GEE Avançado",
    "section": "🎯 Parte B: Comparação de Modelos com QIC",
    "text": "🎯 Parte B: Comparação de Modelos com QIC\n\n\n\n\n\n\nO que é QIC?\n\n\n\nQuasi-likelihood Information Criterion é análogo ao AIC, mas para modelos GEE.\nInterpretação: - Menor QIC = melhor modelo - Diferença &gt; 2 indica melhoria substancial - Penaliza complexidade do modelo\nComponentes: - QIC: Informação geral - QICu: Versão não ajustada - Quasi Lik: Quasi-verossimilhança\n\n\n\nCálculo do QIC\n\n# Calcular QIC para modelos GEE\nqic_normal &lt;- QIC(modelo_gee_pulse_normal)\nqic_gamma &lt;- QIC(modelo_gee_pulse_gamma)\n\n# Criar tabela comparativa\ntabela_qic &lt;- data.frame(\n  Modelo = c(\"Normal\", \"Gamma\"),\n  QIC = c(qic_normal[1], qic_gamma[1]),\n  QICu = c(qic_normal[2], qic_gamma[2]),\n  QuasiLik = c(qic_normal[3], qic_gamma[3])\n)\n\n# Ordenar por QIC\ntabela_qic &lt;- tabela_qic[order(tabela_qic$QIC), ]\n\n# Adicionar ranking\ntabela_qic$Ranking &lt;- 1:nrow(tabela_qic)\n\n# Exibir resultado\nknitr::kable(\n  tabela_qic,\n  digits = 2,\n  caption = \"Comparação de Modelos via QIC (menor é melhor)\"\n)\n\n\nComparação de Modelos via QIC (menor é melhor)\n\n\nModelo\nQIC\nQICu\nQuasiLik\nRanking\n\n\n\n\nNormal\n12.3\n12.3\n-0.17\n1\n\n\nGamma\n125.2\n125.2\n-56.58\n2\n\n\n\n\n\n\n\n\n\n\n\n⚠️ Limitação do QIC\n\n\n\nA função QIC() não funciona com modelos glm() ou lm(), apenas com geeglm().\nPara o modelo Tweedie, você precisará: - Usar software específico (SPSS, SAS) - Aguardar implementação em R - Comparar apenas Normal vs Gamma por enquanto\n\n\n\n\n\nInterpretação dos Resultados\n\nDiferenças SubstantivasOutros Critérios\n\n\nRegra prática: - ΔqIC &lt; 2: Modelos equivalentes - ΔqIC 2-10: Diferença moderada - ΔqIC &gt; 10: Diferença substancial\n\n# Calcular diferenças\ndelta_qic &lt;- abs(diff(tabela_qic$QIC))\n\ncat(\"Diferença QIC:\", round(delta_qic, 2), \"\\n\")\n\nDiferença QIC: 113 \n\nif (delta_qic &lt; 2) {\n  cat(\"→ Modelos são equivalentes\\n\")\n} else if (delta_qic &lt; 10) {\n  cat(\"→ Diferença moderada - considere outros fatores\\n\")\n} else {\n  cat(\"→ Diferença substancial - prefira modelo com menor QIC\\n\")\n}\n\n→ Diferença substancial - prefira modelo com menor QIC\n\n\n\n\nAlém do QIC, considere:\n\nPressupostos teóricos\n\nQual distribuição faz sentido para a variável?\nPulse tem limite inferior (&gt; 0)?\n\nDiagnósticos visuais\n\nQual modelo tem melhores diagnósticos?\nResíduos mais bem comportados?\n\nInterpretabilidade\n\nCoeficientes fazem sentido?\nIntervalos de confiança plausíveis?\n\nValidação cruzada\n\nComo o modelo prediz novos dados?",
    "crumbs": [
      "Modelos Lineares",
      "Lista 2: GEE Avançado"
    ]
  },
  {
    "objectID": "lista_2.html#parte-c-sumarizando-resultados",
    "href": "lista_2.html#parte-c-sumarizando-resultados",
    "title": "Lista 2: GEE Avançado",
    "section": "📝 Parte C: Sumarizando Resultados",
    "text": "📝 Parte C: Sumarizando Resultados\n\n\n\n\n\n\nLimitação do report()\n\n\n\nA função report() não funciona para modelos GEE (geeglm).\nFunciona apenas para: glm, lm, lme, etc.\nAproveite para treinar escrita científica!\n\n\n\nExemplo de Relatório - Modelo Tweedie\n\nreport(modelo_gee_pulse_tweedie)\n\nWe fitted a general linear model (Tweedie family with a mu^0 link) (estimated\nusing ML) to predict pulse with drug and Tempo (formula: pulse ~ drug + Tempo +\ndrug * Tempo). The model's explanatory power is substantial (Nagelkerke's R2 =\n0.87). The model's intercept, corresponding to drug = New Drug and Tempo = 1,\nis at 0.79 (95% CI [0.75, 0.83], p &lt; .001). Within this model:\n\n  - The effect of drug [Placebo] is statistically significant and positive (beta\n= 0.19, 95% CI [0.14, 0.24], p &lt; .001; Std. beta = 0.19, 95% CI [0.14, 0.24])\n  - The effect of Tempo [2] is statistically non-significant and positive (beta =\n7.55e-03, 95% CI [-0.04, 0.06], p = 0.774; Std. beta = 7.55e-03, 95% CI [-0.04,\n0.06])\n  - The effect of Tempo [3] is statistically non-significant and positive (beta =\n0.04, 95% CI [-0.01, 0.09], p = 0.157; Std. beta = 0.04, 95% CI [-0.01, 0.09])\n  - The effect of drug [Placebo] × Tempo [2] is statistically non-significant and\npositive (beta = 0.05, 95% CI [-0.03, 0.12], p = 0.204; Std. beta = 0.05, 95%\nCI [-0.03, 0.12])\n  - The effect of drug [Placebo] × Tempo [3] is statistically non-significant and\npositive (beta = 5.64e-03, 95% CI [-0.07, 0.08], p = 0.879; Std. beta =\n5.64e-03, 95% CI [-0.07, 0.08])\n\nStandardized parameters were obtained by fitting the model on a standardized\nversion of the dataset. 95% Confidence Intervals (CIs) and p-values were\ncomputed using a Wald z-distribution approximation.\n\n\n\n\n\nTemplate para Redação Manual\n\n\n\n\n\n\n📝 Estrutura Sugerida para Resultados\n\n\n\n\n\nPara GEE, estruture seus resultados assim:\n\nAnálise de Medidas Repetidas via GEE\nUtilizamos Equações de Estimação Generalizadas (GEE) com estrutura de correlação não-estruturada para modelar a trajetória de pulso ao longo de três momentos de avaliação (Tempo 1, 2, 3), comparando grupo experimental (droga) e controle (placebo).\nComparação de Distribuições\nTestamos três especificações de distribuição: - Gaussiana (Normal) - Gamma - Tweedie (var.power = 2)\nA comparação via QIC indicou que [MODELO X] apresentou melhor ajuste (QIC = X.XX), seguido por [MODELO Y] (QIC = Y.YY, ΔQIC = Z.ZZ).\nResultados Principais\nNo modelo [ESCOLHIDO]:\nEfeito de Grupo: - O grupo que recebeu droga apresentou [maior/menor] pulso comparado ao placebo (β = X.XX, EP = Y.YY, p = Z.ZZ)\nEfeito de Tempo: - Observou-se [aumento/redução/estabilidade] no pulso ao longo do tempo (β_Tempo2 = X.XX, p = Y.YY; β_Tempo3 = A.AA, p = B.BB)\nInteração Grupo × Tempo: - [Houve/Não houve] interação significativa, indicando que [INTERPRETAÇÃO]\nMédias Estimadas\nAs médias marginais estimadas revelaram que: - No Tempo 1: Droga M = X.X (IC95% Y.Y-Z.Z), Placebo M = A.A (IC95% B.B-C.C) - No Tempo 2: [continuar…] - No Tempo 3: [continuar…]\nConclusão\n[Resumo dos achados principais e implicações]\n\n🎯 Desafio: Análise da Variável “Resp”\n\n\n\n\n\n\nSua Vez!\n\n\n\nAgora replique todas as análises para a variável “resp” (respiração):\nChecklist: - [ ] Modelo GEE com distribuição Normal - [ ] Modelo GEE com distribuição Gamma - [ ] Modelo GLM com distribuição Tweedie - [ ] Diagnósticos de cada modelo - [ ] Visualizações com ggplot2 - [ ] Comparação via QIC - [ ] Interpretação dos resultados - [ ] Redação científica dos achados\n\n\n\n\n\n\n\n\n💡 Dica Importante\n\n\n\nNão faça apenas copy/paste!\n\nDigite os códigos para treinar sintaxe\nRenomeie variáveis apropriadamente:\n\nmodelo_gee_pulse_normal → modelo_gee_resp_normal\nmeans_ci_normal → means_ci_resp_normal\n\nAjuste labels nos gráficos (Pulse → Resp)\nCompare seus resultados com a aula prática\nReflita sobre diferenças entre as variáveis\n\n\n\n\n\n\n📚 Material Complementar\n\nAula em Vídeo (SPSS)\n\n\n\n\nAprofundamento Teórico\n\n\n\n\n\n\n📖 Entendendo Distribuições\n\n\n\n\n\nNormal (Gaussian): - Clássica, simétrica, bem conhecida - Assume variância constante - Adequada para muitas variáveis contínuas\nGamma: - Assimétrica à direita - Variância aumenta com a média - Ideal para tempos, concentrações\nTweedie: - Família flexível entre Poisson e Gamma - var.power controla forma: - 0: Normal - 1: Poisson\n- 2: Gamma - 1 &lt; p &lt; 2: Distribuições compostas - Útil para dados com zeros\nComo escolher? 1. Examine distribuição dos dados (histogramas) 2. Considere natureza da variável (positiva? contínua?) 3. Teste múltiplas e compare QIC 4. Verifique pressupostos (diagnósticos)\n\n\n\n\n\n\nEstruturas de Correlação GEE\n\n\n\n\n\n\n🔗 Tipos de corstr\n\n\n\n\n\nIndependence: - Assume observações independentes - Mais simples, menos realista\nExchangeable: - Correlação constante entre momentos - Assume simetria composta\nAR(1) - Autorregressiva: - Correlação diminui com distância temporal - Adequada para séries temporais\nUnstructured: - Sem restrições, mais flexível - Estima todas as correlações - Requer mais dados\nComo escolher? - Depende da estrutura temporal - unstructured é mais flexível mas menos eficiente - AR(1) para medições igualmente espaçadas - Teste e compare resultados\n\n\n\n\n\n\n\n🔧 Informações de Sessão\n\nreport(sessionInfo())\n\nAnalyses were conducted using the R Statistical language (version 4.4.2; R Core\nTeam, 2024) on Windows 11 x64 (build 26100), using the packages lme4 (version\n1.1.37; Bates D et al., 2015), Matrix (version 1.7.1; Bates D et al., 2024),\neffectsize (version 1.0.1; Ben-Shachar MS et al., 2020), gee (version 4.13.29;\nCarey VJ, 2024), statmod (version 1.5.1; Chen Y et al., 2025), fitdistrplus\n(version 1.2.2; Delignette-Muller ML, Dutang C, 2015), tweedie (version 2.3.5;\nDunn PK, Smyth GK, 2005), flexplot (version 0.24.3; Fife, D, 2022), effects\n(version 4.2.4; Fox J, Weisberg S, 2019), car (version 3.1.3; Fox J, Weisberg\nS, 2019), carData (version 3.0.5; Fox J et al., 2022), mvtnorm (version 1.3.3;\nGenz A, Bretz F, 2009), geepack (version 1.3.13; Halekoh U et al., 2006),\nTH.data (version 1.1.3; Hothorn T, 2025), multcomp (version 1.4.28; Hothorn T\net al., 2008), rstatix (version 0.7.2; Kassambara A, 2023), emmeans (version\n1.11.0; Lenth R, 2025), sjstats (version 0.19.1; Lüdecke D, 2025), parameters\n(version 0.28.3; Lüdecke D et al., 2020), performance (version 0.15.2; Lüdecke\nD et al., 2021), easystats (version 0.7.5; Lüdecke D et al., 2022), see\n(version 0.12.0; Lüdecke D et al., 2021), insight (version 1.4.4; Lüdecke D et\nal., 2019), bayestestR (version 0.17.0; Makowski D et al., 2019), modelbased\n(version 0.13.1; Makowski D et al., 2025), report (version 0.6.3; Makowski D et\nal., 2023), correlation (version 0.8.8; Makowski D et al., 2022), datawizard\n(version 1.3.0; Patil I et al., 2022), nlme (version 3.1.166; Pinheiro J et\nal., 2024), foreign (version 0.8.87; R Core Team, 2024), GGally (version 2.2.1;\nSchloerke B et al., 2024), rempsyc (version 0.2.0; Thériault R, 2023), survival\n(version 3.7.0; Therneau T, 2024), MASS (version 7.3.61; Venables WN, Ripley\nBD, 2002), ggplot2 (version 4.0.1; Wickham H, 2016), dplyr (version 1.1.4;\nWickham H et al., 2023) and tidyr (version 1.3.1; Wickham H et al., 2024).\n\nReferences\n----------\n  - Bates D, Mächler M, Bolker B, Walker S (2015). \"Fitting Linear Mixed-Effects\nModels Using lme4.\" _Journal of Statistical Software_, *67*(1), 1-48.\ndoi:10.18637/jss.v067.i01 &lt;https://doi.org/10.18637/jss.v067.i01&gt;.\n  - Bates D, Maechler M, Jagan M (2024). _Matrix: Sparse and Dense Matrix Classes\nand Methods_. R package version 1.7-1,\n&lt;https://CRAN.R-project.org/package=Matrix&gt;.\n  - Ben-Shachar MS, Lüdecke D, Makowski D (2020). \"effectsize: Estimation of\nEffect Size Indices and Standardized Parameters.\" _Journal of Open Source\nSoftware_, *5*(56), 2815. doi:10.21105/joss.02815\n&lt;https://doi.org/10.21105/joss.02815&gt;, &lt;https://doi.org/10.21105/joss.02815&gt;.\n  - Carey VJ (2024). _gee: Generalized Estimation Equation Solver_. R package\nversion 4.13-29, &lt;https://CRAN.R-project.org/package=gee&gt;.\n  - Chen Y, Chen L, Lun ATL, Baldoni P, Smyth GK (2025). \"edgeR v4: powerful\ndifferential analysis of sequencing data with expanded functionality and\nimproved support for small counts and larger datasets.\" _Nucleic Acids\nResearch_, *53*(2), gkaf018. doi:10.1093/nar/gkaf018\n&lt;https://doi.org/10.1093/nar/gkaf018&gt;. Dunn PK, Smyth GK (1996). \"Randomized\nquantile residuals.\" _J. Comput. Graph. Statist_, *5*, 236-244. Giner G, Smyth\nGK (2016). \"statmod: probability calculations for the inverse Gaussian\ndistribution.\" _R Journal_, *8*(1), 339-351. Hu Y, Smyth GK (2009). \"ELDA:\nextreme limiting dilution analysis for comparing depleted and enriched\npopulations in stem cell and other assays.\" _Journal of Immunological Methods_,\n*347*(1), 70-78. Phipson B, Smyth GK (2010). \"Permutation p-values should never\nbe zero: calculating exact p-values when permutations are randomly drawn.\"\n_Statistical Applications in Genetics and Molecular Biology_, *9*(1), Article\n39. Smyth GK (2005). \"Numerical integration.\" _Encyclopedia of Biostatistics_,\n3088-3095. Smyth GK (2005). \"Optimization and nonlinear equations.\"\n_Encyclopedia of Biostatistics_, 3088-3095. Smyth GK (2002). \"An efficient\nalgorithm for REML in heteroscedastic regression.\" _Journal of Computational\nand Graphical Statistics_, *11*, 836-847.\n  - Delignette-Muller ML, Dutang C (2015). \"fitdistrplus: An R Package for\nFitting Distributions.\" _Journal of Statistical Software_, *64*(4), 1-34.\ndoi:10.18637/jss.v064.i04 &lt;https://doi.org/10.18637/jss.v064.i04&gt;.\n  - Dunn PK, Smyth GK (2005). \"Series evaluation of Tweedie exponential\ndispersion models.\" _Statistics and Computing_, *15*(4), 267-280. Dunn PK,\nSmyth GK (2008). \"Evaluation of Tweedie exponential dispersion models using\nFourier inversion.\" _Statistics and Computing_, *18*(1), 73-86. Dunn PK (2022).\n_Tweedie: Evaluation of Tweedie Exponential Family Models_. R package version\n2.3.5.\n  - Fife, A. D (2022). \"Flexplot: Graphically-based data analysis.\"\n_Psychological Methods_, *27*(4), -19. &lt;doi.org/10.1037/met0000424&gt;.\n  - Fox J, Weisberg S (2019). _An R Companion to Applied Regression_, 3rd\nedition. Sage, Thousand Oaks CA.\n&lt;https://www.john-fox.ca/Companion/index.html&gt;. Fox J, Weisberg S (2018).\n\"Visualizing Fit and Lack of Fit in Complex Regression Models with Predictor\nEffect Plots and Partial Residuals.\" _Journal of Statistical Software_,\n*87*(9), 1-27. doi:10.18637/jss.v087.i09\n&lt;https://doi.org/10.18637/jss.v087.i09&gt;. Fox J (2003). \"Effect Displays in R\nfor Generalised Linear Models.\" _Journal of Statistical Software_, *8*(15),\n1-27. doi:10.18637/jss.v008.i15 &lt;https://doi.org/10.18637/jss.v008.i15&gt;. Fox J,\nHong J (2009). \"Effect Displays in R for Multinomial and Proportional-Odds\nLogit Models: Extensions to the effects Package.\" _Journal of Statistical\nSoftware_, *32*(1), 1-24. doi:10.18637/jss.v032.i01\n&lt;https://doi.org/10.18637/jss.v032.i01&gt;.\n  - Fox J, Weisberg S (2019). _An R Companion to Applied Regression_, Third\nedition. Sage, Thousand Oaks CA. &lt;https://www.john-fox.ca/Companion/&gt;.\n  - Fox J, Weisberg S, Price B (2022). _carData: Companion to Applied Regression\nData Sets_. R package version 3.0-5,\n&lt;https://CRAN.R-project.org/package=carData&gt;.\n  - Genz A, Bretz F (2009). _Computation of Multivariate Normal and t\nProbabilities_, series Lecture Notes in Statistics. Springer-Verlag,\nHeidelberg. ISBN 978-3-642-01688-2.\n  - Halekoh U, Højsgaard S, Yan J (2006). \"The R Package geepack for Generalized\nEstimating Equations.\" _Journal of Statistical Software_, *15/2*, 1-11. Yan J,\nFine JP (2004). \"Estimating Equations for Association Structures.\" _Statistics\nin Medicine_, *23*, 859-880. Yan J (2002). \"geepack: Yet Another Package for\nGeneralized Estimating Equations.\" _R-News_, *2/3*, 12-14. Xu, Z., Fine, P. J,\nSong, W., Yan, J. (2025). \"On GEE for mean-variance-correlation models:\nVariance estimation and model selection.\" _Statistics in Medicine_, *44*, 1-2.\n  - Hothorn T (2025). _TH.data: TH's Data Archive_. R package version 1.1-3,\n&lt;https://CRAN.R-project.org/package=TH.data&gt;.\n  - Hothorn T, Bretz F, Westfall P (2008). \"Simultaneous Inference in General\nParametric Models.\" _Biometrical Journal_, *50*(3), 346-363.\n  - Kassambara A (2023). _rstatix: Pipe-Friendly Framework for Basic Statistical\nTests_. R package version 0.7.2, &lt;https://CRAN.R-project.org/package=rstatix&gt;.\n  - Lenth R (2025). _emmeans: Estimated Marginal Means, aka Least-Squares Means_.\nR package version 1.11.0, &lt;https://CRAN.R-project.org/package=emmeans&gt;.\n  - Lüdecke D (2025). _sjstats: Statistical Functions for Regression Models\n(Version 0.19.1)_. doi:10.5281/zenodo.1284472\n&lt;https://doi.org/10.5281/zenodo.1284472&gt;,\n&lt;https://CRAN.R-project.org/package=sjstats&gt;.\n  - Lüdecke D, Ben-Shachar M, Patil I, Makowski D (2020). \"Extracting, Computing\nand Exploring the Parameters of Statistical Models using R.\" _Journal of Open\nSource Software_, *5*(53), 2445. doi:10.21105/joss.02445\n&lt;https://doi.org/10.21105/joss.02445&gt;.\n  - Lüdecke D, Ben-Shachar M, Patil I, Waggoner P, Makowski D (2021).\n\"performance: An R Package for Assessment, Comparison and Testing of\nStatistical Models.\" _Journal of Open Source Software_, *6*(60), 3139.\ndoi:10.21105/joss.03139 &lt;https://doi.org/10.21105/joss.03139&gt;.\n  - Lüdecke D, Ben-Shachar M, Patil I, Wiernik B, Bacher E, Thériault R, Makowski\nD (2022). \"easystats: Framework for Easy Statistical Modeling, Visualization,\nand Reporting.\" _CRAN_. doi:10.32614/CRAN.package.easystats\n&lt;https://doi.org/10.32614/CRAN.package.easystats&gt;, R package,\n&lt;https://easystats.github.io/easystats/&gt;.\n  - Lüdecke D, Patil I, Ben-Shachar M, Wiernik B, Waggoner P, Makowski D (2021).\n\"see: An R Package for Visualizing Statistical Models.\" _Journal of Open Source\nSoftware_, *6*(64), 3393. doi:10.21105/joss.03393\n&lt;https://doi.org/10.21105/joss.03393&gt;.\n  - Lüdecke D, Waggoner P, Makowski D (2019). \"insight: A Unified Interface to\nAccess Information from Model Objects in R.\" _Journal of Open Source Software_,\n*4*(38), 1412. doi:10.21105/joss.01412 &lt;https://doi.org/10.21105/joss.01412&gt;.\n  - Makowski D, Ben-Shachar M, Lüdecke D (2019). \"bayestestR: Describing Effects\nand their Uncertainty, Existence and Significance within the Bayesian\nFramework.\" _Journal of Open Source Software_, *4*(40), 1541.\ndoi:10.21105/joss.01541 &lt;https://doi.org/10.21105/joss.01541&gt;,\n&lt;https://joss.theoj.org/papers/10.21105/joss.01541&gt;.\n  - Makowski D, Ben-Shachar M, Wiernik B, Patil I, Thériault R, Lüdecke D (2025).\n\"modelbased: An R package to make the most out of your statistical models\nthrough marginal means, marginal effects, and model predictions.\" _Journal of\nOpen Source Software_, *10*(109), 7969. doi:10.21105/joss.07969\n&lt;https://doi.org/10.21105/joss.07969&gt;,\n&lt;https://joss.theoj.org/papers/10.21105/joss.07969&gt;.\n  - Makowski D, Lüdecke D, Patil I, Thériault R, Ben-Shachar M, Wiernik B (2023).\n\"Automated Results Reporting as a Practical Tool to Improve Reproducibility and\nMethodological Best Practices Adoption.\" _CRAN_.\ndoi:10.32614/CRAN.package.report\n&lt;https://doi.org/10.32614/CRAN.package.report&gt;,\n&lt;https://easystats.github.io/report/&gt;.\n  - Makowski D, Wiernik B, Patil I, Lüdecke D, Ben-Shachar M (2022).\n\"correlation: Methods for Correlation Analysis.\" Version 0.8.3,\n&lt;https://CRAN.R-project.org/package=correlation&gt;. Makowski D, Ben-Shachar M,\nPatil I, Lüdecke D (2020). \"Methods and Algorithms for Correlation Analysis in\nR.\" _Journal of Open Source Software_, *5*(51), 2306. doi:10.21105/joss.02306\n&lt;https://doi.org/10.21105/joss.02306&gt;,\n&lt;https://joss.theoj.org/papers/10.21105/joss.02306&gt;.\n  - Patil I, Makowski D, Ben-Shachar M, Wiernik B, Bacher E, Lüdecke D (2022).\n\"datawizard: An R Package for Easy Data Preparation and Statistical\nTransformations.\" _Journal of Open Source Software_, *7*(78), 4684.\ndoi:10.21105/joss.04684 &lt;https://doi.org/10.21105/joss.04684&gt;.\n  - Pinheiro J, Bates D, R Core Team (2024). _nlme: Linear and Nonlinear Mixed\nEffects Models_. R package version 3.1-166,\n&lt;https://CRAN.R-project.org/package=nlme&gt;. Pinheiro JC, Bates DM (2000).\n_Mixed-Effects Models in S and S-PLUS_. Springer, New York. doi:10.1007/b98882\n&lt;https://doi.org/10.1007/b98882&gt;.\n  - R Core Team (2024). _foreign: Read Data Stored by 'Minitab', 'S', 'SAS',\n'SPSS', 'Stata', 'Systat', 'Weka', 'dBase', ..._. R package version 0.8-87,\n&lt;https://CRAN.R-project.org/package=foreign&gt;.\n  - R Core Team (2024). _R: A Language and Environment for Statistical\nComputing_. R Foundation for Statistical Computing, Vienna, Austria.\n&lt;https://www.R-project.org/&gt;.\n  - Schloerke B, Cook D, Larmarange J, Briatte F, Marbach M, Thoen E, Elberg A,\nCrowley J (2024). _GGally: Extension to 'ggplot2'_. R package version 2.2.1,\n&lt;https://CRAN.R-project.org/package=GGally&gt;.\n  - Thériault R (2023). \"rempsyc: Convenience functions for psychology.\" _Journal\nof Open Source Software_, *8*(87), 5466. doi:10.21105/joss.05466\n&lt;https://doi.org/10.21105/joss.05466&gt;, &lt;https://doi.org/10.21105/joss.05466&gt;.\n  - Therneau T (2024). _A Package for Survival Analysis in R_. R package version\n3.7-0, &lt;https://CRAN.R-project.org/package=survival&gt;. Terry M. Therneau,\nPatricia M. Grambsch (2000). _Modeling Survival Data: Extending the Cox Model_.\nSpringer, New York. ISBN 0-387-98784-3.\n  - Venables WN, Ripley BD (2002). _Modern Applied Statistics with S_, Fourth\nedition. Springer, New York. ISBN 0-387-95457-0,\n&lt;https://www.stats.ox.ac.uk/pub/MASS4/&gt;.\n  - Wickham H (2016). _ggplot2: Elegant Graphics for Data Analysis_.\nSpringer-Verlag New York. ISBN 978-3-319-24277-4,\n&lt;https://ggplot2.tidyverse.org&gt;.\n  - Wickham H, François R, Henry L, Müller K, Vaughan D (2023). _dplyr: A Grammar\nof Data Manipulation_. R package version 1.1.4,\n&lt;https://CRAN.R-project.org/package=dplyr&gt;.\n  - Wickham H, Vaughan D, Girlich M (2024). _tidyr: Tidy Messy Data_. R package\nversion 1.3.1, &lt;https://CRAN.R-project.org/package=tidyr&gt;.\n\n\n\n\n\n\n\n\n\n🎓 Resumo da Lista 2\n\n\n\nNesta lista você:\n✅ Ajustou modelos GEE com três distribuições diferentes\n✅ Aprendeu a comparar modelos via QIC\n✅ Criou visualizações profissionais com ggplot2\n✅ Interpretou diagnósticos de modelos complexos\n✅ Praticou redação científica de resultados\nPróximos passos: - Complete análises para variável “resp” - Compare resultados entre pulse e resp - Reflita sobre qual distribuição é mais adequada - Prepare-se para Lista 3: Modelos Mistos!",
    "crumbs": [
      "Modelos Lineares",
      "Lista 2: GEE Avançado"
    ]
  },
  {
    "objectID": "lista_2.html#desafio-análise-da-variável-resp",
    "href": "lista_2.html#desafio-análise-da-variável-resp",
    "title": "Lista 2: GEE Avançado",
    "section": "🎯 Desafio: Análise da Variável “Resp”",
    "text": "🎯 Desafio: Análise da Variável “Resp”\n\n\n\n\n\n\nSua Vez!\n\n\n\nAgora replique todas as análises para a variável “resp” (respiração):\nChecklist: - [ ] Modelo GEE com distribuição Normal - [ ] Modelo GEE com distribuição Gamma - [ ] Modelo GLM com distribuição Tweedie - [ ] Diagnósticos de cada modelo - [ ] Visualizações com ggplot2 - [ ] Comparação via QIC - [ ] Interpretação dos resultados - [ ] Redação científica dos achados\n\n\n\n\n\n\n\n\n💡 Dica Importante\n\n\n\nNão faça apenas copy/paste!\n\nDigite os códigos para treinar sintaxe\nRenomeie variáveis apropriadamente:\n\nmodelo_gee_pulse_normal → modelo_gee_resp_normal\nmeans_ci_normal → means_ci_resp_normal\n\nAjuste labels nos gráficos (Pulse → Resp)\nCompare seus resultados com a aula prática\nReflita sobre diferenças entre as variáveis",
    "crumbs": [
      "Modelos Lineares",
      "Lista 2: GEE Avançado"
    ]
  },
  {
    "objectID": "lista_2.html#material-complementar",
    "href": "lista_2.html#material-complementar",
    "title": "Lista 2: GEE Avançado",
    "section": "📚 Material Complementar",
    "text": "📚 Material Complementar\n\nAula em Vídeo (SPSS)\n\n\n\n\nAprofundamento Teórico\n\n\n\n\n\n\n📖 Entendendo Distribuições\n\n\n\n\n\nNormal (Gaussian): - Clássica, simétrica, bem conhecida - Assume variância constante - Adequada para muitas variáveis contínuas\nGamma: - Assimétrica à direita - Variância aumenta com a média - Ideal para tempos, concentrações\nTweedie: - Família flexível entre Poisson e Gamma - var.power controla forma: - 0: Normal - 1: Poisson\n- 2: Gamma - 1 &lt; p &lt; 2: Distribuições compostas - Útil para dados com zeros\nComo escolher? 1. Examine distribuição dos dados (histogramas) 2. Considere natureza da variável (positiva? contínua?) 3. Teste múltiplas e compare QIC 4. Verifique pressupostos (diagnósticos)\n\n\n\n\n\n\nEstruturas de Correlação GEE\n\n\n\n\n\n\n🔗 Tipos de corstr\n\n\n\n\n\nIndependence: - Assume observações independentes - Mais simples, menos realista\nExchangeable: - Correlação constante entre momentos - Assume simetria composta\nAR(1) - Autorregressiva: - Correlação diminui com distância temporal - Adequada para séries temporais\nUnstructured: - Sem restrições, mais flexível - Estima todas as correlações - Requer mais dados\nComo escolher? - Depende da estrutura temporal - unstructured é mais flexível mas menos eficiente - AR(1) para medições igualmente espaçadas - Teste e compare resultados",
    "crumbs": [
      "Modelos Lineares",
      "Lista 2: GEE Avançado"
    ]
  },
  {
    "objectID": "lista_2.html#informações-de-sessão",
    "href": "lista_2.html#informações-de-sessão",
    "title": "Lista 2: GEE Avançado",
    "section": "🔧 Informações de Sessão",
    "text": "🔧 Informações de Sessão\n\nreport(sessionInfo())\n\nAnalyses were conducted using the R Statistical language (version 4.4.2; R Core\nTeam, 2024) on Windows 11 x64 (build 26100), using the packages lme4 (version\n1.1.37; Bates D et al., 2015), Matrix (version 1.7.1; Bates D et al., 2024),\neffectsize (version 1.0.1; Ben-Shachar MS et al., 2020), gee (version 4.13.29;\nCarey VJ, 2024), statmod (version 1.5.1; Chen Y et al., 2025), fitdistrplus\n(version 1.2.2; Delignette-Muller ML, Dutang C, 2015), tweedie (version 2.3.5;\nDunn PK, Smyth GK, 2005), flexplot (version 0.24.3; Fife, D, 2022), effects\n(version 4.2.4; Fox J, Weisberg S, 2019), car (version 3.1.3; Fox J, Weisberg\nS, 2019), carData (version 3.0.5; Fox J et al., 2022), mvtnorm (version 1.3.3;\nGenz A, Bretz F, 2009), geepack (version 1.3.13; Halekoh U et al., 2006),\nTH.data (version 1.1.3; Hothorn T, 2025), multcomp (version 1.4.28; Hothorn T\net al., 2008), rstatix (version 0.7.2; Kassambara A, 2023), emmeans (version\n1.11.0; Lenth R, 2025), sjstats (version 0.19.1; Lüdecke D, 2025), parameters\n(version 0.28.3; Lüdecke D et al., 2020), performance (version 0.15.2; Lüdecke\nD et al., 2021), easystats (version 0.7.5; Lüdecke D et al., 2022), see\n(version 0.12.0; Lüdecke D et al., 2021), insight (version 1.4.4; Lüdecke D et\nal., 2019), bayestestR (version 0.17.0; Makowski D et al., 2019), modelbased\n(version 0.13.1; Makowski D et al., 2025), report (version 0.6.3; Makowski D et\nal., 2023), correlation (version 0.8.8; Makowski D et al., 2022), datawizard\n(version 1.3.0; Patil I et al., 2022), nlme (version 3.1.166; Pinheiro J et\nal., 2024), foreign (version 0.8.87; R Core Team, 2024), GGally (version 2.2.1;\nSchloerke B et al., 2024), rempsyc (version 0.2.0; Thériault R, 2023), survival\n(version 3.7.0; Therneau T, 2024), MASS (version 7.3.61; Venables WN, Ripley\nBD, 2002), ggplot2 (version 4.0.1; Wickham H, 2016), dplyr (version 1.1.4;\nWickham H et al., 2023) and tidyr (version 1.3.1; Wickham H et al., 2024).\n\nReferences\n----------\n  - Bates D, Mächler M, Bolker B, Walker S (2015). \"Fitting Linear Mixed-Effects\nModels Using lme4.\" _Journal of Statistical Software_, *67*(1), 1-48.\ndoi:10.18637/jss.v067.i01 &lt;https://doi.org/10.18637/jss.v067.i01&gt;.\n  - Bates D, Maechler M, Jagan M (2024). _Matrix: Sparse and Dense Matrix Classes\nand Methods_. R package version 1.7-1,\n&lt;https://CRAN.R-project.org/package=Matrix&gt;.\n  - Ben-Shachar MS, Lüdecke D, Makowski D (2020). \"effectsize: Estimation of\nEffect Size Indices and Standardized Parameters.\" _Journal of Open Source\nSoftware_, *5*(56), 2815. doi:10.21105/joss.02815\n&lt;https://doi.org/10.21105/joss.02815&gt;, &lt;https://doi.org/10.21105/joss.02815&gt;.\n  - Carey VJ (2024). _gee: Generalized Estimation Equation Solver_. R package\nversion 4.13-29, &lt;https://CRAN.R-project.org/package=gee&gt;.\n  - Chen Y, Chen L, Lun ATL, Baldoni P, Smyth GK (2025). \"edgeR v4: powerful\ndifferential analysis of sequencing data with expanded functionality and\nimproved support for small counts and larger datasets.\" _Nucleic Acids\nResearch_, *53*(2), gkaf018. doi:10.1093/nar/gkaf018\n&lt;https://doi.org/10.1093/nar/gkaf018&gt;. Dunn PK, Smyth GK (1996). \"Randomized\nquantile residuals.\" _J. Comput. Graph. Statist_, *5*, 236-244. Giner G, Smyth\nGK (2016). \"statmod: probability calculations for the inverse Gaussian\ndistribution.\" _R Journal_, *8*(1), 339-351. Hu Y, Smyth GK (2009). \"ELDA:\nextreme limiting dilution analysis for comparing depleted and enriched\npopulations in stem cell and other assays.\" _Journal of Immunological Methods_,\n*347*(1), 70-78. Phipson B, Smyth GK (2010). \"Permutation p-values should never\nbe zero: calculating exact p-values when permutations are randomly drawn.\"\n_Statistical Applications in Genetics and Molecular Biology_, *9*(1), Article\n39. Smyth GK (2005). \"Numerical integration.\" _Encyclopedia of Biostatistics_,\n3088-3095. Smyth GK (2005). \"Optimization and nonlinear equations.\"\n_Encyclopedia of Biostatistics_, 3088-3095. Smyth GK (2002). \"An efficient\nalgorithm for REML in heteroscedastic regression.\" _Journal of Computational\nand Graphical Statistics_, *11*, 836-847.\n  - Delignette-Muller ML, Dutang C (2015). \"fitdistrplus: An R Package for\nFitting Distributions.\" _Journal of Statistical Software_, *64*(4), 1-34.\ndoi:10.18637/jss.v064.i04 &lt;https://doi.org/10.18637/jss.v064.i04&gt;.\n  - Dunn PK, Smyth GK (2005). \"Series evaluation of Tweedie exponential\ndispersion models.\" _Statistics and Computing_, *15*(4), 267-280. Dunn PK,\nSmyth GK (2008). \"Evaluation of Tweedie exponential dispersion models using\nFourier inversion.\" _Statistics and Computing_, *18*(1), 73-86. Dunn PK (2022).\n_Tweedie: Evaluation of Tweedie Exponential Family Models_. R package version\n2.3.5.\n  - Fife, A. D (2022). \"Flexplot: Graphically-based data analysis.\"\n_Psychological Methods_, *27*(4), -19. &lt;doi.org/10.1037/met0000424&gt;.\n  - Fox J, Weisberg S (2019). _An R Companion to Applied Regression_, 3rd\nedition. Sage, Thousand Oaks CA.\n&lt;https://www.john-fox.ca/Companion/index.html&gt;. Fox J, Weisberg S (2018).\n\"Visualizing Fit and Lack of Fit in Complex Regression Models with Predictor\nEffect Plots and Partial Residuals.\" _Journal of Statistical Software_,\n*87*(9), 1-27. doi:10.18637/jss.v087.i09\n&lt;https://doi.org/10.18637/jss.v087.i09&gt;. Fox J (2003). \"Effect Displays in R\nfor Generalised Linear Models.\" _Journal of Statistical Software_, *8*(15),\n1-27. doi:10.18637/jss.v008.i15 &lt;https://doi.org/10.18637/jss.v008.i15&gt;. Fox J,\nHong J (2009). \"Effect Displays in R for Multinomial and Proportional-Odds\nLogit Models: Extensions to the effects Package.\" _Journal of Statistical\nSoftware_, *32*(1), 1-24. doi:10.18637/jss.v032.i01\n&lt;https://doi.org/10.18637/jss.v032.i01&gt;.\n  - Fox J, Weisberg S (2019). _An R Companion to Applied Regression_, Third\nedition. Sage, Thousand Oaks CA. &lt;https://www.john-fox.ca/Companion/&gt;.\n  - Fox J, Weisberg S, Price B (2022). _carData: Companion to Applied Regression\nData Sets_. R package version 3.0-5,\n&lt;https://CRAN.R-project.org/package=carData&gt;.\n  - Genz A, Bretz F (2009). _Computation of Multivariate Normal and t\nProbabilities_, series Lecture Notes in Statistics. Springer-Verlag,\nHeidelberg. ISBN 978-3-642-01688-2.\n  - Halekoh U, Højsgaard S, Yan J (2006). \"The R Package geepack for Generalized\nEstimating Equations.\" _Journal of Statistical Software_, *15/2*, 1-11. Yan J,\nFine JP (2004). \"Estimating Equations for Association Structures.\" _Statistics\nin Medicine_, *23*, 859-880. Yan J (2002). \"geepack: Yet Another Package for\nGeneralized Estimating Equations.\" _R-News_, *2/3*, 12-14. Xu, Z., Fine, P. J,\nSong, W., Yan, J. (2025). \"On GEE for mean-variance-correlation models:\nVariance estimation and model selection.\" _Statistics in Medicine_, *44*, 1-2.\n  - Hothorn T (2025). _TH.data: TH's Data Archive_. R package version 1.1-3,\n&lt;https://CRAN.R-project.org/package=TH.data&gt;.\n  - Hothorn T, Bretz F, Westfall P (2008). \"Simultaneous Inference in General\nParametric Models.\" _Biometrical Journal_, *50*(3), 346-363.\n  - Kassambara A (2023). _rstatix: Pipe-Friendly Framework for Basic Statistical\nTests_. R package version 0.7.2, &lt;https://CRAN.R-project.org/package=rstatix&gt;.\n  - Lenth R (2025). _emmeans: Estimated Marginal Means, aka Least-Squares Means_.\nR package version 1.11.0, &lt;https://CRAN.R-project.org/package=emmeans&gt;.\n  - Lüdecke D (2025). _sjstats: Statistical Functions for Regression Models\n(Version 0.19.1)_. doi:10.5281/zenodo.1284472\n&lt;https://doi.org/10.5281/zenodo.1284472&gt;,\n&lt;https://CRAN.R-project.org/package=sjstats&gt;.\n  - Lüdecke D, Ben-Shachar M, Patil I, Makowski D (2020). \"Extracting, Computing\nand Exploring the Parameters of Statistical Models using R.\" _Journal of Open\nSource Software_, *5*(53), 2445. doi:10.21105/joss.02445\n&lt;https://doi.org/10.21105/joss.02445&gt;.\n  - Lüdecke D, Ben-Shachar M, Patil I, Waggoner P, Makowski D (2021).\n\"performance: An R Package for Assessment, Comparison and Testing of\nStatistical Models.\" _Journal of Open Source Software_, *6*(60), 3139.\ndoi:10.21105/joss.03139 &lt;https://doi.org/10.21105/joss.03139&gt;.\n  - Lüdecke D, Ben-Shachar M, Patil I, Wiernik B, Bacher E, Thériault R, Makowski\nD (2022). \"easystats: Framework for Easy Statistical Modeling, Visualization,\nand Reporting.\" _CRAN_. doi:10.32614/CRAN.package.easystats\n&lt;https://doi.org/10.32614/CRAN.package.easystats&gt;, R package,\n&lt;https://easystats.github.io/easystats/&gt;.\n  - Lüdecke D, Patil I, Ben-Shachar M, Wiernik B, Waggoner P, Makowski D (2021).\n\"see: An R Package for Visualizing Statistical Models.\" _Journal of Open Source\nSoftware_, *6*(64), 3393. doi:10.21105/joss.03393\n&lt;https://doi.org/10.21105/joss.03393&gt;.\n  - Lüdecke D, Waggoner P, Makowski D (2019). \"insight: A Unified Interface to\nAccess Information from Model Objects in R.\" _Journal of Open Source Software_,\n*4*(38), 1412. doi:10.21105/joss.01412 &lt;https://doi.org/10.21105/joss.01412&gt;.\n  - Makowski D, Ben-Shachar M, Lüdecke D (2019). \"bayestestR: Describing Effects\nand their Uncertainty, Existence and Significance within the Bayesian\nFramework.\" _Journal of Open Source Software_, *4*(40), 1541.\ndoi:10.21105/joss.01541 &lt;https://doi.org/10.21105/joss.01541&gt;,\n&lt;https://joss.theoj.org/papers/10.21105/joss.01541&gt;.\n  - Makowski D, Ben-Shachar M, Wiernik B, Patil I, Thériault R, Lüdecke D (2025).\n\"modelbased: An R package to make the most out of your statistical models\nthrough marginal means, marginal effects, and model predictions.\" _Journal of\nOpen Source Software_, *10*(109), 7969. doi:10.21105/joss.07969\n&lt;https://doi.org/10.21105/joss.07969&gt;,\n&lt;https://joss.theoj.org/papers/10.21105/joss.07969&gt;.\n  - Makowski D, Lüdecke D, Patil I, Thériault R, Ben-Shachar M, Wiernik B (2023).\n\"Automated Results Reporting as a Practical Tool to Improve Reproducibility and\nMethodological Best Practices Adoption.\" _CRAN_.\ndoi:10.32614/CRAN.package.report\n&lt;https://doi.org/10.32614/CRAN.package.report&gt;,\n&lt;https://easystats.github.io/report/&gt;.\n  - Makowski D, Wiernik B, Patil I, Lüdecke D, Ben-Shachar M (2022).\n\"correlation: Methods for Correlation Analysis.\" Version 0.8.3,\n&lt;https://CRAN.R-project.org/package=correlation&gt;. Makowski D, Ben-Shachar M,\nPatil I, Lüdecke D (2020). \"Methods and Algorithms for Correlation Analysis in\nR.\" _Journal of Open Source Software_, *5*(51), 2306. doi:10.21105/joss.02306\n&lt;https://doi.org/10.21105/joss.02306&gt;,\n&lt;https://joss.theoj.org/papers/10.21105/joss.02306&gt;.\n  - Patil I, Makowski D, Ben-Shachar M, Wiernik B, Bacher E, Lüdecke D (2022).\n\"datawizard: An R Package for Easy Data Preparation and Statistical\nTransformations.\" _Journal of Open Source Software_, *7*(78), 4684.\ndoi:10.21105/joss.04684 &lt;https://doi.org/10.21105/joss.04684&gt;.\n  - Pinheiro J, Bates D, R Core Team (2024). _nlme: Linear and Nonlinear Mixed\nEffects Models_. R package version 3.1-166,\n&lt;https://CRAN.R-project.org/package=nlme&gt;. Pinheiro JC, Bates DM (2000).\n_Mixed-Effects Models in S and S-PLUS_. Springer, New York. doi:10.1007/b98882\n&lt;https://doi.org/10.1007/b98882&gt;.\n  - R Core Team (2024). _foreign: Read Data Stored by 'Minitab', 'S', 'SAS',\n'SPSS', 'Stata', 'Systat', 'Weka', 'dBase', ..._. R package version 0.8-87,\n&lt;https://CRAN.R-project.org/package=foreign&gt;.\n  - R Core Team (2024). _R: A Language and Environment for Statistical\nComputing_. R Foundation for Statistical Computing, Vienna, Austria.\n&lt;https://www.R-project.org/&gt;.\n  - Schloerke B, Cook D, Larmarange J, Briatte F, Marbach M, Thoen E, Elberg A,\nCrowley J (2024). _GGally: Extension to 'ggplot2'_. R package version 2.2.1,\n&lt;https://CRAN.R-project.org/package=GGally&gt;.\n  - Thériault R (2023). \"rempsyc: Convenience functions for psychology.\" _Journal\nof Open Source Software_, *8*(87), 5466. doi:10.21105/joss.05466\n&lt;https://doi.org/10.21105/joss.05466&gt;, &lt;https://doi.org/10.21105/joss.05466&gt;.\n  - Therneau T (2024). _A Package for Survival Analysis in R_. R package version\n3.7-0, &lt;https://CRAN.R-project.org/package=survival&gt;. Terry M. Therneau,\nPatricia M. Grambsch (2000). _Modeling Survival Data: Extending the Cox Model_.\nSpringer, New York. ISBN 0-387-98784-3.\n  - Venables WN, Ripley BD (2002). _Modern Applied Statistics with S_, Fourth\nedition. Springer, New York. ISBN 0-387-95457-0,\n&lt;https://www.stats.ox.ac.uk/pub/MASS4/&gt;.\n  - Wickham H (2016). _ggplot2: Elegant Graphics for Data Analysis_.\nSpringer-Verlag New York. ISBN 978-3-319-24277-4,\n&lt;https://ggplot2.tidyverse.org&gt;.\n  - Wickham H, François R, Henry L, Müller K, Vaughan D (2023). _dplyr: A Grammar\nof Data Manipulation_. R package version 1.1.4,\n&lt;https://CRAN.R-project.org/package=dplyr&gt;.\n  - Wickham H, Vaughan D, Girlich M (2024). _tidyr: Tidy Messy Data_. R package\nversion 1.3.1, &lt;https://CRAN.R-project.org/package=tidyr&gt;.\n\n\n\n\n\n\n\n\n\n🎓 Resumo da Lista 2\n\n\n\nNesta lista você:\n✅ Ajustou modelos GEE com três distribuições diferentes\n✅ Aprendeu a comparar modelos via QIC\n✅ Criou visualizações profissionais com ggplot2\n✅ Interpretou diagnósticos de modelos complexos\n✅ Praticou redação científica de resultados\nPróximos passos: - Complete análises para variável “resp” - Compare resultados entre pulse e resp - Reflita sobre qual distribuição é mais adequada - Prepare-se para Lista 3: Modelos Mistos!",
    "crumbs": [
      "Modelos Lineares",
      "Lista 2: GEE Avançado"
    ]
  },
  {
    "objectID": "lista_3.html",
    "href": "lista_3.html",
    "title": "Lista 3: Matrizes de Covariância",
    "section": "",
    "text": "📦 Pacotes Necessários\n# Lista de pacotes\npacotes &lt;- c(\n  \"emmeans\",      # Médias marginais\n  \"nlme\",         # Modelos mistos com estruturas de correlação\n  \"flexplot\",     # Visualizações\n  \"foreign\",      # Importar SPSS\n  \"dplyr\",        # Manipulação de dados\n  \"multcomp\",     # Comparações múltiplas\n  \"effects\",      # Efeitos do modelo\n  \"performance\",  # Comparação de modelos\n  \"easystats\",\n  \"ggplot2\" \n)\n\n# Verificar e instalar\npacotes_faltantes &lt;- pacotes[!pacotes %in% installed.packages()[, \"Package\"]]\nif (length(pacotes_faltantes) &gt; 0) {\n  install.packages(pacotes_faltantes, dependencies = TRUE)\n}\n\n# Carregar\ninvisible(lapply(pacotes, library, character.only = TRUE))\ncat(\"✓ Pacotes carregados com sucesso!\\n\")\n\n✓ Pacotes carregados com sucesso!",
    "crumbs": [
      "Modelos Lineares",
      "Lista 3: Matrizes de Covariância"
    ]
  },
  {
    "objectID": "lista_3.html#preparação-dos-dados",
    "href": "lista_3.html#preparação-dos-dados",
    "title": "Lista 3: Matrizes de Covariância",
    "section": "📥 Preparação dos Dados",
    "text": "📥 Preparação dos Dados\n\n\n\n\n\n\nDados Já no Formato Long!\n\n\n\nPara esta lista, use o banco “New Drug (RESHAPE)” que já está em formato long.\n\n\n\nCarregamento e Verificação\n\n# Carregar dados\ndataset &lt;- read.spss(\"bd_New drug_respiratory&pulseRESHAPE.sav\", \n                     to.data.frame = TRUE)\n\n# Visualizar estrutura inicial\nglimpse(dataset)\n\nRows: 36\nColumns: 5\n$ Sujeito &lt;dbl&gt; 1, 1, 1, 2, 2, 2, 3, 3, 3, 4, 4, 4, 5, 5, 5, 6, 6, 6, 7, 7, 7,…\n$ drug    &lt;fct&gt; New Drug, New Drug, New Drug, New Drug, New Drug, New Drug, Ne…\n$ Tempo   &lt;dbl&gt; 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3,…\n$ resp    &lt;dbl&gt; 3.4, 3.3, 3.3, 3.4, 3.4, 3.3, 3.3, 3.4, 3.4, 3.4, 3.4, 3.4, 3.…\n$ pulse   &lt;dbl&gt; 2.2, 2.1, 2.1, 2.2, 2.1, 2.2, 2.3, 2.4, 2.3, 2.3, 2.4, 2.3, 2.…\n\n\n\n\n\nVerificação de Tipos de Variáveis\n\n\n\n\n\n\n⚠️ Tipos de Variáveis São Cruciais!\n\n\n\nSEMPRE verifique os tipos antes de modelar. As análises mudam drasticamente dependendo se a variável é: - Fator (&lt;fct&gt;): Categorias nominais ou ordinais - Numérica (&lt;dbl&gt;): Valores contínuos - Inteiro (&lt;int&gt;): Contagens discretas\n\n\n\nProblema IdentificadoSolução AplicadaComparação\n\n\n\nglimpse(dataset)\n\nRows: 36\nColumns: 5\n$ Sujeito &lt;dbl&gt; 1, 1, 1, 2, 2, 2, 3, 3, 3, 4, 4, 4, 5, 5, 5, 6, 6, 6, 7, 7, 7,…\n$ drug    &lt;fct&gt; New Drug, New Drug, New Drug, New Drug, New Drug, New Drug, Ne…\n$ Tempo   &lt;dbl&gt; 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3,…\n$ resp    &lt;dbl&gt; 3.4, 3.3, 3.3, 3.4, 3.4, 3.3, 3.3, 3.4, 3.4, 3.4, 3.4, 3.4, 3.…\n$ pulse   &lt;dbl&gt; 2.2, 2.1, 2.1, 2.2, 2.1, 2.2, 2.3, 2.4, 2.3, 2.3, 2.4, 2.3, 2.…\n\n\nObservação Crítica: - Tempo aparece como &lt;dbl&gt; (numérica contínua) - Mas representa categorias (“Momento 1”, “Momento 2”, “Momento 3”) - Não há ordem contínua entre os momentos\n\n\n\n# Converter Tempo para fator\ndataset$Tempo &lt;- as.factor(dataset$Tempo)\n\n# Verificar mudança\nglimpse(dataset)\n\nRows: 36\nColumns: 5\n$ Sujeito &lt;dbl&gt; 1, 1, 1, 2, 2, 2, 3, 3, 3, 4, 4, 4, 5, 5, 5, 6, 6, 6, 7, 7, 7,…\n$ drug    &lt;fct&gt; New Drug, New Drug, New Drug, New Drug, New Drug, New Drug, Ne…\n$ Tempo   &lt;fct&gt; 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3,…\n$ resp    &lt;dbl&gt; 3.4, 3.3, 3.3, 3.4, 3.4, 3.3, 3.3, 3.4, 3.4, 3.4, 3.4, 3.4, 3.…\n$ pulse   &lt;dbl&gt; 2.2, 2.1, 2.1, 2.2, 2.1, 2.2, 2.3, 2.4, 2.3, 2.3, 2.4, 2.3, 2.…\n\n\nAgora sim: - Tempo é &lt;fct&gt; (fator) - Representa categorias discretas - Análise apropriada para medidas repetidas\n\n\n\n\n\n\n\n\n🔍 Por que isso importa?\n\n\n\n\n\nSe Tempo for numérica: - R assume relação linear entre momentos - Força pontos em uma reta - Perde flexibilidade para padrões não-lineares\nSe Tempo for fator: - R trata cada momento independentemente - Permite médias diferentes para cada tempo - Detecta mudanças não-lineares\nExperimente: Rode modelos com ambas as especificações e compare!",
    "crumbs": [
      "Modelos Lineares",
      "Lista 3: Matrizes de Covariância"
    ]
  },
  {
    "objectID": "lista_3.html#parte-a-modelos-com-diferentes-matrizes",
    "href": "lista_3.html#parte-a-modelos-com-diferentes-matrizes",
    "title": "Lista 3: Matrizes de Covariância",
    "section": "🎯 Parte A: Modelos com Diferentes Matrizes",
    "text": "🎯 Parte A: Modelos com Diferentes Matrizes\n\n\n\n\n\n\nO que são Matrizes de Covariância?\n\n\n\nEm dados longitudinais, observações do mesmo sujeito são correlacionadas. A matriz de covariância especifica como modelamos essa correlação.\nPor que importa? - Afeta estimativas dos efeitos fixos - Influencia erros-padrão - Altera conclusões estatísticas\n\n\n\n\nMatriz 1: Simétrica Composta (Compound Symmetry)\n\nmodel_resp_sim &lt;- lme(\n  fixed = resp ~ drug + Tempo + drug*Tempo,\n  random = ~1|Sujeito,\n  correlation = corCompSymm(form = ~1|Sujeito),\n  data = dataset\n)\n\n\n\n\n\n\n\n📊 Matriz Simétrica Composta\n\n\n\n\n\nEstrutura: \\[\n\\begin{bmatrix}\n1 & \\rho & \\rho \\\\\n\\rho & 1 & \\rho \\\\\n\\rho & \\rho & 1\n\\end{bmatrix}\n\\]\nCaracterísticas: - Correlação constante entre todos os pares - Um único parâmetro \\(\\rho\\) para estimar - Mais simples, mais parcimoniosa\nQuando usar: - Dados com intervalos irregulares - Correlação não muda com distância temporal - Tamanho de amostra pequeno\nLimitações: - Pouco realista para séries longas - Assume correlação não decai com tempo\n\n\n\n\n\n\nMatriz 2: Autorregressiva de Ordem 1 - AR(1)\n\nmodel_resp_AR1 &lt;- lme(\n  fixed = resp ~ drug + Tempo + drug*Tempo,\n  random = ~1|Sujeito,\n  correlation = corAR1(form = ~1|Sujeito),\n  data = dataset\n)\n\n\n\n\n\n\n\n📊 Matriz AR(1)\n\n\n\n\n\nEstrutura: \\[\n\\begin{bmatrix}\n1 & \\rho & \\rho^2 \\\\\n\\rho & 1 & \\rho \\\\\n\\rho^2 & \\rho & 1\n\\end{bmatrix}\n\\]\nCaracterísticas: - Correlação decai exponencialmente com distância - Um único parâmetro \\(\\rho\\) (0 &lt; ρ &lt; 1) - Observações adjacentes mais correlacionadas\nQuando usar: - Medições igualmente espaçadas no tempo - Expectativa de correlação decrescente - Séries temporais clássicas\nVantagens: - Realista para muitos processos biológicos - Parcimoniosa (1 parâmetro) - Boa relação viés-eficiência\nExemplo: Se ρ = 0.7: - Tempos adjacentes: r = 0.70 - Tempos separados por 1: r = 0.49 - Tempos separados por 2: r = 0.34\n\n\n\n\n\n\nMatriz 3: Identidade (Independence)\n\nmodel_resp_Iden &lt;- lme(\n  fixed = resp ~ drug + Tempo + drug*Tempo,\n  random = ~1|Sujeito,\n  correlation = corIdent(form = ~1|Sujeito),\n  data = dataset\n)\n\n\n\n\n\n\n\n📊 Matriz Identidade\n\n\n\n\n\nEstrutura: \\[\n\\begin{bmatrix}\n1 & 0 & 0 \\\\\n0 & 1 & 0 \\\\\n0 & 0 & 1\n\\end{bmatrix}\n\\]\nCaracterísticas: - Nenhuma correlação entre medidas - Assume independência total - Não estima parâmetros de correlação\nQuando usar: - Baseline para comparações - Testes de necessidade de correlação - Raramente apropriada na prática\nLimitações: - Ignora estrutura de medidas repetidas - Subestima erros-padrão - Infla erro Tipo I\nNota: Geralmente não é recomendada para dados longitudinais reais!\n\n\n\n\n\n\nMatriz 4: Não-Estruturada (Unstructured)\n\nmodel_resp_Uns &lt;- lme(\n  fixed = resp ~ drug + Tempo + drug*Tempo,\n  random = ~1|Sujeito,\n  correlation = corSymm(form = ~1|Sujeito),\n  data = dataset\n)\n\n\n\n\n\n\n\n📊 Matriz Não-Estruturada\n\n\n\n\n\nEstrutura (3 tempos): \\[\n\\begin{bmatrix}\n1 & \\rho_{12} & \\rho_{13} \\\\\n\\rho_{12} & 1 & \\rho_{23} \\\\\n\\rho_{13} & \\rho_{23} & 1\n\\end{bmatrix}\n\\]\nCaracterísticas: - Estima todas as correlações separadamente - Máxima flexibilidade - Para T tempos: estima T(T-1)/2 correlações\nQuando usar: - Amostra grande (regra: n &gt; 10 × parâmetros) - Padrão de correlação desconhecido - Análise exploratória\nVantagens: - Não assume estrutura específica - Permite padrões complexos - Mais realista quando bem estimada\nLimitações: - Muitos parâmetros para estimar - Requer amostra grande - Pode não convergir - Pode sobre-ajustar\nExemplo (3 tempos): - 3 correlações diferentes: - r(1,2) = 0.65 - r(1,3) = 0.52 - r(2,3) = 0.71",
    "crumbs": [
      "Modelos Lineares",
      "Lista 3: Matrizes de Covariância"
    ]
  },
  {
    "objectID": "lista_3.html#parte-b-comparação-de-modelos",
    "href": "lista_3.html#parte-b-comparação-de-modelos",
    "title": "Lista 3: Matrizes de Covariância",
    "section": "🎯 Parte B: Comparação de Modelos",
    "text": "🎯 Parte B: Comparação de Modelos\n\nCritérios de Informação\n\n\n\n\n\n\nAIC vs BIC\n\n\n\nAIC (Akaike Information Criterion): - Penalização moderada para complexidade - Tende a favorecer modelos mais complexos - Foco em predição\nBIC (Bayesian Information Criterion): - Penalização mais forte para complexidade - Tende a favorecer modelos mais simples - Foco em parcimônia\nRegra geral: - Menor é melhor - Diferença &gt; 2 = evidência moderada - Diferença &gt; 10 = evidência forte\n\n\n\n\n\nComparação Manual\n\n# Criar dataframe comparativo\ndf_aderencia &lt;- data.frame(\n  Modelo = c(\"Simétrica\", \"AR(1)\", \"Identidade\", \"Não-estruturada\"),\n  AIC = c(\n    AIC(model_resp_sim),\n    AIC(model_resp_AR1),\n    AIC(model_resp_Iden),\n    AIC(model_resp_Uns)\n  ),\n  BIC = c(\n    BIC(model_resp_sim),\n    BIC(model_resp_AR1),\n    BIC(model_resp_Iden),\n    BIC(model_resp_Uns)\n  )\n)\n\n# Arredondar\ndf_aderencia$AIC &lt;- round(df_aderencia$AIC, 2)\ndf_aderencia$BIC &lt;- round(df_aderencia$BIC, 2)\n\n# Marcar melhores modelos\ndf_aderencia$AIC &lt;- ifelse(\n  df_aderencia$AIC == min(df_aderencia$AIC),\n  paste0(df_aderencia$AIC, \" ★\"),\n  df_aderencia$AIC\n)\n\ndf_aderencia$BIC &lt;- ifelse(\n  df_aderencia$BIC == min(df_aderencia$BIC),\n  paste0(df_aderencia$BIC, \" ★\"),\n  df_aderencia$BIC\n)\n\n# Exibir\nknitr::kable(\n  df_aderencia,\n  caption = \"Comparação de Matrizes de Covariância (★ = melhor)\"\n)\n\n\nComparação de Matrizes de Covariância (★ = melhor)\n\n\nModelo\nAIC\nBIC\n\n\n\n\nSimétrica\n-51.36\n-38.75\n\n\nAR(1)\n-54.3 ★\n-41.69\n\n\nIdentidade\n-53.36\n-42.15 ★\n\n\nNão-estruturada\n-53.46\n-38.04\n\n\n\n\n\n\n\n\nComparação Automatizada\n\n\n\n\n\n\n🚀 Função compare_performance()\n\n\n\nA função do pacote performance automatiza comparações e calcula pesos de evidência!\n\n\n\ncompare_performance(\n  model_resp_sim,\n  model_resp_AR1,\n  model_resp_Iden,\n  model_resp_Uns,\n  metrics = c(\"AIC\", \"BIC\"),\n  rank = TRUE\n)\n\nSome of the nested models seem to be identical and probably only vary in\n  their random effects.\n\n\n# Comparison of Model Performance Indices\n\nName            | Model | AIC weights | BIC weights | Performance-Score\n-----------------------------------------------------------------------\nmodel_resp_AR1  |   lme |       0.394 |       0.419 |            98.26%\nmodel_resp_Iden |   lme |       0.184 |       0.432 |            67.80%\nmodel_resp_Uns  |   lme |       0.354 |       0.077 |            44.62%\nmodel_resp_sim  |   lme |       0.068 |       0.072 |             0.00%\n\n\n\n\n\n\n\n\n📊 Interpretando Pesos\n\n\n\n\n\nAIC_wt e BIC_wt são pesos de evidência: - Variam de 0 a 1 - Somam 1 entre todos os modelos - Interpretação: probabilidade relativa de ser o melhor modelo\nExemplo: - AIC_wt = 0.85 → 85% de chance de ser o melhor - AIC_wt = 0.10 → 10% de chance de ser o melhor\nDelta_AIC/BIC: - Diferença em relação ao melhor modelo - 0 = melhor modelo - &gt; 10 = evidência muito forte contra\n\n\n\n\n\n\nAnálise dos Resultados\n\n# Calcular diferenças\ndelta_aic &lt;- abs(AIC(model_resp_AR1) - AIC(model_resp_sim))\ndelta_bic &lt;- abs(BIC(model_resp_AR1) - BIC(model_resp_sim))\n\ncat(\"═══ ANÁLISE DE SELEÇÃO ═══\\n\\n\")\n\n═══ ANÁLISE DE SELEÇÃO ═══\n\ncat(\"Diferenças do melhor vs segundo melhor:\\n\")\n\nDiferenças do melhor vs segundo melhor:\n\ncat(\"  ΔAIC:\", round(delta_aic, 2), \"\\n\")\n\n  ΔAIC: 2.94 \n\ncat(\"  ΔBIC:\", round(delta_bic, 2), \"\\n\\n\")\n\n  ΔBIC: 2.94 \n\ncat(\"Interpretação:\\n\")\n\nInterpretação:\n\nif (delta_aic &lt; 2) {\n  cat(\"  • Modelos equivalentes (ΔAIC &lt; 2)\\n\")\n} else if (delta_aic &lt; 10) {\n  cat(\"  • Evidência moderada para o melhor (2 &lt; ΔAIC &lt; 10)\\n\")\n} else {\n  cat(\"  • Evidência forte para o melhor (ΔAIC &gt; 10)\\n\")\n}\n\n  • Evidência moderada para o melhor (2 &lt; ΔAIC &lt; 10)\n\ncat(\"\\nConclusão: Modelo AR(1) apresenta melhor ajuste aos dados\\n\")\n\n\nConclusão: Modelo AR(1) apresenta melhor ajuste aos dados",
    "crumbs": [
      "Modelos Lineares",
      "Lista 3: Matrizes de Covariância"
    ]
  },
  {
    "objectID": "lista_3.html#parte-c-modelo-escolhido---ar1",
    "href": "lista_3.html#parte-c-modelo-escolhido---ar1",
    "title": "Lista 3: Matrizes de Covariância",
    "section": "🎯 Parte C: Modelo Escolhido - AR(1)",
    "text": "🎯 Parte C: Modelo Escolhido - AR(1)\n\n\n\n\n\n\nPor que AR(1) é Adequado?\n\n\n\nJustificativa teórica: A matriz AR(1) é especialmente apropriada para estudos farmacológicos porque:\n\nDecaimento temporal: Efeitos de drogas tendem a diminuir com o tempo\nMemória de curto prazo: Medições próximas são mais relacionadas\nParcimônia: Apenas 1 parâmetro, evita sobre-ajuste\nIntervalos regulares: Comum em protocolos experimentais\n\nNo contexto atual: - Pacientes medidos em intervalos regulares - Expectativa de correlação decrescente - Efeito da droga pode persistir mas enfraquecer\n\n\n\n\nResultados Completos\n\nsummary(model_resp_AR1)\n\nLinear mixed-effects model fit by REML\n  Data: dataset \n        AIC       BIC   logLik\n  -54.30036 -41.68958 36.15018\n\nRandom effects:\n Formula: ~1 | Sujeito\n        (Intercept)   Residual\nStdDev: 1.51949e-06 0.06528019\n\nCorrelation Structure: AR(1)\n Formula: ~1 | Sujeito \n Parameter estimate(s):\n      Phi \n0.4463339 \nFixed effects:  resp ~ drug + Tempo + drug * Tempo \n                       Value  Std.Error DF   t-value p-value\n(Intercept)         3.350000 0.02665053 20 125.70107  0.0000\ndrugPlacebo        -0.116667 0.03768954 10  -3.09547  0.0113\nTempo2              0.016667 0.02804431 20   0.59430  0.5590\nTempo3             -0.016667 0.03372710 20  -0.49416  0.6266\ndrugPlacebo:Tempo2  0.000000 0.03966064 20   0.00000  1.0000\ndrugPlacebo:Tempo3  0.033333 0.04769733 20   0.69885  0.4927\n Correlation: \n                   (Intr) drgPlc Tempo2 Tempo3 drP:T2\ndrugPlacebo        -0.707                            \nTempo2             -0.526  0.372                     \nTempo3             -0.633  0.447  0.601              \ndrugPlacebo:Tempo2  0.372 -0.526 -0.707 -0.425       \ndrugPlacebo:Tempo3  0.447 -0.633 -0.425 -0.707  0.601\n\nStandardized Within-Group Residuals:\n       Min         Q1        Med         Q3        Max \n-2.2977873 -0.7659291 -0.5106194  0.7659291  2.2977873 \n\nNumber of Observations: 36\nNumber of Groups: 12 \n\n\n\n\n\nRelatório Automatizado\n\nreport(model_resp_AR1)\n\nRandom effect variances not available. Returned R2 does not account for random effects.\nRandom effect variances not available. Returned R2 does not account for random effects.\n\n\nWe fitted a linear mixed model (estimated using REML and nlminb optimizer) to\npredict resp with drug, Tempo and Sujeito (formula: resp ~ drug + Tempo + drug\n* Tempo). The model included Sujeito as random effect (formula: ~1 | Sujeito).\nThe model's explanatory power related to the fixed effects alone (marginal R2)\nis 0.41. The model's intercept, corresponding to drug = New Drug and Tempo = 1,\nis at 3.35 (95% CI [3.29, 3.41], t(20) = 125.70, p &lt; .001). Within this model:\n\n  - The effect of drug [Placebo] is statistically significant and negative (beta\n= -0.12, 95% CI [-0.20, -0.03], t(10) = -3.10, p = 0.011; Std. beta = -1.44,\n95% CI [-2.48, -0.40])\n  - The effect of Tempo [2] is statistically non-significant and positive (beta =\n0.02, 95% CI [-0.04, 0.08], t(20) = 0.59, p = 0.559; Std. beta = 0.21, 95% CI\n[-0.52, 0.93])\n  - The effect of Tempo [3] is statistically non-significant and negative (beta =\n-0.02, 95% CI [-0.09, 0.05], t(20) = -0.49, p = 0.627; Std. beta = -0.21, 95%\nCI [-1.07, 0.66])\n  - The effect of drug [Placebo] × Tempo [2] is statistically non-significant and\npositive (beta = 5.39e-17, 95% CI [-0.08, 0.08], t(20) = 1.36e-15, p &gt; .999;\nStd. beta = -8.35e-16, 95% CI [-1.02, 1.02])\n  - The effect of drug [Placebo] × Tempo [3] is statistically non-significant and\npositive (beta = 0.03, 95% CI [-0.07, 0.13], t(20) = 0.70, p = 0.493; Std. beta\n= 0.41, 95% CI [-0.82, 1.64])\n\nStandardized parameters were obtained by fitting the model on a standardized\nversion of the dataset. 95% Confidence Intervals (CIs) and p-values were\ncomputed using a Wald t-distribution approximation.\n\n\n\n\n\nInterpretação Guiada\n\nEfeitos FixosEstrutura de CorrelaçãoVariâncias\n\n\nInterpretar coeficientes:\n\n# Extrair coeficientes\ncoef_table &lt;- summary(model_resp_AR1)$tTable\nknitr::kable(coef_table, digits = 3)\n\n\n\n\n\nValue\nStd.Error\nDF\nt-value\np-value\n\n\n\n\n(Intercept)\n3.350\n0.027\n20\n125.701\n0.000\n\n\ndrugPlacebo\n-0.117\n0.038\n10\n-3.095\n0.011\n\n\nTempo2\n0.017\n0.028\n20\n0.594\n0.559\n\n\nTempo3\n-0.017\n0.034\n20\n-0.494\n0.627\n\n\ndrugPlacebo:Tempo2\n0.000\n0.040\n20\n0.000\n1.000\n\n\ndrugPlacebo:Tempo3\n0.033\n0.048\n20\n0.699\n0.493\n\n\n\n\n\nLeitura: - Intercept: Média baseline do grupo referência no tempo 1 - drugPlacebo: Diferença Placebo vs Droga no tempo 1 - Tempo2/3: Mudança ao longo do tempo no grupo droga - Interações: Como efeito da droga muda com tempo\n\n\n\n# Extrair correlação estimada\nrho &lt;- as.numeric(coef(model_resp_AR1$modelStruct$corStruct, unconstrained = FALSE))\n\ncat(\"Parâmetro AR(1) estimado: ρ =\", round(rho, 3), \"\\n\\n\")\n\nParâmetro AR(1) estimado: ρ = 0.446 \n\ncat(\"Correlações implícitas:\\n\")\n\nCorrelações implícitas:\n\ncat(\"  Tempos adjacentes (1-2, 2-3):\", round(rho, 3), \"\\n\")\n\n  Tempos adjacentes (1-2, 2-3): 0.446 \n\ncat(\"  Tempos separados (1-3):\", round(rho^2, 3), \"\\n\")\n\n  Tempos separados (1-3): 0.199 \n\n\nInterpretação: - ρ próximo de 1: Correlação forte e persistente - ρ próximo de 0: Correlação decai rapidamente - ρ = 0.5: Correlação moderada com decaimento típico\n\n\n\n# Componentes de variância\nvar_components &lt;- VarCorr(model_resp_AR1)\nknitr::kable(var_components)\n\n\n\n\n\nVariance\nStdDev\n\n\n\n\n(Intercept)\n2.308851e-12\n1.519490e-06\n\n\nResidual\n4.261504e-03\n6.528019e-02\n\n\n\n\n\nComponentes: - Between-subject: Variabilidade entre sujeitos (intercepto aleatório) - Within-subject: Variabilidade residual dentro de sujeitos",
    "crumbs": [
      "Modelos Lineares",
      "Lista 3: Matrizes de Covariância"
    ]
  },
  {
    "objectID": "lista_3.html#visualizações-avançadas",
    "href": "lista_3.html#visualizações-avançadas",
    "title": "Lista 3: Matrizes de Covariância",
    "section": "📊 Visualizações Avançadas",
    "text": "📊 Visualizações Avançadas\n\nGráfico dos Efeitos\n\n\n\n\n\n\nPlot em Uma Linha!\n\n\n\nA função allEffects() + plot() cria visualizações rápidas e informativas:\n\n\n\nplot(allEffects(model_resp_AR1))\n\n\n\n\n\n\n\n\n\n\n\nGráfico Personalizado\n\n# Calcular médias preditas\nmeans_pred &lt;- emmeans(model_resp_AR1, \n                      specs = ~drug*Tempo)\n\n# Criar gráfico elegante\nggplot(as.data.frame(means_pred),\n       aes(x = Tempo, y = emmean, color = drug, group = drug)) +\n  geom_errorbar(\n    aes(ymin = lower.CL, ymax = upper.CL),\n    width = 0.15,\n    linewidth = 1,\n    position = position_dodge(0.1)\n  ) +\n  geom_point(\n    size = 4,\n    position = position_dodge(0.1)\n  ) +\n  geom_line(\n    linewidth = 1.2,\n    position = position_dodge(0.1)\n  ) +\n  labs(\n    title = \"Efeito da Droga na Respiração ao Longo do Tempo\",\n    subtitle = \"Modelo com estrutura de correlação AR(1)\",\n    x = \"Momento de Avaliação\",\n    y = \"Frequência Respiratória\",\n    color = \"Tratamento\",\n    caption = \"Barras de erro: IC 95%\"\n  ) +\n  theme_minimal(base_size = 14) +\n  theme(\n    legend.position = \"bottom\",\n    plot.title = element_text(face = \"bold\", size = 16),\n    panel.grid.minor = element_blank()\n  ) +\n  scale_color_manual(values = c(\"#E41A1C\", \"#377EB8\"))",
    "crumbs": [
      "Modelos Lineares",
      "Lista 3: Matrizes de Covariância"
    ]
  },
  {
    "objectID": "lista_3.html#extras-dicas-avançadas",
    "href": "lista_3.html#extras-dicas-avançadas",
    "title": "Lista 3: Matrizes de Covariância",
    "section": "🔧 Extras: Dicas Avançadas",
    "text": "🔧 Extras: Dicas Avançadas\n\nMudando Grupo de Referência\n\n\n\n\n\n\nControle de Referência\n\n\n\nPor padrão, R usa ordem alfabética para escolher o nível de referência. Você pode alterar isso:\n\n\n\n# Verificar nível atual\ncat(\"Níveis originais:\\n\")\n\nNíveis originais:\n\nprint(levels(dataset$drug))\n\n[1] \"New Drug\" \"Placebo\" \n\n# Mudar referência para Placebo\ndataset$drug &lt;- relevel(dataset$drug, ref = \"Placebo\")\n\ncat(\"\\nNovos níveis:\\n\")\n\n\nNovos níveis:\n\nprint(levels(dataset$drug))\n\n[1] \"Placebo\"  \"New Drug\"\n\n\nImpacto: Agora os coeficientes comparam Droga vs Placebo (não o contrário)\n\n\n\nComparando com Nova Referência\n\n# Refazer modelo com nova referência\nmodel_resp_AR1_v2 &lt;- lme(\n  fixed = resp ~ drug + Tempo + drug*Tempo,\n  random = ~1|Sujeito,\n  correlation = corAR1(form = ~1|Sujeito),\n  data = dataset\n)\n\n# Comparar coeficientes\ncat(\"═══ COMPARAÇÃO DE REFERÊNCIAS ═══\\n\\n\")\n\n═══ COMPARAÇÃO DE REFERÊNCIAS ═══\n\ncat(\"Modelo Original (ref: New Drug):\\n\")\n\nModelo Original (ref: New Drug):\n\nprint(summary(model_resp_AR1)$tTable[2, c(\"Value\", \"p-value\")])\n\n     Value    p-value \n-0.1166667  0.0113379 \n\ncat(\"\\nModelo com Nova Referência (ref: Placebo):\\n\")\n\n\nModelo com Nova Referência (ref: Placebo):\n\nprint(summary(model_resp_AR1_v2)$tTable[2, c(\"Value\", \"p-value\")])\n\n    Value   p-value \n0.1166667 0.0113379 \n\n\n\n\n\n\n\n\nInterpretação\n\n\n\nNote que: - Magnitude: Igual em valor absoluto - Sinal: Invertido - p-valor: Idêntico - Interpretação: Mudou de “Placebo vs Droga” para “Droga vs Placebo”",
    "crumbs": [
      "Modelos Lineares",
      "Lista 3: Matrizes de Covariância"
    ]
  },
  {
    "objectID": "lista_3.html#desafio-análise-da-variável-pulse",
    "href": "lista_3.html#desafio-análise-da-variável-pulse",
    "title": "Lista 3: Matrizes de Covariância",
    "section": "🎯 Desafio: Análise da Variável “Pulse”",
    "text": "🎯 Desafio: Análise da Variável “Pulse”\n\n\n\n\n\n\nSua Vez - Checklist Completo!\n\n\n\nReplique toda a análise para a variável “pulse”:\nParte A - Modelos: - [ ] Matriz Simétrica Composta - [ ] Matriz AR(1) - [ ] Matriz Identidade - [ ] Matriz Não-Estruturada\nParte B - Comparações: - [ ] Tabela manual de AIC/BIC - [ ] Comparação com compare_performance() - [ ] Interpretação dos deltas - [ ] Identificação do melhor modelo\nParte C - Modelo Escolhido: - [ ] Relatório completo - [ ] Interpretação dos coeficientes - [ ] Análise de correlação estimada - [ ] Gráficos dos efeitos\nExtras: - [ ] Testar mudança de referência - [ ] Comparar resultados com “resp” - [ ] Refletir sobre diferenças\n\n\n\n\n\n\n\n\n💡 Dicas para o Desafio\n\n\n\n\nRenomeie adequadamente: model_resp_* → model_pulse_*\nNão copie-cole: Digite para aprender\nCompare matrizes: Qual é melhor para pulse?\nReflita: Por que pode diferir de resp?\nDocumente: Anote suas conclusões",
    "crumbs": [
      "Modelos Lineares",
      "Lista 3: Matrizes de Covariância"
    ]
  },
  {
    "objectID": "lista_3.html#material-complementar",
    "href": "lista_3.html#material-complementar",
    "title": "Lista 3: Matrizes de Covariância",
    "section": "📚 Material Complementar",
    "text": "📚 Material Complementar\n\nAula em Vídeo (SPSS)\n\n\n\n\nLeituras Recomendadas\n\n\n\n\n\n\n📖 Aprofundamento em Matrizes de Covariância\n\n\n\n\n\nRecursos Online: - Marginal Models - Correlated Data - Pinheiro & Bates (2000). Mixed-Effects Models in S and S-PLUS - Fitzmaurice et al. (2011). Applied Longitudinal Analysis\nTópicos Avançados: - Estruturas ARMA(p,q) - Matrizes Toeplitz - Bandas de covariância - Testes de razão de verossimilhança\nQuando explorar além: - Dados com muitos tempos (T &gt; 5) - Padrões complexos de correlação - Intervalos irregulares - Comparações formais de estruturas\n\n\n\n\n\n\nTabela de Decisão Rápida\n\n\n\n\n\n\n🗺️ Guia para Escolha de Matriz\n\n\n\n\n\n\n\n\n\n\n\n\n\nSituação\nMatriz Recomendada\nJustificativa\n\n\n\n\nPoucos tempos (T ≤ 3)\nAR(1) ou Simétrica\nParcimônia\n\n\nMuitos tempos (T &gt; 5)\nAR(1)\nEscalabilidade\n\n\nIntervalos irregulares\nSimétrica ou Não-estruturada\nFlexibilidade temporal\n\n\nAmostra grande (n &gt; 100)\nNão-estruturada\nPermite exploração\n\n\nAmostra pequena (n &lt; 30)\nAR(1) ou Simétrica\nEvita sobre-ajuste\n\n\nCorrelação desconhecida\nTestar múltiplas, comparar AIC\nSeleção empírica\n\n\nSérie temporal clássica\nAR(1)\nFundamentação teórica\n\n\nMedições muito espaçadas\nSimétrica ou Identidade\nCorrelação pode ser fraca\n\n\n\nRegra de ouro: Quando em dúvida, teste múltiplas e compare!",
    "crumbs": [
      "Modelos Lineares",
      "Lista 3: Matrizes de Covariância"
    ]
  },
  {
    "objectID": "lista_3.html#informações-de-sessão",
    "href": "lista_3.html#informações-de-sessão",
    "title": "Lista 3: Matrizes de Covariância",
    "section": "🔧 Informações de Sessão",
    "text": "🔧 Informações de Sessão\n\nreport(sessionInfo())\n\nAnalyses were conducted using the R Statistical language (version 4.4.2; R Core\nTeam, 2024) on Windows 11 x64 (build 26100), using the packages effectsize\n(version 1.0.1; Ben-Shachar MS et al., 2020), flexplot (version 0.24.3; Fife,\nD, 2022), effects (version 4.2.4; Fox J, Weisberg S, 2019), carData (version\n3.0.5; Fox J et al., 2022), mvtnorm (version 1.3.3; Genz A, Bretz F, 2009),\nTH.data (version 1.1.3; Hothorn T, 2025), multcomp (version 1.4.28; Hothorn T\net al., 2008), emmeans (version 1.11.0; Lenth R, 2025), parameters (version\n0.28.3; Lüdecke D et al., 2020), performance (version 0.15.2; Lüdecke D et al.,\n2021), easystats (version 0.7.5; Lüdecke D et al., 2022), see (version 0.12.0;\nLüdecke D et al., 2021), insight (version 1.4.4; Lüdecke D et al., 2019),\nbayestestR (version 0.17.0; Makowski D et al., 2019), modelbased (version\n0.13.1; Makowski D et al., 2025), report (version 0.6.3; Makowski D et al.,\n2023), correlation (version 0.8.8; Makowski D et al., 2022), datawizard\n(version 1.3.0; Patil I et al., 2022), nlme (version 3.1.166; Pinheiro J et\nal., 2024), foreign (version 0.8.87; R Core Team, 2024), survival (version\n3.7.0; Therneau T, 2024), MASS (version 7.3.61; Venables WN, Ripley BD, 2002),\nggplot2 (version 4.0.1; Wickham H, 2016) and dplyr (version 1.1.4; Wickham H et\nal., 2023).\n\nReferences\n----------\n  - Ben-Shachar MS, Lüdecke D, Makowski D (2020). \"effectsize: Estimation of\nEffect Size Indices and Standardized Parameters.\" _Journal of Open Source\nSoftware_, *5*(56), 2815. doi:10.21105/joss.02815\n&lt;https://doi.org/10.21105/joss.02815&gt;, &lt;https://doi.org/10.21105/joss.02815&gt;.\n  - Fife, A. D (2022). \"Flexplot: Graphically-based data analysis.\"\n_Psychological Methods_, *27*(4), -19. &lt;doi.org/10.1037/met0000424&gt;.\n  - Fox J, Weisberg S (2019). _An R Companion to Applied Regression_, 3rd\nedition. Sage, Thousand Oaks CA.\n&lt;https://www.john-fox.ca/Companion/index.html&gt;. Fox J, Weisberg S (2018).\n\"Visualizing Fit and Lack of Fit in Complex Regression Models with Predictor\nEffect Plots and Partial Residuals.\" _Journal of Statistical Software_,\n*87*(9), 1-27. doi:10.18637/jss.v087.i09\n&lt;https://doi.org/10.18637/jss.v087.i09&gt;. Fox J (2003). \"Effect Displays in R\nfor Generalised Linear Models.\" _Journal of Statistical Software_, *8*(15),\n1-27. doi:10.18637/jss.v008.i15 &lt;https://doi.org/10.18637/jss.v008.i15&gt;. Fox J,\nHong J (2009). \"Effect Displays in R for Multinomial and Proportional-Odds\nLogit Models: Extensions to the effects Package.\" _Journal of Statistical\nSoftware_, *32*(1), 1-24. doi:10.18637/jss.v032.i01\n&lt;https://doi.org/10.18637/jss.v032.i01&gt;.\n  - Fox J, Weisberg S, Price B (2022). _carData: Companion to Applied Regression\nData Sets_. R package version 3.0-5,\n&lt;https://CRAN.R-project.org/package=carData&gt;.\n  - Genz A, Bretz F (2009). _Computation of Multivariate Normal and t\nProbabilities_, series Lecture Notes in Statistics. Springer-Verlag,\nHeidelberg. ISBN 978-3-642-01688-2.\n  - Hothorn T (2025). _TH.data: TH's Data Archive_. R package version 1.1-3,\n&lt;https://CRAN.R-project.org/package=TH.data&gt;.\n  - Hothorn T, Bretz F, Westfall P (2008). \"Simultaneous Inference in General\nParametric Models.\" _Biometrical Journal_, *50*(3), 346-363.\n  - Lenth R (2025). _emmeans: Estimated Marginal Means, aka Least-Squares Means_.\nR package version 1.11.0, &lt;https://CRAN.R-project.org/package=emmeans&gt;.\n  - Lüdecke D, Ben-Shachar M, Patil I, Makowski D (2020). \"Extracting, Computing\nand Exploring the Parameters of Statistical Models using R.\" _Journal of Open\nSource Software_, *5*(53), 2445. doi:10.21105/joss.02445\n&lt;https://doi.org/10.21105/joss.02445&gt;.\n  - Lüdecke D, Ben-Shachar M, Patil I, Waggoner P, Makowski D (2021).\n\"performance: An R Package for Assessment, Comparison and Testing of\nStatistical Models.\" _Journal of Open Source Software_, *6*(60), 3139.\ndoi:10.21105/joss.03139 &lt;https://doi.org/10.21105/joss.03139&gt;.\n  - Lüdecke D, Ben-Shachar M, Patil I, Wiernik B, Bacher E, Thériault R, Makowski\nD (2022). \"easystats: Framework for Easy Statistical Modeling, Visualization,\nand Reporting.\" _CRAN_. doi:10.32614/CRAN.package.easystats\n&lt;https://doi.org/10.32614/CRAN.package.easystats&gt;, R package,\n&lt;https://easystats.github.io/easystats/&gt;.\n  - Lüdecke D, Patil I, Ben-Shachar M, Wiernik B, Waggoner P, Makowski D (2021).\n\"see: An R Package for Visualizing Statistical Models.\" _Journal of Open Source\nSoftware_, *6*(64), 3393. doi:10.21105/joss.03393\n&lt;https://doi.org/10.21105/joss.03393&gt;.\n  - Lüdecke D, Waggoner P, Makowski D (2019). \"insight: A Unified Interface to\nAccess Information from Model Objects in R.\" _Journal of Open Source Software_,\n*4*(38), 1412. doi:10.21105/joss.01412 &lt;https://doi.org/10.21105/joss.01412&gt;.\n  - Makowski D, Ben-Shachar M, Lüdecke D (2019). \"bayestestR: Describing Effects\nand their Uncertainty, Existence and Significance within the Bayesian\nFramework.\" _Journal of Open Source Software_, *4*(40), 1541.\ndoi:10.21105/joss.01541 &lt;https://doi.org/10.21105/joss.01541&gt;,\n&lt;https://joss.theoj.org/papers/10.21105/joss.01541&gt;.\n  - Makowski D, Ben-Shachar M, Wiernik B, Patil I, Thériault R, Lüdecke D (2025).\n\"modelbased: An R package to make the most out of your statistical models\nthrough marginal means, marginal effects, and model predictions.\" _Journal of\nOpen Source Software_, *10*(109), 7969. doi:10.21105/joss.07969\n&lt;https://doi.org/10.21105/joss.07969&gt;,\n&lt;https://joss.theoj.org/papers/10.21105/joss.07969&gt;.\n  - Makowski D, Lüdecke D, Patil I, Thériault R, Ben-Shachar M, Wiernik B (2023).\n\"Automated Results Reporting as a Practical Tool to Improve Reproducibility and\nMethodological Best Practices Adoption.\" _CRAN_.\ndoi:10.32614/CRAN.package.report\n&lt;https://doi.org/10.32614/CRAN.package.report&gt;,\n&lt;https://easystats.github.io/report/&gt;.\n  - Makowski D, Wiernik B, Patil I, Lüdecke D, Ben-Shachar M (2022).\n\"correlation: Methods for Correlation Analysis.\" Version 0.8.3,\n&lt;https://CRAN.R-project.org/package=correlation&gt;. Makowski D, Ben-Shachar M,\nPatil I, Lüdecke D (2020). \"Methods and Algorithms for Correlation Analysis in\nR.\" _Journal of Open Source Software_, *5*(51), 2306. doi:10.21105/joss.02306\n&lt;https://doi.org/10.21105/joss.02306&gt;,\n&lt;https://joss.theoj.org/papers/10.21105/joss.02306&gt;.\n  - Patil I, Makowski D, Ben-Shachar M, Wiernik B, Bacher E, Lüdecke D (2022).\n\"datawizard: An R Package for Easy Data Preparation and Statistical\nTransformations.\" _Journal of Open Source Software_, *7*(78), 4684.\ndoi:10.21105/joss.04684 &lt;https://doi.org/10.21105/joss.04684&gt;.\n  - Pinheiro J, Bates D, R Core Team (2024). _nlme: Linear and Nonlinear Mixed\nEffects Models_. R package version 3.1-166,\n&lt;https://CRAN.R-project.org/package=nlme&gt;. Pinheiro JC, Bates DM (2000).\n_Mixed-Effects Models in S and S-PLUS_. Springer, New York. doi:10.1007/b98882\n&lt;https://doi.org/10.1007/b98882&gt;.\n  - R Core Team (2024). _foreign: Read Data Stored by 'Minitab', 'S', 'SAS',\n'SPSS', 'Stata', 'Systat', 'Weka', 'dBase', ..._. R package version 0.8-87,\n&lt;https://CRAN.R-project.org/package=foreign&gt;.\n  - R Core Team (2024). _R: A Language and Environment for Statistical\nComputing_. R Foundation for Statistical Computing, Vienna, Austria.\n&lt;https://www.R-project.org/&gt;.\n  - Therneau T (2024). _A Package for Survival Analysis in R_. R package version\n3.7-0, &lt;https://CRAN.R-project.org/package=survival&gt;. Terry M. Therneau,\nPatricia M. Grambsch (2000). _Modeling Survival Data: Extending the Cox Model_.\nSpringer, New York. ISBN 0-387-98784-3.\n  - Venables WN, Ripley BD (2002). _Modern Applied Statistics with S_, Fourth\nedition. Springer, New York. ISBN 0-387-95457-0,\n&lt;https://www.stats.ox.ac.uk/pub/MASS4/&gt;.\n  - Wickham H (2016). _ggplot2: Elegant Graphics for Data Analysis_.\nSpringer-Verlag New York. ISBN 978-3-319-24277-4,\n&lt;https://ggplot2.tidyverse.org&gt;.\n  - Wickham H, François R, Henry L, Müller K, Vaughan D (2023). _dplyr: A Grammar\nof Data Manipulation_. R package version 1.1.4,\n&lt;https://CRAN.R-project.org/package=dplyr&gt;.\n\n\n\n\n\n\n\n\n\n🎓 Resumo da Lista 3\n\n\n\nNesta lista você:\n✅ Compreendeu quatro estruturas de covariância\n✅ Aprendeu a comparar modelos via AIC/BIC\n✅ Identificou a estrutura mais adequada aos dados\n✅ Interpretou parâmetros de correlação\n✅ Criou visualizações profissionais\n✅ Dominou mudança de níveis de referência\nConceitos-chave: - Matrizes capturam correlação entre medidas repetidas - AR(1) assume decaimento exponencial (comum em farmacologia) - AIC/BIC penalizam complexidade diferentemente - Estrutura apropriada melhora estimativas e inferências\nPróximos passos: - Complete análise para “pulse” - Compare qual estrutura funciona melhor - Prepare-se para Lista 4: GzLM!",
    "crumbs": [
      "Modelos Lineares",
      "Lista 3: Matrizes de Covariância"
    ]
  },
  {
    "objectID": "lista_4.html",
    "href": "lista_4.html",
    "title": "Lista 4: Modelos Hierárquicos e ICC",
    "section": "",
    "text": "📖 Contexto: Estudo TVSFP",
    "crumbs": [
      "Modelos Lineares",
      "Lista 4: Modelos Hierárquicos e ICC"
    ]
  },
  {
    "objectID": "lista_4.html#contexto-estudo-tvsfp",
    "href": "lista_4.html#contexto-estudo-tvsfp",
    "title": "Lista 4: Modelos Hierárquicos e ICC",
    "section": "",
    "text": "Television, School and Family Smoking Prevention Project\n\n\n\n\n\nObjetivo: Avaliar eficácia de programas anti-tabagismo\nIntervenções: - CC: Currículo presencial - TV: Programa televisivo\n4 Grupos: Curriculum&TV, Curriculum, TV, Neither (controle)\nAmostra: 1.600 alunos, 135 classes, 28 escolas (Los Angeles)\nVD: THKS (Tobacco and Health Knowledge Scale) pré e pós",
    "crumbs": [
      "Modelos Lineares",
      "Lista 4: Modelos Hierárquicos e ICC"
    ]
  },
  {
    "objectID": "lista_4.html#pacotes",
    "href": "lista_4.html#pacotes",
    "title": "Lista 4: Modelos Hierárquicos e ICC",
    "section": "📦 Pacotes",
    "text": "📦 Pacotes\n\npacotes &lt;- c(\"emmeans\", \"lme4\", \"nlme\", \"flexplot\", \"foreign\",\n             \"dplyr\", \"ggplot2\", \"forcats\", \"performance\",\n             \"easystats\", \"misty\", \"tidyr\", \"kableExtra\")\n\npacotes_faltantes &lt;- pacotes[!pacotes %in% installed.packages()[, \"Package\"]]\nif (length(pacotes_faltantes) &gt; 0) install.packages(pacotes_faltantes, dependencies = TRUE)\ninvisible(lapply(pacotes, library, character.only = TRUE))",
    "crumbs": [
      "Modelos Lineares",
      "Lista 4: Modelos Hierárquicos e ICC"
    ]
  },
  {
    "objectID": "lista_4.html#dados",
    "href": "lista_4.html#dados",
    "title": "Lista 4: Modelos Hierárquicos e ICC",
    "section": "📥 Dados",
    "text": "📥 Dados\n\ndataset &lt;- read.spss(\"THKS2.sav\", to.data.frame = TRUE)\n\n# Corrigir tipos\ndataset$SchoolID &lt;- as.factor(dataset$SchoolID)\ndataset$ClassID &lt;- as.factor(dataset$ClassID)\ndataset$PreTHKS &lt;- as.integer(dataset$PreTHKS)\ndataset$PosTHKS &lt;- as.integer(dataset$PosTHKS)\ndataset$Tamanho_Classe &lt;- ave(dataset$PreTHKS, dataset$SchoolID, dataset$ClassID, FUN = length)",
    "crumbs": [
      "Modelos Lineares",
      "Lista 4: Modelos Hierárquicos e ICC"
    ]
  },
  {
    "objectID": "lista_4.html#parte-a-análise-visual-dos-níveis",
    "href": "lista_4.html#parte-a-análise-visual-dos-níveis",
    "title": "Lista 4: Modelos Hierárquicos e ICC",
    "section": "🎯 Parte A: Análise Visual dos Níveis",
    "text": "🎯 Parte A: Análise Visual dos Níveis\n\nPor Escola\n\nmedia_escola &lt;- aggregate(cbind(PreTHKS, PosTHKS) ~ SchoolID, data = dataset, FUN = mean)\nmedia_escola_long &lt;- pivot_longer(media_escola, cols = c(\"PreTHKS\", \"PosTHKS\"), names_to = \"tempo\", values_to = \"media\")\n\nggplot(media_escola_long, aes(x = fct_rev(tempo), y = media, color = SchoolID, group = SchoolID)) +\n  geom_point(size = 3) + geom_line() +\n  labs(title = \"Trajetória por Escola\", x = \"\", y = \"Média THKS\") +\n  theme_minimal() + theme(legend.position = \"right\")\n\n\n\n\n\n\n\n\nPadrão: Aumento consistente → Escola = efeito fixo?\n\n\n\nPor Classe\n\nmedia_classe &lt;- aggregate(cbind(PreTHKS, PosTHKS) ~ ClassID, data = dataset, FUN = mean)\nmedia_classe_long &lt;- pivot_longer(media_classe, cols = c(\"PreTHKS\", \"PosTHKS\"), names_to = \"tempo\", values_to = \"media\")\n\nggplot(media_classe_long, aes(x = fct_rev(tempo), y = media, color = ClassID, group = ClassID)) +\n  geom_point(size = 2) + geom_line(alpha = 0.4) +\n  labs(title = \"Trajetória por Classe (135 classes)\", x = \"\", y = \"Média THKS\") +\n  theme_minimal() + theme(legend.position = \"none\")\n\n\n\n\n\n\n\n\nPadrão: Heterogêneo → Classe = efeito aleatório!",
    "crumbs": [
      "Modelos Lineares",
      "Lista 4: Modelos Hierárquicos e ICC"
    ]
  },
  {
    "objectID": "lista_4.html#parte-d-icc",
    "href": "lista_4.html#parte-d-icc",
    "title": "Lista 4: Modelos Hierárquicos e ICC",
    "section": "🎯 Parte D: ICC",
    "text": "🎯 Parte D: ICC\n\nModelo 1: Com Preditores\n\nmodelo_1 &lt;- lmer(PosTHKS ~ 1 + Group * PreTHKS + (1|SchoolID:ClassID) + (1|SchoolID), data = dataset, REML = TRUE)\nvar_modelo_1 &lt;- as.data.frame(VarCorr(modelo_1))\n\nvar_classe_1 &lt;- var_modelo_1$vcov[1]\nvar_escola_1 &lt;- var_modelo_1$vcov[2]\nvar_erro_1 &lt;- var_modelo_1$vcov[3]\n\nicc_escola_1 &lt;- var_escola_1 / (var_escola_1 + var_erro_1)\nicc_classe_1 &lt;- var_classe_1 / (var_classe_1 + var_erro_1)\n\ncat(\"ICC Escola:\", round(icc_escola_1, 4), \"=\", round(icc_escola_1 * 100, 2), \"%\\n\")\n\nICC Escola: 0.0235 = 2.35 %\n\ncat(\"ICC Classe:\", round(icc_classe_1, 4), \"=\", round(icc_classe_1 * 100, 2), \"%\\n\")\n\nICC Classe: 0.0389 = 3.89 %\n\n\n\n\n\nModelo 2: Apenas Aleatórios\n\nmodelo_2 &lt;- lmer(PosTHKS ~ 1 + (1|SchoolID:ClassID) + (1|SchoolID), data = dataset, REML = TRUE)\nvar_modelo_2 &lt;- as.data.frame(VarCorr(modelo_2))\n\nicc_escola_2 &lt;- var_modelo_2$vcov[2] / (var_modelo_2$vcov[2] + var_modelo_2$vcov[3])\nicc_classe_2 &lt;- var_modelo_2$vcov[1] / (var_modelo_2$vcov[1] + var_modelo_2$vcov[3])\n\ncat(\"ICC Escola:\", round(icc_escola_2, 4), \"=\", round(icc_escola_2 * 100, 2), \"%\\n\")\n\nICC Escola: 0.0634 = 6.34 %\n\ncat(\"ICC Classe:\", round(icc_classe_2, 4), \"=\", round(icc_classe_2 * 100, 2), \"%\\n\")\n\nICC Classe: 0.047 = 4.7 %\n\n\n\n\n\n\n\n\nNote\n\n\n\nEscola passa de &lt;5% para &gt;5% sem preditores!",
    "crumbs": [
      "Modelos Lineares",
      "Lista 4: Modelos Hierárquicos e ICC"
    ]
  },
  {
    "objectID": "lista_4.html#parte-e-modelo-final",
    "href": "lista_4.html#parte-e-modelo-final",
    "title": "Lista 4: Modelos Hierárquicos e ICC",
    "section": "🎯 Parte E: Modelo Final",
    "text": "🎯 Parte E: Modelo Final\n\ndataset$Group &lt;- relevel(dataset$Group, ref = \"Neither\")\n\nmodelo_final &lt;- lme(\n  fixed = PosTHKS ~ 1 + PreTHKS + Group,\n  random = ~1|SchoolID/ClassID,\n  data = dataset,\n  method = \"REML\"\n)\n\n\nDiagnóstico\n\ncheck_model(modelo_final)\n\nConverting missing values (`NA`) into regular values currently not\n  possible for variables of class `NULL`.\n\n\n\n\n\n\n\n\n\n\n\nComparações\n\ncomparacoes &lt;- emmeans(modelo_final, pairwise ~ Group, adjust = \"bonferroni\")\ncomparacoes$contrasts\n\n contrast                     estimate    SE df t.ratio p.value\n Neither - Curriculum & TV      -0.492 0.159 24  -3.104  0.0290\n Neither - Curriculum           -0.641 0.161 24  -3.985  0.0033\n Neither - TV                   -0.182 0.157 24  -1.158  1.0000\n Curriculum & TV - Curriculum   -0.149 0.160 24  -0.928  1.0000\n Curriculum & TV - TV            0.310 0.157 24   1.981  0.3550\n Curriculum - TV                 0.459 0.159 24   2.888  0.0485\n\nDegrees-of-freedom method: containment \nP value adjustment: bonferroni method for 6 tests \n\n\n\n\nVisualização\n\nmeans_plot &lt;- as.data.frame(comparacoes$emmeans)\n\nggplot(means_plot, aes(x = reorder(Group, -emmean), y = emmean, fill = Group)) +\n  geom_col(alpha = 0.8) +\n  geom_errorbar(aes(ymin = lower.CL, ymax = upper.CL), width = 0.2) +\n  labs(title = \"THKS Pós-Intervenção por Grupo\", y = \"THKS Estimado\") +\n  theme_minimal() + theme(legend.position = \"none\")",
    "crumbs": [
      "Modelos Lineares",
      "Lista 4: Modelos Hierárquicos e ICC"
    ]
  },
  {
    "objectID": "lista_4.html#extras",
    "href": "lista_4.html#extras",
    "title": "Lista 4: Modelos Hierárquicos e ICC",
    "section": "🔧 Extras",
    "text": "🔧 Extras\n\nFunção ICC Personalizada\n\nicc_lme_3nv &lt;- function(modelo) {\n  var_escola &lt;- as.numeric(VarCorr(modelo)[2, \"Variance\"])\n  var_classe &lt;- as.numeric(VarCorr(modelo)[4, \"Variance\"])\n  var_res &lt;- as.numeric(VarCorr(modelo)[5, \"Variance\"])\n  \n  list(\n    ICC_Escola = var_escola / (var_escola + var_res),\n    ICC_Classe = var_classe / (var_classe + var_res)\n  )\n}\n\nicc_lme_3nv(modelo_final)\n\n$ICC_Escola\n[1] 0.02354758\n\n$ICC_Classe\n[1] 0.03879018\n\n\n\n\nComparação Modelos\n\ncompare_performance(modelo_1, modelo_2, metrics = c(\"AIC\", \"BIC\"), rank = TRUE)\n\n# Comparison of Model Performance Indices\n\nName     |   Model | AIC weights | BIC weights | Performance-Score\n------------------------------------------------------------------\nmodelo_1 | lmerMod |        1.00 |        1.00 |           100.00%\nmodelo_2 | lmerMod |    2.80e-30 |    4.19e-22 |             0.00%",
    "crumbs": [
      "Modelos Lineares",
      "Lista 4: Modelos Hierárquicos e ICC"
    ]
  },
  {
    "objectID": "lista_4.html#material-complementar",
    "href": "lista_4.html#material-complementar",
    "title": "Lista 4: Modelos Hierárquicos e ICC",
    "section": "📚 Material Complementar",
    "text": "📚 Material Complementar",
    "crumbs": [
      "Modelos Lineares",
      "Lista 4: Modelos Hierárquicos e ICC"
    ]
  },
  {
    "objectID": "lista_4.html#sessão",
    "href": "lista_4.html#sessão",
    "title": "Lista 4: Modelos Hierárquicos e ICC",
    "section": "🔧 Sessão",
    "text": "🔧 Sessão\n\nreport(sessionInfo())\n\nAnalyses were conducted using the R Statistical language (version 4.4.2; R Core\nTeam, 2024) on Windows 11 x64 (build 26100), using the packages lme4 (version\n1.1.37; Bates D et al., 2015), Matrix (version 1.7.1; Bates D et al., 2024),\neffectsize (version 1.0.1; Ben-Shachar MS et al., 2020), flexplot (version\n0.24.3; Fife, D, 2022), emmeans (version 1.11.0; Lenth R, 2025), parameters\n(version 0.28.3; Lüdecke D et al., 2020), performance (version 0.15.2; Lüdecke\nD et al., 2021), easystats (version 0.7.5; Lüdecke D et al., 2022), see\n(version 0.12.0; Lüdecke D et al., 2021), insight (version 1.4.4; Lüdecke D et\nal., 2019), bayestestR (version 0.17.0; Makowski D et al., 2019), modelbased\n(version 0.13.1; Makowski D et al., 2025), report (version 0.6.3; Makowski D et\nal., 2023), correlation (version 0.8.8; Makowski D et al., 2022), datawizard\n(version 1.3.0; Patil I et al., 2022), nlme (version 3.1.166; Pinheiro J et\nal., 2024), foreign (version 0.8.87; R Core Team, 2024), ggplot2 (version\n4.0.1; Wickham H, 2016), forcats (version 1.0.0; Wickham H, 2023), dplyr\n(version 1.1.4; Wickham H et al., 2023), tidyr (version 1.3.1; Wickham H et\nal., 2024), misty (version 0.7.6; Yanagida T, 2025) and kableExtra (version\n1.4.0; Zhu H, 2024).\n\nReferences\n----------\n  - Bates D, Mächler M, Bolker B, Walker S (2015). \"Fitting Linear Mixed-Effects\nModels Using lme4.\" _Journal of Statistical Software_, *67*(1), 1-48.\ndoi:10.18637/jss.v067.i01 &lt;https://doi.org/10.18637/jss.v067.i01&gt;.\n  - Bates D, Maechler M, Jagan M (2024). _Matrix: Sparse and Dense Matrix Classes\nand Methods_. R package version 1.7-1,\n&lt;https://CRAN.R-project.org/package=Matrix&gt;.\n  - Ben-Shachar MS, Lüdecke D, Makowski D (2020). \"effectsize: Estimation of\nEffect Size Indices and Standardized Parameters.\" _Journal of Open Source\nSoftware_, *5*(56), 2815. doi:10.21105/joss.02815\n&lt;https://doi.org/10.21105/joss.02815&gt;, &lt;https://doi.org/10.21105/joss.02815&gt;.\n  - Fife, A. D (2022). \"Flexplot: Graphically-based data analysis.\"\n_Psychological Methods_, *27*(4), -19. &lt;doi.org/10.1037/met0000424&gt;.\n  - Lenth R (2025). _emmeans: Estimated Marginal Means, aka Least-Squares Means_.\nR package version 1.11.0, &lt;https://CRAN.R-project.org/package=emmeans&gt;.\n  - Lüdecke D, Ben-Shachar M, Patil I, Makowski D (2020). \"Extracting, Computing\nand Exploring the Parameters of Statistical Models using R.\" _Journal of Open\nSource Software_, *5*(53), 2445. doi:10.21105/joss.02445\n&lt;https://doi.org/10.21105/joss.02445&gt;.\n  - Lüdecke D, Ben-Shachar M, Patil I, Waggoner P, Makowski D (2021).\n\"performance: An R Package for Assessment, Comparison and Testing of\nStatistical Models.\" _Journal of Open Source Software_, *6*(60), 3139.\ndoi:10.21105/joss.03139 &lt;https://doi.org/10.21105/joss.03139&gt;.\n  - Lüdecke D, Ben-Shachar M, Patil I, Wiernik B, Bacher E, Thériault R, Makowski\nD (2022). \"easystats: Framework for Easy Statistical Modeling, Visualization,\nand Reporting.\" _CRAN_. doi:10.32614/CRAN.package.easystats\n&lt;https://doi.org/10.32614/CRAN.package.easystats&gt;, R package,\n&lt;https://easystats.github.io/easystats/&gt;.\n  - Lüdecke D, Patil I, Ben-Shachar M, Wiernik B, Waggoner P, Makowski D (2021).\n\"see: An R Package for Visualizing Statistical Models.\" _Journal of Open Source\nSoftware_, *6*(64), 3393. doi:10.21105/joss.03393\n&lt;https://doi.org/10.21105/joss.03393&gt;.\n  - Lüdecke D, Waggoner P, Makowski D (2019). \"insight: A Unified Interface to\nAccess Information from Model Objects in R.\" _Journal of Open Source Software_,\n*4*(38), 1412. doi:10.21105/joss.01412 &lt;https://doi.org/10.21105/joss.01412&gt;.\n  - Makowski D, Ben-Shachar M, Lüdecke D (2019). \"bayestestR: Describing Effects\nand their Uncertainty, Existence and Significance within the Bayesian\nFramework.\" _Journal of Open Source Software_, *4*(40), 1541.\ndoi:10.21105/joss.01541 &lt;https://doi.org/10.21105/joss.01541&gt;,\n&lt;https://joss.theoj.org/papers/10.21105/joss.01541&gt;.\n  - Makowski D, Ben-Shachar M, Wiernik B, Patil I, Thériault R, Lüdecke D (2025).\n\"modelbased: An R package to make the most out of your statistical models\nthrough marginal means, marginal effects, and model predictions.\" _Journal of\nOpen Source Software_, *10*(109), 7969. doi:10.21105/joss.07969\n&lt;https://doi.org/10.21105/joss.07969&gt;,\n&lt;https://joss.theoj.org/papers/10.21105/joss.07969&gt;.\n  - Makowski D, Lüdecke D, Patil I, Thériault R, Ben-Shachar M, Wiernik B (2023).\n\"Automated Results Reporting as a Practical Tool to Improve Reproducibility and\nMethodological Best Practices Adoption.\" _CRAN_.\ndoi:10.32614/CRAN.package.report\n&lt;https://doi.org/10.32614/CRAN.package.report&gt;,\n&lt;https://easystats.github.io/report/&gt;.\n  - Makowski D, Wiernik B, Patil I, Lüdecke D, Ben-Shachar M (2022).\n\"correlation: Methods for Correlation Analysis.\" Version 0.8.3,\n&lt;https://CRAN.R-project.org/package=correlation&gt;. Makowski D, Ben-Shachar M,\nPatil I, Lüdecke D (2020). \"Methods and Algorithms for Correlation Analysis in\nR.\" _Journal of Open Source Software_, *5*(51), 2306. doi:10.21105/joss.02306\n&lt;https://doi.org/10.21105/joss.02306&gt;,\n&lt;https://joss.theoj.org/papers/10.21105/joss.02306&gt;.\n  - Patil I, Makowski D, Ben-Shachar M, Wiernik B, Bacher E, Lüdecke D (2022).\n\"datawizard: An R Package for Easy Data Preparation and Statistical\nTransformations.\" _Journal of Open Source Software_, *7*(78), 4684.\ndoi:10.21105/joss.04684 &lt;https://doi.org/10.21105/joss.04684&gt;.\n  - Pinheiro J, Bates D, R Core Team (2024). _nlme: Linear and Nonlinear Mixed\nEffects Models_. R package version 3.1-166,\n&lt;https://CRAN.R-project.org/package=nlme&gt;. Pinheiro JC, Bates DM (2000).\n_Mixed-Effects Models in S and S-PLUS_. Springer, New York. doi:10.1007/b98882\n&lt;https://doi.org/10.1007/b98882&gt;.\n  - R Core Team (2024). _foreign: Read Data Stored by 'Minitab', 'S', 'SAS',\n'SPSS', 'Stata', 'Systat', 'Weka', 'dBase', ..._. R package version 0.8-87,\n&lt;https://CRAN.R-project.org/package=foreign&gt;.\n  - R Core Team (2024). _R: A Language and Environment for Statistical\nComputing_. R Foundation for Statistical Computing, Vienna, Austria.\n&lt;https://www.R-project.org/&gt;.\n  - Wickham H (2016). _ggplot2: Elegant Graphics for Data Analysis_.\nSpringer-Verlag New York. ISBN 978-3-319-24277-4,\n&lt;https://ggplot2.tidyverse.org&gt;.\n  - Wickham H (2023). _forcats: Tools for Working with Categorical Variables\n(Factors)_. R package version 1.0.0,\n&lt;https://CRAN.R-project.org/package=forcats&gt;.\n  - Wickham H, François R, Henry L, Müller K, Vaughan D (2023). _dplyr: A Grammar\nof Data Manipulation_. R package version 1.1.4,\n&lt;https://CRAN.R-project.org/package=dplyr&gt;.\n  - Wickham H, Vaughan D, Girlich M (2024). _tidyr: Tidy Messy Data_. R package\nversion 1.3.1, &lt;https://CRAN.R-project.org/package=tidyr&gt;.\n  - Yanagida T (2025). _misty: Miscellaneous Functions 'T. Yanagida'_. R package\nversion 0.7.6, &lt;https://CRAN.R-project.org/package=misty&gt;.\n  - Zhu H (2024). _kableExtra: Construct Complex Table with 'kable' and Pipe\nSyntax_. R package version 1.4.0,\n&lt;https://CRAN.R-project.org/package=kableExtra&gt;.",
    "crumbs": [
      "Modelos Lineares",
      "Lista 4: Modelos Hierárquicos e ICC"
    ]
  },
  {
    "objectID": "lista_5.html",
    "href": "lista_5.html",
    "title": "Lista 5: Modelos Lineares Generalizados (GzLM)",
    "section": "",
    "text": "📦 Pacotes Necessários\npacotes &lt;- c(\n  \"emmeans\", \"tidyverse\", \"lme4\", \"nlme\", \"flexplot\",\n  \"foreign\", \"dplyr\", \"multcomp\", \"effects\", \"sjstats\",\n  \"sjPlot\", \"ggplot2\", \"forcats\", \"performance\",\n  \"easystats\", \"kableExtra\", \"fitdistrplus\", \"AER\",\n  \"gtsummary\", \"broom\"\n)\n\npacotes_faltantes &lt;- pacotes[!pacotes %in% installed.packages()[, \"Package\"]]\nif (length(pacotes_faltantes) &gt; 0) {\n  install.packages(pacotes_faltantes, dependencies = TRUE)\n}\n\ninvisible(lapply(pacotes, library, character.only = TRUE))\ncat(\"✓ Pacotes carregados!\\n\")\n\n✓ Pacotes carregados!",
    "crumbs": [
      "Modelos Lineares",
      "Lista 5: Modelos Lineares Generalizados (GzLM)"
    ]
  },
  {
    "objectID": "lista_5.html#preparação-dos-dados",
    "href": "lista_5.html#preparação-dos-dados",
    "title": "Lista 5: Modelos Lineares Generalizados (GzLM)",
    "section": "📥 Preparação dos Dados",
    "text": "📥 Preparação dos Dados\n\n\n\n\n\n\nDownload Necessário\n\n\n\nBaixe o banco “Dados Amostra” e salve na pasta do projeto.\n\n\n\n# Carregar dados originais\noriginal &lt;- read.spss(\"Dados Amostra.sav\", to.data.frame = TRUE)\n\n# Criar cópia de trabalho (boa prática!)\ndb &lt;- original\n\n\n\nCorreção de Tipos\n\n# Verificar estrutura\nglimpse(db)\n\nRows: 1,500\nColumns: 10\n$ id        &lt;dbl&gt; 188, 730, 855, 866, 1165, 1225, 1294, 1339, 1343, 168, 1390,…\n$ childs    &lt;fct&gt; 2, 2, 0, 0, 3, 2, 3, NA, NA, 0, 2, 1, 0, 0, 0, 2, 0, 1, 4, 3…\n$ age       &lt;fct&gt; 76, 48, 19, 38, 54, 53, 65, 52, 72, 82, 55, 43, 44, 43, 45, …\n$ educ      &lt;fct&gt; 14, 12, 13, 16, 16, NA, 12, 12, 9, 15, 12, 11, 16, 16, 15, 1…\n$ sex       &lt;fct&gt; Female, Female, Male, Female, Female, Female, Male, Female, …\n$ life      &lt;fct&gt; Routine, Routine, Exciting, Exciting, NA, Dull, NA, NA, NA, …\n$ tvhours   &lt;fct&gt; 5, 1, 1, NA, 3, 4, 1, NA, NA, 2, 2, 4, 5, 2, 4, 4, 4, 3, 6, …\n$ attsprts  &lt;fct&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, No, No, No, No, …\n$ tempo_obs &lt;dbl&gt; 123.0000, 424.0000, 124.0000, 500.0000, 500.0000, 500.0000, …\n$ aderencia &lt;fct&gt; SIM, SIM, SIM, SIM, SIM, SIM, SIM, SIM, SIM, SIM, SIM, SIM, …\n\n# Converter variáveis numéricas\ndb$childs &lt;- as.integer(db$childs)\ndb$age &lt;- as.numeric(db$age)\ndb$educ &lt;- as.numeric(db$educ)\ndb$tvhours &lt;- as.numeric(db$tvhours)\n\n# Confirmar mudanças\nglimpse(db)\n\nRows: 1,500\nColumns: 10\n$ id        &lt;dbl&gt; 188, 730, 855, 866, 1165, 1225, 1294, 1339, 1343, 168, 1390,…\n$ childs    &lt;int&gt; 3, 3, 1, 1, 4, 3, 4, NA, NA, 1, 3, 2, 1, 1, 1, 3, 1, 2, 5, 4…\n$ age       &lt;dbl&gt; 59, 31, 2, 21, 37, 36, 48, 35, 55, 65, 38, 26, 27, 26, 28, 6…\n$ educ      &lt;dbl&gt; 13, 11, 12, 15, 15, NA, 11, 11, 8, 14, 11, 10, 15, 15, 14, 1…\n$ sex       &lt;fct&gt; Female, Female, Male, Female, Female, Female, Male, Female, …\n$ life      &lt;fct&gt; Routine, Routine, Exciting, Exciting, NA, Dull, NA, NA, NA, …\n$ tvhours   &lt;dbl&gt; 6, 2, 2, NA, 4, 5, 2, NA, NA, 3, 3, 5, 6, 3, 5, 5, 5, 4, 7, …\n$ attsprts  &lt;fct&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, No, No, No, No, …\n$ tempo_obs &lt;dbl&gt; 123.0000, 424.0000, 124.0000, 500.0000, 500.0000, 500.0000, …\n$ aderencia &lt;fct&gt; SIM, SIM, SIM, SIM, SIM, SIM, SIM, SIM, SIM, SIM, SIM, SIM, …\n\n\n\n\n\n\n\n\n💡 Boa Prática\n\n\n\nMantenha sempre uma cópia do banco original! Facilita comparações e evita perda de dados.\n\n\n\n\n\nVerificar Representatividade\n\n# Tabelas de contingência\nxtabs(~ attsprts + sex, data = db)\n\n        sex\nattsprts Male Female\n     Yes  384    407\n     No   254    444\n\nxtabs(~ attsprts + life, data = db)\n\n        life\nattsprts Dull Routine Exciting\n     Yes   16     226      281\n     No    48     230      190\n\nxtabs(~ attsprts + aderencia, data = db)\n\n        aderencia\nattsprts Não SIM\n     Yes 750  41\n     No    0 698\n\n\n\n\n\n\n\n\nNote\n\n\n\nVerifique se há células vazias ou com poucos casos. Isso pode afetar a estabilidade dos modelos.",
    "crumbs": [
      "Modelos Lineares",
      "Lista 5: Modelos Lineares Generalizados (GzLM)"
    ]
  },
  {
    "objectID": "lista_5.html#parte-a-regressão-logística",
    "href": "lista_5.html#parte-a-regressão-logística",
    "title": "Lista 5: Modelos Lineares Generalizados (GzLM)",
    "section": "🎯 Parte A: Regressão Logística",
    "text": "🎯 Parte A: Regressão Logística\n\n\n\n\n\n\nQuando Usar?\n\n\n\nRegressão Logística é adequada para: - VD binária: Sim/Não, Sucesso/Fracasso - Modelar probabilidade de pertencer a uma categoria - Estimar Odds Ratios (razão de chances)\nExemplo: Praticar esportes (Sim vs Não)\n\n\n\n\nPergunta de Pesquisa\n\n\n\n\n\n\nExercício A\n\n\n\nQual o efeito de sexo, opinião sobre vida, número de filhos, idade, escolaridade e horas de TV sobre a prática de esportes?\n\n\n\n\n\nPreparação: Níveis de Referência\n\n# Verificar níveis atuais\ncat(\"Níveis originais:\\n\")\n\nNíveis originais:\n\nprint(levels(db$attsprts))\n\n[1] \"Yes\" \"No\" \n\nprint(levels(db$sex))\n\n[1] \"Male\"   \"Female\"\n\nprint(levels(db$life))\n\n[1] \"Dull\"     \"Routine\"  \"Exciting\"\n\n# Ajustar referência para \"No\" (não pratica)\ndb$attsprts &lt;- relevel(db$attsprts, ref = \"No\")\n\ncat(\"\\nNovo nível de referência:\\n\")\n\n\nNovo nível de referência:\n\nprint(levels(db$attsprts))\n\n[1] \"No\"  \"Yes\"\n\n\n\n\n\n\n\n\nPor que isso importa?\n\n\n\nCom “No” como referência, OR &gt; 1 indica maior chance de praticar esportes.\n\n\n\n\n\nAjuste do Modelo\n\nmodelo_logistico &lt;- glm(\n  attsprts ~ sex + life + childs + educ + tvhours + age,\n  data = db,\n  family = \"binomial\"\n)\n\n\n\n\n\n\n\n🔍 Anatomia do Modelo Logístico\n\n\n\n\n\nFunção: glm() (Generalized Linear Model)\nFamily: binomial com link logit (padrão) \\[\n\\log\\left(\\frac{p}{1-p}\\right) = \\beta_0 + \\beta_1 X_1 + \\beta_2 X_2 + \\ldots\n\\]\nInterpretação: - Coeficientes: mudança no log-odds - exp(coeficiente): Odds Ratio (OR)\n\n\n\n\n\n\nResultados: Saída Básica\n\nsummary(modelo_logistico)\n\n\nCall:\nglm(formula = attsprts ~ sex + life + childs + educ + tvhours + \n    age, family = \"binomial\", data = db)\n\nCoefficients:\n              Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)  -1.625849   0.560416  -2.901  0.00372 ** \nsexFemale    -0.452288   0.145961  -3.099  0.00194 ** \nlifeRoutine   0.649746   0.333770   1.947  0.05157 .  \nlifeExciting  0.787760   0.336597   2.340  0.01926 *  \nchilds        0.121782   0.049603   2.455  0.01408 *  \neduc          0.200783   0.029138   6.891 5.55e-12 ***\ntvhours      -0.097926   0.039787  -2.461  0.01384 *  \nage          -0.036856   0.004969  -7.417 1.20e-13 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 1352.4  on 977  degrees of freedom\nResidual deviance: 1143.6  on 970  degrees of freedom\n  (522 observations deleted due to missingness)\nAIC: 1159.6\n\nNumber of Fisher Scoring iterations: 4\n\n\n\n\n\n\n\n\nWarning\n\n\n\nCoeficientes estão em log-odds. Precisamos exponenciar para obter ORs interpretáveis!\n\n\n\n\n\nResultados: Tabela Formatada\n\ntab_model(\n  modelo_logistico,\n  show.se = TRUE,\n  show.aic = TRUE,\n  show.loglik = TRUE,\n  show.ci = TRUE,\n  transform = \"exp\",\n  title = \"Regressão Logística: Prática de Esportes\"\n)\n\n\nRegressão Logística: Prática de Esportes\n\n\n \nattsprts\n\n\nPredictors\nOdds Ratios\nstd. Error\nCI\np\n\n\n(Intercept)\n0.20\n0.11\n0.00 – Inf\n0.004\n\n\nsex [Female]\n0.64\n0.09\n0.00 – Inf\n0.002\n\n\nlife [Routine]\n1.92\n0.64\n0.00 – Inf\n0.052\n\n\nlife [Exciting]\n2.20\n0.74\n0.00 – Inf\n0.019\n\n\nchilds\n1.13\n0.06\n0.00 – Inf\n0.014\n\n\neduc\n1.22\n0.04\n0.00 – Inf\n&lt;0.001\n\n\ntvhours\n0.91\n0.04\n0.00 – Inf\n0.014\n\n\nage\n0.96\n0.00\n0.00 – Inf\n&lt;0.001\n\n\nObservations\n978\n\n\nR2 Tjur\n0.194\n\n\nAIC\n1159.552\n\n\nlog-Likelihood\n-571.776\n\n\n\n\n\n\n\n\n\n\n\n\n\n📊 Interpretando Odds Ratios\n\n\n\nOR = 1: Nenhum efeito\nOR &gt; 1: Aumenta chance de praticar esportes\nOR &lt; 1: Diminui chance de praticar esportes\nExemplo: OR = 1.50 → 50% mais chance\n\n\n\n\n\nResultados: Função summary()\n\nsummary(modelo_logistico)\n\n\nCall:\nglm(formula = attsprts ~ sex + life + childs + educ + tvhours + \n    age, family = \"binomial\", data = db)\n\nCoefficients:\n              Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)  -1.625849   0.560416  -2.901  0.00372 ** \nsexFemale    -0.452288   0.145961  -3.099  0.00194 ** \nlifeRoutine   0.649746   0.333770   1.947  0.05157 .  \nlifeExciting  0.787760   0.336597   2.340  0.01926 *  \nchilds        0.121782   0.049603   2.455  0.01408 *  \neduc          0.200783   0.029138   6.891 5.55e-12 ***\ntvhours      -0.097926   0.039787  -2.461  0.01384 *  \nage          -0.036856   0.004969  -7.417 1.20e-13 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 1352.4  on 977  degrees of freedom\nResidual deviance: 1143.6  on 970  degrees of freedom\n  (522 observations deleted due to missingness)\nAIC: 1159.6\n\nNumber of Fisher Scoring iterations: 4\n\n\n\n\n\n\n\n\n🔍 Interpretando a Tabela\n\n\n\n\n\nColunas importantes: - OR: Odds Ratio direta - inverse.OR: OR com referência invertida - p.value: Significância estatística\nUso do inverse.OR: Quando OR &lt; 1, use inverse.OR para facilitar interpretação.\nExemplo com sexo: - OR = 0.636 (Female vs Male) - inverse.OR = 1.57 (Male vs Female)\nInterpretação (usando inverse.OR): “Mulheres têm 1.57× mais chance de praticar esportes que homens”\n\n\n\n\n\n\nMudando Referência: Demonstração\n\n# Mudar referência de sexo\ndb$sex &lt;- relevel(db$sex, ref = \"Female\")\n\n# Re-ajustar modelo\nmodelo_logistico_v2 &lt;- glm(\n  attsprts ~ sex + life + childs + educ + tvhours + age,\n  data = db,\n  family = \"binomial\"\n)\nsummary(modelo_logistico_v2)\n\n\nCall:\nglm(formula = attsprts ~ sex + life + childs + educ + tvhours + \n    age, family = \"binomial\", data = db)\n\nCoefficients:\n              Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)  -2.078137   0.564641  -3.680 0.000233 ***\nsexMale       0.452288   0.145961   3.099 0.001944 ** \nlifeRoutine   0.649746   0.333770   1.947 0.051572 .  \nlifeExciting  0.787760   0.336597   2.340 0.019265 *  \nchilds        0.121782   0.049603   2.455 0.014082 *  \neduc          0.200783   0.029138   6.891 5.55e-12 ***\ntvhours      -0.097926   0.039787  -2.461 0.013844 *  \nage          -0.036856   0.004969  -7.417 1.20e-13 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 1352.4  on 977  degrees of freedom\nResidual deviance: 1143.6  on 970  degrees of freedom\n  (522 observations deleted due to missingness)\nAIC: 1159.6\n\nNumber of Fisher Scoring iterations: 4\n\n\n\n\n\n\n\n\nNote\n\n\n\nNote que OR do Modelo 2 = inverse.OR do Modelo 1! A escolha da referência afeta apenas a direção da comparação, não o resultado estatístico.",
    "crumbs": [
      "Modelos Lineares",
      "Lista 5: Modelos Lineares Generalizados (GzLM)"
    ]
  },
  {
    "objectID": "lista_5.html#parte-d-regressão-de-poisson",
    "href": "lista_5.html#parte-d-regressão-de-poisson",
    "title": "Lista 5: Modelos Lineares Generalizados (GzLM)",
    "section": "🎯 Parte D: Regressão de Poisson",
    "text": "🎯 Parte D: Regressão de Poisson\n\n\n\n\n\n\nQuando Usar?\n\n\n\nRegressão de Poisson é adequada para: - VD de contagem: 0, 1, 2, 3, … - Eventos raros - Estimar Razões de Prevalência (RP) ou Taxas\nExemplo: Número de filhos\n\n\n\n\nPergunta de Pesquisa\n\n\n\n\n\n\nExercício D\n\n\n\nQual o efeito de sexo, opinião sobre vida e prática de esportes sobre número de filhos, controlando por idade e escolaridade?\n\n\n\n\n\nModelo 1: GLM Normal (Baseline)\n\nmodelo_glm_normal &lt;- glm(\n  childs ~ sex + life + attsprts + age + educ,\n  data = db,\n  family = \"gaussian\"  # Assume normalidade\n)\n\nsummary(modelo_glm_normal)\n\n\nCall:\nglm(formula = childs ~ sex + life + attsprts + age + educ, family = \"gaussian\", \n    data = db)\n\nCoefficients:\n              Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)   2.872623   0.292672   9.815  &lt; 2e-16 ***\nsexMale      -0.186317   0.098990  -1.882   0.0601 .  \nlifeRoutine  -0.346761   0.206683  -1.678   0.0937 .  \nlifeExciting -0.209890   0.210422  -0.997   0.3188    \nattsprtsYes   0.258686   0.107586   2.404   0.0164 *  \nage           0.038723   0.002994  12.934  &lt; 2e-16 ***\neduc         -0.082284   0.017801  -4.623  4.3e-06 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for gaussian family taken to be 2.322978)\n\n    Null deviance: 2839.0  on 983  degrees of freedom\nResidual deviance: 2269.5  on 977  degrees of freedom\n  (516 observations deleted due to missingness)\nAIC: 3630.8\n\nNumber of Fisher Scoring iterations: 2\n\n\n\n\n\nModelo 2: GLM Poisson\n\nmodelo_poisson &lt;- glm(\n  childs ~ sex + life + attsprts + age + educ,\n  data = db,\n  family = \"poisson\"\n)\n\nsummary(modelo_poisson)\n\n\nCall:\nglm(formula = childs ~ sex + life + attsprts + age + educ, family = \"poisson\", \n    data = db)\n\nCoefficients:\n              Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)   0.988656   0.110271   8.966  &lt; 2e-16 ***\nsexMale      -0.067072   0.039024  -1.719   0.0857 .  \nlifeRoutine  -0.102725   0.074303  -1.383   0.1668    \nlifeExciting -0.052165   0.075989  -0.686   0.4924    \nattsprtsYes   0.095588   0.042782   2.234   0.0255 *  \nage           0.013111   0.001144  11.462  &lt; 2e-16 ***\neduc         -0.026711   0.006805  -3.925 8.67e-05 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for poisson family taken to be 1)\n\n    Null deviance: 951.59  on 983  degrees of freedom\nResidual deviance: 757.85  on 977  degrees of freedom\n  (516 observations deleted due to missingness)\nAIC: 3498.8\n\nNumber of Fisher Scoring iterations: 4\n\n\n\n\n\nComparação de Modelos\n\n# Critérios de informação\ncriterios &lt;- data.frame(\n  Modelo = c(\"Normal\", \"Poisson\"),\n  AIC = c(AIC(modelo_glm_normal), AIC(modelo_poisson)),\n  BIC = c(BIC(modelo_glm_normal), BIC(modelo_poisson))\n)\n\ncriterios$AIC &lt;- round(criterios$AIC, 2)\ncriterios$BIC &lt;- round(criterios$BIC, 2)\n\n# Marcar melhor\ncriterios$AIC &lt;- ifelse(\n  criterios$AIC == min(criterios$AIC),\n  paste0(criterios$AIC, \" ★\"),\n  criterios$AIC\n)\n\ncriterios$BIC &lt;- ifelse(\n  criterios$BIC == min(criterios$BIC),\n  paste0(criterios$BIC, \" ★\"),\n  criterios$BIC\n)\n\nknitr::kable(criterios, caption = \"Comparação: Normal vs Poisson\")\n\n\nComparação: Normal vs Poisson\n\n\nModelo\nAIC\nBIC\n\n\n\n\nNormal\n3630.81\n3669.94\n\n\nPoisson\n3498.78 ★\n3533.02 ★\n\n\n\n\n\n\n\n\n\n\n\n📊 Resultado\n\n\n\nModelo Poisson apresenta melhor ajuste (menor AIC/BIC).\n\n\n\n\n\nInterpretação: Razões de Prevalência\n\n# Usando estimates()\nest_poisson &lt;- summary(modelo_poisson)\nprint(est_poisson)\n\n\nCall:\nglm(formula = childs ~ sex + life + attsprts + age + educ, family = \"poisson\", \n    data = db)\n\nCoefficients:\n              Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)   0.988656   0.110271   8.966  &lt; 2e-16 ***\nsexMale      -0.067072   0.039024  -1.719   0.0857 .  \nlifeRoutine  -0.102725   0.074303  -1.383   0.1668    \nlifeExciting -0.052165   0.075989  -0.686   0.4924    \nattsprtsYes   0.095588   0.042782   2.234   0.0255 *  \nage           0.013111   0.001144  11.462  &lt; 2e-16 ***\neduc         -0.026711   0.006805  -3.925 8.67e-05 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for poisson family taken to be 1)\n\n    Null deviance: 951.59  on 983  degrees of freedom\nResidual deviance: 757.85  on 977  degrees of freedom\n  (516 observations deleted due to missingness)\nAIC: 3498.8\n\nNumber of Fisher Scoring iterations: 4\n\n\n\n\n\n\n\n\n📊 Interpretando Razões de Prevalência\n\n\n\nmultiplicative.coef = exp(β) = Razão de Prevalência (RP)\nRP = 1: Nenhum efeito\nRP &gt; 1: Aumenta contagem esperada\nRP &lt; 1: Diminui contagem esperada\nExemplo: - RP = 1.10 → 10% mais filhos esperados - RP = 0.97 → 3% menos filhos esperados\n\n\n\n\n\nExemplo de Interpretação\n\n# Extrair coeficientes exponenciados\nrp_table &lt;- data.frame(\n  Variavel = names(coef(modelo_poisson)),\n  RP = round(exp(coef(modelo_poisson)), 3),\n  RP_Inversa = round(exp(-coef(modelo_poisson)), 3)\n)\n\nknitr::kable(\n  rp_table[c(\"attsprtsYes\", \"educ\"), ],\n  caption = \"Razões de Prevalência Selecionadas\"\n)\n\n\nRazões de Prevalência Selecionadas\n\n\n\nVariavel\nRP\nRP_Inversa\n\n\n\n\nattsprtsYes\nattsprtsYes\n1.100\n0.909\n\n\neduc\neduc\n0.974\n1.027\n\n\n\n\n\nInterpretações:\nPrática de Esportes (attsprtsYes): “Pessoas que praticam esportes têm 10% mais chance de ter um filho adicional comparado a sedentários”\nEducação (educ): “Para cada ano adicional de educação, a chance de ter um filho diminui ~3%”",
    "crumbs": [
      "Modelos Lineares",
      "Lista 5: Modelos Lineares Generalizados (GzLM)"
    ]
  },
  {
    "objectID": "lista_5.html#diagnósticos-e-pressupostos",
    "href": "lista_5.html#diagnósticos-e-pressupostos",
    "title": "Lista 5: Modelos Lineares Generalizados (GzLM)",
    "section": "🔧 Diagnósticos e Pressupostos",
    "text": "🔧 Diagnósticos e Pressupostos\n\nSobredispersão em Poisson\n\n\n\n\n\n\n⚠️ Sobredispersão\n\n\n\nProblema: Variância &gt; Média (viola pressuposto de Poisson)\nConsequência: Erros-padrão subestimados, p-valores muito otimistas\nSolução: Usar Binomial Negativa ou correção quasi-Poisson\n\n\n\n# Teste formal de sobredispersão\ndispersiontest(modelo_poisson, trafo = 1)\n\n\n    Overdispersion test\n\ndata:  modelo_poisson\nz = -5.1887, p-value = 1\nalternative hypothesis: true alpha is greater than 0\nsample estimates:\n     alpha \n-0.2078915 \n\n\n\n\n\n\n\n\nInterpretação\n\n\n\nH₀: Não há sobredispersão\np &lt; 0.05: Sobredispersão detectada → Considerar Binomial Negativa\n\n\n\n\n\nGráficos Diagnósticos\n\npar(mfrow = c(2, 3))\nplot(modelo_poisson, which = 1:6)\n\n\n\n\n\n\n\npar(mfrow = c(1, 1))",
    "crumbs": [
      "Modelos Lineares",
      "Lista 5: Modelos Lineares Generalizados (GzLM)"
    ]
  },
  {
    "objectID": "lista_5.html#extras-avançados",
    "href": "lista_5.html#extras-avançados",
    "title": "Lista 5: Modelos Lineares Generalizados (GzLM)",
    "section": "🔧 Extras Avançados",
    "text": "🔧 Extras Avançados\n\nPseudo R²\n\n\n\n\n\n\nO que é Pseudo R²?\n\n\n\nAnálogo ao R² para modelos logísticos/Poisson. Indica “proporção de verossimilhança explicada”.\nMétodos comuns: - Hosmer-Lemeshow: Baseado em deviance - Cox-Snell: Ajustado pelo tamanho amostral - Nagelkerke: Normalizado para variar 0-1\n\n\n\n# Função personalizada\nlogisticPseudoR2s &lt;- function(LogModel) {\n  dev &lt;- LogModel$deviance\n  nullDev &lt;- LogModel$null.deviance\n  modelN &lt;- length(LogModel$fitted.values)\n  \n  R.l &lt;- 1 - dev / nullDev\n  R.cs &lt;- 1 - exp(-(nullDev - dev) / modelN)\n  R.n &lt;- R.cs / (1 - (exp(-(nullDev / modelN))))\n  \n  data.frame(\n    Metodo = c(\"Hosmer-Lemeshow\", \"Cox-Snell\", \"Nagelkerke\"),\n    Pseudo_R2 = c(round(R.l, 3), round(R.cs, 3), round(R.n, 3))\n  )\n}\n\n# Aplicar ao modelo logístico\nlogisticPseudoR2s(modelo_logistico)\n\n           Metodo Pseudo_R2\n1 Hosmer-Lemeshow     0.154\n2       Cox-Snell     0.192\n3      Nagelkerke     0.257\n\n\n\n\n\nCorreção de Bonferroni\n\n\n\n\n\n\nQuando Usar Correções?\n\n\n\n\n\nProblema: Múltiplas comparações inflam erro Tipo I\nCorreções disponíveis: - Bonferroni: Mais conservadora (divide α por nº de testes) - Holm: Menos conservadora, sequencial - Hochberg: Similar a Holm - FDR (Benjamini-Hochberg): Controla taxa de falsas descobertas\nTrade-off: Proteção contra falsos positivos ↔︎ Poder estatístico\n\n\n\n\ntab_model(\n  modelo_logistico,\n  show.se = TRUE,\n  show.ci = TRUE,\n  transform = \"exp\",\n  p.adjust = \"bonferroni\",\n  title = \"Regressão Logística com Correção de Bonferroni\"\n)\n\n\nRegressão Logística com Correção de Bonferroni\n\n\n \nattsprts\n\n\nPredictors\nOdds Ratios\nstd. Error\nCI\np\n\n\n(Intercept)\n0.20\n0.11\n0.00 – Inf\n0.030\n\n\nsex [Female]\n0.64\n0.09\n0.00 – Inf\n0.016\n\n\nlife [Routine]\n1.92\n0.64\n0.00 – Inf\n0.413\n\n\nlife [Exciting]\n2.20\n0.74\n0.00 – Inf\n0.154\n\n\nchilds\n1.13\n0.06\n0.00 – Inf\n0.113\n\n\neduc\n1.22\n0.04\n0.00 – Inf\n&lt;0.001\n\n\ntvhours\n0.91\n0.04\n0.00 – Inf\n0.111\n\n\nage\n0.96\n0.00\n0.00 – Inf\n&lt;0.001\n\n\nObservations\n978\n\n\nR2 Tjur\n0.194\n\n\n\n\n\n\n\n\n\n\nTabela de Resultados Completa\n\n# Extrair tudo em uma tabela\nresultados_completos &lt;- tidy(\n  modelo_logistico,\n  exponentiate = TRUE,\n  conf.int = TRUE\n)\n\nknitr::kable(\n  resultados_completos,\n  digits = 3,\n  caption = \"Resultados Completos: Regressão Logística\"\n)\n\n\nResultados Completos: Regressão Logística\n\n\n\n\n\n\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\nconf.low\nconf.high\n\n\n\n\n(Intercept)\n0.197\n0.560\n-2.901\n0.004\n0.065\n0.583\n\n\nsexFemale\n0.636\n0.146\n-3.099\n0.002\n0.477\n0.846\n\n\nlifeRoutine\n1.915\n0.334\n1.947\n0.052\n1.010\n3.765\n\n\nlifeExciting\n2.198\n0.337\n2.340\n0.019\n1.153\n4.343\n\n\nchilds\n1.130\n0.050\n2.455\n0.014\n1.025\n1.246\n\n\neduc\n1.222\n0.029\n6.891\n0.000\n1.156\n1.296\n\n\ntvhours\n0.907\n0.040\n-2.461\n0.014\n0.838\n0.980\n\n\nage\n0.964\n0.005\n-7.417\n0.000\n0.954\n0.973\n\n\n\n\n\n\n\n\nModelo com Interações\n\nmodelo_interacao &lt;- glm(\n  childs ~ sex * life * attsprts + age + educ,\n  data = db,\n  family = \"poisson\"\n)\n\n# Tabela formatada\ntab_model(\n  modelo_interacao,\n  show.se = TRUE,\n  show.ci = TRUE,\n  title = \"Modelo Poisson com Interações\"\n)\n\n\nModelo Poisson com Interações\n\n\n\n\n\n\n\n\n\n \nchilds\n\n\nPredictors\nIncidence Rate Ratios\nstd. Error\nCI\np\n\n\n(Intercept)\n2.67\n0.33\n0.00 – Inf\n&lt;0.001\n\n\nsex [Male]\n0.87\n0.15\n0.00 – Inf\n0.404\n\n\nlife [Routine]\n0.91\n0.09\n0.00 – Inf\n0.357\n\n\nlife [Exciting]\n0.93\n0.10\n0.00 – Inf\n0.521\n\n\nattsprts [Yes]\n1.19\n0.23\n0.00 – Inf\n0.357\n\n\nage\n1.01\n0.00\n0.00 – Inf\n&lt;0.001\n\n\neduc\n0.97\n0.01\n0.00 – Inf\n&lt;0.001\n\n\nsex [Male] × life\n[Routine]\n1.12\n0.21\n0.00 – Inf\n0.547\n\n\nsex [Male] × life\n[Exciting]\n1.03\n0.20\n0.00 – Inf\n0.862\n\n\nsex [Male] × attsprts\n[Yes]\n1.03\n0.36\n0.00 – Inf\n0.937\n\n\nlife [Routine] × attsprts\n[Yes]\n0.91\n0.19\n0.00 – Inf\n0.648\n\n\nlife [Exciting] ×\nattsprts [Yes]\n0.93\n0.19\n0.00 – Inf\n0.713\n\n\n(sex [Male] × life\n[Routine]) × attsprts\n[Yes]\n0.88\n0.32\n0.00 – Inf\n0.730\n\n\n(sex [Male] × life\n[Exciting]) × attsprts\n[Yes]\n1.07\n0.39\n0.00 – Inf\n0.860\n\n\nObservations\n984\n\n\nR2 Nagelkerke\n0.293\n\n\n\n\n\n\n\n\n\n\n\n\n\n💡 Pratique!\n\n\n\nCrie modelos com diferentes interações e compare AICs. Qual combinação explica melhor os dados?",
    "crumbs": [
      "Modelos Lineares",
      "Lista 5: Modelos Lineares Generalizados (GzLM)"
    ]
  },
  {
    "objectID": "lista_5.html#material-complementar",
    "href": "lista_5.html#material-complementar",
    "title": "Lista 5: Modelos Lineares Generalizados (GzLM)",
    "section": "📚 Material Complementar",
    "text": "📚 Material Complementar\n\nAula em Vídeo (SPSS)\n\n\n\n\nRecursos Adicionais\n\n\n\n\n\n\n📖 Leituras Recomendadas\n\n\n\n\n\nRegressão Logística: - Hosmer & Lemeshow (2013). Applied Logistic Regression - UCLA Stats Guide - Logistic Regression\nRegressão de Poisson: - Bookdown: Poisson Regression - Agresti (2015). Foundations of Linear and Generalized Linear Models\nVídeos: - StatQuest: Logistic Regression\n\n\n\n\n\n\nDecisão: Poisson vs Binomial Negativa\n\n\n\n\n\n\nGuia Rápido\n\n\n\n\n\n\nSituação\nModelo Recomendado\n\n\n\n\nVariância ≈ Média\nPoisson\n\n\nVariância &gt;&gt; Média\nBinomial Negativa\n\n\nMuitos zeros\nZero-Inflated Poisson/NB\n\n\nEventos raros\nPoisson\n\n\n\nTestar sobredispersão: Use dispersiontest() ou compare AIC de Poisson vs NB",
    "crumbs": [
      "Modelos Lineares",
      "Lista 5: Modelos Lineares Generalizados (GzLM)"
    ]
  },
  {
    "objectID": "lista_5.html#informações-de-sessão",
    "href": "lista_5.html#informações-de-sessão",
    "title": "Lista 5: Modelos Lineares Generalizados (GzLM)",
    "section": "🔧 Informações de Sessão",
    "text": "🔧 Informações de Sessão\n\nreport(sessionInfo())\n\nAnalyses were conducted using the R Statistical language (version 4.4.2; R Core\nTeam, 2024) on Windows 11 x64 (build 26100), using the packages lme4 (version\n1.1.37; Bates D et al., 2015), Matrix (version 1.7.1; Bates D et al., 2024),\neffectsize (version 1.0.1; Ben-Shachar MS et al., 2020), fitdistrplus (version\n1.2.2; Delignette-Muller ML, Dutang C, 2015), flexplot (version 0.24.3; Fife,\nD, 2022), effects (version 4.2.4; Fox J, Weisberg S, 2019), car (version 3.1.3;\nFox J, Weisberg S, 2019), carData (version 3.0.5; Fox J et al., 2022), mvtnorm\n(version 1.3.3; Genz A, Bretz F, 2009), lubridate (version 1.9.4; Grolemund G,\nWickham H, 2011), TH.data (version 1.1.3; Hothorn T, 2025), multcomp (version\n1.4.28; Hothorn T et al., 2008), AER (version 1.2.15; Kleiber C, Zeileis A,\n2008), emmeans (version 1.11.0; Lenth R, 2025), sjPlot (version 2.9.0; Lüdecke\nD, 2025), sjstats (version 0.19.1; Lüdecke D, 2025), parameters (version\n0.28.3; Lüdecke D et al., 2020), performance (version 0.15.2; Lüdecke D et al.,\n2021), easystats (version 0.7.5; Lüdecke D et al., 2022), see (version 0.12.0;\nLüdecke D et al., 2021), insight (version 1.4.4; Lüdecke D et al., 2019),\nbayestestR (version 0.17.0; Makowski D et al., 2019), modelbased (version\n0.13.1; Makowski D et al., 2025), report (version 0.6.3; Makowski D et al.,\n2023), correlation (version 0.8.8; Makowski D et al., 2022), tibble (version\n3.3.1; Müller K, Wickham H, 2026), datawizard (version 1.3.0; Patil I et al.,\n2022), nlme (version 3.1.166; Pinheiro J et al., 2024), foreign (version\n0.8.87; R Core Team, 2024), broom (version 1.0.7; Robinson D et al., 2024),\ngtsummary (version 2.1.0; Sjoberg D et al., 2021), survival (version 3.7.0;\nTherneau T, 2024), MASS (version 7.3.61; Venables WN, Ripley BD, 2002), ggplot2\n(version 4.0.1; Wickham H, 2016), forcats (version 1.0.0; Wickham H, 2023),\nstringr (version 1.5.1; Wickham H, 2023), tidyverse (version 2.0.0; Wickham H\net al., 2019), dplyr (version 1.1.4; Wickham H et al., 2023), purrr (version\n1.0.4; Wickham H, Henry L, 2025), readr (version 2.1.5; Wickham H et al.,\n2024), tidyr (version 1.3.1; Wickham H et al., 2024), zoo (version 1.8.14;\nZeileis A, Grothendieck G, 2005), lmtest (version 0.9.40; Zeileis A, Hothorn T,\n2002), sandwich (version 3.1.1; Zeileis A et al., 2020) and kableExtra (version\n1.4.0; Zhu H, 2024).\n\nReferences\n----------\n  - Bates D, Mächler M, Bolker B, Walker S (2015). \"Fitting Linear Mixed-Effects\nModels Using lme4.\" _Journal of Statistical Software_, *67*(1), 1-48.\ndoi:10.18637/jss.v067.i01 &lt;https://doi.org/10.18637/jss.v067.i01&gt;.\n  - Bates D, Maechler M, Jagan M (2024). _Matrix: Sparse and Dense Matrix Classes\nand Methods_. R package version 1.7-1,\n&lt;https://CRAN.R-project.org/package=Matrix&gt;.\n  - Ben-Shachar MS, Lüdecke D, Makowski D (2020). \"effectsize: Estimation of\nEffect Size Indices and Standardized Parameters.\" _Journal of Open Source\nSoftware_, *5*(56), 2815. doi:10.21105/joss.02815\n&lt;https://doi.org/10.21105/joss.02815&gt;, &lt;https://doi.org/10.21105/joss.02815&gt;.\n  - Delignette-Muller ML, Dutang C (2015). \"fitdistrplus: An R Package for\nFitting Distributions.\" _Journal of Statistical Software_, *64*(4), 1-34.\ndoi:10.18637/jss.v064.i04 &lt;https://doi.org/10.18637/jss.v064.i04&gt;.\n  - Fife, A. D (2022). \"Flexplot: Graphically-based data analysis.\"\n_Psychological Methods_, *27*(4), -19. &lt;doi.org/10.1037/met0000424&gt;.\n  - Fox J, Weisberg S (2019). _An R Companion to Applied Regression_, 3rd\nedition. Sage, Thousand Oaks CA.\n&lt;https://www.john-fox.ca/Companion/index.html&gt;. Fox J, Weisberg S (2018).\n\"Visualizing Fit and Lack of Fit in Complex Regression Models with Predictor\nEffect Plots and Partial Residuals.\" _Journal of Statistical Software_,\n*87*(9), 1-27. doi:10.18637/jss.v087.i09\n&lt;https://doi.org/10.18637/jss.v087.i09&gt;. Fox J (2003). \"Effect Displays in R\nfor Generalised Linear Models.\" _Journal of Statistical Software_, *8*(15),\n1-27. doi:10.18637/jss.v008.i15 &lt;https://doi.org/10.18637/jss.v008.i15&gt;. Fox J,\nHong J (2009). \"Effect Displays in R for Multinomial and Proportional-Odds\nLogit Models: Extensions to the effects Package.\" _Journal of Statistical\nSoftware_, *32*(1), 1-24. doi:10.18637/jss.v032.i01\n&lt;https://doi.org/10.18637/jss.v032.i01&gt;.\n  - Fox J, Weisberg S (2019). _An R Companion to Applied Regression_, Third\nedition. Sage, Thousand Oaks CA. &lt;https://www.john-fox.ca/Companion/&gt;.\n  - Fox J, Weisberg S, Price B (2022). _carData: Companion to Applied Regression\nData Sets_. R package version 3.0-5,\n&lt;https://CRAN.R-project.org/package=carData&gt;.\n  - Genz A, Bretz F (2009). _Computation of Multivariate Normal and t\nProbabilities_, series Lecture Notes in Statistics. Springer-Verlag,\nHeidelberg. ISBN 978-3-642-01688-2.\n  - Grolemund G, Wickham H (2011). \"Dates and Times Made Easy with lubridate.\"\n_Journal of Statistical Software_, *40*(3), 1-25.\n&lt;https://www.jstatsoft.org/v40/i03/&gt;.\n  - Hothorn T (2025). _TH.data: TH's Data Archive_. R package version 1.1-3,\n&lt;https://CRAN.R-project.org/package=TH.data&gt;.\n  - Hothorn T, Bretz F, Westfall P (2008). \"Simultaneous Inference in General\nParametric Models.\" _Biometrical Journal_, *50*(3), 346-363.\n  - Kleiber C, Zeileis A (2008). _Applied Econometrics with R_. Springer-Verlag,\nNew York. doi:10.1007/978-0-387-77318-6\n&lt;https://doi.org/10.1007/978-0-387-77318-6&gt;,\n&lt;https://CRAN.R-project.org/package=AER&gt;.\n  - Lenth R (2025). _emmeans: Estimated Marginal Means, aka Least-Squares Means_.\nR package version 1.11.0, &lt;https://CRAN.R-project.org/package=emmeans&gt;.\n  - Lüdecke D (2025). _sjPlot: Data Visualization for Statistics in Social\nScience_. R package version 2.9.0, &lt;https://CRAN.R-project.org/package=sjPlot&gt;.\n  - Lüdecke D (2025). _sjstats: Statistical Functions for Regression Models\n(Version 0.19.1)_. doi:10.5281/zenodo.1284472\n&lt;https://doi.org/10.5281/zenodo.1284472&gt;,\n&lt;https://CRAN.R-project.org/package=sjstats&gt;.\n  - Lüdecke D, Ben-Shachar M, Patil I, Makowski D (2020). \"Extracting, Computing\nand Exploring the Parameters of Statistical Models using R.\" _Journal of Open\nSource Software_, *5*(53), 2445. doi:10.21105/joss.02445\n&lt;https://doi.org/10.21105/joss.02445&gt;.\n  - Lüdecke D, Ben-Shachar M, Patil I, Waggoner P, Makowski D (2021).\n\"performance: An R Package for Assessment, Comparison and Testing of\nStatistical Models.\" _Journal of Open Source Software_, *6*(60), 3139.\ndoi:10.21105/joss.03139 &lt;https://doi.org/10.21105/joss.03139&gt;.\n  - Lüdecke D, Ben-Shachar M, Patil I, Wiernik B, Bacher E, Thériault R, Makowski\nD (2022). \"easystats: Framework for Easy Statistical Modeling, Visualization,\nand Reporting.\" _CRAN_. doi:10.32614/CRAN.package.easystats\n&lt;https://doi.org/10.32614/CRAN.package.easystats&gt;, R package,\n&lt;https://easystats.github.io/easystats/&gt;.\n  - Lüdecke D, Patil I, Ben-Shachar M, Wiernik B, Waggoner P, Makowski D (2021).\n\"see: An R Package for Visualizing Statistical Models.\" _Journal of Open Source\nSoftware_, *6*(64), 3393. doi:10.21105/joss.03393\n&lt;https://doi.org/10.21105/joss.03393&gt;.\n  - Lüdecke D, Waggoner P, Makowski D (2019). \"insight: A Unified Interface to\nAccess Information from Model Objects in R.\" _Journal of Open Source Software_,\n*4*(38), 1412. doi:10.21105/joss.01412 &lt;https://doi.org/10.21105/joss.01412&gt;.\n  - Makowski D, Ben-Shachar M, Lüdecke D (2019). \"bayestestR: Describing Effects\nand their Uncertainty, Existence and Significance within the Bayesian\nFramework.\" _Journal of Open Source Software_, *4*(40), 1541.\ndoi:10.21105/joss.01541 &lt;https://doi.org/10.21105/joss.01541&gt;,\n&lt;https://joss.theoj.org/papers/10.21105/joss.01541&gt;.\n  - Makowski D, Ben-Shachar M, Wiernik B, Patil I, Thériault R, Lüdecke D (2025).\n\"modelbased: An R package to make the most out of your statistical models\nthrough marginal means, marginal effects, and model predictions.\" _Journal of\nOpen Source Software_, *10*(109), 7969. doi:10.21105/joss.07969\n&lt;https://doi.org/10.21105/joss.07969&gt;,\n&lt;https://joss.theoj.org/papers/10.21105/joss.07969&gt;.\n  - Makowski D, Lüdecke D, Patil I, Thériault R, Ben-Shachar M, Wiernik B (2023).\n\"Automated Results Reporting as a Practical Tool to Improve Reproducibility and\nMethodological Best Practices Adoption.\" _CRAN_.\ndoi:10.32614/CRAN.package.report\n&lt;https://doi.org/10.32614/CRAN.package.report&gt;,\n&lt;https://easystats.github.io/report/&gt;.\n  - Makowski D, Wiernik B, Patil I, Lüdecke D, Ben-Shachar M (2022).\n\"correlation: Methods for Correlation Analysis.\" Version 0.8.3,\n&lt;https://CRAN.R-project.org/package=correlation&gt;. Makowski D, Ben-Shachar M,\nPatil I, Lüdecke D (2020). \"Methods and Algorithms for Correlation Analysis in\nR.\" _Journal of Open Source Software_, *5*(51), 2306. doi:10.21105/joss.02306\n&lt;https://doi.org/10.21105/joss.02306&gt;,\n&lt;https://joss.theoj.org/papers/10.21105/joss.02306&gt;.\n  - Müller K, Wickham H (2026). _tibble: Simple Data Frames_. R package version\n3.3.1, &lt;https://CRAN.R-project.org/package=tibble&gt;.\n  - Patil I, Makowski D, Ben-Shachar M, Wiernik B, Bacher E, Lüdecke D (2022).\n\"datawizard: An R Package for Easy Data Preparation and Statistical\nTransformations.\" _Journal of Open Source Software_, *7*(78), 4684.\ndoi:10.21105/joss.04684 &lt;https://doi.org/10.21105/joss.04684&gt;.\n  - Pinheiro J, Bates D, R Core Team (2024). _nlme: Linear and Nonlinear Mixed\nEffects Models_. R package version 3.1-166,\n&lt;https://CRAN.R-project.org/package=nlme&gt;. Pinheiro JC, Bates DM (2000).\n_Mixed-Effects Models in S and S-PLUS_. Springer, New York. doi:10.1007/b98882\n&lt;https://doi.org/10.1007/b98882&gt;.\n  - R Core Team (2024). _foreign: Read Data Stored by 'Minitab', 'S', 'SAS',\n'SPSS', 'Stata', 'Systat', 'Weka', 'dBase', ..._. R package version 0.8-87,\n&lt;https://CRAN.R-project.org/package=foreign&gt;.\n  - R Core Team (2024). _R: A Language and Environment for Statistical\nComputing_. R Foundation for Statistical Computing, Vienna, Austria.\n&lt;https://www.R-project.org/&gt;.\n  - Robinson D, Hayes A, Couch S (2024). _broom: Convert Statistical Objects into\nTidy Tibbles_. R package version 1.0.7,\n&lt;https://CRAN.R-project.org/package=broom&gt;.\n  - Sjoberg D, Whiting K, Curry M, Lavery J, Larmarange J (2021). \"Reproducible\nSummary Tables with the gtsummary Package.\" _The R Journal_, *13*, 570-580.\ndoi:10.32614/RJ-2021-053 &lt;https://doi.org/10.32614/RJ-2021-053&gt;,\n&lt;https://doi.org/10.32614/RJ-2021-053&gt;.\n  - Therneau T (2024). _A Package for Survival Analysis in R_. R package version\n3.7-0, &lt;https://CRAN.R-project.org/package=survival&gt;. Terry M. Therneau,\nPatricia M. Grambsch (2000). _Modeling Survival Data: Extending the Cox Model_.\nSpringer, New York. ISBN 0-387-98784-3.\n  - Venables WN, Ripley BD (2002). _Modern Applied Statistics with S_, Fourth\nedition. Springer, New York. ISBN 0-387-95457-0,\n&lt;https://www.stats.ox.ac.uk/pub/MASS4/&gt;.\n  - Wickham H (2016). _ggplot2: Elegant Graphics for Data Analysis_.\nSpringer-Verlag New York. ISBN 978-3-319-24277-4,\n&lt;https://ggplot2.tidyverse.org&gt;.\n  - Wickham H (2023). _forcats: Tools for Working with Categorical Variables\n(Factors)_. R package version 1.0.0,\n&lt;https://CRAN.R-project.org/package=forcats&gt;.\n  - Wickham H (2023). _stringr: Simple, Consistent Wrappers for Common String\nOperations_. R package version 1.5.1,\n&lt;https://CRAN.R-project.org/package=stringr&gt;.\n  - Wickham H, Averick M, Bryan J, Chang W, McGowan LD, François R, Grolemund G,\nHayes A, Henry L, Hester J, Kuhn M, Pedersen TL, Miller E, Bache SM, Müller K,\nOoms J, Robinson D, Seidel DP, Spinu V, Takahashi K, Vaughan D, Wilke C, Woo K,\nYutani H (2019). \"Welcome to the tidyverse.\" _Journal of Open Source Software_,\n*4*(43), 1686. doi:10.21105/joss.01686 &lt;https://doi.org/10.21105/joss.01686&gt;.\n  - Wickham H, François R, Henry L, Müller K, Vaughan D (2023). _dplyr: A Grammar\nof Data Manipulation_. R package version 1.1.4,\n&lt;https://CRAN.R-project.org/package=dplyr&gt;.\n  - Wickham H, Henry L (2025). _purrr: Functional Programming Tools_. R package\nversion 1.0.4, &lt;https://CRAN.R-project.org/package=purrr&gt;.\n  - Wickham H, Hester J, Bryan J (2024). _readr: Read Rectangular Text Data_. R\npackage version 2.1.5, &lt;https://CRAN.R-project.org/package=readr&gt;.\n  - Wickham H, Vaughan D, Girlich M (2024). _tidyr: Tidy Messy Data_. R package\nversion 1.3.1, &lt;https://CRAN.R-project.org/package=tidyr&gt;.\n  - Zeileis A, Grothendieck G (2005). \"zoo: S3 Infrastructure for Regular and\nIrregular Time Series.\" _Journal of Statistical Software_, *14*(6), 1-27.\ndoi:10.18637/jss.v014.i06 &lt;https://doi.org/10.18637/jss.v014.i06&gt;.\n  - Zeileis A, Hothorn T (2002). \"Diagnostic Checking in Regression\nRelationships.\" _R News_, *2*(3), 7-10.\n&lt;https://CRAN.R-project.org/doc/Rnews/&gt;.\n  - Zeileis A, Köll S, Graham N (2020). \"Various Versatile Variances: An\nObject-Oriented Implementation of Clustered Covariances in R.\" _Journal of\nStatistical Software_, *95*(1), 1-36. doi:10.18637/jss.v095.i01\n&lt;https://doi.org/10.18637/jss.v095.i01&gt;. Zeileis A (2004). \"Econometric\nComputing with HC and HAC Covariance Matrix Estimators.\" _Journal of\nStatistical Software_, *11*(10), 1-17. doi:10.18637/jss.v011.i10\n&lt;https://doi.org/10.18637/jss.v011.i10&gt;. Zeileis A (2006). \"Object-Oriented\nComputation of Sandwich Estimators.\" _Journal of Statistical Software_,\n*16*(9), 1-16. doi:10.18637/jss.v016.i09\n&lt;https://doi.org/10.18637/jss.v016.i09&gt;.\n  - Zhu H (2024). _kableExtra: Construct Complex Table with 'kable' and Pipe\nSyntax_. R package version 1.4.0,\n&lt;https://CRAN.R-project.org/package=kableExtra&gt;.\n\n\n\n\n\n\n\n\n\n🎓 Resumo da Lista 5\n\n\n\nNesta lista você:\n✅ Dominou regressão logística para variáveis binárias\n✅ Aprendeu a interpretar Odds Ratios\n✅ Explorou regressão de Poisson para contagens\n✅ Calculou e interpretou Razões de Prevalência\n✅ Comparou modelos via AIC/BIC\n✅ Testou sobredispersão em Poisson\n✅ Aplicou correções para comparações múltiplas\nConceitos-chave: - GzLM estende GLM para distribuições não-normais - Logística: OR interpreta mudanças em chances - Poisson: RP interpreta mudanças em contagens - Sobredispersão: problema comum que requer atenção\nPróximos passos: - Explore interações complexas - Teste modelos Zero-Inflated para excesso de zeros - Pratique interpretação de ORs e RPs - Compare com Binomial Negativa quando apropriado",
    "crumbs": [
      "Modelos Lineares",
      "Lista 5: Modelos Lineares Generalizados (GzLM)"
    ]
  },
  {
    "objectID": "lista_6.html",
    "href": "lista_6.html",
    "title": "Lista 6: Análise de Sobrevida",
    "section": "",
    "text": "📖 Contexto do Estudo",
    "crumbs": [
      "SURVIVAL",
      "Lista 6: Análise de Sobrevida"
    ]
  },
  {
    "objectID": "lista_6.html#contexto-do-estudo",
    "href": "lista_6.html#contexto-do-estudo",
    "title": "Lista 6: Análise de Sobrevida",
    "section": "",
    "text": "Dados: Fila de Transplante Renal\n\n\n\nAmostra: 124 pacientes aguardando transplante de rim\nVariáveis: - t_seg: Tempo de seguimento (meses) - tx: Realizou transplante? (sim/não) - obito: Óbito do paciente (sim/não) - evento de interesse - t_tx: Tempo até o transplante (meses)\nPergunta: O transplante afeta a sobrevida dos pacientes?",
    "crumbs": [
      "SURVIVAL",
      "Lista 6: Análise de Sobrevida"
    ]
  },
  {
    "objectID": "lista_6.html#pacotes",
    "href": "lista_6.html#pacotes",
    "title": "Lista 6: Análise de Sobrevida",
    "section": "📦 Pacotes",
    "text": "📦 Pacotes\n\n\n✓ Pacotes de sobrevida carregados!",
    "crumbs": [
      "SURVIVAL",
      "Lista 6: Análise de Sobrevida"
    ]
  },
  {
    "objectID": "lista_6.html#boas-práticas-ambiente-limpo",
    "href": "lista_6.html#boas-práticas-ambiente-limpo",
    "title": "Lista 6: Análise de Sobrevida",
    "section": "🧹 Boas Práticas: Ambiente Limpo",
    "text": "🧹 Boas Práticas: Ambiente Limpo\n\n# Limpar ambiente\nrm(list = ls(all.names = TRUE))\ngc()\n\n          used  (Mb) gc trigger  (Mb) max used  (Mb)\nNcells 2605469 139.2    4276531 228.4  4276531 228.4\nVcells 4458572  34.1   10146329  77.5  7235079  55.2\n\n# Configurações\noptions(max.print = .Machine$integer.max, \n        scipen = 999, \n        stringsAsFactors = FALSE)\n\nset.seed(42)",
    "crumbs": [
      "SURVIVAL",
      "Lista 6: Análise de Sobrevida"
    ]
  },
  {
    "objectID": "lista_6.html#tema-customizado-opcional",
    "href": "lista_6.html#tema-customizado-opcional",
    "title": "Lista 6: Análise de Sobrevida",
    "section": "🎨 Tema Customizado (Opcional)",
    "text": "🎨 Tema Customizado (Opcional)\n\nmeu_tema &lt;- theme(\n  plot.title = element_text(size = rel(1.5), face = \"bold\"),\n  panel.grid.major.y = element_line(colour = 'gray90'),\n  panel.grid.minor.y = element_line(colour = 'gray95'),\n  panel.grid.major.x = element_blank(),\n  panel.grid.minor.x = element_blank(),\n  plot.background = element_rect(fill = 'white', colour = 'white'),\n  panel.background = element_rect(fill = 'white'),\n  axis.line = element_line(colour = 'black', linewidth = 0.8),\n  axis.text = element_text(colour = \"black\", face = 'bold'),\n  axis.title = element_text(size = rel(1.2)),\n  axis.ticks = element_line(colour = 'black', linewidth = 0.8),\n  legend.position = \"bottom\",\n  legend.background = element_blank(),\n  legend.box.background = element_rect(colour = \"black\")\n)",
    "crumbs": [
      "SURVIVAL",
      "Lista 6: Análise de Sobrevida"
    ]
  },
  {
    "objectID": "lista_6.html#preparação-dos-dados",
    "href": "lista_6.html#preparação-dos-dados",
    "title": "Lista 6: Análise de Sobrevida",
    "section": "📥 Preparação dos Dados",
    "text": "📥 Preparação dos Dados\n\n# Carregar\noriginal &lt;- read.spss(\"teste Cox tempo dep Tx.sav\", to.data.frame = TRUE)\n\nglimpse(original)\n\nRows: 124\nColumns: 5\n$ id    &lt;chr&gt; \"13758618I                     \", \"13750502G                    …\n$ t_seg &lt;dbl&gt; 99, 98, 97, 97, 97, 96, 92, 90, 89, 87, 83, 83, 82, 82, 80, 77, …\n$ t_tx  &lt;dbl&gt; 22, 81, NA, 25, 93, 5, 1, 30, 88, 28, 30, 13, 49, NA, NA, 10, NA…\n$ tx    &lt;fct&gt; sim, sim, não, sim, sim, sim, sim, sim, sim, sim, sim, sim, sim,…\n$ obito &lt;fct&gt; não, não, não, não, não, não, não, não, sim, não, não, não, não,…\n\n\n\n\n⚠️ Conversão Crítica: Evento Binário\n\n\n\n\n\n\nRegra Fundamental!\n\n\n\nA variável de evento DEVE ser numérica binária (0 = censura, 1 = evento).\nNão use: Fatores “sim”/“não”\nUse: 0 = sem óbito (censurado), 1 = com óbito (evento)\n\n\n\n# Criar versão corrigida\ndb &lt;- original %&gt;%\n  mutate(obito = as.integer(obito == \"sim\"))\n\n# Verificar\nglimpse(db$obito)\n\n int [1:124] 0 0 0 0 0 0 0 0 1 0 ...\n\ntable(db$obito)\n\n\n 0  1 \n90 34 \n\n\n\n\n\nAnálise Exploratória\n\n# Verificar missing values\ndata.frame(\n  NA_t_seg = sum(is.na(db$t_seg)),\n  NA_t_tx = sum(is.na(db$t_tx)),\n  NA_tx = sum(is.na(db$tx)),\n  NA_obito = sum(is.na(db$obito))\n) %&gt;% kable(caption = \"Dados Faltantes\")\n\n\nDados Faltantes\n\n\nNA_t_seg\nNA_t_tx\nNA_tx\nNA_obito\n\n\n\n\n0\n64\n0\n0\n\n\n\n\n\n\n\n\n\n\n\n📊 Interpretando NAs em t_tx\n\n\n\n\n\n51.6% de NAs em t_tx é esperado! Representa pacientes que não fizeram transplante.\nVerificação: Nenhum paciente com tx=“sim” deveria ter NA em t_tx.\n\n# Verificar inconsistências\ndb %&gt;% filter(tx == \"sim\" & is.na(t_tx))\n\n[1] id    t_seg t_tx  tx    obito\n&lt;0 linhas&gt; (ou row.names de comprimento 0)\n\n\nSe retornar 0 linhas → OK!",
    "crumbs": [
      "SURVIVAL",
      "Lista 6: Análise de Sobrevida"
    ]
  },
  {
    "objectID": "lista_6.html#estrutura-de-dados-de-sobrevida",
    "href": "lista_6.html#estrutura-de-dados-de-sobrevida",
    "title": "Lista 6: Análise de Sobrevida",
    "section": "🎯 Estrutura de Dados de Sobrevida",
    "text": "🎯 Estrutura de Dados de Sobrevida\n\n# Criar objeto Surv\nsurv_obj &lt;- Surv(time = db$t_seg, event = db$obito)\n\n# Visualizar primeiros casos\nhead(surv_obj)\n\n[1] 99+ 98+ 97+ 97+ 97+ 96+\n\n\n\n\n\n\n\n\n🔍 Interpretando a Notação\n\n\n\n\n34: Tempo 34, evento ocorreu\n58+: Tempo 58, censurado (+ indica censura)\n\nCensura = paciente saiu do estudo sem evento (perdeu acompanhamento, fim do estudo, etc.)",
    "crumbs": [
      "SURVIVAL",
      "Lista 6: Análise de Sobrevida"
    ]
  },
  {
    "objectID": "lista_6.html#parte-a-tábua-de-vida",
    "href": "lista_6.html#parte-a-tábua-de-vida",
    "title": "Lista 6: Análise de Sobrevida",
    "section": "📊 Parte A: Tábua de Vida",
    "text": "📊 Parte A: Tábua de Vida\n\n# Modelo geral (sem grupos)\nfit1 &lt;- survfit(surv_obj ~ 1, data = db)\n\n# Resumo\nsummary(fit1)\n\nCall: survfit(formula = surv_obj ~ 1, data = db)\n\n time n.risk n.event survival std.err lower 95% CI upper 95% CI\n    0    124       2    0.984  0.0113        0.962        1.000\n    3    121       2    0.968  0.0159        0.937        0.999\n    4    119       2    0.951  0.0194        0.914        0.990\n    6    117       1    0.943  0.0208        0.903        0.985\n    8    116       2    0.927  0.0234        0.882        0.974\n   11    114       1    0.919  0.0246        0.872        0.968\n   13    113       1    0.911  0.0257        0.862        0.962\n   16    110       1    0.902  0.0268        0.851        0.956\n   19    108       1    0.894  0.0278        0.841        0.950\n   24    106       2    0.877  0.0297        0.821        0.937\n   25    104       1    0.869  0.0306        0.811        0.931\n   26    103       1    0.860  0.0314        0.801        0.924\n   27    102       1    0.852  0.0323        0.791        0.917\n   29    101       1    0.843  0.0330        0.781        0.911\n   34     89       3    0.815  0.0358        0.748        0.888\n   36     82       1    0.805  0.0367        0.736        0.880\n   38     70       1    0.794  0.0379        0.723        0.871\n   40     68       1    0.782  0.0391        0.709        0.862\n   41     65       2    0.758  0.0414        0.681        0.844\n   44     59       1    0.745  0.0427        0.666        0.834\n   45     55       1    0.731  0.0440        0.650        0.823\n   46     53       1    0.718  0.0453        0.634        0.812\n   49     47       1    0.702  0.0468        0.616        0.800\n   58     32       1    0.680  0.0502        0.589        0.786\n   66     24       1    0.652  0.0556        0.552        0.771\n   89      9       1    0.580  0.0843        0.436        0.771\n\n\n\n\nTabela Formatada\n\ntidy_survfit(fit1) %&gt;%\n  head(10) %&gt;%\n  kable(digits = 3, caption = \"Primeiras 10 Linhas da Tábua de Vida\")\n\n\nPrimeiras 10 Linhas da Tábua de Vida\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ntime\nn.risk\nn.event\nn.censor\ncum.event\ncum.censor\nestimate\nstd.error\nconf.high\nconf.low\nestimate_type\nestimate_type_label\nmonotonicity_type\nconf.level\n\n\n\n\n0\n124\n2\n1\n2\n1\n0.984\n0.011\n1.000\n0.962\nsurvival\nSurvival Probability\ndecreasing\n0.95\n\n\n3\n121\n2\n0\n4\n1\n0.968\n0.016\n0.999\n0.937\nsurvival\nSurvival Probability\ndecreasing\n0.95\n\n\n4\n119\n2\n0\n6\n1\n0.951\n0.020\n0.990\n0.914\nsurvival\nSurvival Probability\ndecreasing\n0.95\n\n\n6\n117\n1\n0\n7\n1\n0.943\n0.022\n0.985\n0.903\nsurvival\nSurvival Probability\ndecreasing\n0.95\n\n\n8\n116\n2\n0\n9\n1\n0.927\n0.025\n0.974\n0.882\nsurvival\nSurvival Probability\ndecreasing\n0.95\n\n\n11\n114\n1\n0\n10\n1\n0.919\n0.027\n0.968\n0.872\nsurvival\nSurvival Probability\ndecreasing\n0.95\n\n\n13\n113\n1\n0\n11\n1\n0.911\n0.028\n0.962\n0.862\nsurvival\nSurvival Probability\ndecreasing\n0.95\n\n\n14\n112\n0\n1\n11\n2\n0.911\n0.028\n0.962\n0.862\nsurvival\nSurvival Probability\ndecreasing\n0.95\n\n\n15\n111\n0\n1\n11\n3\n0.911\n0.028\n0.962\n0.862\nsurvival\nSurvival Probability\ndecreasing\n0.95\n\n\n16\n110\n1\n0\n12\n3\n0.902\n0.030\n0.956\n0.851\nsurvival\nSurvival Probability\ndecreasing\n0.95",
    "crumbs": [
      "SURVIVAL",
      "Lista 6: Análise de Sobrevida"
    ]
  },
  {
    "objectID": "lista_6.html#parte-b-curva-de-kaplan-meier",
    "href": "lista_6.html#parte-b-curva-de-kaplan-meier",
    "title": "Lista 6: Análise de Sobrevida",
    "section": "📈 Parte B: Curva de Kaplan-Meier",
    "text": "📈 Parte B: Curva de Kaplan-Meier\n\nCurva Geral\n\nggsurvfit(fit1, linewidth = 1.2) +\n  labs(\n    title = \"Curva de Sobrevida Geral\",\n    x = \"Tempo (meses)\",\n    y = \"Probabilidade de Sobrevida\"\n  ) +\n  add_confidence_interval(alpha = 0.2) +\n  add_risktable() +\n  scale_ggsurvfit() +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\n\n\nComparando Grupos: Transplante vs Não-Transplante\n\n# Modelo com grupos\nfit2 &lt;- survfit(surv_obj ~ tx, data = db)\n\n# Resumo em tempos específicos\ntempos &lt;- seq(0, 100, by = 20)\nsummary(fit2, times = tempos)\n\nCall: survfit(formula = surv_obj ~ tx, data = db)\n\n                tx=sim \n time n.risk n.event survival std.err lower 95% CI upper 95% CI\n    0     60       0    1.000  0.0000        1.000        1.000\n   20     57       2    0.966  0.0236        0.921        1.000\n   40     42       4    0.894  0.0410        0.818        0.978\n   60     21       3    0.823  0.0550        0.722        0.938\n   80     12       1    0.779  0.0670        0.658        0.922\n\n                tx=não \n time n.risk n.event survival std.err lower 95% CI upper 95% CI\n    0     64       2    0.969  0.0217        0.927        1.000\n   20     50       9    0.827  0.0476        0.738        0.925\n   40     26       8    0.668  0.0643        0.553        0.806\n   60      7       4    0.523  0.0841        0.382        0.717\n   80      3       0    0.523  0.0841        0.382        0.717\n\n\n\n\n\nVisualização Comparativa\n\nfit2_km &lt;- ggsurvfit(fit2, linewidth = 1.2) +\n  labs(\n    title = \"Sobrevida: Transplante vs Não-Transplante\",\n    x = \"Tempo (meses)\",\n    y = \"Probabilidade de Sobrevida (%)\"\n  ) +\n  add_confidence_interval(alpha = 0.2) +\n  add_risktable() +\n  scale_ggsurvfit() +\n  theme_minimal()\n\nfit2_km\n\n\n\n\n\n\n\n\n\n\n\nAnálise em Tempo Específico\n\n# Sobrevida aos 75 meses\nsurv_75 &lt;- summary(fit2, times = 75)\n\ncat(\"═══ SOBREVIDA AOS 75 MESES ═══\\n\\n\")\n\n═══ SOBREVIDA AOS 75 MESES ═══\n\ncat(\"Transplante = SIM:\\n\")\n\nTransplante = SIM:\n\ncat(\"  Sobrevida:\", round(surv_75$surv[1], 3), \"\\n\")\n\n  Sobrevida: 0.779 \n\ncat(\"  IC 95%: [\", round(surv_75$lower[1], 3), \",\",\n    round(surv_75$upper[1], 3), \"]\\n\\n\")\n\n  IC 95%: [ 0.658 , 0.922 ]\n\ncat(\"Transplante = NÃO:\\n\")\n\nTransplante = NÃO:\n\ncat(\"  Sobrevida:\", round(surv_75$surv[2], 3), \"\\n\")\n\n  Sobrevida: 0.523 \n\ncat(\"  IC 95%: [\", round(surv_75$lower[2], 3), \",\",\n    round(surv_75$upper[2], 3), \"]\\n\\n\")\n\n  IC 95%: [ 0.382 , 0.717 ]\n\n# Razão\nrazao &lt;- surv_75$surv[1] / surv_75$surv[2]\ncat(\"Razão (Sim/Não):\", round(razao, 2), \"×\\n\")\n\nRazão (Sim/Não): 1.49 ×\n\ncat(\"→ Grupo com transplante tem\", round(razao, 2), \n    \"× mais chance de estar vivo aos 75 meses\\n\")\n\n→ Grupo com transplante tem 1.49 × mais chance de estar vivo aos 75 meses\n\n\n\n\n\nGráfico com Marcação de Tempo\n\nfit2_km +\n  geom_vline(xintercept = 75, linetype = 'dashed', \n             colour = 'red', linewidth = 1) +\n  geom_hline(yintercept = surv_75$surv, linetype = 'dashed',\n             colour = 'red', linewidth = 1) +\n  annotate(\"text\", x = 77, y = 0.9, label = \"75 meses\",\n           hjust = 0, color = \"red\", fontface = \"bold\")\n\n\n\n\n\n\n\n\n\n\n\nPercentil Fixo: Tempo para 75% de Sobrevida\n\nfit2 %&gt;%\n  ggsurvfit(linewidth = 1.2) +\n  labs(\n    title = \"Tempo até 75% de Sobrevida\",\n    x = \"Tempo (meses)\",\n    y = \"Probabilidade de Sobrevida\"\n  ) +\n  add_confidence_interval(alpha = 0.2) +\n  add_quantile(y_value = 0.75, color = \"gray30\", linewidth = 0.8) +\n  scale_ggsurvfit() +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n📊 Interpretação\n\n\n\n\nSem transplante: Atinge 75% de sobrevida ~35 meses\nCom transplante: Atinge 75% de sobrevida ~90 meses\n\nTransplante mais que dobra o tempo para atingir esse patamar!",
    "crumbs": [
      "SURVIVAL",
      "Lista 6: Análise de Sobrevida"
    ]
  },
  {
    "objectID": "lista_6.html#comparação-de-curvas-testes-estatísticos",
    "href": "lista_6.html#comparação-de-curvas-testes-estatísticos",
    "title": "Lista 6: Análise de Sobrevida",
    "section": "🔬 Comparação de Curvas: Testes Estatísticos",
    "text": "🔬 Comparação de Curvas: Testes Estatísticos\n\n\n\n\n\n\nEscolhendo o Teste Certo\n\n\n\n\nLog-rank: Diferenças ao longo de todo o período (padrão)\nGehan-Breslow: Enfatiza diferenças iniciais\nTarone-Ware: Peso intermediário\nPeto-Peto: Similar ao log-rank, robusto\n\nRegra geral: Use log-rank a menos que haja razão específica.\n\n\n\n\nLog-Rank (Mantel-Cox)\n\nlogrank_test(surv_obj ~ tx, data = db, type = \"logrank\")\n\n\n    Asymptotic Two-Sample Logrank Test\n\ndata:  surv_obj by tx (sim, não)\nZ = 2.9275, p-value = 0.003417\nalternative hypothesis: true theta is not equal to 1\n\n\n\n\n\nGehan-Breslow\n\nlogrank_test(surv_obj ~ tx, data = db, type = \"Gehan-Breslow\")\n\n\n    Asymptotic Two-Sample Gehan-Breslow Test\n\ndata:  surv_obj by tx (sim, não)\nZ = 3.0103, p-value = 0.00261\nalternative hypothesis: true theta is not equal to 1\n\n\n\n\n\nTarone-Ware\n\nlogrank_test(surv_obj ~ tx, data = db, type = \"Tarone-Ware\")\n\n\n    Asymptotic Two-Sample Tarone-Ware Test\n\ndata:  surv_obj by tx (sim, não)\nZ = 3.0338, p-value = 0.002415\nalternative hypothesis: true theta is not equal to 1\n\n\n\n\n\n\n\n\n\n📊 Conclusão dos Testes\n\n\n\nTodos os testes indicam p &lt; 0.05, rejeitando H₀.\nConclusão: Há evidência significativa de que as curvas de sobrevida diferem entre grupos com e sem transplante.",
    "crumbs": [
      "SURVIVAL",
      "Lista 6: Análise de Sobrevida"
    ]
  },
  {
    "objectID": "lista_6.html#parte-c-regressão-de-cox",
    "href": "lista_6.html#parte-c-regressão-de-cox",
    "title": "Lista 6: Análise de Sobrevida",
    "section": "🎯 Parte C: Regressão de Cox",
    "text": "🎯 Parte C: Regressão de Cox\n\n\n\n\n\n\nO que é Regressão de Cox?\n\n\n\nModelo semi-paramétrico que estima o risco instantâneo (hazard) de um evento ao longo do tempo.\nVantagens: - Permite múltiplas covariáveis - Não assume distribuição específica do tempo - Estima Hazard Ratios (HR)\nHR interpretação: - HR = 1: Sem efeito - HR &gt; 1: Aumenta risco - HR &lt; 1: Diminui risco (proteção)\n\n\n\n\nAjuste do Modelo\n\n# Modelo Cox\ncox_res &lt;- coxph(surv_obj ~ tx, data = db)\n\n# Resumo\nsummary(cox_res)\n\nCall:\ncoxph(formula = surv_obj ~ tx, data = db)\n\n  n= 124, number of events= 34 \n\n        coef exp(coef) se(coef)     z Pr(&gt;|z|)   \ntxnão 1.0787    2.9409   0.3753 2.874  0.00405 **\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n      exp(coef) exp(-coef) lower .95 upper .95\ntxnão     2.941       0.34     1.409     6.136\n\nConcordance= 0.638  (se = 0.04 )\nLikelihood ratio test= 8.99  on 1 df,   p=0.003\nWald test            = 8.26  on 1 df,   p=0.004\nScore (logrank) test = 9.01  on 1 df,   p=0.003\n\n\n\n\n\nTabela Formatada para Publicação\n\ntbl_regression(\n  cox_res,\n  exponentiate = TRUE,\n  label = list(tx ~ \"Transplante\")\n) %&gt;%\n  bold_p() %&gt;%\n  add_global_p()\n\n\n\n\n\n\n\n\n\n\n\n\n\nCharacteristic\nHR\n95% CI\np-value\n\n\n\n\nTransplante\n\n\n\n\n0.003\n\n\n    sim\n—\n—\n\n\n\n\n    não\n2.94\n1.41, 6.14\n\n\n\n\n\nAbbreviations: CI = Confidence Interval, HR = Hazard Ratio\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n📊 Interpretação\n\n\n\nHR = 2.94 para tx=“não”\n“Pacientes sem transplante têm 2.94× mais risco de óbito comparado aos que fizeram transplante”\nEquivalente: Transplante reduz risco em 66% [(1 - 1/2.94) × 100]\n\n\n\n\n\nCurvas Ajustadas pelo Modelo\n\n# Prever para ambos os grupos\ntx_df &lt;- data.frame(tx = c(\"sim\", \"não\"))\ncox_pred &lt;- survfit(cox_res, newdata = tx_df)\n\nggsurvplot(\n  cox_pred,\n  data = db,\n  conf.int = TRUE,\n  legend.labs = c(\"Transplante = Sim\", \"Transplante = Não\"),\n  ggtheme = theme_minimal(),\n  title = \"Curvas de Sobrevida Ajustadas (Modelo Cox)\"\n)\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead.\nℹ The deprecated feature was likely used in the ggpubr package.\n  Please report the issue at &lt;https://github.com/kassambara/ggpubr/issues&gt;.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n⚠️ Cox vs Kaplan-Meier\n\n\n\nAs curvas do modelo Cox são ajustadas e podem diferir ligeiramente das curvas Kaplan-Meier empíricas. Isso é normal!\n\nK-M: Dados brutos, não-paramétrico\nCox: Modelo ajustado, assume proporcionalidade\n\n\n\n\n\n\nForest Plot do Modelo\n\nggforest(cox_res, data = db)",
    "crumbs": [
      "SURVIVAL",
      "Lista 6: Análise de Sobrevida"
    ]
  },
  {
    "objectID": "lista_6.html#parte-d-calculando-hazard-ratio-em-tempo-específico",
    "href": "lista_6.html#parte-d-calculando-hazard-ratio-em-tempo-específico",
    "title": "Lista 6: Análise de Sobrevida",
    "section": "📐 Parte D: Calculando Hazard Ratio em Tempo Específico",
    "text": "📐 Parte D: Calculando Hazard Ratio em Tempo Específico\n\n# Especificando o modelo \n\ncox_res &lt;- coxph(Surv(time = t_seg, event = obito) ~ tx, data = db)\n\n# Criar dados para predição (tempo 50 meses)\npred_dat &lt;- data.frame(t_seg = c(50,50),\n                       obito = c(0,0), \n                       tx = c(\"sim\",\"não\")\n                       )\n\nkable(pred_dat)\n\n\n\n\nt_seg\nobito\ntx\n\n\n\n\n50\n0\nsim\n\n\n50\n0\nnão\n\n\n\n\n\n\n# Prever sobrevida\npreds &lt;- predict(cox_res,\n                 pred_dat, \n                 type = \"survival\", \n                 se.fit = TRUE)\n\n# Adicionar ao dataframe\npred_dat$prob &lt;- preds$fit\npred_dat$lcl &lt;- preds$fit - 1.96 * preds$se.fit\npred_dat$ucl &lt;- preds$fit + 1.96 * preds$se.fit\n\n# Exibir\nkable(pred_dat, digits = 3, caption = \"Sobrevida Predita aos 50 meses\")\n\n\nSobrevida Predita aos 50 meses\n\n\nt_seg\nobito\ntx\nprob\nlcl\nucl\n\n\n\n\n50\n0\nsim\n0.825\n0.725\n0.924\n\n\n50\n0\nnão\n0.567\n0.423\n0.711\n\n\n\n\n# HR\nHR_50 &lt;- pred_dat$prob[1] / pred_dat$prob[2]\ncat(\"\\nHR aos 50 meses:\", round(HR_50, 3), \"\\n\")\n\n\nHR aos 50 meses: 1.454 \n\ncat(\"→ Grupo com transplante tem\", round(HR_50, 2), \n    \"× mais sobrevida que grupo sem transplante\\n\")\n\n→ Grupo com transplante tem 1.45 × mais sobrevida que grupo sem transplante\n\n\n\n\nHR em Múltiplos Tempos\n\n# Múltiplos tempos\ntempos_interesse &lt;- c(30, 50, 75, 90)\nresultados_hr &lt;- data.frame()\n\nfor (t in tempos_interesse) {\n  pred_temp &lt;- data.frame(\n    t_seg = c(t, t),\n    obito = c(0, 0),\n    tx = c(\"sim\", \"não\")\n  )\n  \n  preds_temp &lt;- predict(cox_res, newdata = pred_temp, \n                        type = \"survival\", se.fit = TRUE)\n  \n  hr &lt;- preds_temp$fit[1] / preds_temp$fit[2]\n  \n  resultados_hr &lt;- rbind(resultados_hr, data.frame(\n    Tempo = t,\n    Sobrevida_Sim = round(preds_temp$fit[1], 3),\n    Sobrevida_Não = round(preds_temp$fit[2], 3),\n    HR = round(hr, 3)\n  ))\n}\n\nkable(resultados_hr, caption = \"Hazard Ratios ao Longo do Tempo\")\n\n\nHazard Ratios ao Longo do Tempo\n\n\nTempo\nSobrevida_Sim\nSobrevida_Não\nHR\n\n\n\n\n30\n0.917\n0.774\n1.184\n\n\n50\n0.825\n0.567\n1.454\n\n\n75\n0.786\n0.492\n1.598\n\n\n90\n0.717\n0.376\n1.908",
    "crumbs": [
      "SURVIVAL",
      "Lista 6: Análise de Sobrevida"
    ]
  },
  {
    "objectID": "lista_6.html#verificação-de-pressupostos",
    "href": "lista_6.html#verificação-de-pressupostos",
    "title": "Lista 6: Análise de Sobrevida",
    "section": "✅ Verificação de Pressupostos",
    "text": "✅ Verificação de Pressupostos\n\n\n\n\n\n\nPressuposto Principal: Proporcionalidade dos Riscos\n\n\n\nO modelo Cox assume que o hazard ratio é constante ao longo do tempo.\nViolação: Se HR muda com o tempo, use modelo estratificado ou tempo-dependente.\n\n\n\n\n1. Inspeção Visual: Curvas Paralelas?\n\nfit2_km +\n  labs(subtitle = \"Curvas paralelas? → Riscos proporcionais ✓\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nSe curvas cruzam, há violação! Neste caso, são aproximadamente paralelas → OK.\n\n\n\n\n\n2. Teste de Schoenfeld\n\n# Teste formal\ntest_schoenfeld &lt;- cox.zph(cox_res)\nprint(test_schoenfeld)\n\n       chisq df    p\ntx      0.58  1 0.45\nGLOBAL  0.58  1 0.45\n\n\n\n\n\n\n\n\nInterpretando o Teste\n\n\n\nH₀: Riscos são proporcionais\np &gt; 0.05: Não rejeitamos H₀ → Proporcionalidade mantida ✓\nNeste caso: p = 0.43 → Pressuposto atendido!\n\n\n\n\n\nGráfico de Resíduos\n\nggcoxzph(test_schoenfeld, point.size = 0.5)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n🔍 Interpretando Resíduos de Schoenfeld\n\n\n\n\n\nO que procurar: - Sem padrão: Resíduos aleatórios ao redor de zero → Bom! - Tendência linear: Violação da proporcionalidade - Padrão não-linear: Violação severa\nLinha de suavização: - Aproximadamente horizontal → Proporcionalidade OK - Inclinação clara → Problema!",
    "crumbs": [
      "SURVIVAL",
      "Lista 6: Análise de Sobrevida"
    ]
  },
  {
    "objectID": "lista_6.html#material-complementar",
    "href": "lista_6.html#material-complementar",
    "title": "Lista 6: Análise de Sobrevida",
    "section": "📚 Material Complementar",
    "text": "📚 Material Complementar",
    "crumbs": [
      "SURVIVAL",
      "Lista 6: Análise de Sobrevida"
    ]
  },
  {
    "objectID": "lista_6.html#informações-de-sessão",
    "href": "lista_6.html#informações-de-sessão",
    "title": "Lista 6: Análise de Sobrevida",
    "section": "🔧 Informações de Sessão",
    "text": "🔧 Informações de Sessão\n\nreport(sessionInfo())\n\nAnalyses were conducted using the R Statistical language (version 4.4.2; R Core\nTeam, 2024) on Windows 11 x64 (build 26100), using the packages lubridate\n(version 1.9.4; Grolemund G, Wickham H, 2011), coin (version 1.4.3; Hothorn T\net al., 2006), ggpubr (version 0.6.0; Kassambara A, 2023), survminer (version\n0.5.1; Kassambara A et al., 2025), report (version 0.6.3; Makowski D et al.,\n2023), tibble (version 3.3.1; Müller K, Wickham H, 2026), foreign (version\n0.8.87; R Core Team, 2024), broom (version 1.0.7; Robinson D et al., 2024),\nggsurvfit (version 1.2.0; Sjoberg D et al., 2025), gtsummary (version 2.1.0;\nSjoberg D et al., 2021), survival (version 3.7.0; Therneau T, 2024), ggplot2\n(version 4.0.1; Wickham H, 2016), forcats (version 1.0.0; Wickham H, 2023),\nstringr (version 1.5.1; Wickham H, 2023), tidyverse (version 2.0.0; Wickham H\net al., 2019), dplyr (version 1.1.4; Wickham H et al., 2023), purrr (version\n1.0.4; Wickham H, Henry L, 2025), readr (version 2.1.5; Wickham H et al.,\n2024), tidyr (version 1.3.1; Wickham H et al., 2024) and kableExtra (version\n1.4.0; Zhu H, 2024).\n\nReferences\n----------\n  - Grolemund G, Wickham H (2011). \"Dates and Times Made Easy with lubridate.\"\n_Journal of Statistical Software_, *40*(3), 1-25.\n&lt;https://www.jstatsoft.org/v40/i03/&gt;.\n  - Hothorn T, Hornik K, van de Wiel MA, Zeileis A (2006). \"A Lego system for\nconditional inference.\" _The American Statistician_, *60*(3), 257-263.\ndoi:10.1198/000313006X118430 &lt;https://doi.org/10.1198/000313006X118430&gt;.\nHothorn T, Hornik K, van de Wiel MA, Zeileis A (2008). \"Implementing a class of\npermutation tests: The coin package.\" _Journal of Statistical Software_,\n*28*(8), 1-23. doi:10.18637/jss.v028.i08\n&lt;https://doi.org/10.18637/jss.v028.i08&gt;.\n  - Kassambara A (2023). _ggpubr: 'ggplot2' Based Publication Ready Plots_. R\npackage version 0.6.0, &lt;https://CRAN.R-project.org/package=ggpubr&gt;.\n  - Kassambara A, Kosinski M, Biecek P (2025). _survminer: Drawing Survival\nCurves using 'ggplot2'_. R package version 0.5.1,\n&lt;https://CRAN.R-project.org/package=survminer&gt;.\n  - Makowski D, Lüdecke D, Patil I, Thériault R, Ben-Shachar M, Wiernik B (2023).\n\"Automated Results Reporting as a Practical Tool to Improve Reproducibility and\nMethodological Best Practices Adoption.\" _CRAN_.\ndoi:10.32614/CRAN.package.report\n&lt;https://doi.org/10.32614/CRAN.package.report&gt;,\n&lt;https://easystats.github.io/report/&gt;.\n  - Müller K, Wickham H (2026). _tibble: Simple Data Frames_. R package version\n3.3.1, &lt;https://CRAN.R-project.org/package=tibble&gt;.\n  - R Core Team (2024). _foreign: Read Data Stored by 'Minitab', 'S', 'SAS',\n'SPSS', 'Stata', 'Systat', 'Weka', 'dBase', ..._. R package version 0.8-87,\n&lt;https://CRAN.R-project.org/package=foreign&gt;.\n  - R Core Team (2024). _R: A Language and Environment for Statistical\nComputing_. R Foundation for Statistical Computing, Vienna, Austria.\n&lt;https://www.R-project.org/&gt;.\n  - Robinson D, Hayes A, Couch S (2024). _broom: Convert Statistical Objects into\nTidy Tibbles_. R package version 1.0.7,\n&lt;https://CRAN.R-project.org/package=broom&gt;.\n  - Sjoberg D, Baillie M, Fruechtenicht C, Haesendonckx S, Treis T (2025).\n_ggsurvfit: Flexible Time-to-Event Figures_. R package version 1.2.0,\n&lt;https://CRAN.R-project.org/package=ggsurvfit&gt;.\n  - Sjoberg D, Whiting K, Curry M, Lavery J, Larmarange J (2021). \"Reproducible\nSummary Tables with the gtsummary Package.\" _The R Journal_, *13*, 570-580.\ndoi:10.32614/RJ-2021-053 &lt;https://doi.org/10.32614/RJ-2021-053&gt;,\n&lt;https://doi.org/10.32614/RJ-2021-053&gt;.\n  - Therneau T (2024). _A Package for Survival Analysis in R_. R package version\n3.7-0, &lt;https://CRAN.R-project.org/package=survival&gt;. Terry M. Therneau,\nPatricia M. Grambsch (2000). _Modeling Survival Data: Extending the Cox Model_.\nSpringer, New York. ISBN 0-387-98784-3.\n  - Wickham H (2016). _ggplot2: Elegant Graphics for Data Analysis_.\nSpringer-Verlag New York. ISBN 978-3-319-24277-4,\n&lt;https://ggplot2.tidyverse.org&gt;.\n  - Wickham H (2023). _forcats: Tools for Working with Categorical Variables\n(Factors)_. R package version 1.0.0,\n&lt;https://CRAN.R-project.org/package=forcats&gt;.\n  - Wickham H (2023). _stringr: Simple, Consistent Wrappers for Common String\nOperations_. R package version 1.5.1,\n&lt;https://CRAN.R-project.org/package=stringr&gt;.\n  - Wickham H, Averick M, Bryan J, Chang W, McGowan LD, François R, Grolemund G,\nHayes A, Henry L, Hester J, Kuhn M, Pedersen TL, Miller E, Bache SM, Müller K,\nOoms J, Robinson D, Seidel DP, Spinu V, Takahashi K, Vaughan D, Wilke C, Woo K,\nYutani H (2019). \"Welcome to the tidyverse.\" _Journal of Open Source Software_,\n*4*(43), 1686. doi:10.21105/joss.01686 &lt;https://doi.org/10.21105/joss.01686&gt;.\n  - Wickham H, François R, Henry L, Müller K, Vaughan D (2023). _dplyr: A Grammar\nof Data Manipulation_. R package version 1.1.4,\n&lt;https://CRAN.R-project.org/package=dplyr&gt;.\n  - Wickham H, Henry L (2025). _purrr: Functional Programming Tools_. R package\nversion 1.0.4, &lt;https://CRAN.R-project.org/package=purrr&gt;.\n  - Wickham H, Hester J, Bryan J (2024). _readr: Read Rectangular Text Data_. R\npackage version 2.1.5, &lt;https://CRAN.R-project.org/package=readr&gt;.\n  - Wickham H, Vaughan D, Girlich M (2024). _tidyr: Tidy Messy Data_. R package\nversion 1.3.1, &lt;https://CRAN.R-project.org/package=tidyr&gt;.\n  - Zhu H (2024). _kableExtra: Construct Complex Table with 'kable' and Pipe\nSyntax_. R package version 1.4.0,\n&lt;https://CRAN.R-project.org/package=kableExtra&gt;.\n\n\n\n\n\n\n\n\n\n🎓 Resumo da Lista 6\n\n\n\nNesta lista você:\n✅ Construiu tábuas de vida e curvas Kaplan-Meier\n✅ Comparou grupos com testes log-rank\n✅ Ajustou Regressão de Cox e interpretou Hazard Ratios\n✅ Calculou HR em tempos específicos\n✅ Verificou proporcionalidade dos riscos\nConceitos-chave: - Censura: dado incompleto (não é perda de dados!) - K-M: método não-paramétrico para sobrevida - Cox: modelo semi-paramétrico para riscos - HR: razão de riscos instantâneos - Proporcionalidade: HR constante ao longo do tempo\nPróximos passos: - Lista 7: Cox com covariáveis tempo-dependentes - Explorar modelos com múltiplas covariáveis - Análises estratificadas para violações de proporcionalidade",
    "crumbs": [
      "SURVIVAL",
      "Lista 6: Análise de Sobrevida"
    ]
  },
  {
    "objectID": "lista_7.html#o-que-é-arima",
    "href": "lista_7.html#o-que-é-arima",
    "title": "Lista 7: Séries Temporais (ARIMA)",
    "section": "🔍 O que é ARIMA?",
    "text": "🔍 O que é ARIMA?\n\n\n\n\n\n\nARIMA = AutoRegressive Integrated Moving Average\n\n\n\nModelo para séries temporais que combina três componentes:\nAR (p) - AutoRegressivo - Usa valores passados da série - “O hoje depende do ontem” - p = número de defasagens (lags)\nI (d) - Integrado - Número de diferenças para tornar série estacionária - d = 0 (estacionária), d = 1 (1ª diferença), etc.\nMA (q) - Média Móvel - Usa erros passados da série - “Correções baseadas em erros anteriores” - q = número de termos de erro\nNotação: ARIMA(p, d, q)",
    "crumbs": [
      "ARIMA",
      "Lista 7: Séries Temporais (ARIMA)"
    ]
  },
  {
    "objectID": "lista_7.html#preparação-do-ambiente",
    "href": "lista_7.html#preparação-do-ambiente",
    "title": "Lista 7: Séries Temporais (ARIMA)",
    "section": "🧹 Preparação do Ambiente",
    "text": "🧹 Preparação do Ambiente\n\n# Limpar ambiente\nrm(list = ls(all.names = TRUE))\ngc()\n\n          used (Mb) gc trigger  (Mb) max used  (Mb)\nNcells 1682340 89.9    3138441 167.7  2478994 132.4\nVcells 2892755 22.1    8388608  64.0  4629138  35.4\n\n# Configurações\noptions(scipen = 999, stringsAsFactors = FALSE)\nset.seed(42)",
    "crumbs": [
      "ARIMA",
      "Lista 7: Séries Temporais (ARIMA)"
    ]
  },
  {
    "objectID": "lista_7.html#parte-1-estacionaridade-dados-de-cigarros",
    "href": "lista_7.html#parte-1-estacionaridade-dados-de-cigarros",
    "title": "Lista 7: Séries Temporais (ARIMA)",
    "section": "📥 Parte 1: Estacionaridade (Dados de Cigarros)",
    "text": "📥 Parte 1: Estacionaridade (Dados de Cigarros)\n\n\n\n\n\n\nConceito Fundamental: Estacionaridade\n\n\n\nUma série é estacionária quando: - Média constante ao longo do tempo - Variância constante - Autocorrelação depende apenas da defasagem, não do tempo\nPor que importa? Modelos ARIMA requerem estacionaridade!\n\n\n\n\nCarregar Dados\n\ndb_cigarro &lt;- read.spss(\"CigarrosROD_1.sav\", to.data.frame = TRUE)\nglimpse(db_cigarro)\n\nRows: 20\nColumns: 2\n$ Dia         &lt;dbl&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17,…\n$ cigarrosROD &lt;dbl&gt; 6, 10, 4, 13, 4, 11, 4, 6, 4, 15, 5, 14, 5, 21, 10, 31, 13…\n\n\n\n\n\nInspeção Visual\n\n# Média da série\nmedia_cigarros &lt;- mean(db_cigarro$cigarrosROD)\n\n# Plot simples\nplot.ts(db_cigarro$cigarrosROD, \n        main = \"Consumo de Cigarros ao Longo do Tempo\",\n        ylab = \"Cigarros por Dia\", xlab = \"Tempo\")\nabline(h = media_cigarros, col = \"blue\", lty = 2, lwd = 2)\nlegend(\"topright\", legend = \"Média\", col = \"blue\", lty = 2, lwd = 2)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n📊 Diagnóstico Visual\n\n\n\nValores desviam bastante da média → Série NÃO é estacionária\nObserve tendência de queda ao longo do tempo.\n\n\n\n\n\nTeste Augmented Dickey-Fuller (ADF)\n\n\n\n\n\n\nTeste ADF\n\n\n\nH₀: Série é não-estacionária (possui raiz unitária)\nH₁: Série é estacionária\nDecisão: - p &lt; 0.05 → Rejeita H₀ → Estacionária ✓ - p &gt; 0.05 → Não rejeita H₀ → Não-estacionária ✗\n\n\n\nadf.test(db_cigarro$cigarrosROD)\n\n\n    Augmented Dickey-Fuller Test\n\ndata:  db_cigarro$cigarrosROD\nDickey-Fuller = -0.38979, Lag order = 2, p-value = 0.9797\nalternative hypothesis: stationary\n\n\n\n\n\n\n\n\nResultado\n\n\n\np &gt; 0.05 → Série não é estacionária\nPrecisamos transformá-la!\n\n\n\n\n\nFunção de Autocorrelação (ACF)\n\n# Análise completa\nggtsdisplay(db_cigarro$cigarrosROD, \n            main = \"Diagnóstico da Série Original\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n🔍 Interpretando ACF\n\n\n\n\n\nBarras acima da linha tracejada = Autocorrelação significativa\nPadrão decrescente lento = Tendência (não-estacionária)\nLags candidatos: Onde ACF cruza o limiar pela primeira vez\n\n\n\n\n\n\nTeste de Ljung-Box\n\n# Calcular ACF\nacf_valores &lt;- acf(db_cigarro$cigarrosROD, plot = FALSE)\n\n# Testar múltiplos lags\nmax_lags &lt;- min(20, length(acf_valores$acf) - 1)\nresultados &lt;- data.frame(\n  Lag = 1:max_lags,\n  P_Value = sapply(1:max_lags, function(lag) {\n    Box.test(acf_valores$acf, lag = lag, type = \"Ljung-Box\")$p.value\n  })\n)\n\n# Destacar significativos\nresultados$Sig &lt;- ifelse(resultados$P_Value &lt; 0.05, \"✓\", \"\")\n\nkable(head(resultados, 10), digits = 4,\n      caption = \"Teste de Ljung-Box por Lag\")\n\n\nTeste de Ljung-Box por Lag\n\n\nLag\nP_Value\nSig\n\n\n\n\n1\n0.9410\n\n\n\n2\n0.0166\n✓\n\n\n3\n0.0364\n✓\n\n\n4\n0.0200\n✓\n\n\n5\n0.0237\n✓\n\n\n6\n0.0359\n✓\n\n\n7\n0.0198\n✓\n\n\n8\n0.0337\n✓\n\n\n9\n0.0101\n✓\n\n\n10\n0.0151\n✓\n\n\n\n\n\n\n\n\nTransformação: Diferenciação\n\n# Determinar número ótimo de diferenças\nn_diffs &lt;- ndiffs(db_cigarro$cigarrosROD)\ncat(\"Diferenças necessárias:\", n_diffs, \"\\n\")\n\nDiferenças necessárias: 1 \n\n# Aplicar diferenciação\nserie_diff &lt;- diff(db_cigarro$cigarrosROD, differences = n_diffs)\n\n# Verificar estacionaridade\nadf.test(serie_diff)\n\n\n    Augmented Dickey-Fuller Test\n\ndata:  serie_diff\nDickey-Fuller = -4.1249, Lag order = 2, p-value = 0.0189\nalternative hypothesis: stationary\n\n\n\n\n\nVisualização Pós-Transformação\n\n# Plot da série diferenciada\nmedia_diff &lt;- mean(serie_diff)\nplot.ts(serie_diff,\n        main = \"Série Após Diferenciação\",\n        ylab = \"Diferença\", xlab = \"Tempo\")\nabline(h = media_diff, col = \"red\", lty = 2, lwd = 2)\nabline(h = 0, col = \"gray\", lty = 3)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n✓ Série Agora Estacionária!\n\n\n\n\nOscila em torno da média (linha vermelha)\nVariância constante\nADF test significativo (p &lt; 0.05)",
    "crumbs": [
      "ARIMA",
      "Lista 7: Séries Temporais (ARIMA)"
    ]
  },
  {
    "objectID": "lista_7.html#parte-2-modelagem-arima-dados-de-salários",
    "href": "lista_7.html#parte-2-modelagem-arima-dados-de-salários",
    "title": "Lista 7: Séries Temporais (ARIMA)",
    "section": "📊 Parte 2: Modelagem ARIMA (Dados de Salários)",
    "text": "📊 Parte 2: Modelagem ARIMA (Dados de Salários)\n\nCarregar Dados\n\ndb_salarios &lt;- read.spss(\"dados series temporais.sav\", \n                         to.data.frame = TRUE)\nglimpse(db_salarios)\n\nRows: 120\nColumns: 11\n$ date         &lt;dbl&gt; 12818995200, 12821673600, 12824092800, 12826771200, 12829…\n$ men          &lt;dbl&gt; 11357.92, 10605.95, 16998.57, 6563.75, 6607.69, 9839.00, …\n$ women        &lt;dbl&gt; 16578.93, 18236.13, 43393.55, 30908.49, 28701.58, 29647.5…\n$ horas        &lt;dbl&gt; 7978, 8290, 8029, 7752, 8685, 7847, 7881, 8121, 7811, 870…\n$ divida       &lt;dbl&gt; 73, 88, 65, 85, 74, 87, 79, 72, 83, 111, 74, 105, 66, 59,…\n$ idade        &lt;dbl&gt; 34, 29, 24, 20, 17, 30, 28, 27, 35, 25, 30, 45, 35, 20, 2…\n$ propaganda   &lt;dbl&gt; 22294.48, 27426.47, 27978.66, 28949.65, 22642.27, 27210.6…\n$ escolaridade &lt;dbl&gt; 20, 20, 26, 22, 21, 23, 22, 20, 15, 20, 16, 29, 22, 28, 2…\n$ YEAR_        &lt;dbl&gt; 1989, 1989, 1989, 1989, 1989, 1989, 1989, 1989, 1989, 198…\n$ MONTH_       &lt;dbl&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 1, 2, 3, 4, 5, 6, …\n$ DATE_        &lt;chr&gt; \"JAN 1989\", \"FEB 1989\", \"MAR 1989\", \"APR 1989\", \"MAY 1989…\n\n\n\n\n\nCriar Objeto de Série Temporal\n\n# Salários masculinos como série temporal\nts_men &lt;- ts(db_salarios$men,\n             frequency = 12,      # Mensal\n             start = c(1989, 1))  # Janeiro de 1989\n\n# Visualização\nplot(ts_men, main = \"Salários Masculinos (1989-)\",\n     ylab = \"Salário\", xlab = \"Tempo\")\n\n\n\n\n\n\n\n\n\n\n\nPlot Sazonal\n\nseasonplot(ts_men,\n           col = rainbow(12),\n           year.labels = TRUE,\n           type = \"o\", pch = 16,\n           main = \"Padrão Sazonal de Salários\")\n\n\n\n\n\n\n\n\n\n\n\nDiagnóstico da Série\n\nggtsdisplay(ts_men, main = \"Diagnóstico: Salários Masculinos\")",
    "crumbs": [
      "ARIMA",
      "Lista 7: Séries Temporais (ARIMA)"
    ]
  },
  {
    "objectID": "lista_7.html#ajustando-modelos-arima",
    "href": "lista_7.html#ajustando-modelos-arima",
    "title": "Lista 7: Séries Temporais (ARIMA)",
    "section": "🎯 Ajustando Modelos ARIMA",
    "text": "🎯 Ajustando Modelos ARIMA\n\nModelo 1: ARIMA(1,0,0)\n\nmodelo_100 &lt;- Arima(db_salarios$men, order = c(1, 0, 0))\nsummary(modelo_100)\n\nSeries: db_salarios$men \nARIMA(1,0,0) with non-zero mean \n\nCoefficients:\n         ar1        mean\n      0.4461  16358.8539\ns.e.  0.0870    934.3313\n\nsigma^2 = 33065905:  log likelihood = -1208.22\nAIC=2422.43   AICc=2422.64   BIC=2430.79\n\nTraining set error measures:\n                   ME     RMSE      MAE       MPE    MAPE      MASE        ACF1\nTraining set 22.80781 5702.176 4155.971 -13.46047 30.1633 0.8885625 -0.09098277\n\n\n\n\n\nModelo 2: ARIMA(0,1,0)\n\nmodelo_010 &lt;- Arima(db_salarios$men, order = c(0, 1, 0))\nsummary(modelo_010)\n\nSeries: db_salarios$men \nARIMA(0,1,0) \n\nsigma^2 = 43555282:  log likelihood = -1215.43\nAIC=2432.86   AICc=2432.9   BIC=2435.64\n\nTraining set error measures:\n                   ME     RMSE      MAE       MPE     MAPE      MASE       ACF1\nTraining set 227.1925 6572.087 4638.303 -8.641961 31.89164 0.9916869 -0.4271109\n\n\n\n\n\nModelo 3: Auto ARIMA\n\n\n\n\n\n\nauto.arima()\n\n\n\nFunção que automaticamente seleciona os melhores parâmetros (p, d, q) minimizando AIC/BIC.\n\n\n\n# Encontrar melhor modelo\nauto.arima(db_salarios$men, trace = TRUE)\n\n\n ARIMA(2,1,2) with drift         : Inf\n ARIMA(0,1,0) with drift         : 2434.823\n ARIMA(1,1,0) with drift         : 2412.096\n ARIMA(0,1,1) with drift         : Inf\n ARIMA(0,1,0)                    : 2432.897\n ARIMA(2,1,0) with drift         : 2411.86\n ARIMA(3,1,0) with drift         : 2408.495\n ARIMA(4,1,0) with drift         : 2407.461\n ARIMA(5,1,0) with drift         : 2408.674\n ARIMA(4,1,1) with drift         : Inf\n ARIMA(3,1,1) with drift         : Inf\n ARIMA(5,1,1) with drift         : Inf\n ARIMA(4,1,0)                    : 2405.816\n ARIMA(3,1,0)                    : 2406.731\n ARIMA(5,1,0)                    : 2407.075\n ARIMA(4,1,1)                    : 2394.525\n ARIMA(3,1,1)                    : 2392.515\n ARIMA(2,1,1)                    : 2392.416\n ARIMA(1,1,1)                    : 2391.073\n ARIMA(0,1,1)                    : 2393.07\n ARIMA(1,1,0)                    : 2410.255\n ARIMA(1,1,2)                    : 2392.894\n ARIMA(0,1,2)                    : 2391.92\n ARIMA(2,1,0)                    : 2410.02\n ARIMA(2,1,2)                    : Inf\n ARIMA(1,1,1) with drift         : Inf\n\n Best model: ARIMA(1,1,1)                    \n\n\nSeries: db_salarios$men \nARIMA(1,1,1) \n\nCoefficients:\n         ar1      ma1\n      0.2036  -0.9139\ns.e.  0.1002   0.0347\n\nsigma^2 = 29737029:  log likelihood = -1192.43\nAIC=2390.86   AICc=2391.07   BIC=2399.2\n\n\n\n# Ajustar modelo sugerido\nmodelo_auto &lt;- auto.arima(db_salarios$men)\nsummary(modelo_auto)\n\nSeries: db_salarios$men \nARIMA(1,1,1) \n\nCoefficients:\n         ar1      ma1\n      0.2036  -0.9139\ns.e.  0.1002   0.0347\n\nsigma^2 = 29737029:  log likelihood = -1192.43\nAIC=2390.86   AICc=2391.07   BIC=2399.2\n\nTraining set error measures:\n                   ME     RMSE      MAE       MPE     MAPE      MASE\nTraining set 915.6723 5384.571 3662.003 -5.571742 25.15003 0.7829504\n                    ACF1\nTraining set -0.04692903\n\n\n\n\n\nComparação de Modelos\n\nmodelos_comp &lt;- data.frame(\n  Modelo = c(\"ARIMA(1,0,0)\", \"ARIMA(0,1,0)\", \"Auto\"),\n  AIC = c(AIC(modelo_100), AIC(modelo_010), AIC(modelo_auto)),\n  BIC = c(BIC(modelo_100), BIC(modelo_010), BIC(modelo_auto))\n)\n\nmodelos_comp &lt;- modelos_comp %&gt;%\n  mutate(\n    AIC = round(AIC, 2),\n    BIC = round(BIC, 2),\n    Melhor_AIC = ifelse(AIC == min(AIC), \"★\", \"\"),\n    Melhor_BIC = ifelse(BIC == min(BIC), \"★\", \"\")\n  )\n\nkable(modelos_comp, caption = \"Comparação de Modelos (★ = melhor)\")\n\n\nComparação de Modelos (★ = melhor)\n\n\nModelo\nAIC\nBIC\nMelhor_AIC\nMelhor_BIC\n\n\n\n\nARIMA(1,0,0)\n2422.43\n2430.79\n\n\n\n\nARIMA(0,1,0)\n2432.86\n2435.64\n\n\n\n\nAuto\n2390.86\n2399.20\n★\n★\n\n\n\n\n\n\n\n\nVisualização: Ajustado vs Real\n\n# Dataframe para plot\ndf_plot &lt;- data.frame(\n  Tempo = seq_along(modelo_auto$fitted),\n  Ajustado = as.numeric(modelo_auto$fitted),\n  Real = as.numeric(modelo_auto$x)\n)\n\n# Gráfico\nggplot(df_plot, aes(x = Tempo)) +\n  geom_line(aes(y = Real, color = \"Real\"), linewidth = 1) +\n  geom_line(aes(y = Ajustado, color = \"Ajustado\"), linewidth = 1) +\n  labs(\n    title = \"Modelo ARIMA: Valores Ajustados vs Reais\",\n    x = \"Tempo\",\n    y = \"Salário\",\n    color = \"Série\"\n  ) +\n  scale_color_manual(values = c(\"Real\" = \"blue\", \"Ajustado\" = \"red\")) +\n  theme_minimal() +\n  theme(legend.position = \"bottom\")",
    "crumbs": [
      "ARIMA",
      "Lista 7: Séries Temporais (ARIMA)"
    ]
  },
  {
    "objectID": "lista_7.html#modelo-com-covariáveis",
    "href": "lista_7.html#modelo-com-covariáveis",
    "title": "Lista 7: Séries Temporais (ARIMA)",
    "section": "🔧 Modelo com Covariáveis",
    "text": "🔧 Modelo com Covariáveis\n\n# Matriz de covariáveis\ncovars &lt;- as.matrix(db_salarios[, c(\"horas\", \"divida\", \"idade\", \n                                     \"propaganda\", \"escolaridade\")])\n\n# Auto ARIMA com covariáveis\nmodelo_com_covars &lt;- auto.arima(db_salarios$men, xreg = covars)\nsummary(modelo_com_covars)\n\nSeries: db_salarios$men \nRegression with ARIMA(1,0,0) errors \n\nCoefficients:\n         ar1   intercept   horas   divida     idade  propaganda  escolaridade\n      0.1968  -23753.966  2.0271  34.5286  342.9908      0.2046      -30.3841\ns.e.  0.1000    2752.766  0.2204  20.1900   43.9319      0.0733       41.3101\n\nsigma^2 = 8316739:  log likelihood = -1122.71\nAIC=2261.43   AICc=2262.72   BIC=2283.73\n\nTraining set error measures:\n                    ME     RMSE      MAE       MPE     MAPE      MASE\nTraining set -1.571885 2798.499 2100.857 -2.062733 13.69221 0.4491713\n                     ACF1\nTraining set -0.006183707\n\n\n\n\nCoeficientes e Significância\n\n# Teste de coeficientes\ntest_coef &lt;- coeftest(modelo_com_covars)\n\n# Formatar resultados\nresultados &lt;- data.frame(\n  Variavel = rownames(test_coef),\n  Coeficiente = round(test_coef[, \"Estimate\"], 3),\n  EP = round(test_coef[, \"Std. Error\"], 3),\n  z = round(test_coef[, \"z value\"], 2),\n  p = round(test_coef[, \"Pr(&gt;|z|)\"], 4)\n) %&gt;%\n  mutate(Sig = case_when(\n    p &lt; 0.001 ~ \"***\",\n    p &lt; 0.01 ~ \"**\",\n    p &lt; 0.05 ~ \"*\",\n    TRUE ~ \"\"\n  ))\n\nkable(resultados, caption = \"Coeficientes do Modelo com Covariáveis\")\n\n\nCoeficientes do Modelo com Covariáveis\n\n\n\nVariavel\nCoeficiente\nEP\nz\np\nSig\n\n\n\n\nar1\nar1\n0.197\n0.100\n1.97\n0.0490\n*\n\n\nintercept\nintercept\n-23753.966\n2752.766\n-8.63\n0.0000\n***\n\n\nhoras\nhoras\n2.027\n0.220\n9.20\n0.0000\n***\n\n\ndivida\ndivida\n34.529\n20.190\n1.71\n0.0872\n\n\n\nidade\nidade\n342.991\n43.932\n7.81\n0.0000\n***\n\n\npropaganda\npropaganda\n0.205\n0.073\n2.79\n0.0053\n**\n\n\nescolaridade\nescolaridade\n-30.384\n41.310\n-0.74\n0.4620",
    "crumbs": [
      "ARIMA",
      "Lista 7: Séries Temporais (ARIMA)"
    ]
  },
  {
    "objectID": "lista_7.html#previsões-forecasting",
    "href": "lista_7.html#previsões-forecasting",
    "title": "Lista 7: Séries Temporais (ARIMA)",
    "section": "🔮 Previsões (Forecasting)",
    "text": "🔮 Previsões (Forecasting)\n\nSalários Masculinos: 50 Meses à Frente\n\n# Ajustar modelo\nfit_men &lt;- auto.arima(ts_men)\n\n# Prever 50 meses\nfcast_men &lt;- forecast(fit_men, h = 50)\n\n# Visualizar\nautoplot(fcast_men) +\n  labs(\n    title = \"Previsão de Salários Masculinos (50 meses)\",\n    x = \"Tempo\",\n    y = \"Salário\"\n  ) +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\n\n\nSalários Femininos: Comparação\n\n# Série temporal feminina\nts_women &lt;- ts(db_salarios$women,\n               frequency = 12,\n               start = c(1989, 1))\n\n# Modelo e previsão\nfit_women &lt;- auto.arima(ts_women)\nfcast_women &lt;- forecast(fit_women, h = 50)\n\n# Visualizar\nautoplot(fcast_women) +\n  labs(\n    title = \"Previsão de Salários Femininos (50 meses)\",\n    x = \"Tempo\",\n    y = \"Salário\"\n  ) +\n  theme_minimal()",
    "crumbs": [
      "ARIMA",
      "Lista 7: Séries Temporais (ARIMA)"
    ]
  },
  {
    "objectID": "lista_7.html#diagnóstico-de-resíduos",
    "href": "lista_7.html#diagnóstico-de-resíduos",
    "title": "Lista 7: Séries Temporais (ARIMA)",
    "section": "✅ Diagnóstico de Resíduos",
    "text": "✅ Diagnóstico de Resíduos\n\n\n\n\n\n\nPor que Verificar Resíduos?\n\n\n\nResíduos devem ser ruído branco: - Média zero - Variância constante - Sem autocorrelação - Normalmente distribuídos\nSe resíduos têm padrão → Modelo não capturou toda a informação!\n\n\n\ncheckresiduals(modelo_auto)\n\n\n\n\n\n\n\n\n\n    Ljung-Box test\n\ndata:  Residuals from ARIMA(1,1,1)\nQ* = 10.891, df = 8, p-value = 0.208\n\nModel df: 2.   Total lags used: 10\n\n\n\n\n\n\n\n\n🔍 Interpretando Diagnósticos\n\n\n\n\n\nGráfico 1 (Resíduos ao longo do tempo): - Deve oscilar aleatoriamente em torno de zero - Sem padrões ou tendências\nGráfico 2 (ACF dos resíduos): - Nenhuma barra significativa (exceto lag 0) - Indica ausência de autocorrelação restante\nGráfico 3 (Histograma): - Aproximadamente normal - Centrado em zero\nTeste de Ljung-Box: - p &gt; 0.05 → Resíduos são ruído branco ✓",
    "crumbs": [
      "ARIMA",
      "Lista 7: Séries Temporais (ARIMA)"
    ]
  },
  {
    "objectID": "lista_7.html#material-complementar",
    "href": "lista_7.html#material-complementar",
    "title": "Lista 7: Séries Temporais (ARIMA)",
    "section": "📚 Material Complementar",
    "text": "📚 Material Complementar\n\n\n\nRecursos Adicionais\n\n\n\n\n\n\n📖 Leituras e Vídeos Recomendados\n\n\n\n\n\nLivros: - Hyndman & Athanasopoulos. Forecasting: Principles and Practice\nTutoriais Online: - Prophet (Facebook) - RPubs - Time Series with Prophet\nVídeos em Português: - ARIMA em R - Tutorial Completo - Playlist Séries Temporais",
    "crumbs": [
      "ARIMA",
      "Lista 7: Séries Temporais (ARIMA)"
    ]
  },
  {
    "objectID": "lista_7.html#fluxo-de-trabalho-arima",
    "href": "lista_7.html#fluxo-de-trabalho-arima",
    "title": "Lista 7: Séries Temporais (ARIMA)",
    "section": "🎯 Fluxo de Trabalho ARIMA",
    "text": "🎯 Fluxo de Trabalho ARIMA\n\n\n\n\n\n\nChecklist Passo-a-Passo\n\n\n\n\nVisualizar a série\nTestar estacionaridade (ADF, KPSS)\nTransformar se necessário (diferenciação, Box-Cox)\nIdentificar p, d, q (ACF, PACF, ou auto.arima)\nAjustar modelo\nDiagnosticar resíduos\nComparar modelos (AIC, BIC)\nPrever valores futuros\nValidar com dados holdout",
    "crumbs": [
      "ARIMA",
      "Lista 7: Séries Temporais (ARIMA)"
    ]
  },
  {
    "objectID": "lista_7.html#informações-de-sessão",
    "href": "lista_7.html#informações-de-sessão",
    "title": "Lista 7: Séries Temporais (ARIMA)",
    "section": "🔧 Informações de Sessão",
    "text": "🔧 Informações de Sessão\n\nreport(sessionInfo())\n\nAnalyses were conducted using the R Statistical language (version 4.4.2; R Core\nTeam, 2024) on Windows 11 x64 (build 26100), using the packages Rcpp (version\n1.0.14; Eddelbuettel D et al., 2025), lubridate (version 1.9.4; Grolemund G,\nWickham H, 2011), rlang (version 1.1.6; Henry L, Wickham H, 2025), forecast\n(version 9.0.0; Hyndman R et al., 2026), report (version 0.6.3; Makowski D et\nal., 2023), tibble (version 3.3.1; Müller K, Wickham H, 2026), foreign (version\n0.8.87; R Core Team, 2024), prophet (version 1.0; Taylor S, Letham B, 2021),\ntseries (version 0.10.59; Trapletti A, Hornik K, 2026), ggplot2 (version 4.0.1;\nWickham H, 2016), forcats (version 1.0.0; Wickham H, 2023), stringr (version\n1.5.1; Wickham H, 2023), tidyverse (version 2.0.0; Wickham H et al., 2019),\ndplyr (version 1.1.4; Wickham H et al., 2023), purrr (version 1.0.4; Wickham H,\nHenry L, 2025), readr (version 2.1.5; Wickham H et al., 2024), tidyr (version\n1.3.1; Wickham H et al., 2024), zoo (version 1.8.14; Zeileis A, Grothendieck G,\n2005), lmtest (version 0.9.40; Zeileis A, Hothorn T, 2002) and kableExtra\n(version 1.4.0; Zhu H, 2024).\n\nReferences\n----------\n  - Eddelbuettel D, Francois R, Allaire J, Ushey K, Kou Q, Russell N, Ucar I,\nBates D, Chambers J (2025). _Rcpp: Seamless R and C++ Integration_. R package\nversion 1.0.14, &lt;https://CRAN.R-project.org/package=Rcpp&gt;. Eddelbuettel D,\nFrançois R (2011). \"Rcpp: Seamless R and C++ Integration.\" _Journal of\nStatistical Software_, *40*(8), 1-18. doi:10.18637/jss.v040.i08\n&lt;https://doi.org/10.18637/jss.v040.i08&gt;. Eddelbuettel D (2013). _Seamless R and\nC++ Integration with Rcpp_. Springer, New York. doi:10.1007/978-1-4614-6868-4\n&lt;https://doi.org/10.1007/978-1-4614-6868-4&gt;, ISBN 978-1-4614-6867-7.\nEddelbuettel D, Balamuta J (2018). \"Extending R with C++: A Brief Introduction\nto Rcpp.\" _The American Statistician_, *72*(1), 28-36.\ndoi:10.1080/00031305.2017.1375990\n&lt;https://doi.org/10.1080/00031305.2017.1375990&gt;.\n  - Grolemund G, Wickham H (2011). \"Dates and Times Made Easy with lubridate.\"\n_Journal of Statistical Software_, *40*(3), 1-25.\n&lt;https://www.jstatsoft.org/v40/i03/&gt;.\n  - Henry L, Wickham H (2025). _rlang: Functions for Base Types and Core R and\n'Tidyverse' Features_. R package version 1.1.6,\n&lt;https://CRAN.R-project.org/package=rlang&gt;.\n  - Hyndman R, Athanasopoulos G, Bergmeir C, Caceres G, Chhay L, O'Hara-Wild M,\nPetropoulos F, Razbash S, Wang E, Yasmeen F (2026). _forecast: Forecasting\nfunctions for time series and linear models_. R package version 9.0.0,\n&lt;https://pkg.robjhyndman.com/forecast/&gt;. Hyndman RJ, Khandakar Y (2008).\n\"Automatic time series forecasting: the forecast package for R.\" _Journal of\nStatistical Software_, *27*(3), 1-22. doi:10.18637/jss.v027.i03\n&lt;https://doi.org/10.18637/jss.v027.i03&gt;.\n  - Makowski D, Lüdecke D, Patil I, Thériault R, Ben-Shachar M, Wiernik B (2023).\n\"Automated Results Reporting as a Practical Tool to Improve Reproducibility and\nMethodological Best Practices Adoption.\" _CRAN_.\ndoi:10.32614/CRAN.package.report\n&lt;https://doi.org/10.32614/CRAN.package.report&gt;,\n&lt;https://easystats.github.io/report/&gt;.\n  - Müller K, Wickham H (2026). _tibble: Simple Data Frames_. R package version\n3.3.1, &lt;https://CRAN.R-project.org/package=tibble&gt;.\n  - R Core Team (2024). _foreign: Read Data Stored by 'Minitab', 'S', 'SAS',\n'SPSS', 'Stata', 'Systat', 'Weka', 'dBase', ..._. R package version 0.8-87,\n&lt;https://CRAN.R-project.org/package=foreign&gt;.\n  - R Core Team (2024). _R: A Language and Environment for Statistical\nComputing_. R Foundation for Statistical Computing, Vienna, Austria.\n&lt;https://www.R-project.org/&gt;.\n  - Taylor S, Letham B (2021). _prophet: Automatic Forecasting Procedure_. R\npackage version 1.0, &lt;https://CRAN.R-project.org/package=prophet&gt;.\n  - Trapletti A, Hornik K (2026). _tseries: Time Series Analysis and\nComputational Finance_. R package version 0.10-59,\n&lt;https://CRAN.R-project.org/package=tseries&gt;.\n  - Wickham H (2016). _ggplot2: Elegant Graphics for Data Analysis_.\nSpringer-Verlag New York. ISBN 978-3-319-24277-4,\n&lt;https://ggplot2.tidyverse.org&gt;.\n  - Wickham H (2023). _forcats: Tools for Working with Categorical Variables\n(Factors)_. R package version 1.0.0,\n&lt;https://CRAN.R-project.org/package=forcats&gt;.\n  - Wickham H (2023). _stringr: Simple, Consistent Wrappers for Common String\nOperations_. R package version 1.5.1,\n&lt;https://CRAN.R-project.org/package=stringr&gt;.\n  - Wickham H, Averick M, Bryan J, Chang W, McGowan LD, François R, Grolemund G,\nHayes A, Henry L, Hester J, Kuhn M, Pedersen TL, Miller E, Bache SM, Müller K,\nOoms J, Robinson D, Seidel DP, Spinu V, Takahashi K, Vaughan D, Wilke C, Woo K,\nYutani H (2019). \"Welcome to the tidyverse.\" _Journal of Open Source Software_,\n*4*(43), 1686. doi:10.21105/joss.01686 &lt;https://doi.org/10.21105/joss.01686&gt;.\n  - Wickham H, François R, Henry L, Müller K, Vaughan D (2023). _dplyr: A Grammar\nof Data Manipulation_. R package version 1.1.4,\n&lt;https://CRAN.R-project.org/package=dplyr&gt;.\n  - Wickham H, Henry L (2025). _purrr: Functional Programming Tools_. R package\nversion 1.0.4, &lt;https://CRAN.R-project.org/package=purrr&gt;.\n  - Wickham H, Hester J, Bryan J (2024). _readr: Read Rectangular Text Data_. R\npackage version 2.1.5, &lt;https://CRAN.R-project.org/package=readr&gt;.\n  - Wickham H, Vaughan D, Girlich M (2024). _tidyr: Tidy Messy Data_. R package\nversion 1.3.1, &lt;https://CRAN.R-project.org/package=tidyr&gt;.\n  - Zeileis A, Grothendieck G (2005). \"zoo: S3 Infrastructure for Regular and\nIrregular Time Series.\" _Journal of Statistical Software_, *14*(6), 1-27.\ndoi:10.18637/jss.v014.i06 &lt;https://doi.org/10.18637/jss.v014.i06&gt;.\n  - Zeileis A, Hothorn T (2002). \"Diagnostic Checking in Regression\nRelationships.\" _R News_, *2*(3), 7-10.\n&lt;https://CRAN.R-project.org/doc/Rnews/&gt;.\n  - Zhu H (2024). _kableExtra: Construct Complex Table with 'kable' and Pipe\nSyntax_. R package version 1.4.0,\n&lt;https://CRAN.R-project.org/package=kableExtra&gt;.\n\n\n\n\n\n\n\n\n\n🎓 Resumo da Lista 7\n\n\n\nNesta lista você:\n✅ Compreendeu conceitos fundamentais de séries temporais\n✅ Avaliou estacionaridade visualmente e com testes\n✅ Aplicou diferenciação para tornar séries estacionárias\n✅ Ajustou modelos ARIMA manualmente e com auto.arima\n✅ Incluiu covariáveis em modelos ARIMA\n✅ Fez previsões futuras com intervalos de confiança\n✅ Diagnosticou resíduos para validar modelos\nConceitos-chave: - ARIMA(p,d,q): AR + Diferenciação + MA - Estacionaridade: pré-requisito para ARIMA - ADF test: teste formal de estacionaridade - ACF/PACF: identificar ordem do modelo - auto.arima(): seleção automática de modelo - Resíduos: devem ser ruído branco\nPróximos passos: - Explorar SARIMA (sazonal) - Modelos Prophet para padrões complexos - VAR para múltiplas séries interdependentes - Machine Learning para séries temporais",
    "crumbs": [
      "ARIMA",
      "Lista 7: Séries Temporais (ARIMA)"
    ]
  },
  {
    "objectID": "lista_6.html#pacotes-necessários",
    "href": "lista_6.html#pacotes-necessários",
    "title": "Lista 6: Análise de Sobrevida",
    "section": "📦 Pacotes necessários",
    "text": "📦 Pacotes necessários\n\npacotes &lt;- c(\n  \"tidyverse\", \"foreign\", \"ggplot2\", \"kableExtra\",\n  \"survival\", \"ggsurvfit\", \"survminer\", \"broom\",\n  \"gtsummary\", \"report\", \"coin\"\n)\n\npacotes_faltantes &lt;- pacotes[!pacotes %in% installed.packages()[, \"Package\"]]\nif (length(pacotes_faltantes) &gt; 0) {\n  install.packages(pacotes_faltantes, dependencies = TRUE)\n}\n\ninvisible(lapply(pacotes, library, character.only = TRUE))\ncat(\"✓ Pacotes de sobrevida carregados!\\n\")\n\n✓ Pacotes de sobrevida carregados!",
    "crumbs": [
      "SURVIVAL",
      "Lista 6: Análise de Sobrevida"
    ]
  },
  {
    "objectID": "lista_6_1.html",
    "href": "lista_6_1.html",
    "title": "Lista 6.1: Cox com Covariáveis Tempo-Dependentes",
    "section": "",
    "text": "📖 Contexto do Estudo",
    "crumbs": [
      "SURVIVAL",
      "Lista 6.1: Cox com Covariáveis Tempo-Dependentes"
    ]
  },
  {
    "objectID": "lista_6_1.html#contexto-do-estudo",
    "href": "lista_6_1.html#contexto-do-estudo",
    "title": "Lista 6.1: Cox com Covariáveis Tempo-Dependentes",
    "section": "",
    "text": "Estudo de Transplante Renal\n\n\n\nAmostra: 628 pacientes de serviço de nefrologia\nSeguimento: ~1000 dias\nVariáveis: - time: Tempo de seguimento - morte: Óbito (evento de interesse) - treat: Realizou transplante? (0 = não, 1 = sim) - Tempo_dialise: Tempo em diálise (meses) - age: Idade - race: Raça (branco vs negro/pardo)\nPergunta: Transplante aumenta sobrevida? Mas… e se o efeito muda ao longo do tempo?",
    "crumbs": [
      "SURVIVAL",
      "Lista 6.1: Cox com Covariáveis Tempo-Dependentes"
    ]
  },
  {
    "objectID": "lista_6_1.html#pacotes",
    "href": "lista_6_1.html#pacotes",
    "title": "Lista 6.1: Cox com Covariáveis Tempo-Dependentes",
    "section": "📦 Pacotes",
    "text": "📦 Pacotes\n\npacotes &lt;- c(\n  \"tidyverse\", \"foreign\", \"ggplot2\", \"kableExtra\",\n  \"survival\", \"ggsurvfit\", \"survminer\", \"broom\",\n  \"gtsummary\", \"coin\", \"report\"\n)\n\npacotes_faltantes &lt;- pacotes[!pacotes %in% installed.packages()[, \"Package\"]]\nif (length(pacotes_faltantes) &gt; 0) {\n  install.packages(pacotes_faltantes, dependencies = TRUE)\n}\n\ninvisible(lapply(pacotes, library, character.only = TRUE))\ncat(\"✓ Pacotes carregados!\\n\")\n\n✓ Pacotes carregados!",
    "crumbs": [
      "SURVIVAL",
      "Lista 6.1: Cox com Covariáveis Tempo-Dependentes"
    ]
  },
  {
    "objectID": "lista_6_1.html#preparação-dos-dados",
    "href": "lista_6_1.html#preparação-dos-dados",
    "title": "Lista 6.1: Cox com Covariáveis Tempo-Dependentes",
    "section": "📥 Preparação dos Dados",
    "text": "📥 Preparação dos Dados\n\n# Carregar e preparar\noriginal &lt;- read.spss(\"Cox tempo dependente 2_1.sav\", \n                      to.data.frame = TRUE)\n\n# Converter tipos\ndb &lt;- original %&gt;%\n  mutate(\n    morte = as.integer(morte == \"Sim\"),\n    treat = as.factor(treat)\n  )\n\nglimpse(db)\n\nRows: 628\nColumns: 7\n$ ID            &lt;dbl&gt; 112, 91, 113, 150, 22, 139, 104, 590, 189, 171, 338, 492…\n$ age           &lt;dbl&gt; 35, 33, 35, 31, 33, 43, 25, 35, 29, 27, 35, 23, 24, 23, …\n$ race          &lt;fct&gt; branco, branco, branco, branco, branco, branco, branco, …\n$ treat         &lt;fct&gt; 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1,…\n$ Tempo_dialise &lt;dbl&gt; 51, 67, 88, 156, 12, 139, 90, 25, 187, 34, 29, 78, 63, 8…\n$ time          &lt;dbl&gt; 1172, 762, 734, 720, 659, 658, 655, 654, 634, 630, 621, …\n$ morte         &lt;int&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n\n\n\n\nVerificar Dados Faltantes\n\ndb %&gt;%\n  summarise(across(everything(), ~sum(is.na(.)))) %&gt;%\n  pivot_longer(everything(), names_to = \"Variável\", values_to = \"NAs\") %&gt;%\n  kable(caption = \"Dados Faltantes por Variável\")\n\n\nDados Faltantes por Variável\n\n\nVariável\nNAs\n\n\n\n\nID\n0\n\n\nage\n5\n\n\nrace\n6\n\n\ntreat\n0\n\n\nTempo_dialise\n0\n\n\ntime\n0\n\n\nmorte\n0",
    "crumbs": [
      "SURVIVAL",
      "Lista 6.1: Cox com Covariáveis Tempo-Dependentes"
    ]
  },
  {
    "objectID": "lista_6_1.html#revisão-análise-cox-padrão",
    "href": "lista_6_1.html#revisão-análise-cox-padrão",
    "title": "Lista 6.1: Cox com Covariáveis Tempo-Dependentes",
    "section": "🔄 Revisão: Análise Cox Padrão",
    "text": "🔄 Revisão: Análise Cox Padrão\n\nObjeto de Sobrevida\n\nsurv_obj &lt;- Surv(time = db$time, event = db$morte)\n\n\n\n\nCurva de Kaplan-Meier\n\nfit_km &lt;- survfit(surv_obj ~ treat, data = db)\n\nggsurvfit(fit_km, linewidth = 1.2) +\n  labs(\n    title = \"Sobrevida: Transplante vs Não-Transplante\",\n    x = \"Tempo (dias)\",\n    y = \"Probabilidade de Sobrevida\"\n  ) +\n  add_confidence_interval(alpha = 0.2) +\n  add_risktable() +\n  scale_ggsurvfit() +\n  scale_x_continuous(breaks = seq(0, 1000, by = 100)) +\n  theme_minimal()\n\nScale for x is already present.\nAdding another scale for x, which will replace the existing scale.\n\n\n\n\n\n\n\n\n\n\n\n\nTestes de Comparação\n\n# Log-rank\nlogrank_test(surv_obj ~ treat, data = db, type = \"logrank\")\n\n\n    Asymptotic Two-Sample Logrank Test\n\ndata:  surv_obj by treat (0, 1)\nZ = -2.5984, p-value = 0.009365\nalternative hypothesis: true theta is not equal to 1\n\n\n\n\n\nModelo Cox Padrão\n\ncox_padrao &lt;- coxph(surv_obj ~ treat, data = db)\n\ntbl_regression(cox_padrao, \n               exponentiate = TRUE,\n               label = list(treat ~ \"Transplante\"))\n\n\n\n\n\n\n\n\n\n\n\n\n\nCharacteristic\nHR\n95% CI\np-value\n\n\n\n\nTransplante\n\n\n\n\n\n\n\n\n    0\n—\n—\n\n\n\n\n    1\n0.79\n0.67, 0.94\n0.009\n\n\n\nAbbreviations: CI = Confidence Interval, HR = Hazard Ratio",
    "crumbs": [
      "SURVIVAL",
      "Lista 6.1: Cox com Covariáveis Tempo-Dependentes"
    ]
  },
  {
    "objectID": "lista_6_1.html#problema-violação-de-proporcionalidade",
    "href": "lista_6_1.html#problema-violação-de-proporcionalidade",
    "title": "Lista 6.1: Cox com Covariáveis Tempo-Dependentes",
    "section": "⚠️ Problema: Violação de Proporcionalidade",
    "text": "⚠️ Problema: Violação de Proporcionalidade\n\nTeste de Schoenfeld\n\ntest_prop &lt;- cox.zph(cox_padrao)\nprint(test_prop)\n\n       chisq df     p\ntreat   3.11  1 0.078\nGLOBAL  3.11  1 0.078\n\n\n\n\n\n\n\n\n🚨 Violação Detectada!\n\n\n\np &lt; 0.05 → Riscos NÃO são proporcionais!\nO efeito do transplante muda ao longo do tempo. Modelo Cox padrão não é apropriado!\n\n\n\n\n\nVisualização dos Resíduos\n\nggcoxzph(test_prop, point.size = 0.5)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n🔍 Interpretando o Gráfico\n\n\n\n\n\nO que procurar: - Linha horizontal: Proporcionalidade OK - Tendência clara: Violação! Efeito muda com tempo\nNeste caso: Linha de suavização tem inclinação → β(t) não é constante",
    "crumbs": [
      "SURVIVAL",
      "Lista 6.1: Cox com Covariáveis Tempo-Dependentes"
    ]
  },
  {
    "objectID": "lista_6_1.html#solução-covariáveis-tempo-dependentes",
    "href": "lista_6_1.html#solução-covariáveis-tempo-dependentes",
    "title": "Lista 6.1: Cox com Covariáveis Tempo-Dependentes",
    "section": "🔧 Solução: Covariáveis Tempo-Dependentes",
    "text": "🔧 Solução: Covariáveis Tempo-Dependentes\n\n\n\n\n\n\nO que são Covariáveis Tempo-Dependentes?\n\n\n\nPermitem que o efeito de uma variável mude ao longo do tempo.\nModelo padrão: β é constante\nModelo tempo-dependente: β(t) varia com tempo\nTrês abordagens comuns:\n\nLinear: x × t → Efeito muda linearmente\nLogarítmica: x × log(t) → Mudança desacelera\nThreshold: x × (t &gt; corte) → Dois períodos distintos\n\n\n\n\n\nIdentificando a Covariável\n\n\n\n\n\n\nFundamentação Teórica!\n\n\n\nPela literatura médica: Tempo em diálise afeta diferentemente pacientes em diferentes estágios.\nHipótese: Efeito do tempo em diálise não é constante ao longo do acompanhamento.\n\n\n\n# Verificar variável\nglimpse(db$Tempo_dialise)\n\n num [1:628] 51 67 88 156 12 139 90 25 187 34 ...",
    "crumbs": [
      "SURVIVAL",
      "Lista 6.1: Cox com Covariáveis Tempo-Dependentes"
    ]
  },
  {
    "objectID": "lista_6_1.html#modelagem-tempo-dependente",
    "href": "lista_6_1.html#modelagem-tempo-dependente",
    "title": "Lista 6.1: Cox com Covariáveis Tempo-Dependentes",
    "section": "📊 Modelagem Tempo-Dependente",
    "text": "📊 Modelagem Tempo-Dependente\n\nModelo 1: Sem Tempo-Dependência (Baseline)\n\nmodelo_base &lt;- coxph(\n  surv_obj ~ treat + Tempo_dialise,\n  data = db\n)\n\nsummary(modelo_base)\n\nCall:\ncoxph(formula = surv_obj ~ treat + Tempo_dialise, data = db)\n\n  n= 628, number of events= 508 \n\n                    coef  exp(coef)   se(coef)       z Pr(&gt;|z|)    \ntreat1         0.0618983  1.0638541  0.0899990   0.688    0.492    \nTempo_dialise -0.0084493  0.9915863  0.0007709 -10.960   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n              exp(coef) exp(-coef) lower .95 upper .95\ntreat1           1.0639      0.940    0.8918    1.2691\nTempo_dialise    0.9916      1.008    0.9901    0.9931\n\nConcordance= 0.75  (se = 0.012 )\nLikelihood ratio test= 151.4  on 2 df,   p=&lt;2e-16\nWald test            = 121.2  on 2 df,   p=&lt;2e-16\nScore (logrank) test = 120.6  on 2 df,   p=&lt;2e-16\n\n\n\n\n\nModelo 2: Mudança Linear\n\nmodelo_linear &lt;- coxph(\n  surv_obj ~ treat + Tempo_dialise + tt(Tempo_dialise),\n  data = db,\n  tt = function(x, t, ...) x * t\n)\n\nsummary(modelo_linear)\n\nCall:\ncoxph(formula = surv_obj ~ treat + Tempo_dialise + tt(Tempo_dialise), \n    data = db, tt = function(x, t, ...) x * t)\n\n  n= 628, number of events= 508 \n\n                        coef  exp(coef)   se(coef)       z Pr(&gt;|z|)    \ntreat1            -1.600e-02  9.841e-01  9.168e-02  -0.175    0.861    \nTempo_dialise     -2.378e-02  9.765e-01  1.506e-03 -15.787   &lt;2e-16 ***\ntt(Tempo_dialise)  7.070e-05  1.000e+00  5.184e-06  13.637   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n                  exp(coef) exp(-coef) lower .95 upper .95\ntreat1               0.9841     1.0161    0.8223    1.1778\nTempo_dialise        0.9765     1.0241    0.9736    0.9794\ntt(Tempo_dialise)    1.0001     0.9999    1.0001    1.0001\n\nConcordance= 0.761  (se = 0.009 )\nLikelihood ratio test= 337.6  on 3 df,   p=&lt;2e-16\nWald test            = 249.3  on 3 df,   p=&lt;2e-16\nScore (logrank) test = 229.1  on 3 df,   p=&lt;2e-16\n\n\n\n\n\n\n\n\n📊 Interpretação\n\n\n\nTempo_dialise: Efeito no tempo t = 0\ntt(Tempo_dialise): Mudança do efeito por unidade de tempo\nEfeito total em tempo t:\nβ(t) = β₀ + β₁ × t\n\n\n\n\n\nModelo 3: Mudança Logarítmica\n\nmodelo_log &lt;- coxph(\n  surv_obj ~ treat + Tempo_dialise + tt(Tempo_dialise),\n  data = db,\n  tt = function(x, t, ...) x * log(t)\n)\n\nsummary(modelo_log)\n\nCall:\ncoxph(formula = surv_obj ~ treat + Tempo_dialise + tt(Tempo_dialise), \n    data = db, tt = function(x, t, ...) x * log(t))\n\n  n= 628, number of events= 508 \n\n                       coef exp(coef)  se(coef)      z Pr(&gt;|z|)    \ntreat1            -0.071106  0.931363  0.092369  -0.77    0.441    \nTempo_dialise     -0.097417  0.907178  0.005942 -16.40   &lt;2e-16 ***\ntt(Tempo_dialise)  0.017178  1.017326  0.001087  15.80   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n                  exp(coef) exp(-coef) lower .95 upper .95\ntreat1               0.9314      1.074    0.7771    1.1162\nTempo_dialise        0.9072      1.102    0.8967    0.9178\ntt(Tempo_dialise)    1.0173      0.983    1.0152    1.0195\n\nConcordance= 0.759  (se = 0.01 )\nLikelihood ratio test= 461.5  on 3 df,   p=&lt;2e-16\nWald test            = 284.6  on 3 df,   p=&lt;2e-16\nScore (logrank) test = 223.9  on 3 df,   p=&lt;2e-16\n\n\n\n\n\nModelo 4: Threshold (Corte em 650 dias)\n\nmodelo_threshold &lt;- coxph(\n  surv_obj ~ treat + Tempo_dialise + tt(Tempo_dialise),\n  data = db,\n  tt = function(x, t, ...) x * (t &gt; 650)\n)\n\nsummary(modelo_threshold)\n\nCall:\ncoxph(formula = surv_obj ~ treat + Tempo_dialise + tt(Tempo_dialise), \n    data = db, tt = function(x, t, ...) x * (t &gt; 650))\n\n  n= 628, number of events= 508 \n\n                        coef  exp(coef)   se(coef)       z Pr(&gt;|z|)    \ntreat1             0.0617615  1.0637086  0.0900051   0.686    0.493    \nTempo_dialise     -0.0084524  0.9915832  0.0007713 -10.958   &lt;2e-16 ***\ntt(Tempo_dialise)  0.0028519  1.0028560  0.0221016   0.129    0.897    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n                  exp(coef) exp(-coef) lower .95 upper .95\ntreat1               1.0637     0.9401    0.8917    1.2689\nTempo_dialise        0.9916     1.0085    0.9901    0.9931\ntt(Tempo_dialise)    1.0029     0.9972    0.9603    1.0473\n\nConcordance= 0.75  (se = 0.01 )\nLikelihood ratio test= 151.5  on 3 df,   p=&lt;2e-16\nWald test            = 121.2  on 3 df,   p=&lt;2e-16\nScore (logrank) test = 120.6  on 3 df,   p=&lt;2e-16",
    "crumbs": [
      "SURVIVAL",
      "Lista 6.1: Cox com Covariáveis Tempo-Dependentes"
    ]
  },
  {
    "objectID": "lista_6_1.html#comparação-de-modelos",
    "href": "lista_6_1.html#comparação-de-modelos",
    "title": "Lista 6.1: Cox com Covariáveis Tempo-Dependentes",
    "section": "🎯 Comparação de Modelos",
    "text": "🎯 Comparação de Modelos\n\ncomparacao &lt;- data.frame(\n  Modelo = c(\"Base\", \"Linear\", \"Log\", \"Threshold (650)\"),\n  AIC = c(\n    AIC(modelo_base),\n    AIC(modelo_linear),\n    AIC(modelo_log),\n    AIC(modelo_threshold)\n  ),\n  BIC = c(\n    BIC(modelo_base),\n    BIC(modelo_linear),\n    BIC(modelo_log),\n    BIC(modelo_threshold)\n  )\n) %&gt;%\n  mutate(\n    AIC = round(AIC, 2),\n    BIC = round(BIC, 2),\n    Melhor_AIC = ifelse(AIC == min(AIC), \"★\", \"\"),\n    Melhor_BIC = ifelse(BIC == min(BIC), \"★\", \"\")\n  )\n\nkable(comparacao, caption = \"Comparação de Modelos (★ = melhor)\")\n\n\nComparação de Modelos (★ = melhor)\n\n\nModelo\nAIC\nBIC\nMelhor_AIC\nMelhor_BIC\n\n\n\n\nBase\n5771.69\n5780.15\n\n\n\n\nLinear\n5587.56\n5600.26\n\n\n\n\nLog\n5463.65\n5476.34\n★\n★\n\n\nThreshold (650)\n5773.67\n5786.36\n\n\n\n\n\n\n\n\n\n\n\n\n\n📊 Resultado\n\n\n\nModelo logarítmico apresenta melhor ajuste (menor AIC/BIC)!\n\n\n\n\nVisualizando β(t) para Tempo_dialise\n\n# Resíduos de Schoenfeld para Tempo_dialise\ncox_base_dialise &lt;- coxph(surv_obj ~ treat + Tempo_dialise, data = db)\n\nggcoxzph(\n  cox.zph(cox_base_dialise),\n  var = \"Tempo_dialise\",\n  point.size = 0.5\n)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nObserve tendência aproximadamente linear → Justifica modelo linear/log",
    "crumbs": [
      "SURVIVAL",
      "Lista 6.1: Cox com Covariáveis Tempo-Dependentes"
    ]
  },
  {
    "objectID": "lista_6_1.html#modelo-completo-com-covariáveis",
    "href": "lista_6_1.html#modelo-completo-com-covariáveis",
    "title": "Lista 6.1: Cox com Covariáveis Tempo-Dependentes",
    "section": "🔍 Modelo Completo com Covariáveis",
    "text": "🔍 Modelo Completo com Covariáveis\n\nmodelo_completo &lt;- coxph(\n  surv_obj ~ age + race + treat + Tempo_dialise + tt(Tempo_dialise),\n  data = db,\n  tt = function(x, t, ...) x * t\n)\n\nsummary(modelo_completo)\n\nCall:\ncoxph(formula = surv_obj ~ age + race + treat + Tempo_dialise + \n    tt(Tempo_dialise), data = db, tt = function(x, t, ...) x * \n    t)\n\n  n= 617, number of events= 500 \n   (11 observations deleted due to missingness)\n\n                        coef  exp(coef)   se(coef)       z Pr(&gt;|z|)    \nage               -5.531e-03  9.945e-01  7.273e-03  -0.761  0.44693    \nracenegro/pardo   -3.420e-01  7.103e-01  1.081e-01  -3.162  0.00156 ** \ntreat1             4.221e-02  1.043e+00  9.337e-02   0.452  0.65123    \nTempo_dialise     -2.367e-02  9.766e-01  1.512e-03 -15.661  &lt; 2e-16 ***\ntt(Tempo_dialise)  6.881e-05  1.000e+00  5.196e-06  13.242  &lt; 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n                  exp(coef) exp(-coef) lower .95 upper .95\nage                  0.9945     1.0055    0.9804    1.0088\nracenegro/pardo      0.7103     1.4078    0.5747    0.8781\ntreat1               1.0431     0.9587    0.8687    1.2526\nTempo_dialise        0.9766     1.0240    0.9737    0.9795\ntt(Tempo_dialise)    1.0001     0.9999    1.0001    1.0001\n\nConcordance= 0.765  (se = 0.009 )\nLikelihood ratio test= 343.2  on 5 df,   p=&lt;2e-16\nWald test            = 259.4  on 5 df,   p=&lt;2e-16\nScore (logrank) test = 243.3  on 5 df,   p=&lt;2e-16\n\n\n\n\nTabela Formatada\n\ntbl_regression(\n  modelo_completo,\n  exponentiate = TRUE,\n  label = list(\n    age ~ \"Idade\",\n    race ~ \"Raça\",\n    treat ~ \"Transplante\",\n    Tempo_dialise ~ \"Tempo Diálise (t=0)\",\n    `tt(Tempo_dialise)` ~ \"Δ Tempo Diálise (por dia)\"\n  )\n) %&gt;%\n  bold_p()\n\n\n\n\n\n\n\n\n\n\n\n\n\nCharacteristic\nHR\n95% CI\np-value\n\n\n\n\nIdade\n0.99\n0.98, 1.01\n0.4\n\n\nRaça\n\n\n\n\n\n\n\n\n    branco\n—\n—\n\n\n\n\n    negro/pardo\n0.71\n0.57, 0.88\n0.002\n\n\nTransplante\n\n\n\n\n\n\n\n\n    0\n—\n—\n\n\n\n\n    1\n1.04\n0.87, 1.25\n0.7\n\n\nTempo Diálise (t=0)\n0.98\n0.97, 0.98\n&lt;0.001\n\n\nΔ Tempo Diálise (por dia)\n1.00\n1.00, 1.00\n&lt;0.001\n\n\n\nAbbreviations: CI = Confidence Interval, HR = Hazard Ratio",
    "crumbs": [
      "SURVIVAL",
      "Lista 6.1: Cox com Covariáveis Tempo-Dependentes"
    ]
  },
  {
    "objectID": "lista_6_1.html#análise-estratificada-por-raça",
    "href": "lista_6_1.html#análise-estratificada-por-raça",
    "title": "Lista 6.1: Cox com Covariáveis Tempo-Dependentes",
    "section": "📊 Análise Estratificada por Raça",
    "text": "📊 Análise Estratificada por Raça\n\n\n\n\n\n\nNote\n\n\n\nRaça mostrou-se significativa! Vamos explorar separadamente.\n\n\n\nDados: Brancos\n\ndb_branco &lt;- db %&gt;% filter(race == \"branco\")\nsurv_branco &lt;- Surv(time = db_branco$time, event = db_branco$morte)\n\nfit_branco &lt;- survfit(surv_branco ~ treat, data = db_branco)\n\n\n\nCurva K-M: Brancos\n\nggsurvfit(fit_branco, linewidth = 1.2) +\n  labs(\n    title = \"Sobrevida: Pacientes Brancos\",\n    x = \"Tempo (dias)\",\n    y = \"Probabilidade de Sobrevida\"\n  ) +\n  add_confidence_interval(alpha = 0.2) +\n  scale_ggsurvfit() +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\n\n\nModelo Cox: Brancos\n\nmodelo_branco &lt;- coxph(\n  surv_branco ~ age + treat + Tempo_dialise + tt(Tempo_dialise),\n  data = db_branco,\n  tt = function(x, t, ...) x * t\n)\n\ntbl_regression(modelo_branco, exponentiate = TRUE)\n\n\n\n\n\n\n\n\n\n\n\n\n\nCharacteristic\nHR\n95% CI\np-value\n\n\n\n\nage\n1.00\n0.98, 1.02\n&gt;0.9\n\n\ntreat\n\n\n\n\n\n\n\n\n    0\n—\n—\n\n\n\n\n    1\n1.03\n0.83, 1.27\n0.8\n\n\nTempo_dialise\n0.98\n0.97, 0.98\n&lt;0.001\n\n\ntt(Tempo_dialise)\n1.00\n1.00, 1.00\n&lt;0.001\n\n\n\nAbbreviations: CI = Confidence Interval, HR = Hazard Ratio\n\n\n\n\n\n\n\n\n\n\n\n\nDados: Negros/Pardos\n\ndb_pardo_negro &lt;- db %&gt;% filter(race == \"negro/pardo\")\nsurv_pardo_negro &lt;- Surv(time = db_pardo_negro$time, \n                         event = db_pardo_negro$morte)\n\nfit_pardo_negro &lt;- survfit(surv_pardo_negro ~ treat, \n                           data = db_pardo_negro)\n\n\n\nCurva K-M: Negros/Pardos\n\nggsurvfit(fit_pardo_negro, linewidth = 1.2) +\n  labs(\n    title = \"Sobrevida: Pacientes Negros/Pardos\",\n    x = \"Tempo (dias)\",\n    y = \"Probabilidade de Sobrevida\"\n  ) +\n  add_confidence_interval(alpha = 0.2) +\n  scale_ggsurvfit() +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\n\n\nModelo Cox: Negros/Pardos\n\nmodelo_pardo_negro &lt;- coxph(\n  surv_pardo_negro ~ age + treat + Tempo_dialise + tt(Tempo_dialise),\n  data = db_pardo_negro,\n  tt = function(x, t, ...) x * t\n)\n\ntbl_regression(modelo_pardo_negro, exponentiate = TRUE)\n\n\n\n\n\n\n\n\n\n\n\n\n\nCharacteristic\nHR\n95% CI\np-value\n\n\n\n\nage\n0.98\n0.95, 1.01\n0.2\n\n\ntreat\n\n\n\n\n\n\n\n\n    0\n—\n—\n\n\n\n\n    1\n1.08\n0.74, 1.58\n0.7\n\n\nTempo_dialise\n0.98\n0.97, 0.98\n&lt;0.001\n\n\ntt(Tempo_dialise)\n1.00\n1.00, 1.00\n&lt;0.001\n\n\n\nAbbreviations: CI = Confidence Interval, HR = Hazard Ratio",
    "crumbs": [
      "SURVIVAL",
      "Lista 6.1: Cox com Covariáveis Tempo-Dependentes"
    ]
  },
  {
    "objectID": "lista_6_1.html#comparação-entre-grupos-raciais",
    "href": "lista_6_1.html#comparação-entre-grupos-raciais",
    "title": "Lista 6.1: Cox com Covariáveis Tempo-Dependentes",
    "section": "📊 Comparação Entre Grupos Raciais",
    "text": "📊 Comparação Entre Grupos Raciais\n\n# Extrair HRs de transplante\nhr_branco &lt;- exp(coef(modelo_branco)[\"treat1\"])\nhr_pardo_negro &lt;- exp(coef(modelo_pardo_negro)[\"treat1\"])\n\ncomparacao_raca &lt;- data.frame(\n  Grupo = c(\"Brancos\", \"Negros/Pardos\"),\n  HR_Transplante = c(hr_branco, hr_pardo_negro),\n  IC_Lower = c(\n    exp(confint(modelo_branco)[\"treat1\", 1]),\n    exp(confint(modelo_pardo_negro)[\"treat1\", 1])\n  ),\n  IC_Upper = c(\n    exp(confint(modelo_branco)[\"treat1\", 2]),\n    exp(confint(modelo_pardo_negro)[\"treat1\", 2])\n  )\n) %&gt;%\n  mutate(across(where(is.numeric), ~round(., 3)))\n\nkable(comparacao_raca, \n      caption = \"HR do Transplante por Grupo Racial\")\n\n\nHR do Transplante por Grupo Racial\n\n\nGrupo\nHR_Transplante\nIC_Lower\nIC_Upper\n\n\n\n\nBrancos\n1.029\n0.834\n1.270\n\n\nNegros/Pardos\n1.081\n0.739\n1.582",
    "crumbs": [
      "SURVIVAL",
      "Lista 6.1: Cox com Covariáveis Tempo-Dependentes"
    ]
  },
  {
    "objectID": "lista_6_1.html#conceitos-chave",
    "href": "lista_6_1.html#conceitos-chave",
    "title": "Lista 6.1: Cox com Covariáveis Tempo-Dependentes",
    "section": "🎓 Conceitos-Chave",
    "text": "🎓 Conceitos-Chave\n\n\n\n\n\n\n📚 Resumo Conceitual\n\n\n\n\n\nProporcionalidade de Riscos: - Pressuposto: HR constante ao longo do tempo - Teste: Resíduos de Schoenfeld - p &lt; 0.05 → Violação!\nCovariáveis Tempo-Dependentes: - Permitem β(t) variar com tempo - Três formas: linear, log, threshold - Escolha baseada em AIC/BIC + teoria\nInterpretação: - β₀: Efeito no tempo inicial - β₁: Taxa de mudança do efeito - β(t) = β₀ + β₁ × f(t) onde f(t) = t, log(t), ou (t&gt;corte)\nQuando usar: - Teste de proporcionalidade significativo - Teoria sugere efeito muda com tempo - Gráfico de resíduos mostra tendência",
    "crumbs": [
      "SURVIVAL",
      "Lista 6.1: Cox com Covariáveis Tempo-Dependentes"
    ]
  },
  {
    "objectID": "lista_6_1.html#material-complementar",
    "href": "lista_6_1.html#material-complementar",
    "title": "Lista 6.1: Cox com Covariáveis Tempo-Dependentes",
    "section": "📚 Material Complementar",
    "text": "📚 Material Complementar\n\n\n\nRecursos Adicionais\n\n\n\n\n\n\n📖 Leituras Avançadas\n\n\n\n\n\nTutoriais: - UCLA: Survival Analysis in R - YouTube: Time-Dependent Cox\nConceitos: - Função tt(): transforma covariável ao longo do tempo - tmerge(): alternativa para criar dados tempo-dependentes - Stratificação vs tempo-dependência",
    "crumbs": [
      "SURVIVAL",
      "Lista 6.1: Cox com Covariáveis Tempo-Dependentes"
    ]
  },
  {
    "objectID": "lista_6_1.html#informações-de-sessão",
    "href": "lista_6_1.html#informações-de-sessão",
    "title": "Lista 6.1: Cox com Covariáveis Tempo-Dependentes",
    "section": "🔧 Informações de Sessão",
    "text": "🔧 Informações de Sessão\n\nreport(sessionInfo())\n\nAnalyses were conducted using the R Statistical language (version 4.4.2; R Core\nTeam, 2024) on Windows 11 x64 (build 26100), using the packages lubridate\n(version 1.9.4; Grolemund G, Wickham H, 2011), coin (version 1.4.3; Hothorn T\net al., 2006), ggpubr (version 0.6.0; Kassambara A, 2023), survminer (version\n0.5.1; Kassambara A et al., 2025), report (version 0.6.3; Makowski D et al.,\n2023), tibble (version 3.3.1; Müller K, Wickham H, 2026), foreign (version\n0.8.87; R Core Team, 2024), broom (version 1.0.7; Robinson D et al., 2024),\nggsurvfit (version 1.2.0; Sjoberg D et al., 2025), gtsummary (version 2.1.0;\nSjoberg D et al., 2021), survival (version 3.7.0; Therneau T, 2024), ggplot2\n(version 4.0.1; Wickham H, 2016), forcats (version 1.0.0; Wickham H, 2023),\nstringr (version 1.5.1; Wickham H, 2023), tidyverse (version 2.0.0; Wickham H\net al., 2019), dplyr (version 1.1.4; Wickham H et al., 2023), purrr (version\n1.0.4; Wickham H, Henry L, 2025), readr (version 2.1.5; Wickham H et al.,\n2024), tidyr (version 1.3.1; Wickham H et al., 2024) and kableExtra (version\n1.4.0; Zhu H, 2024).\n\nReferences\n----------\n  - Grolemund G, Wickham H (2011). \"Dates and Times Made Easy with lubridate.\"\n_Journal of Statistical Software_, *40*(3), 1-25.\n&lt;https://www.jstatsoft.org/v40/i03/&gt;.\n  - Hothorn T, Hornik K, van de Wiel MA, Zeileis A (2006). \"A Lego system for\nconditional inference.\" _The American Statistician_, *60*(3), 257-263.\ndoi:10.1198/000313006X118430 &lt;https://doi.org/10.1198/000313006X118430&gt;.\nHothorn T, Hornik K, van de Wiel MA, Zeileis A (2008). \"Implementing a class of\npermutation tests: The coin package.\" _Journal of Statistical Software_,\n*28*(8), 1-23. doi:10.18637/jss.v028.i08\n&lt;https://doi.org/10.18637/jss.v028.i08&gt;.\n  - Kassambara A (2023). _ggpubr: 'ggplot2' Based Publication Ready Plots_. R\npackage version 0.6.0, &lt;https://CRAN.R-project.org/package=ggpubr&gt;.\n  - Kassambara A, Kosinski M, Biecek P (2025). _survminer: Drawing Survival\nCurves using 'ggplot2'_. R package version 0.5.1,\n&lt;https://CRAN.R-project.org/package=survminer&gt;.\n  - Makowski D, Lüdecke D, Patil I, Thériault R, Ben-Shachar M, Wiernik B (2023).\n\"Automated Results Reporting as a Practical Tool to Improve Reproducibility and\nMethodological Best Practices Adoption.\" _CRAN_.\ndoi:10.32614/CRAN.package.report\n&lt;https://doi.org/10.32614/CRAN.package.report&gt;,\n&lt;https://easystats.github.io/report/&gt;.\n  - Müller K, Wickham H (2026). _tibble: Simple Data Frames_. R package version\n3.3.1, &lt;https://CRAN.R-project.org/package=tibble&gt;.\n  - R Core Team (2024). _foreign: Read Data Stored by 'Minitab', 'S', 'SAS',\n'SPSS', 'Stata', 'Systat', 'Weka', 'dBase', ..._. R package version 0.8-87,\n&lt;https://CRAN.R-project.org/package=foreign&gt;.\n  - R Core Team (2024). _R: A Language and Environment for Statistical\nComputing_. R Foundation for Statistical Computing, Vienna, Austria.\n&lt;https://www.R-project.org/&gt;.\n  - Robinson D, Hayes A, Couch S (2024). _broom: Convert Statistical Objects into\nTidy Tibbles_. R package version 1.0.7,\n&lt;https://CRAN.R-project.org/package=broom&gt;.\n  - Sjoberg D, Baillie M, Fruechtenicht C, Haesendonckx S, Treis T (2025).\n_ggsurvfit: Flexible Time-to-Event Figures_. R package version 1.2.0,\n&lt;https://CRAN.R-project.org/package=ggsurvfit&gt;.\n  - Sjoberg D, Whiting K, Curry M, Lavery J, Larmarange J (2021). \"Reproducible\nSummary Tables with the gtsummary Package.\" _The R Journal_, *13*, 570-580.\ndoi:10.32614/RJ-2021-053 &lt;https://doi.org/10.32614/RJ-2021-053&gt;,\n&lt;https://doi.org/10.32614/RJ-2021-053&gt;.\n  - Therneau T (2024). _A Package for Survival Analysis in R_. R package version\n3.7-0, &lt;https://CRAN.R-project.org/package=survival&gt;. Terry M. Therneau,\nPatricia M. Grambsch (2000). _Modeling Survival Data: Extending the Cox Model_.\nSpringer, New York. ISBN 0-387-98784-3.\n  - Wickham H (2016). _ggplot2: Elegant Graphics for Data Analysis_.\nSpringer-Verlag New York. ISBN 978-3-319-24277-4,\n&lt;https://ggplot2.tidyverse.org&gt;.\n  - Wickham H (2023). _forcats: Tools for Working with Categorical Variables\n(Factors)_. R package version 1.0.0,\n&lt;https://CRAN.R-project.org/package=forcats&gt;.\n  - Wickham H (2023). _stringr: Simple, Consistent Wrappers for Common String\nOperations_. R package version 1.5.1,\n&lt;https://CRAN.R-project.org/package=stringr&gt;.\n  - Wickham H, Averick M, Bryan J, Chang W, McGowan LD, François R, Grolemund G,\nHayes A, Henry L, Hester J, Kuhn M, Pedersen TL, Miller E, Bache SM, Müller K,\nOoms J, Robinson D, Seidel DP, Spinu V, Takahashi K, Vaughan D, Wilke C, Woo K,\nYutani H (2019). \"Welcome to the tidyverse.\" _Journal of Open Source Software_,\n*4*(43), 1686. doi:10.21105/joss.01686 &lt;https://doi.org/10.21105/joss.01686&gt;.\n  - Wickham H, François R, Henry L, Müller K, Vaughan D (2023). _dplyr: A Grammar\nof Data Manipulation_. R package version 1.1.4,\n&lt;https://CRAN.R-project.org/package=dplyr&gt;.\n  - Wickham H, Henry L (2025). _purrr: Functional Programming Tools_. R package\nversion 1.0.4, &lt;https://CRAN.R-project.org/package=purrr&gt;.\n  - Wickham H, Hester J, Bryan J (2024). _readr: Read Rectangular Text Data_. R\npackage version 2.1.5, &lt;https://CRAN.R-project.org/package=readr&gt;.\n  - Wickham H, Vaughan D, Girlich M (2024). _tidyr: Tidy Messy Data_. R package\nversion 1.3.1, &lt;https://CRAN.R-project.org/package=tidyr&gt;.\n  - Zhu H (2024). _kableExtra: Construct Complex Table with 'kable' and Pipe\nSyntax_. R package version 1.4.0,\n&lt;https://CRAN.R-project.org/package=kableExtra&gt;.\n\n\n\n\n\n\n\n\n\n🎓 Resumo da Lista 6.1\n\n\n\nNesta lista você:\n✅ Identificou violação de proporcionalidade com teste de Schoenfeld\n✅ Compreendeu covariáveis tempo-dependentes (linear, log, threshold)\n✅ Ajustou modelos Cox com efeitos variando no tempo\n✅ Comparou modelos via AIC/BIC\n✅ Realizou análise estratificada por raça\n✅ Interpretou β(t) e sua mudança temporal\nConceitos-chave: - Proporcionalidade: HR constante ao longo do tempo - Violação: β(t) não é constante - tt(x): transforma x para variar com tempo - β(t) = β₀ + β₁ × f(t) - Escolha de f(t) baseada em teoria + dados\nQuando usar Cox tempo-dependente: - Teste de Schoenfeld significativo (p &lt; 0.05) - Gráfico de resíduos mostra tendência clara - Teoria sugere efeito muda com tempo - Eventos/exposições ocorrem durante seguimento\nPróximos passos: - Explorar modelos com múltiplas covariáveis tempo-dependentes - Validação cruzada temporal - Modelos de fragilidade para heterogeneidade não-observada",
    "crumbs": [
      "SURVIVAL",
      "Lista 6.1: Cox com Covariáveis Tempo-Dependentes"
    ]
  },
  {
    "objectID": "lista_8.html",
    "href": "lista_8.html",
    "title": "Lista 8: CFA e Path Analysis",
    "section": "",
    "text": "📚 O que é SEM?",
    "crumbs": [
      "SEM",
      "Lista 8: CFA e Path Analysis"
    ]
  },
  {
    "objectID": "lista_8.html#o-que-é-sem",
    "href": "lista_8.html#o-que-é-sem",
    "title": "Lista 8: CFA e Path Analysis",
    "section": "",
    "text": "Structural Equation Modeling (SEM)\n\n\n\nTécnica estatística que combina: - Análise de regressão: Relações direcionais entre variáveis - Análise fatorial: Variáveis latentes não-observadas\nDois componentes principais:\n1. Path Analysis (Análise de Caminhos) - Relações entre variáveis observadas - Testa modelos teóricos de causalidade - Análise de mediação e moderação\n2. CFA (Confirmatory Factor Analysis) - Testa estrutura de variáveis latentes - Confirmação de fatores teóricos - Validação de questionários/escalas",
    "crumbs": [
      "SEM",
      "Lista 8: CFA e Path Analysis"
    ]
  },
  {
    "objectID": "lista_8.html#pacotes",
    "href": "lista_8.html#pacotes",
    "title": "Lista 8: CFA e Path Analysis",
    "section": "📦 Pacotes",
    "text": "📦 Pacotes\n\n\n✓ Pacotes de SEM carregados!",
    "crumbs": [
      "SEM",
      "Lista 8: CFA e Path Analysis"
    ]
  },
  {
    "objectID": "lista_8.html#parte-a-path-analysis",
    "href": "lista_8.html#parte-a-path-analysis",
    "title": "Lista 8: CFA e Path Analysis",
    "section": "🎯 Parte A: Path Analysis",
    "text": "🎯 Parte A: Path Analysis\n\nContexto dos Dados\n\n\n\n\n\n\nTip\n\n\n\nDados: 94 pessoas\nVariáveis: - Idade: Anos - IMC1: Índice de Massa Corporal - Sociabilidade: Escore de questionário - Treinos: Número de treinos (VD)\nPergunta: Como Idade, IMC e Sociabilidade afetam frequência de treinos?\n\n\n\n\n\nCarregar Dados\n\ndados_path &lt;- read.spss(\"DADOS PATH.sav\", to.data.frame = TRUE)\nglimpse(dados_path)\n\nRows: 94\nColumns: 4\n$ Idade         &lt;dbl&gt; 57, 41, 29, 26, 33, 37, 26, 44, 31, 36, 30, 55, 43, 27, …\n$ IMC1          &lt;dbl&gt; 28.46122, 32.62609, 26.99050, 19.03602, 28.76650, 24.686…\n$ Treinos       &lt;dbl&gt; 108, 144, 48, 102, 123, 63, 39, 105, 6, 48, 144, 144, 11…\n$ Sociabilidade &lt;dbl&gt; 14, 34, 17, 20, 26, 19, 15, 32, 27, 19, 28, 9, 30, 29, 1…\n\n\n\n\n\nBaseline: Regressão Linear\n\nmodelo_lm &lt;- lm(Treinos ~ Idade + IMC1 + Sociabilidade, \n                data = dados_path)\n\nsummary(modelo_lm)$coefficients %&gt;%\n  kable(digits = 3, caption = \"Coeficientes de Regressão Linear\")\n\n\nCoeficientes de Regressão Linear\n\n\n\nEstimate\nStd. Error\nt value\nPr(&gt;|t|)\n\n\n\n\n(Intercept)\n78.010\n33.132\n2.355\n0.021\n\n\nIdade\n1.907\n0.548\n3.480\n0.001\n\n\nIMC1\n-2.802\n1.181\n-2.373\n0.020\n\n\nSociabilidade\n0.518\n0.590\n0.877\n0.383\n\n\n\n\n\n\n\n\nModelo de Path Analysis\n\n\n\n\n\n\nSintaxe lavaan\n\n\n\nEm SEM, especificamos modelos com texto:\n~ = “é regredido por” (Y ~ X)\n=~ = “é medido por” (Fator =~ itens)\n~~ = “covaria com”\n\n\n\n# Especificar modelo (idêntico à regressão)\npath_modelo &lt;- \"Treinos ~ Idade + IMC1 + Sociabilidade\"\n\n# Ajustar\nfit_path &lt;- sem(path_modelo, data = dados_path)\n\n\n\n\nResultados da Path Analysis\n\nsummary(fit_path, standardized = TRUE, fit.measures = TRUE)\n\nlavaan 0.6-19 ended normally after 1 iteration\n\n  Estimator                                         ML\n  Optimization method                           NLMINB\n  Number of model parameters                         4\n\n  Number of observations                            94\n\nModel Test User Model:\n                                                      \n  Test statistic                                 0.000\n  Degrees of freedom                                 0\n\nModel Test Baseline Model:\n\n  Test statistic                                14.649\n  Degrees of freedom                                 3\n  P-value                                        0.002\n\nUser Model versus Baseline Model:\n\n  Comparative Fit Index (CFI)                    1.000\n  Tucker-Lewis Index (TLI)                       1.000\n\nLoglikelihood and Information Criteria:\n\n  Loglikelihood user model (H0)               -491.806\n  Loglikelihood unrestricted model (H1)       -491.806\n                                                      \n  Akaike (AIC)                                 991.612\n  Bayesian (BIC)                              1001.785\n  Sample-size adjusted Bayesian (SABIC)        989.157\n\nRoot Mean Square Error of Approximation:\n\n  RMSEA                                          0.000\n  90 Percent confidence interval - lower         0.000\n  90 Percent confidence interval - upper         0.000\n  P-value H_0: RMSEA &lt;= 0.050                       NA\n  P-value H_0: RMSEA &gt;= 0.080                       NA\n\nStandardized Root Mean Square Residual:\n\n  SRMR                                           0.000\n\nParameter Estimates:\n\n  Standard errors                             Standard\n  Information                                 Expected\n  Information saturated (h1) model          Structured\n\nRegressions:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all\n  Treinos ~                                                             \n    Idade             1.907    0.536    3.557    0.000    1.907    0.354\n    IMC1             -2.802    1.156   -2.425    0.015   -2.802   -0.241\n    Sociabilidade     0.518    0.578    0.896    0.370    0.518    0.086\n\nVariances:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all\n   .Treinos        2050.999  299.169    6.856    0.000 2050.999    0.856\n\n\n\n\n\nTabela de Estimativas\n\nparameterEstimates(fit_path) %&gt;%\n  filter(op == \"~\") %&gt;%\n  select(lhs, op, rhs, est, se, z, pvalue, ci.lower, ci.upper) %&gt;%\n  kable(\n    digits = 3,\n    col.names = c(\"VD\", \"←\", \"VI\", \"β\", \"EP\", \"z\", \"p\", \"IC_low\", \"IC_up\"),\n    caption = \"Estimativas de Parâmetros (Path Analysis)\"\n  )\n\n\nEstimativas de Parâmetros (Path Analysis)\n\n\n\n\n\n\n\n\n\n\n\n\n\nVD\n←\nVI\nβ\nEP\nz\np\nIC_low\nIC_up\n\n\n\n\nTreinos\n~\nIdade\n1.907\n0.536\n3.557\n0.000\n0.856\n2.958\n\n\nTreinos\n~\nIMC1\n-2.802\n1.156\n-2.425\n0.015\n-5.067\n-0.537\n\n\nTreinos\n~\nSociabilidade\n0.518\n0.578\n0.896\n0.370\n-0.614\n1.650\n\n\n\n\n\n\n\n\n\n\n\n📊 Comparação: Path vs Regressão\n\n\n\nResultados são idênticos! Path Analysis com apenas variáveis observadas = Regressão Linear.\nVantagem do SEM: Permite modelos mais complexos (múltiplas VDs, mediação, variáveis latentes)\n\n\n\n\n\nÍndices de Ajuste\n\nmodel_performance(\n  fit_path,\n  metrics = c(\"Chi2\", \"Chi2_df\", \"NFI\", \"NNFI\", \"CFI\", \n              \"RMSEA\", \"AIC\", \"BIC\")\n) %&gt;%\n  kable(digits = 3, caption = \"Índices de Ajuste do Modelo\")\n\n\nÍndices de Ajuste do Modelo\n\n\nChi2\nChi2_df\nNFI\nNNFI\nCFI\nRMSEA\nAIC\nBIC\n\n\n\n\n0\n0\n1\n1\n1\n0\n991.612\n1001.785\n\n\n\n\n\n\n\n\n\n\n\n🔍 Interpretando Índices de Ajuste\n\n\n\n\n\nχ² (Chi-quadrado): - Testa H₀: modelo perfeito - p &gt; 0.05 = bom ajuste (mas sensível a N)\nCFI (Comparative Fit Index): - Compara com modelo nulo - &gt; 0.90 aceitável, &gt; 0.95 bom\nRMSEA (Root Mean Square Error): - &lt; 0.05 excelente - 0.05-0.08 aceitável - &gt; 0.10 pobre\nAIC/BIC: Comparação entre modelos (menor = melhor)\n\n\n\n\n\n\nDiagrama do Modelo\n\nsemPaths(\n  fit_path,\n  what = \"std\",\n  whatLabels = \"par\",\n  style = \"ram\",\n  layout = \"tree\",\n  rotation = 2,\n  sizeMan = 8,\n  edge.label.cex = 1.2,\n  label.cex = 1.3,\n  color = list(man = \"lightblue\", lat = \"lightgreen\")\n)",
    "crumbs": [
      "SEM",
      "Lista 8: CFA e Path Analysis"
    ]
  },
  {
    "objectID": "lista_8.html#parte-b-análise-fatorial-confirmatória-cfa",
    "href": "lista_8.html#parte-b-análise-fatorial-confirmatória-cfa",
    "title": "Lista 8: CFA e Path Analysis",
    "section": "🎯 Parte B: Análise Fatorial Confirmatória (CFA)",
    "text": "🎯 Parte B: Análise Fatorial Confirmatória (CFA)\n\nContexto Teórico\n\n\n\n\n\n\nEscala de Apego a Amigos (IAA)\n\n\n\nTeoria: Apego a amigos tem 2 dimensões latentes:\n1. Alienação (sentir-se isolado) - IAa1, IAa2, IAa3\n2. Confiança (segurança nas amizades) - IAa13, IAa14, IAa15\nObjetivo: Confirmar essa estrutura com CFA\n\n\n\n\n\nCarregar Dados\n\ndados_cfa &lt;- read.spss(\"fatorial CFA.sav\", to.data.frame = TRUE)\nglimpse(dados_cfa)\n\nRows: 348\nColumns: 26\n$ Protocolo &lt;dbl&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 1…\n$ IAa1      &lt;dbl&gt; 3, 5, 4, 5, 3, 3, 1, 1, 2, 3, 5, 3, 3, 5, 3, 4, 2, 4, 1, 5, …\n$ IAa2      &lt;dbl&gt; 3, 5, 3, 3, 1, 3, 2, 3, 2, 4, 3, 4, 4, 4, 3, 3, 3, 2, 3, 2, …\n$ IAa3      &lt;dbl&gt; 3, 5, 4, 3, 2, 2, 4, 5, 3, 4, 5, 3, 4, 3, 4, 4, 3, 2, 5, 5, …\n$ IAa4      &lt;dbl&gt; 3, 2, 4, 2, 1, 1, 1, 1, 4, 2, 1, 1, 2, 1, 2, 3, 2, 2, 1, 2, …\n$ IAa5      &lt;dbl&gt; 3, 1, 1, 1, 4, 4, 2, 2, 5, 3, 1, 1, 2, 1, 1, 1, 3, 2, 1, 1, …\n$ IAa6      &lt;dbl&gt; 3, 4, 5, 3, 2, 2, 2, 5, 1, 5, 3, 3, 4, 4, 4, 4, 3, 3, 4, 5, …\n$ IAa7      &lt;dbl&gt; 3, 3, 3, 3, 5, 4, 1, 3, 1, 4, 1, 4, 3, 4, 3, 2, 2, 3, 1, 5, …\n$ IAa8      &lt;dbl&gt; 3, 4, 5, 4, 3, 5, 3, 5, 4, 4, 2, 5, 4, 5, 4, 5, 4, 3, 5, 5, …\n$ IAa9      &lt;dbl&gt; 3, 5, 5, 3, 2, 1, 4, 5, 3, 5, 2, 4, 4, 4, 4, 2, 3, 3, 2, 5, …\n$ IAa10     &lt;dbl&gt; 3, 2, 2, 2, 3, 3, 1, 5, 4, 4, 3, 1, 1, 3, 2, 2, 3, 4, 1, 3, …\n$ IAa11     &lt;dbl&gt; 3, 1, 1, 1, 2, 4, 3, 1, 5, 3, 5, 1, 1, 2, 1, 1, 4, 1, 1, 1, …\n$ IAa12     &lt;dbl&gt; 3, 4, 5, 4, 4, 2, 4, 5, 3, 5, 3, 4, 4, 4, 4, 4, 3, 5, 5, 5, …\n$ IAa13     &lt;dbl&gt; 3, 4, 5, 5, 4, 5, 3, 5, 2, 5, 4, 5, 4, 5, 4, 5, 4, 5, 5, 5, …\n$ IAa14     &lt;dbl&gt; 3, 4, 5, 5, 3, 1, 2, 5, 3, 4, 5, 5, 3, 5, 4, 5, 4, 4, 5, 5, …\n$ IAa15     &lt;dbl&gt; 3, 4, 4, 4, 2, 2, 2, 2, 4, 4, 3, 4, 3, 3, 4, 5, 3, 4, 5, 5, …\n$ IAa16     &lt;dbl&gt; 3, 4, 4, 3, 3, 3, 3, 4, 2, 4, 3, 4, 4, 4, 3, 3, 3, 2, 1, 5, …\n$ IAa17     &lt;dbl&gt; 3, 4, 4, 4, 4, 4, 4, 3, 4, 3, 4, 4, 4, 3, 3, 4, 3, 4, 3, 5, …\n$ IAa18     &lt;dbl&gt; 3, 1, 1, 2, 2, 1, 1, 3, 1, 1, 1, 2, 2, 2, 1, 1, 2, 1, 1, 2, …\n$ IAa19     &lt;dbl&gt; 3, 5, 5, 4, 5, 2, 5, 3, 1, 4, 4, 5, 3, 4, 4, 4, 2, 5, 4, 5, …\n$ IAa20     &lt;dbl&gt; 3, 4, 5, 5, 2, 5, 3, 2, 3, 4, 4, 5, 4, 4, 4, 5, 3, 5, 5, 5, …\n$ IAa21     &lt;dbl&gt; 3, 4, 5, 5, 3, 3, 1, 5, 2, 5, 3, 4, 4, 4, 4, 5, 4, 5, 5, 5, …\n$ IAa22     &lt;dbl&gt; 3, 1, 3, 1, 3, 5, 3, 2, 4, 4, 5, 2, 2, 3, 1, 3, 2, 3, 2, 5, …\n$ IAa23     &lt;dbl&gt; 3, 1, 2, 1, 2, 1, 1, 1, 2, 3, 2, 1, 2, 2, 1, 2, 1, 1, 1, 1, …\n$ IAa24     &lt;dbl&gt; 3, 4, 5, 3, 2, 2, 2, 5, 1, 5, 4, 4, 4, 4, 2, 3, 2, 4, 3, 5, …\n$ IAa25     &lt;dbl&gt; 3, 5, 4, 3, 4, 4, 4, 5, 3, 4, 4, 4, 3, 4, 3, 5, 2, 5, 5, 5, …\n\n\n\n\n\nModelo 1: CFA com 2 Fatores\n\n# Especificar modelo\n# Variáveis latentes (=~ significa 'medido por')\ncfa_eq1 &lt;- \"\n  alienacao =~ IAa1 + IAa2 + IAa3\n  confianca =~ IAa13 + IAa14 + IAa15\n\"\n\n# Ajustar\ncfa_modelo1 &lt;- cfa(\n  cfa_eq1,\n  data = dados_cfa,\n  std.lv = TRUE  # Padronizar variáveis latentes\n)\n\n\n\n\n\n\n\nstd.lv = TRUE\n\n\n\nFixa variância das variáveis latentes em 1 (padronização).\nAlternativa: std.lv = FALSE fixa primeira carga fatorial = 1\n\n\n\n\n\nResultados do Modelo 1\n\nsummary(cfa_modelo1, fit.measures = TRUE, standardized = TRUE)\n\nlavaan 0.6-19 ended normally after 18 iterations\n\n  Estimator                                         ML\n  Optimization method                           NLMINB\n  Number of model parameters                        13\n\n                                                  Used       Total\n  Number of observations                           347         348\n\nModel Test User Model:\n                                                      \n  Test statistic                                39.166\n  Degrees of freedom                                 8\n  P-value (Chi-square)                           0.000\n\nModel Test Baseline Model:\n\n  Test statistic                               477.985\n  Degrees of freedom                                15\n  P-value                                        0.000\n\nUser Model versus Baseline Model:\n\n  Comparative Fit Index (CFI)                    0.933\n  Tucker-Lewis Index (TLI)                       0.874\n\nLoglikelihood and Information Criteria:\n\n  Loglikelihood user model (H0)              -2688.238\n  Loglikelihood unrestricted model (H1)      -2668.655\n                                                      \n  Akaike (AIC)                                5402.476\n  Bayesian (BIC)                              5452.517\n  Sample-size adjusted Bayesian (SABIC)       5411.277\n\nRoot Mean Square Error of Approximation:\n\n  RMSEA                                          0.106\n  90 Percent confidence interval - lower         0.074\n  90 Percent confidence interval - upper         0.140\n  P-value H_0: RMSEA &lt;= 0.050                    0.003\n  P-value H_0: RMSEA &gt;= 0.080                    0.914\n\nStandardized Root Mean Square Residual:\n\n  SRMR                                           0.047\n\nParameter Estimates:\n\n  Standard errors                             Standard\n  Information                                 Expected\n  Information saturated (h1) model          Structured\n\nLatent Variables:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all\n  alienacao =~                                                          \n    IAa1              0.578    0.069    8.408    0.000    0.578    0.496\n    IAa2              0.842    0.069   12.135    0.000    0.842    0.715\n    IAa3              0.423    0.051    8.278    0.000    0.423    0.489\n  confianca =~                                                          \n    IAa13             0.580    0.044   13.279    0.000    0.580    0.718\n    IAa14             0.660    0.052   12.652    0.000    0.660    0.688\n    IAa15             0.586    0.053   11.105    0.000    0.586    0.615\n\nCovariances:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all\n  alienacao ~~                                                          \n    confianca         0.865    0.051   16.807    0.000    0.865    0.865\n\nVariances:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all\n   .IAa1              1.023    0.088   11.607    0.000    1.023    0.754\n   .IAa2              0.676    0.089    7.627    0.000    0.676    0.488\n   .IAa3              0.568    0.049   11.667    0.000    0.568    0.761\n   .IAa13             0.316    0.036    8.898    0.000    0.316    0.485\n   .IAa14             0.485    0.051    9.564    0.000    0.485    0.527\n   .IAa15             0.564    0.052   10.767    0.000    0.564    0.622\n    alienacao         1.000                               1.000    1.000\n    confianca         1.000                               1.000    1.000\n\n\n\n\n\nTabela de Cargas Fatoriais\n\nparameterEstimates(cfa_modelo1) %&gt;%\n  filter(op == \"=~\") %&gt;%\n  dplyr::select(lhs, rhs, est, se, z, pvalue, ci.lower, ci.upper) %&gt;%\n  kable(\n    digits = 3,\n    col.names = c(\"Fator\", \"Item\", \"λ\", \"EP\", \"z\", \"p\", \"ci lower\", \"ci upper\"),\n    caption = \"Cargas Fatoriais (Modelo 1)\"\n  )\n\n\nCargas Fatoriais (Modelo 1)\n\n\nFator\nItem\nλ\nEP\nz\np\nci lower\nci upper\n\n\n\n\nalienacao\nIAa1\n0.578\n0.069\n8.408\n0\n0.444\n0.713\n\n\nalienacao\nIAa2\n0.842\n0.069\n12.135\n0\n0.706\n0.978\n\n\nalienacao\nIAa3\n0.423\n0.051\n8.278\n0\n0.323\n0.523\n\n\nconfianca\nIAa13\n0.580\n0.044\n13.279\n0\n0.494\n0.665\n\n\nconfianca\nIAa14\n0.660\n0.052\n12.652\n0\n0.558\n0.763\n\n\nconfianca\nIAa15\n0.586\n0.053\n11.105\n0\n0.482\n0.689\n\n\n\n\n\n\n\n\n\n\n\n📊 Interpretando Cargas (λ)\n\n\n\nλ_pad (padronizado): - &gt; 0.70 = Excelente - 0.50-0.70 = Aceitável - &lt; 0.50 = Problemático\nIndica quanto cada item “carrega” no fator latente.\n\n\n\n\n\nÍndices de Ajuste - Modelo 1\n\nmodel_performance(\n  cfa_modelo1,\n  metrics = c(\"Chi2\", \"Chi2_df\", \"NFI\", \"NNFI\", \"CFI\",\n              \"RMSEA\", \"p_RMSEA\", \"AIC\", \"BIC\")\n) %&gt;%\n  kable(digits = 3, caption = \"Ajuste do Modelo 1\")\n\n\nAjuste do Modelo 1\n\n\n\n\n\n\n\n\n\n\n\n\n\nChi2\nChi2_df\nNFI\nNNFI\nCFI\nRMSEA\np_RMSEA\nAIC\nBIC\n\n\n\n\n39.166\n8\n0.918\n0.874\n0.933\n0.106\n0.003\n5402.476\n5452.517\n\n\n\n\n\n\n\n\n\n\n\n⚠️ Ajuste Moderado\n\n\n\n\nCFI/NNFI: Bons (&gt; 0.90)\nRMSEA: Alto (0.10) → Modelo pode melhorar\n\nPróximo passo: Verificar índices de modificação\n\n\n\n\n\nÍndices de Modificação\n\nmodificationindices(cfa_modelo1, sort = TRUE, minimum.value = 5) %&gt;%\n  head(10) %&gt;%\n  kable(digits = 3, caption = \"Top 10 Modificações Sugeridas\")\n\n\nTop 10 Modificações Sugeridas\n\n\n\nlhs\nop\nrhs\nmi\nepc\nsepc.lv\nsepc.all\nsepc.nox\n\n\n\n\n34\nIAa13\n~~\nIAa14\n18.246\n0.183\n0.183\n0.466\n0.466\n\n\n18\nalienacao\n=~\nIAa15\n18.246\n0.957\n0.957\n1.005\n1.005\n\n\n29\nIAa2\n~~\nIAa14\n17.160\n-0.204\n-0.204\n-0.357\n-0.357\n\n\n30\nIAa2\n~~\nIAa15\n10.461\n0.154\n0.154\n0.249\n0.249\n\n\n20\nconfianca\n=~\nIAa2\n8.404\n-1.642\n-1.642\n-1.395\n-1.395\n\n\n23\nIAa1\n~~\nIAa3\n8.404\n-0.139\n-0.139\n-0.182\n-0.182\n\n\n35\nIAa13\n~~\nIAa15\n5.006\n-0.084\n-0.084\n-0.199\n-0.199\n\n\n17\nalienacao\n=~\nIAa14\n5.006\n-0.560\n-0.560\n-0.584\n-0.584\n\n\n\n\n\n\n\n\n\n\n\n🔍 Interpretando MI\n\n\n\n\n\nMI (Modification Index): - Prediz redução em χ² se parâmetro for liberado - MI &gt; 10 = modificação substancial\nEPC (Expected Parameter Change): - Valor esperado do parâmetro\nDecisão: Só adicionar se teoricamente justificável!\n\n\n\n\n\n\nModelo 2: Com Covariâncias de Resíduos\n\ncfa_eq2 &lt;- \"\n  # Fatores\n  alienacao =~ IAa1 + IAa2 + IAa3\n  confianca =~ IAa13 + IAa14 + IAa15\n  \n  # Covariâncias de resíduos (baseadas em MI)\n  IAa1 ~~ IAa3\n  IAa13 ~~ IAa14\n  IAa13 ~~ IAa15\n\"\n\ncfa_modelo2 &lt;- cfa(cfa_eq2, data = dados_cfa, std.lv = TRUE)\n\n\n\n\nResultados do Modelo 2\n\nparameterEstimates(cfa_modelo2) %&gt;%\n  kable(digits = 3, caption = \"Estimativas - Modelo 2\")\n\n\nEstimativas - Modelo 2\n\n\n\n\n\n\n\n\n\n\n\n\n\nlhs\nop\nrhs\nest\nse\nz\npvalue\nci.lower\nci.upper\n\n\n\n\nalienacao\n=~\nIAa1\n0.625\n0.069\n9.009\n0.000\n0.489\n0.761\n\n\nalienacao\n=~\nIAa2\n0.844\n0.066\n12.774\n0.000\n0.714\n0.973\n\n\nalienacao\n=~\nIAa3\n0.440\n0.052\n8.484\n0.000\n0.338\n0.541\n\n\nconfianca\n=~\nIAa13\n0.486\n0.054\n9.010\n0.000\n0.380\n0.591\n\n\nconfianca\n=~\nIAa14\n0.558\n0.057\n9.744\n0.000\n0.446\n0.671\n\n\nconfianca\n=~\nIAa15\n0.627\n0.058\n10.741\n0.000\n0.512\n0.741\n\n\nIAa1\n~~\nIAa3\n-0.131\n0.047\n-2.812\n0.005\n-0.223\n-0.040\n\n\nIAa13\n~~\nIAa14\n0.156\n0.042\n3.700\n0.000\n0.073\n0.238\n\n\nIAa13\n~~\nIAa15\n0.005\n0.037\n0.123\n0.902\n-0.068\n0.077\n\n\nIAa1\n~~\nIAa1\n0.968\n0.088\n11.049\n0.000\n0.796\n1.139\n\n\nIAa2\n~~\nIAa2\n0.674\n0.081\n8.299\n0.000\n0.514\n0.833\n\n\nIAa3\n~~\nIAa3\n0.553\n0.049\n11.303\n0.000\n0.457\n0.649\n\n\nIAa13\n~~\nIAa13\n0.416\n0.048\n8.717\n0.000\n0.323\n0.510\n\n\nIAa14\n~~\nIAa14\n0.609\n0.059\n10.323\n0.000\n0.494\n0.725\n\n\nIAa15\n~~\nIAa15\n0.514\n0.060\n8.497\n0.000\n0.395\n0.632\n\n\nalienacao\n~~\nalienacao\n1.000\n0.000\nNA\nNA\n1.000\n1.000\n\n\nconfianca\n~~\nconfianca\n1.000\n0.000\nNA\nNA\n1.000\n1.000\n\n\nalienacao\n~~\nconfianca\n0.945\n0.063\n15.041\n0.000\n0.822\n1.068\n\n\n\n\n\n\n\n\nComparação: Modelo 1 vs 2\n\ncompare_performance(\n  cfa_modelo1, cfa_modelo2,\n  metrics = c(\"NFI\", \"NNFI\", \"CFI\", \"RMSEA\", \"AIC\", \"BIC\"),\n  rank = TRUE, verbose = FALSE\n) %&gt;%\n  kable(digits = 3, caption = \"Comparação de Modelos\")\n\n\nComparação de Modelos\n\n\n\n\n\n\n\n\n\n\n\n\n\nName\nModel\nNFI\nNNFI\nCFI\nRMSEA\nAIC_wt\nBIC_wt\nPerformance_Score\n\n\n\n\ncfa_modelo2\nlavaan\n0.970\n0.940\n0.980\n0.073\n1\n0.976\n0.833\n\n\ncfa_modelo1\nlavaan\n0.918\n0.874\n0.933\n0.106\n0\n0.024\n0.167\n\n\n\n\n\n\n\n\n\n\n\n✓ Modelo 2 Superior\n\n\n\n\nRMSEA reduzido (0.10 → 0.07)\nAIC/BIC menores\nCFI/NNFI ligeiramente melhores\n\nCovariâncias de resíduos melhoraram ajuste!\n\n\n\n\n\nDiagrama - Modelo 2\n\nsemPaths(\n  cfa_modelo2,\n  what = \"std\",\n  whatLabels = \"std\",\n  style = \"ram\",\n  layout = \"tree2\",\n  rotation = 2,\n  sizeMan = 7,\n  sizeLat = 10,\n  edge.label.cex = 1,\n  label.cex = 1.2,\n  color = list(man = \"lightblue\", lat = \"lightcoral\")\n)",
    "crumbs": [
      "SEM",
      "Lista 8: CFA e Path Analysis"
    ]
  },
  {
    "objectID": "lista_8.html#modelos-alternativos",
    "href": "lista_8.html#modelos-alternativos",
    "title": "Lista 8: CFA e Path Analysis",
    "section": "🔍 Modelos Alternativos",
    "text": "🔍 Modelos Alternativos\n\nModelo 3: Fator Único\n\n\n\n\n\n\nHipótese Alternativa\n\n\n\nE se Alienação e Confiança são na verdade um único fator?\nVamos testar!\n\n\n\ncfa_eq3 &lt;- \"\n  # Um único fator\n  Apego =~ IAa1 + IAa2 + IAa3 + IAa13 + IAa14 + IAa15\n\"\n\ncfa_modelo3 &lt;- cfa(cfa_eq3, data = dados_cfa, std.lv = TRUE)\n\n\n\n\nModelo 4: Fator Único + Covariâncias\n\n# Verificar MI do modelo 3\nmi3 &lt;- modificationindices(cfa_modelo3, minimum.value = 5)\n\n# Adicionar principais covariâncias\ncfa_eq4 &lt;- \"\n  Apego =~ IAa1 + IAa2 + IAa3 + IAa13 + IAa14 + IAa15\n  \n  # Covariâncias\n  IAa2 ~~ IAa14\n  IAa13 ~~ IAa14\n\"\n\ncfa_modelo4 &lt;- cfa(cfa_eq4, data = dados_cfa, std.lv = TRUE)\n\n\n\n\nComparação Final: Todos os Modelos\n\ncompare_performance(\n  cfa_modelo1, cfa_modelo2, cfa_modelo3, cfa_modelo4,\n  metrics = c(\"Chi2\", \"NFI\", \"NNFI\", \"CFI\", \"RMSEA\", \"AIC\", \"BIC\"),\n  rank = TRUE, verbose = FALSE\n) %&gt;%\n  kable(digits = 3, caption = \"Comparação Completa de Modelos CFA\")\n\n\nComparação Completa de Modelos CFA\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nName\nModel\nChi2\nNFI\nNNFI\nCFI\nRMSEA\nAIC_wt\nBIC_wt\nPerformance_Score\n\n\n\n\ncfa_modelo4\nlavaan\n12.216\n0.974\n0.976\n0.989\n0.046\n0.952\n0.999\n0.714\n\n\ncfa_modelo2\nlavaan\n14.194\n0.970\n0.940\n0.980\n0.073\n0.048\n0.001\n0.431\n\n\ncfa_modelo1\nlavaan\n39.166\n0.918\n0.874\n0.933\n0.106\n0.000\n0.000\n0.310\n\n\ncfa_modelo3\nlavaan\n45.034\n0.906\n0.870\n0.922\n0.107\n0.000\n0.000\n0.286\n\n\n\n\n\n\n\n\n\n\n\n🏆 Modelo Vencedor\n\n\n\nModelo 4 (fator único + covariâncias): - Melhor RMSEA (0.046) - Melhores CFI/NNFI (&gt; 0.97) - Menores AIC/BIC\nMas… Teoria sugere 2 fatores! Decisão final deve considerar teoria + ajuste.\n\n\n\n\n\nDiagrama - Modelo 4\n\nsemPaths(\n  cfa_modelo4,\n  what = \"std\",\n  whatLabels = \"std\",\n  style = \"ram\",\n  layout = \"circle\",\n  sizeMan = 7,\n  sizeLat = 12,\n  edge.label.cex = 1,\n  label.cex = 1.2,\n  color = list(man = \"lightyellow\", lat = \"lightcoral\")\n)",
    "crumbs": [
      "SEM",
      "Lista 8: CFA e Path Analysis"
    ]
  },
  {
    "objectID": "lista_8.html#guia-de-interpretação",
    "href": "lista_8.html#guia-de-interpretação",
    "title": "Lista 8: CFA e Path Analysis",
    "section": "📊 Guia de Interpretação",
    "text": "📊 Guia de Interpretação\n\n\n\n\n\n\n🗺️ Checklist de Análise SEM\n\n\n\n\n\n1. Especificação do Modelo - [ ] Baseado em teoria sólida - [ ] Identificado (df ≥ 0) - [ ] Parâmetros interpretáveis\n2. Avaliação de Ajuste - [ ] χ²: p &gt; 0.05 (ideal, mas sensível a N) - [ ] CFI/NNFI: &gt; 0.95 (&gt; 0.90 aceitável) - [ ] RMSEA: &lt; 0.05 (&lt; 0.08 aceitável) - [ ] SRMR: &lt; 0.08\n3. Interpretação de Parâmetros - [ ] Cargas fatoriais: &gt; 0.50 (&gt; 0.70 ideal) - [ ] Todos significativos (p &lt; 0.05) - [ ] Direção teoricamente esperada - [ ] Ausência de casos Heywood (variâncias negativas)\n4. Modificações - [ ] Baseadas em MI &gt; 10 - [ ] Teoricamente justificáveis - [ ] Não data-driven exclusivamente - [ ] Validação cruzada se possível\n5. Comparação de Modelos - [ ] ΔCFI &gt; 0.01 = diferença substancial - [ ] ΔRMSEA &gt; 0.015 = diferença substancial - [ ] Considerar parcimônia (menos parâmetros)",
    "crumbs": [
      "SEM",
      "Lista 8: CFA e Path Analysis"
    ]
  },
  {
    "objectID": "lista_8.html#material-complementar",
    "href": "lista_8.html#material-complementar",
    "title": "Lista 8: CFA e Path Analysis",
    "section": "📚 Material Complementar",
    "text": "📚 Material Complementar\n\n\n\nRecursos Adicionais\n\n\n\n\n\n\n📖 Aprofundamento em SEM\n\n\n\n\n\nPacote lavaan: - Tutorial Oficial - Rosseel (2012). JSS Paper\nLivros: - Kline (2015). Principles and Practice of SEM - Brown (2015). Confirmatory Factor Analysis\nTópicos Avançados: - Modelos multigrupo (invariância) - Variáveis categóricas (WLSMV) - Modelos de crescimento (LGM) - SEM bayesiano",
    "crumbs": [
      "SEM",
      "Lista 8: CFA e Path Analysis"
    ]
  },
  {
    "objectID": "lista_8.html#informações-de-sessão",
    "href": "lista_8.html#informações-de-sessão",
    "title": "Lista 8: CFA e Path Analysis",
    "section": "🔧 Informações de Sessão",
    "text": "🔧 Informações de Sessão\n\nreport(sessionInfo())\n\nAnalyses were conducted using the R Statistical language (version 4.4.2; R Core\nTeam, 2024) on Windows 11 x64 (build 26100), using the packages effectsize\n(version 1.0.1; Ben-Shachar MS et al., 2020), semPlot (version 1.1.6; Epskamp\nS, 2022), lubridate (version 1.9.4; Grolemund G, Wickham H, 2011), parameters\n(version 0.28.3; Lüdecke D et al., 2020), performance (version 0.15.2; Lüdecke\nD et al., 2021), easystats (version 0.7.5; Lüdecke D et al., 2022), see\n(version 0.12.0; Lüdecke D et al., 2021), insight (version 1.4.4; Lüdecke D et\nal., 2019), bayestestR (version 0.17.0; Makowski D et al., 2019), modelbased\n(version 0.13.1; Makowski D et al., 2025), report (version 0.6.3; Makowski D et\nal., 2023), correlation (version 0.8.8; Makowski D et al., 2022), tibble\n(version 3.3.1; Müller K, Wickham H, 2026), datawizard (version 1.3.0; Patil I\net al., 2022), foreign (version 0.8.87; R Core Team, 2024), lavaan (version\n0.6.19; Rosseel Y, 2012), ggplot2 (version 4.0.1; Wickham H, 2016), forcats\n(version 1.0.0; Wickham H, 2023), stringr (version 1.5.1; Wickham H, 2023),\ntidyverse (version 2.0.0; Wickham H et al., 2019), dplyr (version 1.1.4;\nWickham H et al., 2023), purrr (version 1.0.4; Wickham H, Henry L, 2025), readr\n(version 2.1.5; Wickham H et al., 2024), tidyr (version 1.3.1; Wickham H et\nal., 2024) and kableExtra (version 1.4.0; Zhu H, 2024).\n\nReferences\n----------\n  - Ben-Shachar MS, Lüdecke D, Makowski D (2020). \"effectsize: Estimation of\nEffect Size Indices and Standardized Parameters.\" _Journal of Open Source\nSoftware_, *5*(56), 2815. doi:10.21105/joss.02815\n&lt;https://doi.org/10.21105/joss.02815&gt;, &lt;https://doi.org/10.21105/joss.02815&gt;.\n  - Epskamp S (2022). _semPlot: Path Diagrams and Visual Analysis of Various SEM\nPackages' Output_. R package version 1.1.6,\n&lt;https://CRAN.R-project.org/package=semPlot&gt;.\n  - Grolemund G, Wickham H (2011). \"Dates and Times Made Easy with lubridate.\"\n_Journal of Statistical Software_, *40*(3), 1-25.\n&lt;https://www.jstatsoft.org/v40/i03/&gt;.\n  - Lüdecke D, Ben-Shachar M, Patil I, Makowski D (2020). \"Extracting, Computing\nand Exploring the Parameters of Statistical Models using R.\" _Journal of Open\nSource Software_, *5*(53), 2445. doi:10.21105/joss.02445\n&lt;https://doi.org/10.21105/joss.02445&gt;.\n  - Lüdecke D, Ben-Shachar M, Patil I, Waggoner P, Makowski D (2021).\n\"performance: An R Package for Assessment, Comparison and Testing of\nStatistical Models.\" _Journal of Open Source Software_, *6*(60), 3139.\ndoi:10.21105/joss.03139 &lt;https://doi.org/10.21105/joss.03139&gt;.\n  - Lüdecke D, Ben-Shachar M, Patil I, Wiernik B, Bacher E, Thériault R, Makowski\nD (2022). \"easystats: Framework for Easy Statistical Modeling, Visualization,\nand Reporting.\" _CRAN_. doi:10.32614/CRAN.package.easystats\n&lt;https://doi.org/10.32614/CRAN.package.easystats&gt;, R package,\n&lt;https://easystats.github.io/easystats/&gt;.\n  - Lüdecke D, Patil I, Ben-Shachar M, Wiernik B, Waggoner P, Makowski D (2021).\n\"see: An R Package for Visualizing Statistical Models.\" _Journal of Open Source\nSoftware_, *6*(64), 3393. doi:10.21105/joss.03393\n&lt;https://doi.org/10.21105/joss.03393&gt;.\n  - Lüdecke D, Waggoner P, Makowski D (2019). \"insight: A Unified Interface to\nAccess Information from Model Objects in R.\" _Journal of Open Source Software_,\n*4*(38), 1412. doi:10.21105/joss.01412 &lt;https://doi.org/10.21105/joss.01412&gt;.\n  - Makowski D, Ben-Shachar M, Lüdecke D (2019). \"bayestestR: Describing Effects\nand their Uncertainty, Existence and Significance within the Bayesian\nFramework.\" _Journal of Open Source Software_, *4*(40), 1541.\ndoi:10.21105/joss.01541 &lt;https://doi.org/10.21105/joss.01541&gt;,\n&lt;https://joss.theoj.org/papers/10.21105/joss.01541&gt;.\n  - Makowski D, Ben-Shachar M, Wiernik B, Patil I, Thériault R, Lüdecke D (2025).\n\"modelbased: An R package to make the most out of your statistical models\nthrough marginal means, marginal effects, and model predictions.\" _Journal of\nOpen Source Software_, *10*(109), 7969. doi:10.21105/joss.07969\n&lt;https://doi.org/10.21105/joss.07969&gt;,\n&lt;https://joss.theoj.org/papers/10.21105/joss.07969&gt;.\n  - Makowski D, Lüdecke D, Patil I, Thériault R, Ben-Shachar M, Wiernik B (2023).\n\"Automated Results Reporting as a Practical Tool to Improve Reproducibility and\nMethodological Best Practices Adoption.\" _CRAN_.\ndoi:10.32614/CRAN.package.report\n&lt;https://doi.org/10.32614/CRAN.package.report&gt;,\n&lt;https://easystats.github.io/report/&gt;.\n  - Makowski D, Wiernik B, Patil I, Lüdecke D, Ben-Shachar M (2022).\n\"correlation: Methods for Correlation Analysis.\" Version 0.8.3,\n&lt;https://CRAN.R-project.org/package=correlation&gt;. Makowski D, Ben-Shachar M,\nPatil I, Lüdecke D (2020). \"Methods and Algorithms for Correlation Analysis in\nR.\" _Journal of Open Source Software_, *5*(51), 2306. doi:10.21105/joss.02306\n&lt;https://doi.org/10.21105/joss.02306&gt;,\n&lt;https://joss.theoj.org/papers/10.21105/joss.02306&gt;.\n  - Müller K, Wickham H (2026). _tibble: Simple Data Frames_. R package version\n3.3.1, &lt;https://CRAN.R-project.org/package=tibble&gt;.\n  - Patil I, Makowski D, Ben-Shachar M, Wiernik B, Bacher E, Lüdecke D (2022).\n\"datawizard: An R Package for Easy Data Preparation and Statistical\nTransformations.\" _Journal of Open Source Software_, *7*(78), 4684.\ndoi:10.21105/joss.04684 &lt;https://doi.org/10.21105/joss.04684&gt;.\n  - R Core Team (2024). _foreign: Read Data Stored by 'Minitab', 'S', 'SAS',\n'SPSS', 'Stata', 'Systat', 'Weka', 'dBase', ..._. R package version 0.8-87,\n&lt;https://CRAN.R-project.org/package=foreign&gt;.\n  - R Core Team (2024). _R: A Language and Environment for Statistical\nComputing_. R Foundation for Statistical Computing, Vienna, Austria.\n&lt;https://www.R-project.org/&gt;.\n  - Rosseel Y (2012). \"lavaan: An R Package for Structural Equation Modeling.\"\n_Journal of Statistical Software_, *48*(2), 1-36. doi:10.18637/jss.v048.i02\n&lt;https://doi.org/10.18637/jss.v048.i02&gt;.\n  - Wickham H (2016). _ggplot2: Elegant Graphics for Data Analysis_.\nSpringer-Verlag New York. ISBN 978-3-319-24277-4,\n&lt;https://ggplot2.tidyverse.org&gt;.\n  - Wickham H (2023). _forcats: Tools for Working with Categorical Variables\n(Factors)_. R package version 1.0.0,\n&lt;https://CRAN.R-project.org/package=forcats&gt;.\n  - Wickham H (2023). _stringr: Simple, Consistent Wrappers for Common String\nOperations_. R package version 1.5.1,\n&lt;https://CRAN.R-project.org/package=stringr&gt;.\n  - Wickham H, Averick M, Bryan J, Chang W, McGowan LD, François R, Grolemund G,\nHayes A, Henry L, Hester J, Kuhn M, Pedersen TL, Miller E, Bache SM, Müller K,\nOoms J, Robinson D, Seidel DP, Spinu V, Takahashi K, Vaughan D, Wilke C, Woo K,\nYutani H (2019). \"Welcome to the tidyverse.\" _Journal of Open Source Software_,\n*4*(43), 1686. doi:10.21105/joss.01686 &lt;https://doi.org/10.21105/joss.01686&gt;.\n  - Wickham H, François R, Henry L, Müller K, Vaughan D (2023). _dplyr: A Grammar\nof Data Manipulation_. R package version 1.1.4,\n&lt;https://CRAN.R-project.org/package=dplyr&gt;.\n  - Wickham H, Henry L (2025). _purrr: Functional Programming Tools_. R package\nversion 1.0.4, &lt;https://CRAN.R-project.org/package=purrr&gt;.\n  - Wickham H, Hester J, Bryan J (2024). _readr: Read Rectangular Text Data_. R\npackage version 2.1.5, &lt;https://CRAN.R-project.org/package=readr&gt;.\n  - Wickham H, Vaughan D, Girlich M (2024). _tidyr: Tidy Messy Data_. R package\nversion 1.3.1, &lt;https://CRAN.R-project.org/package=tidyr&gt;.\n  - Zhu H (2024). _kableExtra: Construct Complex Table with 'kable' and Pipe\nSyntax_. R package version 1.4.0,\n&lt;https://CRAN.R-project.org/package=kableExtra&gt;.\n\n\n\n\n\n\n\n\n\n🎓 Resumo da Lista 8\n\n\n\nNesta lista você:\n✅ Compreendeu diferença entre Path Analysis e CFA\n✅ Especificou modelos em sintaxe lavaan\n✅ Ajustou e interpretou cargas fatoriais\n✅ Avaliou índices de ajuste (CFI, RMSEA, etc.)\n✅ Usou índices de modificação para melhorar modelos\n✅ Comparou modelos aninhados e não-aninhados\n✅ Criou diagramas de modelos SEM\nConceitos-chave: - SEM = Regressão + Análise Fatorial - Path Analysis: apenas variáveis observadas - CFA: testa estrutura de variáveis latentes - =~ “é medido por”, ~ “é regredido por” - Índices de ajuste: CFI, RMSEA, χ² - Modificações devem ser teoricamente justificadas\nAplicações: - Validação de escalas/questionários - Testes de modelos teóricos - Análise de mediação/moderação - Modelos de equações simultâneas\nPróximos passos: - SEM completo (Path + CFA combinados) - Mediação e moderação - Modelos multigrupo - Análise de invariância",
    "crumbs": [
      "SEM",
      "Lista 8: CFA e Path Analysis"
    ]
  },
  {
    "objectID": "lista_8_1.html",
    "href": "lista_8_1.html",
    "title": "1  Lista 8.1: Moderação e Mediação",
    "section": "",
    "text": "1.1 📚 Mediação vs Moderação",
    "crumbs": [
      "SEM",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Lista 8.1: Moderação e Mediação</span>"
    ]
  },
  {
    "objectID": "lista_8_1.html#mediação-vs-moderação",
    "href": "lista_8_1.html#mediação-vs-moderação",
    "title": "1  Lista 8.1: Moderação e Mediação",
    "section": "",
    "text": "Conceitos Fundamentais\n\n\n\nMediação (Como? Por que?) - M explica o mecanismo entre X → Y - X influencia M, que influencia Y - “X afeta Y através de M”\nModeração (Quando? Para quem?) - M modifica a força/direção de X → Y - X × M interage para afetar Y - “O efeito de X em Y depende de M”\nExemplo Mediação: - Exercício → Bem-estar → Produtividade - “Exercício aumenta produtividade porque melhora bem-estar”\nExemplo Moderação: - Estresse × Suporte Social → Saúde Mental - “Estresse afeta saúde diferentemente dependendo do suporte”",
    "crumbs": [
      "SEM",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Lista 8.1: Moderação e Mediação</span>"
    ]
  },
  {
    "objectID": "lista_8_1.html#pacotes",
    "href": "lista_8_1.html#pacotes",
    "title": "1  Lista 8.1: Moderação e Mediação",
    "section": "1.2 📦 Pacotes",
    "text": "1.2 📦 Pacotes\n\n\n✓ Pacotes de mediação carregados!",
    "crumbs": [
      "SEM",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Lista 8.1: Moderação e Mediação</span>"
    ]
  },
  {
    "objectID": "lista_8_1.html#contexto-do-estudo",
    "href": "lista_8_1.html#contexto-do-estudo",
    "title": "1  Lista 8.1: Moderação e Mediação",
    "section": "1.3 📖 Contexto do Estudo",
    "text": "1.3 📖 Contexto do Estudo\n\n\n\n\n\n\nHipótese Teórica\n\n\n\nVariáveis: - Sociabilidade: Escore de questionário (X) - IMC1: Índice de Massa Corporal (M - mediador?) - Treinos: Número de treinos/mês (Y) - Idade: Anos (covariável)\nHipótese: “Sociabilidade aumenta Treinos, mas esse efeito é mediado por IMC”\nOu seja: Pessoas mais sociáveis frequentam mais a academia porque isso afeta seu IMC?",
    "crumbs": [
      "SEM",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Lista 8.1: Moderação e Mediação</span>"
    ]
  },
  {
    "objectID": "lista_8_1.html#carregar-dados",
    "href": "lista_8_1.html#carregar-dados",
    "title": "1  Lista 8.1: Moderação e Mediação",
    "section": "1.4 📥 Carregar Dados",
    "text": "1.4 📥 Carregar Dados\n\ndados &lt;- read.spss(\"DADOS PATH.sav\", to.data.frame = TRUE)\nglimpse(dados)\n\nRows: 94\nColumns: 4\n$ Idade         &lt;dbl&gt; 57, 41, 29, 26, 33, 37, 26, 44, 31, 36, 30, 55, 43, 27, …\n$ IMC1          &lt;dbl&gt; 28.46122, 32.62609, 26.99050, 19.03602, 28.76650, 24.686…\n$ Treinos       &lt;dbl&gt; 108, 144, 48, 102, 123, 63, 39, 105, 6, 48, 144, 144, 11…\n$ Sociabilidade &lt;dbl&gt; 14, 34, 17, 20, 26, 19, 15, 32, 27, 19, 28, 9, 30, 29, 1…",
    "crumbs": [
      "SEM",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Lista 8.1: Moderação e Mediação</span>"
    ]
  },
  {
    "objectID": "lista_8_1.html#modelo-1-imc-como-mediador",
    "href": "lista_8_1.html#modelo-1-imc-como-mediador",
    "title": "1  Lista 8.1: Moderação e Mediação",
    "section": "1.5 🎯 Modelo 1: IMC como Mediador",
    "text": "1.5 🎯 Modelo 1: IMC como Mediador\n\nDiagrama Conceitual\nSociabilidade → IMC1 → Treinos\n       \\________________/\n         (efeito direto c')\n\n\n\n\n\n\nTerminologia de Mediação\n\n\n\nCaminho a: X → M (Sociabilidade → IMC)\nCaminho b: M → Y (IMC → Treinos)\nCaminho c’: X → Y direto (efeito após controlar M)\nCaminho c: X → Y total (sem M no modelo)\nEfeito Indireto: a × b\nEfeito Total: c = c’ + (a × b)\nMediação completa: c’ = 0 (todo efeito via M)\nMediação parcial: c’ ≠ 0 (parte do efeito é direto)\n\n\n\n\n\nEspecificar Modelo\n\nmodelo_med1 &lt;- \"\n  # Regressões\n  Treinos ~ c_*Sociabilidade + b*IMC1\n  IMC1 ~ a*Sociabilidade\n  \n  # Efeitos calculados\n  Indireto := a*b\n  Total := a*b + c_\n\"\n\n\n\n\nAjustar com Bootstrap\n\nfit_med1 &lt;- sem(\n  modelo_med1,\n  data = dados,\n  se = \"bootstrap\",\n  bootstrap = 500\n)\n\n\n\n\n\n\n\nPor que Bootstrap?\n\n\n\nEfeitos indiretos (a × b) não têm distribuição normal!\nBootstrap: - Reamostra dados 500× com reposição - Calcula a × b em cada amostra - IC baseado em distribuição empírica\nMais robusto que método de Sobel para mediação.\n\n\n\n\n\nResultados\n\nparameterEstimates(fit_med1) %&gt;%\n  dplyr::select(lhs, op, rhs, label, est, se, z,  pvalue, ci.lower, ci.upper) %&gt;%\n  kable(\n    digits = 3,\n    col.names = c(\"VD\", \"←\", \"VI\", \"Param\", \"β\", \"EP\", \"z\", \"p\", \"IC_low\", \"IC_up\"),\n    caption = \"Estimativas do Modelo de Mediação 1\"\n  )\n\n\nEstimativas do Modelo de Mediação 1\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVD\n←\nVI\nParam\nβ\nEP\nz\np\nIC_low\nIC_up\n\n\n\n\nTreinos\n~\nSociabilidade\nc_\n0.605\n0.630\n0.961\n0.336\n-0.606\n1.985\n\n\nTreinos\n~\nIMC1\nb\n-1.650\n1.013\n-1.628\n0.104\n-3.501\n0.695\n\n\nIMC1\n~\nSociabilidade\na\n0.019\n0.051\n0.373\n0.709\n-0.093\n0.112\n\n\nTreinos\n~~\nTreinos\n\n2327.025\n196.076\n11.868\n0.000\n1862.905\n2603.848\n\n\nIMC1\n~~\nIMC1\n\n17.733\n2.932\n6.048\n0.000\n11.825\n23.446\n\n\nSociabilidade\n~~\nSociabilidade\n\n65.601\n0.000\nNA\nNA\n65.601\n65.601\n\n\nIndireto\n:=\na*b\nIndireto\n-0.031\n0.100\n-0.315\n0.753\n-0.211\n0.227\n\n\nTotal\n:=\na*b+c_\nTotal\n0.574\n0.632\n0.907\n0.364\n-0.730\n1.905\n\n\n\n\n\n\n\n\nInterpretação - Modelo 1\n\n\n\n\n\n\n📊 Resultado: Mediação NÃO Confirmada\n\n\n\nCaminhos: - a (Soc → IMC): β = 0.019, p = 0.693 → NS - b (IMC → Treino): β = -1.650, p = 0.100 → NS - c’ (Soc → Treino direto): β = 0.605, p = 0.360 → NS\nEfeito Indireto: β = -0.031, p = 0.717 → NS\nConclusão: IMC NÃO medeia a relação entre Sociabilidade e Treinos.\nModelo teórico não se sustenta!\n\n\n\n\n\nDiagrama do Modelo 1\n\nsemPaths(\n  fit_med1,\n  what = \"std\",\n  whatLabels = \"std\",\n  style = \"ram\",\n  layout = \"tree\",\n  rotation = 2,\n  sizeMan = 7,\n  edge.label.cex = 1,\n  label.cex = 1.2,\n  color = list(man = \"lightblue\")\n)",
    "crumbs": [
      "SEM",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Lista 8.1: Moderação e Mediação</span>"
    ]
  },
  {
    "objectID": "lista_8_1.html#comparação-sem-vs-regressões-separadas",
    "href": "lista_8_1.html#comparação-sem-vs-regressões-separadas",
    "title": "1  Lista 8.1: Moderação e Mediação",
    "section": "1.6 🔍 Comparação: SEM vs Regressões Separadas",
    "text": "1.6 🔍 Comparação: SEM vs Regressões Separadas\n\nRegressão 1: Efeito Total (c)\n\n# Sociabilidade → Treinos (sem mediador)\nreg_total &lt;- lm(Treinos ~ Sociabilidade, data = dados)\n\nsummary(reg_total)$coefficients %&gt;%\n  kable(digits = 3, caption = \"Efeito Total (c)\")\n\n\nEfeito Total (c)\n\n\n\nEstimate\nStd. Error\nt value\nPr(&gt;|t|)\n\n\n\n\n(Intercept)\n69.440\n14.164\n4.903\n0.000\n\n\nSociabilidade\n0.574\n0.627\n0.915\n0.363\n\n\n\n\n\n\n\n\nRegressão 2: Caminho a\n\n# Sociabilidade → IMC\nreg_a &lt;- lm(IMC1 ~ Sociabilidade, data = dados)\n\nsummary(reg_a)$coefficients %&gt;%\n  kable(digits = 3, caption = \"Caminho a (X → M)\")\n\n\nCaminho a (X → M)\n\n\n\nEstimate\nStd. Error\nt value\nPr(&gt;|t|)\n\n\n\n\n(Intercept)\n25.397\n1.224\n20.753\n0.000\n\n\nSociabilidade\n0.019\n0.054\n0.351\n0.726\n\n\n\n\n\n\n\n\nRegressão 3: Caminhos b e c’\n\n# IMC + Sociabilidade → Treinos\nreg_bc &lt;- lm(Treinos ~ IMC1 + Sociabilidade, data = dados)\n\nsummary(reg_bc)$coefficients %&gt;%\n  kable(digits = 3, caption = \"Caminhos b (M → Y) e c' (X → Y direto)\")\n\n\nCaminhos b (M → Y) e c’ (X → Y direto)\n\n\n\nEstimate\nStd. Error\nt value\nPr(&gt;|t|)\n\n\n\n\n(Intercept)\n111.339\n33.598\n3.314\n0.001\n\n\nIMC1\n-1.650\n1.201\n-1.374\n0.173\n\n\nSociabilidade\n0.605\n0.625\n0.969\n0.335\n\n\n\n\n\n\n\n\nDiferença: SEM vs Regressões\n\n\n\n\n\n\nPor que SEM é Superior?\n\n\n\nRegressões separadas: - ✓ Estimam a, b, c’ - ✗ NÃO calculam efeito indireto (a × b) - ✗ NÃO fornecem IC para mediação - ✗ Não testam significância da mediação\nSEM (lavaan): - ✓ Estima todos os caminhos - ✓ Calcula efeito indireto automaticamente - ✓ Bootstrap IC para a × b - ✓ Teste formal de mediação\nConclusão: Use SEM para mediação!",
    "crumbs": [
      "SEM",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Lista 8.1: Moderação e Mediação</span>"
    ]
  },
  {
    "objectID": "lista_8_1.html#modelo-2-idade-como-mediador",
    "href": "lista_8_1.html#modelo-2-idade-como-mediador",
    "title": "1  Lista 8.1: Moderação e Mediação",
    "section": "1.7 🎯 Modelo 2: Idade como Mediador",
    "text": "1.7 🎯 Modelo 2: Idade como Mediador\n\n\n\n\n\n\nNova Hipótese\n\n\n\nE se: Sociabilidade → Idade → Treinos?\n(Hipótese pouco plausível, mas vamos testar!)\n\n\n\nmodelo_med2 &lt;- \"\n  Treinos ~ c_*Sociabilidade + b*Idade\n  Idade ~ a*Sociabilidade\n  \n  Indireto := a*b\n  Total := a*b + c_\n\"\n\nfit_med2 &lt;- sem(modelo_med2, data = dados, \n                se = \"bootstrap\", bootstrap = 500)\n\nWarning: lavaan-&gt;lav_model_nvcov_bootstrap():  \n   2 bootstrap runs failed or did not converge.\n\n\n\n\nResultados - Modelo 2\n\nparameterEstimates(fit_med2) %&gt;%\n  filter(op %in% c(\"~\", \":=\")) %&gt;%\n  dplyr::select(lhs, op, rhs, label, est, se, z, pvalue, ci.lower, ci.upper) %&gt;%\n  kable(digits = 3, caption = \"Mediação via Idade\")\n\n\nMediação via Idade\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nlhs\nop\nrhs\nlabel\nest\nse\nz\npvalue\nci.lower\nci.upper\n\n\n\n\nTreinos\n~\nSociabilidade\nc_\n0.485\n0.588\n0.826\n0.409\n-0.533\n1.734\n\n\nTreinos\n~\nIdade\nb\n1.543\n0.507\n3.045\n0.002\n0.407\n2.446\n\n\nIdade\n~\nSociabilidade\na\n0.057\n0.106\n0.539\n0.590\n-0.152\n0.279\n\n\nIndireto\n:=\na*b\nIndireto\n0.088\n0.173\n0.513\n0.608\n-0.221\n0.477\n\n\nTotal\n:=\na*b+c_\nTotal\n0.574\n0.637\n0.901\n0.368\n-0.547\n1.894\n\n\n\n\n\n\n\n\n\n\n\n📊 Resultado\n\n\n\nCaminhos: - a (Soc → Idade): p = 0.592 → NS - b (Idade → Treino): p = 0.001 → Sig! - c’: p = 0.384 → NS\nEfeito Indireto: p = 0.605 → NS\nConclusão: Idade prediz Treinos, mas não medeia efeito de Sociabilidade.\n\n\n\n\n\nDiagrama - Modelo 2\n\nsemPaths(\n  fit_med2,\n  what = \"std\",\n  whatLabels = \"std\",\n  style = \"ram\",\n  layout = \"tree\",\n  rotation = 2,\n  sizeMan = 7,\n  edge.label.cex = 1,\n  color = list(man = \"lightyellow\")\n)",
    "crumbs": [
      "SEM",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Lista 8.1: Moderação e Mediação</span>"
    ]
  },
  {
    "objectID": "lista_8_1.html#modelo-3-imc-idade-treinos",
    "href": "lista_8_1.html#modelo-3-imc-idade-treinos",
    "title": "1  Lista 8.1: Moderação e Mediação",
    "section": "1.8 🎯 Modelo 3: IMC → Idade → Treinos",
    "text": "1.8 🎯 Modelo 3: IMC → Idade → Treinos\n\n\n\n\n\n\nTerceira Hipótese\n\n\n\nExplorando: IMC → Idade → Treinos\n“IMC influencia Treinos através de Idade”\n\n\n\nmodelo_med3 &lt;- \"\n  Treinos ~ c_*IMC1 + b*Idade\n  Idade ~ a*IMC1\n  \n  Indireto := a*b\n  Total := a*b + c_\n\"\n\nfit_med3 &lt;- sem(modelo_med3, data = dados,\n                se = \"bootstrap\", bootstrap = 500)\n\nWarning: lavaan-&gt;lav_model_nvcov_bootstrap():  \n   3 bootstrap runs failed or did not converge.\n\n\n\n\nResultados - Modelo 3\n\nparameterEstimates(fit_med3) %&gt;%\n  filter(op %in% c(\"~\", \":=\")) %&gt;%\n  dplyr::select(lhs, op, rhs, label, est, se, z, pvalue, ci.lower, ci.upper) %&gt;%\n  kable(digits = 3, caption = \"Mediação: IMC → Idade → Treinos\")\n\n\nMediação: IMC → Idade → Treinos\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nlhs\nop\nrhs\nlabel\nest\nse\nz\npvalue\nci.lower\nci.upper\n\n\n\n\nTreinos\n~\nIMC1\nc_\n-2.778\n0.979\n-2.839\n0.005\n-4.669\n-0.735\n\n\nTreinos\n~\nIdade\nb\n1.928\n0.493\n3.914\n0.000\n0.775\n2.788\n\n\nIdade\n~\nIMC1\na\n0.608\n0.212\n2.863\n0.004\n0.228\n1.080\n\n\nIndireto\n:=\na*b\nIndireto\n1.171\n0.516\n2.271\n0.023\n0.317\n2.301\n\n\nTotal\n:=\na*b+c_\nTotal\n-1.607\n1.035\n-1.553\n0.120\n-3.634\n0.590\n\n\n\n\n\n\n\n\n\n\n\n✓ Mediação Confirmada!\n\n\n\nCaminhos: - a (IMC → Idade): β = 0.608, p = 0.005 → Sig! - b (Idade → Treino): β = 1.928, p &lt; 0.001 → Sig! - c’ (IMC → Treino direto): β = -2.778, p = 0.006 → Sig!\nEfeito Indireto: β = 1.171, p = 0.030 → Sig!\nInterpretação: - IMC negativamente relacionado a Treinos (direto) - Mas IMC positivamente relacionado a Idade - E Idade positivamente relacionada a Treinos - Mediação parcial: Parte do efeito é indireto (via Idade)\nEfeito supressor: Indireto e direto têm sinais opostos!\n\n\n\n\n\nDiagrama - Modelo 3\n\nsemPaths(\n  fit_med3,\n  what = \"std\",\n  whatLabels = \"std\",\n  style = \"ram\",\n  layout = \"tree\",\n  rotation = 2,\n  sizeMan = 7,\n  edge.label.cex = 1,\n  color = list(man = \"lightcoral\")\n)",
    "crumbs": [
      "SEM",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Lista 8.1: Moderação e Mediação</span>"
    ]
  },
  {
    "objectID": "lista_8_1.html#análise-complementar-pacote-mediation",
    "href": "lista_8_1.html#análise-complementar-pacote-mediation",
    "title": "1  Lista 8.1: Moderação e Mediação",
    "section": "1.9 📊 Análise Complementar: Pacote mediation",
    "text": "1.9 📊 Análise Complementar: Pacote mediation\n\n# Caminho a\nmodelo_a &lt;- lm(Idade ~ IMC1, data = dados)\n\n# Caminhos b e c'\nmodelo_completo &lt;- lm(Treinos ~ Idade + IMC1, data = dados)\n\n# Análise de mediação\nresultado_med &lt;- mediate(\n  modelo_a,\n  modelo_completo,\n  treat = \"IMC1\",\n  mediator = \"Idade\",\n  boot = TRUE,\n  sims = 500\n)\n\nRunning nonparametric bootstrap\n\nsummary(resultado_med)\n\n\nCausal Mediation Analysis \n\nNonparametric Bootstrap Confidence Intervals with the Percentile Method\n\n               Estimate 95% CI Lower 95% CI Upper p-value   \nACME            1.17100      0.31974      2.49958   0.004 **\nADE            -2.77816     -4.65810     -0.70602   0.012 * \nTotal Effect   -1.60717     -3.57212      0.64278   0.164   \nProp. Mediated -0.72861     -7.31420      6.49552   0.168   \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nSample Size Used: 94 \n\n\nSimulations: 500 \n\n\n\n\nVisualização da Mediação\n\nmediate_plot(Treinos ~ Idade + IMC1, data = dados)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n🔍 Interpretando o Gráfico\n\n\n\nPainel 1 (esquerda): IMC → Idade (caminho a)\nPainel 2 (direita): Idade → Treinos (caminho b)\nPainel 3 (centro): IMC → Treinos direto (c’)\nLinhas mostram relação entre variáveis, controlando outras.",
    "crumbs": [
      "SEM",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Lista 8.1: Moderação e Mediação</span>"
    ]
  },
  {
    "objectID": "lista_8_1.html#comparação-dos-três-modelos",
    "href": "lista_8_1.html#comparação-dos-três-modelos",
    "title": "1  Lista 8.1: Moderação e Mediação",
    "section": "1.10 📊 Comparação dos Três Modelos",
    "text": "1.10 📊 Comparação dos Três Modelos\n\n# Extrair efeitos indiretos\nefeitos &lt;- data.frame(\n  Modelo = c(\n    \"1: Soc → IMC → Treino\",\n    \"2: Soc → Idade → Treino\",\n    \"3: IMC → Idade → Treino\"\n  ),\n  Indireto_β = c(\n    parameterEstimates(fit_med1)[8, \"est\"],\n    parameterEstimates(fit_med2)[8, \"est\"],\n    parameterEstimates(fit_med3)[8, \"est\"]\n  ),\n  Indireto_p = c(\n    parameterEstimates(fit_med1)[8, \"pvalue\"],\n    parameterEstimates(fit_med2)[8, \"pvalue\"],\n    parameterEstimates(fit_med3)[8, \"pvalue\"]\n  )\n) %&gt;%\n  mutate(\n    Significativo = ifelse(Indireto_p &lt; 0.05, \"✓ Sim\", \"✗ Não\"),\n    across(where(is.numeric), ~round(., 3))\n  )\n\nkable(efeitos, caption = \"Comparação de Efeitos Indiretos\")\n\n\nComparação de Efeitos Indiretos\n\n\nModelo\nIndireto_β\nIndireto_p\nSignificativo\n\n\n\n\n1: Soc → IMC → Treino\n0.574\n0.364\n✗ Não\n\n\n2: Soc → Idade → Treino\n0.574\n0.368\n✗ Não\n\n\n3: IMC → Idade → Treino\n-1.607\n0.120\n✗ Não\n\n\n\n\n\n\n\n\n\n\n\n🏆 Modelo Vencedor\n\n\n\nModelo 3 é o único com mediação significativa!\nMensagem: IMC afeta Treinos tanto: - Diretamente (negativamente) - Indiretamente via Idade (positivamente)\nSupressão: Efeito total pode ser enganoso!",
    "crumbs": [
      "SEM",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Lista 8.1: Moderação e Mediação</span>"
    ]
  },
  {
    "objectID": "lista_8_1.html#conceitos-avançados",
    "href": "lista_8_1.html#conceitos-avançados",
    "title": "1  Lista 8.1: Moderação e Mediação",
    "section": "1.11 🎓 Conceitos Avançados",
    "text": "1.11 🎓 Conceitos Avançados\n\n\n\n\n\n\n📚 Tipos de Mediação\n\n\n\n\n\n1. Mediação Completa - c’ = 0 (NS) - Todo efeito via M - Raro na prática\n2. Mediação Parcial - c’ ≠ 0 (Sig) - Efeito direto + indireto - Mais comum\n3. Mediação Inconsistente - c’ e (a×b) têm sinais opostos - “Supressão” - Modelo 3 é exemplo!\n4. Não-Mediação - a×b = 0 (NS) - M não explica X → Y - Modelos 1 e 2\n\n\n\n\n\n\n\n\n\n\n🗺️ Checklist de Mediação\n\n\n\n\n\n1. Requisitos Teóricos - [ ] X → M → Y faz sentido temporal - [ ] M é consequência de X (não pré-existente) - [ ] Mecanismo plausível\n2. Requisitos Estatísticos - [ ] Caminho a significativo (X → M) - [ ] Caminho b significativo (M → Y, controlando X) - [ ] Efeito indireto (a×b) significativo\n3. Não é Necessário - ✗ Efeito total (c) ser significativo - ✗ Baron & Kenny desatualizado!\n4. Bootstrap - [ ] Usar bootstrap (≥ 500 simulações) - [ ] IC não contém zero → mediação\n5. Alternativas - [ ] Considerar variáveis confundidoras - [ ] Testar mediação reversa - [ ] Análise de sensibilidade",
    "crumbs": [
      "SEM",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Lista 8.1: Moderação e Mediação</span>"
    ]
  },
  {
    "objectID": "lista_8_1.html#material-complementar",
    "href": "lista_8_1.html#material-complementar",
    "title": "1  Lista 8.1: Moderação e Mediação",
    "section": "1.12 📚 Material Complementar",
    "text": "1.12 📚 Material Complementar\n\n\n\nRecursos Adicionais\n\n\n\n\n\n\n📖 Aprofundamento\n\n\n\n\n\nTutoriais: - Simple Mediation in R - Dustin Fife - Mediation with Visuals\nLeituras: - Hayes (2017). Introduction to Mediation, Moderation - MacKinnon (2008). Introduction to Statistical Mediation Analysis\nTópicos Avançados: - Mediação múltipla (M1, M2…) - Mediação moderada - Mediação multinível - Análise de sensibilidade (Sensitivity analysis)",
    "crumbs": [
      "SEM",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Lista 8.1: Moderação e Mediação</span>"
    ]
  },
  {
    "objectID": "lista_8_1.html#informações-de-sessão",
    "href": "lista_8_1.html#informações-de-sessão",
    "title": "1  Lista 8.1: Moderação e Mediação",
    "section": "1.13 🔧 Informações de Sessão",
    "text": "1.13 🔧 Informações de Sessão\n\nreport(sessionInfo())\n\nAnalyses were conducted using the R Statistical language (version 4.4.2; R Core\nTeam, 2024) on Windows 11 x64 (build 26100), using the packages Matrix (version\n1.7.1; Bates D et al., 2024), effectsize (version 1.0.1; Ben-Shachar MS et al.,\n2020), semPlot (version 1.1.6; Epskamp S, 2022), flexplot (version 0.24.3;\nFife, D, 2022), mvtnorm (version 1.3.3; Genz A, Bretz F, 2009), lubridate\n(version 1.9.4; Grolemund G, Wickham H, 2011), parameters (version 0.28.3;\nLüdecke D et al., 2020), performance (version 0.15.2; Lüdecke D et al., 2021),\neasystats (version 0.7.5; Lüdecke D et al., 2022), see (version 0.12.0; Lüdecke\nD et al., 2021), insight (version 1.4.4; Lüdecke D et al., 2019), bayestestR\n(version 0.17.0; Makowski D et al., 2019), modelbased (version 0.13.1; Makowski\nD et al., 2025), report (version 0.6.3; Makowski D et al., 2023), correlation\n(version 0.8.8; Makowski D et al., 2022), tibble (version 3.3.1; Müller K,\nWickham H, 2026), datawizard (version 1.3.0; Patil I et al., 2022), foreign\n(version 0.8.87; R Core Team, 2024), lavaan (version 0.6.19; Rosseel Y, 2012),\nmediation (version 4.5.1; Tingley D et al., 2014), MASS (version 7.3.61;\nVenables WN, Ripley BD, 2002), ggplot2 (version 4.0.1; Wickham H, 2016),\nforcats (version 1.0.0; Wickham H, 2023), stringr (version 1.5.1; Wickham H,\n2023), tidyverse (version 2.0.0; Wickham H et al., 2019), dplyr (version 1.1.4;\nWickham H et al., 2023), purrr (version 1.0.4; Wickham H, Henry L, 2025), readr\n(version 2.1.5; Wickham H et al., 2024), tidyr (version 1.3.1; Wickham H et\nal., 2024), sandwich (version 3.1.1; Zeileis A et al., 2020) and kableExtra\n(version 1.4.0; Zhu H, 2024).\n\nReferences\n----------\n  - Bates D, Maechler M, Jagan M (2024). _Matrix: Sparse and Dense Matrix Classes\nand Methods_. R package version 1.7-1,\n&lt;https://CRAN.R-project.org/package=Matrix&gt;.\n  - Ben-Shachar MS, Lüdecke D, Makowski D (2020). \"effectsize: Estimation of\nEffect Size Indices and Standardized Parameters.\" _Journal of Open Source\nSoftware_, *5*(56), 2815. doi:10.21105/joss.02815\n&lt;https://doi.org/10.21105/joss.02815&gt;, &lt;https://doi.org/10.21105/joss.02815&gt;.\n  - Epskamp S (2022). _semPlot: Path Diagrams and Visual Analysis of Various SEM\nPackages' Output_. R package version 1.1.6,\n&lt;https://CRAN.R-project.org/package=semPlot&gt;.\n  - Fife, A. D (2022). \"Flexplot: Graphically-based data analysis.\"\n_Psychological Methods_, *27*(4), -19. &lt;doi.org/10.1037/met0000424&gt;.\n  - Genz A, Bretz F (2009). _Computation of Multivariate Normal and t\nProbabilities_, series Lecture Notes in Statistics. Springer-Verlag,\nHeidelberg. ISBN 978-3-642-01688-2.\n  - Grolemund G, Wickham H (2011). \"Dates and Times Made Easy with lubridate.\"\n_Journal of Statistical Software_, *40*(3), 1-25.\n&lt;https://www.jstatsoft.org/v40/i03/&gt;.\n  - Lüdecke D, Ben-Shachar M, Patil I, Makowski D (2020). \"Extracting, Computing\nand Exploring the Parameters of Statistical Models using R.\" _Journal of Open\nSource Software_, *5*(53), 2445. doi:10.21105/joss.02445\n&lt;https://doi.org/10.21105/joss.02445&gt;.\n  - Lüdecke D, Ben-Shachar M, Patil I, Waggoner P, Makowski D (2021).\n\"performance: An R Package for Assessment, Comparison and Testing of\nStatistical Models.\" _Journal of Open Source Software_, *6*(60), 3139.\ndoi:10.21105/joss.03139 &lt;https://doi.org/10.21105/joss.03139&gt;.\n  - Lüdecke D, Ben-Shachar M, Patil I, Wiernik B, Bacher E, Thériault R, Makowski\nD (2022). \"easystats: Framework for Easy Statistical Modeling, Visualization,\nand Reporting.\" _CRAN_. doi:10.32614/CRAN.package.easystats\n&lt;https://doi.org/10.32614/CRAN.package.easystats&gt;, R package,\n&lt;https://easystats.github.io/easystats/&gt;.\n  - Lüdecke D, Patil I, Ben-Shachar M, Wiernik B, Waggoner P, Makowski D (2021).\n\"see: An R Package for Visualizing Statistical Models.\" _Journal of Open Source\nSoftware_, *6*(64), 3393. doi:10.21105/joss.03393\n&lt;https://doi.org/10.21105/joss.03393&gt;.\n  - Lüdecke D, Waggoner P, Makowski D (2019). \"insight: A Unified Interface to\nAccess Information from Model Objects in R.\" _Journal of Open Source Software_,\n*4*(38), 1412. doi:10.21105/joss.01412 &lt;https://doi.org/10.21105/joss.01412&gt;.\n  - Makowski D, Ben-Shachar M, Lüdecke D (2019). \"bayestestR: Describing Effects\nand their Uncertainty, Existence and Significance within the Bayesian\nFramework.\" _Journal of Open Source Software_, *4*(40), 1541.\ndoi:10.21105/joss.01541 &lt;https://doi.org/10.21105/joss.01541&gt;,\n&lt;https://joss.theoj.org/papers/10.21105/joss.01541&gt;.\n  - Makowski D, Ben-Shachar M, Wiernik B, Patil I, Thériault R, Lüdecke D (2025).\n\"modelbased: An R package to make the most out of your statistical models\nthrough marginal means, marginal effects, and model predictions.\" _Journal of\nOpen Source Software_, *10*(109), 7969. doi:10.21105/joss.07969\n&lt;https://doi.org/10.21105/joss.07969&gt;,\n&lt;https://joss.theoj.org/papers/10.21105/joss.07969&gt;.\n  - Makowski D, Lüdecke D, Patil I, Thériault R, Ben-Shachar M, Wiernik B (2023).\n\"Automated Results Reporting as a Practical Tool to Improve Reproducibility and\nMethodological Best Practices Adoption.\" _CRAN_.\ndoi:10.32614/CRAN.package.report\n&lt;https://doi.org/10.32614/CRAN.package.report&gt;,\n&lt;https://easystats.github.io/report/&gt;.\n  - Makowski D, Wiernik B, Patil I, Lüdecke D, Ben-Shachar M (2022).\n\"correlation: Methods for Correlation Analysis.\" Version 0.8.3,\n&lt;https://CRAN.R-project.org/package=correlation&gt;. Makowski D, Ben-Shachar M,\nPatil I, Lüdecke D (2020). \"Methods and Algorithms for Correlation Analysis in\nR.\" _Journal of Open Source Software_, *5*(51), 2306. doi:10.21105/joss.02306\n&lt;https://doi.org/10.21105/joss.02306&gt;,\n&lt;https://joss.theoj.org/papers/10.21105/joss.02306&gt;.\n  - Müller K, Wickham H (2026). _tibble: Simple Data Frames_. R package version\n3.3.1, &lt;https://CRAN.R-project.org/package=tibble&gt;.\n  - Patil I, Makowski D, Ben-Shachar M, Wiernik B, Bacher E, Lüdecke D (2022).\n\"datawizard: An R Package for Easy Data Preparation and Statistical\nTransformations.\" _Journal of Open Source Software_, *7*(78), 4684.\ndoi:10.21105/joss.04684 &lt;https://doi.org/10.21105/joss.04684&gt;.\n  - R Core Team (2024). _foreign: Read Data Stored by 'Minitab', 'S', 'SAS',\n'SPSS', 'Stata', 'Systat', 'Weka', 'dBase', ..._. R package version 0.8-87,\n&lt;https://CRAN.R-project.org/package=foreign&gt;.\n  - R Core Team (2024). _R: A Language and Environment for Statistical\nComputing_. R Foundation for Statistical Computing, Vienna, Austria.\n&lt;https://www.R-project.org/&gt;.\n  - Rosseel Y (2012). \"lavaan: An R Package for Structural Equation Modeling.\"\n_Journal of Statistical Software_, *48*(2), 1-36. doi:10.18637/jss.v048.i02\n&lt;https://doi.org/10.18637/jss.v048.i02&gt;.\n  - Tingley D, Yamamoto T, Hirose K, Keele L, Imai K (2014). \"mediation: R\nPackage for Causal Mediation Analysis.\" _Journal of Statistical Software_,\n*59*(5), 1-38. &lt;https://www.jstatsoft.org/v59/i05/&gt;. Imai K, Keele L, Yamamoto\nT (2010). \"Identification, Inference, and Sensitivity Analysis for Causal\nMediation Effects.\" _Statistical Science_, *25*(1), 51-71.\n&lt;https://imai.fas.harvard.edu/research/mediation.html&gt;. Imai K, Keele L,\nTingley D (2010). \"A General Approach to Causal Mediation Analysis.\"\n_Psychological Methods_, *15*(4), 309-334.\n&lt;https://imai.fas.harvard.edu/research/BaronKenny.html&gt;. Imai K, Keele L,\nTingley D, Yamamoto T (2011). \"Unpacking the Black Box of Causality: Learning\nabout Causal Mechanisms from Experimental and Observational Studies.\" _American\nPolitical Science Review_, *105*(4), 765-789.\n&lt;https://imai.fas.harvard.edu/research/mediationP.html&gt;. Imai K, Yamamoto T\n(2013). \"Identification and Sensitivity Analysis for Multiple Causal\nMechanisms: Revisiting Evidence from Framing Experiments.\" _Political\nAnalysis_, *21*(2), 141-171.\n&lt;https://imai.fas.harvard.edu/research/medsens.html&gt;. Imai K, Keele L, Tingley\nD, Yamamoto T (2010). \"Causal Mediation Analysis Using R.\" In Vinod HD (ed.),\n_Advances in Social Science Research Using R_. Springer-Verlag, New York.\n  - Venables WN, Ripley BD (2002). _Modern Applied Statistics with S_, Fourth\nedition. Springer, New York. ISBN 0-387-95457-0,\n&lt;https://www.stats.ox.ac.uk/pub/MASS4/&gt;.\n  - Wickham H (2016). _ggplot2: Elegant Graphics for Data Analysis_.\nSpringer-Verlag New York. ISBN 978-3-319-24277-4,\n&lt;https://ggplot2.tidyverse.org&gt;.\n  - Wickham H (2023). _forcats: Tools for Working with Categorical Variables\n(Factors)_. R package version 1.0.0,\n&lt;https://CRAN.R-project.org/package=forcats&gt;.\n  - Wickham H (2023). _stringr: Simple, Consistent Wrappers for Common String\nOperations_. R package version 1.5.1,\n&lt;https://CRAN.R-project.org/package=stringr&gt;.\n  - Wickham H, Averick M, Bryan J, Chang W, McGowan LD, François R, Grolemund G,\nHayes A, Henry L, Hester J, Kuhn M, Pedersen TL, Miller E, Bache SM, Müller K,\nOoms J, Robinson D, Seidel DP, Spinu V, Takahashi K, Vaughan D, Wilke C, Woo K,\nYutani H (2019). \"Welcome to the tidyverse.\" _Journal of Open Source Software_,\n*4*(43), 1686. doi:10.21105/joss.01686 &lt;https://doi.org/10.21105/joss.01686&gt;.\n  - Wickham H, François R, Henry L, Müller K, Vaughan D (2023). _dplyr: A Grammar\nof Data Manipulation_. R package version 1.1.4,\n&lt;https://CRAN.R-project.org/package=dplyr&gt;.\n  - Wickham H, Henry L (2025). _purrr: Functional Programming Tools_. R package\nversion 1.0.4, &lt;https://CRAN.R-project.org/package=purrr&gt;.\n  - Wickham H, Hester J, Bryan J (2024). _readr: Read Rectangular Text Data_. R\npackage version 2.1.5, &lt;https://CRAN.R-project.org/package=readr&gt;.\n  - Wickham H, Vaughan D, Girlich M (2024). _tidyr: Tidy Messy Data_. R package\nversion 1.3.1, &lt;https://CRAN.R-project.org/package=tidyr&gt;.\n  - Zeileis A, Köll S, Graham N (2020). \"Various Versatile Variances: An\nObject-Oriented Implementation of Clustered Covariances in R.\" _Journal of\nStatistical Software_, *95*(1), 1-36. doi:10.18637/jss.v095.i01\n&lt;https://doi.org/10.18637/jss.v095.i01&gt;. Zeileis A (2004). \"Econometric\nComputing with HC and HAC Covariance Matrix Estimators.\" _Journal of\nStatistical Software_, *11*(10), 1-17. doi:10.18637/jss.v011.i10\n&lt;https://doi.org/10.18637/jss.v011.i10&gt;. Zeileis A (2006). \"Object-Oriented\nComputation of Sandwich Estimators.\" _Journal of Statistical Software_,\n*16*(9), 1-16. doi:10.18637/jss.v016.i09\n&lt;https://doi.org/10.18637/jss.v016.i09&gt;.\n  - Zhu H (2024). _kableExtra: Construct Complex Table with 'kable' and Pipe\nSyntax_. R package version 1.4.0,\n&lt;https://CRAN.R-project.org/package=kableExtra&gt;.\n\n\n\n\n\n\n\n\n\n🎓 Resumo da Lista 8.1\n\n\n\nNesta lista você:\n✅ Compreendeu mediação vs moderação\n✅ Especificou modelos de mediação em lavaan\n✅ Calculou efeitos indiretos com bootstrap\n✅ Interpretou caminhos a, b, c, c’\n✅ Identificou mediação parcial e supressão\n✅ Comparou SEM vs regressões separadas\n✅ Usou mediation package para análise complementar\nConceitos-chave: - Mediação explica como/por que X afeta Y - Efeito indireto = a × b - Bootstrap para IC robusto - c = c’ + (a × b) - Mediação parcial mais comum que completa - SEM superior a regressões separadas\nAplicações: - Testar mecanismos psicológicos - Validar teorias causais - Identificar variáveis-alvo para intervenção - Análise de processos mediacionais\nArmadilhas comuns: - ✗ Assumir causalidade sem desenho apropriado - ✗ Ignorar confundidores - ✗ Mediação sem fundamentação teórica - ✗ Usar método Baron & Kenny desatualizado\n\n\n\n\n\n\n\n\n\n🎉 Parabéns!\n\n\n\nVocê completou todas as 10 listas do tutorial de Modelos Estatísticos em R!\nJornada percorrida: 1. ✓ Introdução e GLM básico 2. ✓ GEE com diferentes distribuições 3. ✓ Matrizes de covariância (GMM) 4. ✓ Modelos hierárquicos e ICC 5. ✓ Modelos lineares generalizados 6. ✓ Análise de sobrevida (Kaplan-Meier e Cox) 7. ✓ Cox tempo-dependente 8. ✓ Séries temporais (ARIMA) 9. ✓ CFA e Path Analysis 10. ✓ Mediação e Moderação\nPróximos passos: - Aplicar em seus dados reais - Consultar material complementar - Contribuir com feedback - Compartilhar conhecimento!\nBons estudos e sucesso em suas análises! 📊🚀",
    "crumbs": [
      "SEM",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Lista 8.1: Moderação e Mediação</span>"
    ]
  }
]