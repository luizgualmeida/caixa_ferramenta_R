[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Técnicas e Métodos de Pesquisa no R",
    "section": "",
    "text": "Introdução\nTutorial produzido com base nas aulas práticas da disciplina “Estatística Aplicada a Psicobiologia II - 2023”, ministrada pelo Professor Altay Lino de Souza e oferecida pelo Departamento de Psicobiologia da UNIFESP."
  },
  {
    "objectID": "index.html#sobre-as-aulas",
    "href": "index.html#sobre-as-aulas",
    "title": "Técnicas e Métodos de Pesquisa no R",
    "section": "Sobre as aulas",
    "text": "Sobre as aulas\nAs aulas são gravadas e disponibilizadas gratuitamente por meio de lives no canal Cientística & Podcast Naruhodo do YouTube. Destacando aqui o agradecimento mais do que especial para a Maria Lucia Oliveira De Souza Formigoni, por tornar possível a disciplina."
  },
  {
    "objectID": "index.html#sobre-o-tutorial",
    "href": "index.html#sobre-o-tutorial",
    "title": "Técnicas e Métodos de Pesquisa no R",
    "section": "Sobre o tutorial",
    "text": "Sobre o tutorial\nEste tutorial tem como objetivo oferecer uma introdução prática à análise estatística de dados no R, utilizando diversos bancos de dados para cada tipo de anáise. O público-alvo abrange estudantes de Estatística Aplicada a Psicobiologia II, pós-graduandos e pesquisadores que buscam aprimorar suas habilidades em análise de dados. É recomendado ter conhecimento básico em estatística, particularmente Estatística Aplicada a Psicobiologia I, e alguma familiaridade com o ambiente R para acompanhar este tutorial. Abordaremos as seguintes análises:\n\nTransformação de dados para análises\nModelos lineares:\n\nModelo linear geral (GLM ) de medidas repetidas\nGeneralized Estimated Equations (GEE)\nModelos mistos e hierárquicos (GMM)\nGeneralized linear models (GzLM)\n\n\n\n\nAnálise de sobrevida\n\nKaplan-Meier\nRegressão de Cox\nCox Tempo dependente\n\n\n\n\nSéries temporais (ARIMA)\nModelagem de Equação Estrutural (SEM)\n\nPath analysis\nConfrmatory Factor Analysis (CFA)\nModeração e mediação\n\n\nAo fim de cada capítulos, nas seções intituladas “Extras”, vamos mostrar dicas sobre pacotes que podem ser úteis para suas análises, mas que não estão disponíveis no SPSS ou no Jamovi.\n\n\n\n\n\n\nImportante!\n\n\n\nO material apresentado aqui é complementar às aulas teóricas e práticas. É imprescindível que você assista às aulas antes de resolver os exercícios no R."
  },
  {
    "objectID": "index.html#r-e-rstudio",
    "href": "index.html#r-e-rstudio",
    "title": "Técnicas e Métodos de Pesquisa no R",
    "section": "R e Rstudio",
    "text": "R e Rstudio\nEmbora as aulas práticas tenham sido gravadas utilizando o SPSS, o intuito do tutorial é replicar as análises no R, que é gratuito! Portanto você precisa baixar o R e o Rstudio.\nDownload do R\nDownload do Rstudio"
  },
  {
    "objectID": "index.html#aulas-práticas-gravadas",
    "href": "index.html#aulas-práticas-gravadas",
    "title": "Técnicas e Métodos de Pesquisa no R",
    "section": "Aulas práticas gravadas",
    "text": "Aulas práticas gravadas\nOs vídeos das aulas práticas no SPSS foram anexados ao fim de cada capítulo para que você possa ter uma referência do tipo de análise realizada. Em alguns casos você notarão que os resultados não serão idênticos no SPSS e no R. Isso ocorre devido aos diferentes algorítimos de estimação de coeficientes utilizados nos programas. O importante é você sempre reportar como a análise foi feita, quais programas e sempre que possível, disponibilizar o código ou o passo-a-passo utilizado para realizar a análise."
  },
  {
    "objectID": "index.html#boas-práticas-no-rstudio",
    "href": "index.html#boas-práticas-no-rstudio",
    "title": "Técnicas e Métodos de Pesquisa no R",
    "section": "Boas práticas no Rstudio",
    "text": "Boas práticas no Rstudio\nCriar um projeto separado para cada tipo de análise no R é uma prática recomendada porque mantém o ambiente organizado, evita conflitos entre projetos, facilita a colaboração e torna a reprodução e compartilhamento de trabalho mais eficientes.\n\nCriando o projeto e alocando os arquivos\nPara criar um novo projeto no R, siga estes passos simples:\n\nAbra o RStudio.\nVá até a guia “File” (Arquivo) e selecione “New Project” (Novo Projeto).\nEscolha um diretório para o seu projeto, onde todas as pastas e arquivos relacionados a ele serão armazenados. Isso ajudará na organização.\nClique em “Create Project” (Criar Projeto).\n\nFeito isso você terá um novo projeto configurado. Qualquer arquivo que você deseje usar para o tutorial deve ser colocado dentro da pasta desse projeto. Isso garantirá que todos os caminhos e referências aos arquivos sejam relativos ao diretório do projeto, facilitando a portabilidade e compartilhamento do tutorial.\nCom esses passos, você terá um ambiente de projeto limpo e organizado para trabalhar com seus arquivos e conduzir seu tutorial no R."
  },
  {
    "objectID": "index.html#instalando-e-carregando-os-pacotes",
    "href": "index.html#instalando-e-carregando-os-pacotes",
    "title": "Técnicas e Métodos de Pesquisa no R",
    "section": "Instalando e carregando os pacotes",
    "text": "Instalando e carregando os pacotes\nNo início de cada capítulo, você encontrará uma lista completa dos pacotes necessários para reproduzir as análises correspondentes.\nPara instalar um pacote, basta executar o comando install.packages(\"nome_do_pacote\") uma única vez.\nPor exemplo: install.packages(\"effects\"). Este comando instalará o pacote “effects”, que contém funções para calcular os estimadores de modelos lineares. É importante colocar o nome do pacote entre aspas (” “)\nApós a instalação do pacote, será necessário carregá-lo sempre que desejar utilizar alguma função associada a ele. Para isso basta executar o comando library(nome_do_pacote). Note que aqui não há a necessidade de colocar o nome do pacote entre aspas.\nExemplo: library(effects).\nPronto! Agora você está familiarizado com o processo de instalação e carregamento dos pacotes que serão utilizados ao longo deste tutorial. Pode-se fazer uma analogia com uma biblioteca: adquirir os livros seria como instalar os pacotes (install.packages), e retirar um livro da prateleira seria como carregar o pacote (library) quando necessário."
  },
  {
    "objectID": "index.html#referências",
    "href": "index.html#referências",
    "title": "Técnicas e Métodos de Pesquisa no R",
    "section": "Referências",
    "text": "Referências\n\nhttps://r4ds.hadley.nz/"
  },
  {
    "objectID": "lms.html#resumo-sobre-os-modelos-lineares-abordados",
    "href": "lms.html#resumo-sobre-os-modelos-lineares-abordados",
    "title": "GLM, GEE, GMM, GzLM",
    "section": "Resumo sobre os modelos lineares abordados",
    "text": "Resumo sobre os modelos lineares abordados\n\nModelo Linear Geral (GLM) de Medidas Repetidas: O Modelo Linear Geral de Medidas Repetidas é uma extensão do modelo linear geral tradicional, projetado para lidar com dados repetidos ao longo do tempo. Ele é utilizado quando há correlação entre as observações, como em estudos longitudinais, e permite modelar a estrutura de covariância entre as medições repetidas.\n\nDesenho de Estudo Sugerido:\n\nUm estudo longitudinal com medições repetidas ao longo do tempo em um grupo de participantes.\n\nExemplo:\n\nAcompanhamento de pacientes com uma condição médica específica, medindo regularmente os níveis de uma variável biológica para observar mudanças ao longo do tratamento.\n\n\nGeneralized Estimated Equations (GEE): As Equações Estimadas Generalizadas (GEE) são uma abordagem estatística para análise de dados longitudinais ou correlacionados. Elas proporcionam uma estrutura robusta para lidar com a dependência entre as observações, permitindo estimativas eficientes dos parâmetros, mesmo quando a especificação da covariância não é precisa.\n\nDesenho de Estudo Sugerido:\n\nUm estudo observacional ou ensaio clínico longitudinal onde as medições podem ser correlacionadas, como em estudos epidemiológicos.\n\nExemplo:\n\nInvestigação sobre a eficácia de um programa de intervenção de saúde em que as observações estão correlacionadas dentro dos grupos de participantes.\n\n\nModelos Mistos e Hierárquicos (GMM): Os Modelos Mistos e Hierárquicos, também conhecidos como Modelos de Efeitos Misto, combinam componentes fixos e aleatórios para modelar tanto a variabilidade fixa quanto a aleatória nos dados. Esses modelos são particularmente úteis quando há hierarquia nos dados, como em estudos multicêntricos, onde as observações podem ser agrupadas em diferentes níveis (por exemplo, centros de pesquisa). Eles permitem capturar a variabilidade tanto dentro quanto entre os grupos, oferecendo uma abordagem flexível para análise de dados complexos.\n\nDesenho de Estudo Sugerido:\n\nEstudos multicêntricos ou experimentos com estrutura hierárquica, onde as unidades de observação estão agrupadas em diferentes níveis.\n\nExemplo:\n\nAvaliação do desempenho acadêmico de alunos em escolas, onde os alunos (nível inferior) estão agrupados em salas de aula (níveis superiores), considerando o efeito tanto do ensino individual quanto do ambiente escolar."
  },
  {
    "objectID": "lms.html#principais-vantagens-dos-modelos-lineres-de-medidas-repetidas-em-comparação-com-a-anova",
    "href": "lms.html#principais-vantagens-dos-modelos-lineres-de-medidas-repetidas-em-comparação-com-a-anova",
    "title": "GLM, GEE, GMM, GzLM",
    "section": "Principais vantagens dos modelos lineres de medidas repetidas em comparação com a ANOVA",
    "text": "Principais vantagens dos modelos lineres de medidas repetidas em comparação com a ANOVA\n\nModelagem flexível: O GLM permite modelar e analisar experimentos com medidas repetidas de forma mais flexível. Você pode incluir múltiplos fatores independentes (variáveis independentes) em um único modelo e estudar suas interações, o que é especialmente útil em experimentos complexos.\nTratamento de dados desequilibrados: O GLM pode lidar eficazmente com desequilíbrio nas amostras ou tamanhos diferentes de grupos, o que é comum em experimentos do mundo real. A ANOVA tradicional é mais sensível a desequilíbrio.\nModelagem de covariáveis: O GLM permite incorporar covariáveis (variáveis de controle) em sua análise para controlar o efeito de variáveis que não são o foco principal do estudo. Isso melhora a precisão das estimativas dos efeitos de interesse.\nCorreções para violações de pressupostos: Quando os pressupostos da ANOVA, como a homogeneidade de variâncias ou normalidade dos resíduos, são violados, o GLM oferece opções para corrigir ou lidar com essas violações, tornando os resultados mais robustos.\nModelagem de medidas contínuas e categóricas: O GLM pode acomodar variáveis dependentes contínuas e categóricas (nominais ou ordinais), o que é útil em situações em que a variável dependente é de natureza diferente.\nMaior poder estatístico: O GLM pode ser mais poderoso do que a ANOVA em situações em que as medidas repetidas têm alta correlação entre si, permitindo detectar diferenças significativas mesmo com tamanhos de amostra menores.\nAnálise de interações complexas: O GLM é especialmente eficaz na análise de interações complexas entre fatores independentes em designs experimentais com medidas repetidas, o que é difícil de realizar com a ANOVA."
  },
  {
    "objectID": "lms.html#pacotes-que-vamos-utilizar",
    "href": "lms.html#pacotes-que-vamos-utilizar",
    "title": "GLM, GEE, GMM, GzLM",
    "section": "Pacotes que vamos utilizar",
    "text": "Pacotes que vamos utilizar\n\nlibrary(emmeans)   # Cálculo de médias estimadas após análises estatísticas.\nlibrary(lme4)      # Ajuste de modelos lineares mistos.\nlibrary(nlme)      # Ajuste de modelos mistos não lineares.\nlibrary(flexplot)  # Criação de gráficos flexíveis e personalizados.\nlibrary(foreign)   # Importação/exportação de dados de outros formatos.\nlibrary(tidyr)     # Manipulação de dados.\nlibrary(dplyr)     # Manipulação e transformação de dados de maneira eficiente.\nlibrary(multcomp)  # Correção de múltiplas comparações pós-teste.\nlibrary(effects)   # Visualização de efeitos de modelos estatísticos.\nlibrary(sjstats)   # Estatísticas descritivas e sumarização de modelos.\n#library(tm)        # Análise de texto e mineração de texto.\n#library(car)       # Análise de regressão e diagnóstico de regressão.\n#library(pwr)       # Cálculo do poder estatístico em estudos de amostragem.\nlibrary(rstatix)   # Análise estatística simplificada.\nlibrary(geepack)   # Ajuste de modelos de equações de estimação generalizadas.\n#library(htmltools) # Ferramentas para trabalhar com HTML.\n#library(mime)      # Ferramentas para manipulação de tipos MIME.\nlibrary(performance) # Avaliação e melhoria do desempenho do modelo linear\nlibrary(see)       # Simplificar a exploração de dados\nlibrary(rempsyc)   # Métodos psicométricos e estatísticas relacionadas à psicometria\nlibrary(easystats) # Simplifica a análise estatística"
  },
  {
    "objectID": "lms.html#banco-de-dados-script-e-lista-1",
    "href": "lms.html#banco-de-dados-script-e-lista-1",
    "title": "GLM, GEE, GMM, GzLM",
    "section": "Banco de dados, script e Lista 1",
    "text": "Banco de dados, script e Lista 1\nFaça o download do arquivo compactado abaixo.\n\n\nDownload Lista 1.zip\n\n\nLembre-se de descompactar os três arquivos na mesma pasta do projeto que você acabou de criar!\nO arquivo compactado contém:\n\nbd_New drug_respiratory&pulse.sav: Este é o arquivo de banco de dados que será usado ao longo do tutorial. Ele contém os dados que serão analisados e explorados durante os exercícios.\nlista1_parcial.R: Este arquivo .R contém o script parcialmente preenchido para praticar e estudar os códigos abordados no tutorial. Você pode usar este script como um guia interativo para aprender e executar as análises estatísticas.\nA \"Lista de Exercícios 1\" contém os exercícios para serem resolvidos."
  },
  {
    "objectID": "lms.html#carregando-os-dados",
    "href": "lms.html#carregando-os-dados",
    "title": "GLM, GEE, GMM, GzLM",
    "section": "Carregando os Dados",
    "text": "Carregando os Dados\nVamos começar carregando o conjunto de dados original e realizando algumas transformações para tornar possível nossas análises.\n\noriginal_wide = read.spss(\"bd_New drug_respiratory&pulse.sav\", to.data.frame=TRUE) \nhead(original_wide)\n\n      drug resp1 resp2 resp3 pulse1 pulse2 pulse3\n1 New Drug   3.4   3.3   3.3    2.2    2.1    2.1\n2 New Drug   3.4   3.4   3.3    2.2    2.1    2.2\n3 New Drug   3.3   3.4   3.4    2.3    2.4    2.3\n4 New Drug   3.4   3.4   3.4    2.3    2.4    2.3\n5 New Drug   3.3   3.4   3.3    2.2    2.2    2.4\n6 New Drug   3.3   3.3   3.3    2.0    2.1    2.4\n\n\nO código fornecido tem como objetivo carregar um conjunto de dados a partir de um arquivo SPSS chamado “bd_New drug_respiratory&pulse.sav” e exibir as primeiras linhas desse conjunto de dados.\n\noriginal_wide = read.spss(\"bd_New drug_respiratory&pulse.sav\", to.data.frame=TRUE): Esta linha de código utiliza a função read.spss para ler o arquivo SPSS “bd_New drug_respiratory&pulse.sav” e convertê-lo em um objeto de data frame do R. A opção to.data.frame=TRUE especifica que queremos que os dados sejam armazenados em um data frame.\nhead(original_wide): Após a leitura do conjunto de dados, esta linha de código utiliza a função head para mostrar as primeiras linhas do data frame original_wide. Isso ajuda a visualizar rapidamente os dados e verificar sua estrutura."
  },
  {
    "objectID": "lms.html#transformando-o-banco-de-dados-de-wide-para-long",
    "href": "lms.html#transformando-o-banco-de-dados-de-wide-para-long",
    "title": "GLM, GEE, GMM, GzLM",
    "section": "Transformando o Banco de Dados de Wide para Long",
    "text": "Transformando o Banco de Dados de Wide para Long\nPara tornar possível algumas análises, precisamos transformar o banco de dados de formato “wide” para “long”. Isso nos permitirá realizar análises de medidas repetidas.\n\nbd &lt;- original_wide %&gt;%\n  rename_with(~gsub(\"(resp|pulse)(\\\\d+)\", \"\\\\1_\\\\2\", .), -drug) %&gt;%\n  mutate(ID = row_number()) %&gt;%\n  dplyr::select(ID, everything())  \n\n\nhead(bd)\n\n  ID     drug resp_1 resp_2 resp_3 pulse_1 pulse_2 pulse_3\n1  1 New Drug    3.4    3.3    3.3     2.2     2.1     2.1\n2  2 New Drug    3.4    3.4    3.3     2.2     2.1     2.2\n3  3 New Drug    3.3    3.4    3.4     2.3     2.4     2.3\n4  4 New Drug    3.4    3.4    3.4     2.3     2.4     2.3\n5  5 New Drug    3.3    3.4    3.3     2.2     2.2     2.4\n6  6 New Drug    3.3    3.3    3.3     2.0     2.1     2.4\n\n\nOs códigos fornecidos têm como objetivo renomear colunas e transformar um conjunto de dados de formato “wide” para “long”, onde uma expressão regular está sendo utilizada para facilitar esse processo.\nUma expressão regular, ou regex, é uma sequência de caracteres que define um padrão de busca em texto, permitindo operações avançadas de busca e manipulação. Elas são amplamente usadas na programação para validação, extração e transformação de dados em texto.\nNo primeiro trecho de código, estamos renomeando as colunas do conjunto de dados original_wide. Aqui, a expressão regular (resp|pulse)(\\\\d+) está sendo usada na função gsub. Vamos explicar essa expressão regular:\n\n(resp|pulse): Isso corresponde à palavra “resp” OU “pulse”. O operador | atua como uma escolha, permitindo que corresponda a uma das duas palavras.\n(\\\\d+): Isso corresponde a um ou mais dígitos numéricos. O \\\\d+ é usado para extrair os números que seguem “resp” ou “pulse”.\n\nA expressão regular (resp|pulse)(\\\\d+) funciona para identificar colunas com nomes como “resp1”, “resp2”, “pulse1”, “pulse2” etc. A função gsub substitui esses nomes de colunas por um novo formato, onde mantém “resp” ou “pulse” e adiciona o número correspondente. Por exemplo, “resp1” será renomeado para “resp_1”, “pulse2” será renomeado para “pulse_2” e assim por diante.\nIsso é útil para o próximo passo porque torna mais fácil identificar e separar os dados de resp e pulse em diferentes colunas. Além disso, os números extraídos da expressão regular serão usados para criar a variável “Tempo”, que indicará as medidas repetidas ao longo do tempo.\n\nbd_long = pivot_longer(bd, \n                       cols = resp_1:pulse_3, \n                       names_to = c(\".value\", \"Tempo\"), \n                       names_pattern = \"(.+)_(.+)\")\n\nhead(bd_long)\n\n# A tibble: 6 × 5\n     ID drug     Tempo  resp pulse\n  &lt;int&gt; &lt;fct&gt;    &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt;\n1     1 New Drug 1       3.4   2.2\n2     1 New Drug 2       3.3   2.1\n3     1 New Drug 3       3.3   2.1\n4     2 New Drug 1       3.4   2.2\n5     2 New Drug 2       3.4   2.1\n6     2 New Drug 3       3.3   2.2\n\n\nNo segundo trecho de código, estamos usando a função pivot_longer para transformar o conjunto de dados bd de formato “wide” para “long”. A opção names_pattern usa a expressão regular (.)_(.) para dividir os nomes das colunas em duas partes:\n\n(.+): Isso corresponde a qualquer sequência de caracteres, representando os nomes originais das colunas.\n_(.+): Isso corresponde ao caractere sublinhado “_” seguido de qualquer sequência de caracteres. Essa parte será usada para identificar os valores correspondentes nas colunas no formato “long”.\n\nPortanto, a expressão regular (.)_(.) ajuda a extrair informações dos nomes das colunas originais e organizá-las adequadamente no formato “long” do conjunto de dados bd_long, onde a primeira parte é armazenada na coluna \"Tempo\" e a segunda parte é usada para identificar os valores correspondentes na coluna \"valor\" (geralmente representada como .value no R)."
  },
  {
    "objectID": "lms.html#alterando-o-tipo-da-variável-tempo",
    "href": "lms.html#alterando-o-tipo-da-variável-tempo",
    "title": "GLM, GEE, GMM, GzLM",
    "section": "Alterando o tipo da variável “Tempo”",
    "text": "Alterando o tipo da variável “Tempo”\n\n# Suponha que sua variável \"Tempo\" esteja em um dataframe chamado \"seu_data_frame\"\nbd_long$Tempo &lt;- factor(bd_long$Tempo) \n\nO código assume que a variável \"Tempo\" está no dataframe chamado \"bd_long\". Ele usa a função factor() para converter a variável “Tempo” em uma variável categórica. A conversão para uma variável categórica é útil quando você deseja tratar “Tempo” como uma variável de fator com níveis distintos em vez de uma variável numérica contínua. Essa transformação pode ser útil em análises estatísticas que envolvam categorias ou grupos de tempo, como em modelos de medidas repetidas."
  },
  {
    "objectID": "lms.html#pressupostos-da-variável-dependente",
    "href": "lms.html#pressupostos-da-variável-dependente",
    "title": "GLM, GEE, GMM, GzLM",
    "section": "Pressupostos da variável dependente",
    "text": "Pressupostos da variável dependente\nA distribuição dos dados da variável independente é fundamental para inferências estatísticas robustas. Quando os dados seguem uma distribuição normal, isso implica que a maioria das observações está centralizada em torno da média, proporcionando uma simetria e previsibilidade desejáveis. Esta normalidade é frequentemente pressuposta em muitos métodos estatísticos clássicos. Ao observar o histograma da variável independente, esperamos ver uma forma de sino simétrica. No Q-Q plot, quando os dados são normalmente distribuídos, os pontos devem seguir aproximadamente uma linha diagonal. Em contrapartida, quando os dados não são normalmente distribuídos, o histograma pode revelar assimetria ou padrões diferentes, e o Q-Q plot apresentará desvios significativos da linha diagonal, indicando divergências da normalidade. Analisar a normalidade dos dados e interpretar o Q-Q plot ajuda a guiar a escolha adequada de métodos estatísticos e a compreender possíveis limitações na inferência.\nAbaixo exemplos de distribuições normais, não normais e seus respectivos gráicos de disperção e Q-Q plot.\n\nDados com distribuição normal\n\n# Bloco para dados normalmente distribuídos\nset.seed(123)\ndados_normais &lt;- rnorm(1000, mean = 0, sd = 1)\n\n# Função para criar histograma e Q-Q plot\ncriar_graficos_normais &lt;- function(dados, titulo) {\n  par(mfrow = c(1, 2))  # Organiza os gráficos em uma linha com duas colunas\n\n  # Histograma\n  hist(dados, main = paste(\"Histograma -\", titulo), col = \"lightblue\", border = \"black\")\n\n  # Q-Q plot\n  qqnorm(dados, main = paste(\"Q-Q Plot -\", titulo))\n  qqline(dados, col = 2)\n}\n\n# Crie os gráficos para dados normalmente distribuídos\ncriar_graficos_normais(dados_normais, \"Normal\")\n\n\n\n# Restaure o layout gráfico padrão\npar(mfrow = c(1, 1))\n\n\n\nDados com distribuição não-normal\n\n# Bloco para dados não normalmente distribuídos\nset.seed(123)\ndados_nao_normais &lt;- abs(rnorm(1000, mean = 0, sd = 1))\n\n# Função para criar histograma e Q-Q plot\ncriar_graficos_nao_normais &lt;- function(dados, titulo) {\n  par(mfrow = c(1, 2))  # Organiza os gráficos em uma linha com duas colunas\n\n  # Histograma\n  hist(dados, main = paste(\"Histograma -\", titulo), col = \"lightcoral\", border = \"black\")\n\n  # Q-Q plot\n  qqnorm(dados, main = paste(\"Q-Q Plot -\", titulo))\n  qqline(dados, col = 2)\n}\n\n# Crie os gráficos para dados não normalmente distribuídos\ncriar_graficos_nao_normais(dados_nao_normais, \"Não Normal\")\n\n\n\n# Restaure o layout gráfico padrão\npar(mfrow = c(1, 1))\n\nAlém das análises visuais dos gráficos, temos também o teste de Shapiro-Wilk. A hipótese nula no teste de Shapiro-Wilk é que a variável analisada segue uma distribuição normal. Em termos mais formais, a hipótese nula (H0) é:\nH0:Os dados são provenientes de uma distribuição normal.\n\n\n\n\n\n\nCuidado!\n\n\n\nSe o p-valor for maior que 0,05, não há evidências suficientes para rejeitar a hipótese nula, indicando que os dados podem ser considerados normalmente distribuídos. Por outro lado, um p-valor menor que 0,05 sugere que há evidências significativas contra a hipótese nula, indicando não normalidade nos dados. É importante considerar o contexto do estudo ao interpretar os resultados e ter em mente que o teste pode ser sensível a tamanhos amostrais muito grandes, resultando em rejeições mesmo para desvios pequenos da normalidade.\n\n\nPodemos verificar o teste de Shapiro-Wilk para os dois exemplos anteriores e treinar a leitura dos resultados\n\n\nShapiro-Wilk para os dados com distribuição normal\n\nshapiro.test(dados_normais)\n\n\n    Shapiro-Wilk normality test\n\ndata:  dados_normais\nW = 0.99838, p-value = 0.4765\n\n\nO valor de p é maior do que 0,05, portanto podemos assumir que os dados possuem distribuição normal.\n\n\nShapiro-Wilk para os dados com distribuição não-normal\n\nshapiro.test(dados_nao_normais)\n\n\n    Shapiro-Wilk normality test\n\ndata:  dados_nao_normais\nW = 0.92344, p-value &lt; 2.2e-16\n\n\nO valor de p é menor do que 0,05, portanto podemos assumir que os dados possuem distribuição não-normal.\nVamos agora verificar a distribuição, o Q-Q plot e o teste de Shapiro-Wilk das variáveis Resp e Pulse do nosso banco de dados.\n\n\nDensidade (distribuição) + Q-Q plot da variável “Pulse”\nPara verificar a distribuição e o Q-Q plot vamos utilizar a função nice_normality() do pacote rempsyc, que cria os dois gráficos em poucas linhas de código!\n\nnice_normality(data = bd_long, \n               variable = \"pulse\",  \n               histogram = TRUE) \n\n\n\n\nShapiro-Wilk para a variável pulse:\n\nshapiro.test(bd_long$pulse)\n\n\n    Shapiro-Wilk normality test\n\ndata:  bd_long$pulse\nW = 0.90791, p-value = 0.005655\n\n\nTanto pela análise gráfica quanto pelo teste de Shapiro-Wilk podemos observar que a variável “Pulse” não pussui distribuião normal.\n\n\nEsfericidade da Variável “Pulse”\nEm casos de medidas repetidas também precisamos avaliar a esfericidade intra-sujeito ao longo do tempo. A esfericidade intra-sujeitos avalia se as variações nas diferenças entre as medidas ao longo do tempo são consistentes para todas as combinações de momentos. Se essa homogeneidade não for atendida, ajustes como a correção de Greenhouse-Geisser ou Huynh-Feldt podem ser necessários para garantir conclusões estatisticamente válidas. Essas correções ajustam os graus de liberdade dos testes para lidar com a falta de esfericidade intra-sujeitos.\nVamos verificar a esfericidade da variável “pulse” usando o teste de Mauchly.\n\npulse_mauchly = anova_test(data = bd_long, \n                           dv = pulse, \n                           wid = ID, \n                           within = Tempo)\n\nOs códigos fornecidos têm como objetivo realizar um teste de Mauchly para verificar a esfericidade da variável “pulse” em um conjunto de dados no formato longo (bd_long). Vamos explicar o que cada linha de código faz:\n\npulse_mauchly = anova_test(data = bd_long, dv = pulse, wid = ID, within = Tempo): Esta linha de código executa o teste de Mauchly para verificar a esfericidade da variável “pulse”. A função anova_test é usada para realizar esse teste. Os argumentos passados para a função são:\n\ndata: O conjunto de dados no formato longo (bd_long), onde os dados estão organizados em formato apropriado para análises de medidas repetidas.\ndv: A variável dependente sendo analisada, que neste caso é “pulse”.\nwid: A variável de identificação única (ID), que indica quais observações pertencem ao mesmo sujeito.\nwithin: A variável categórica que representa o fator dentro dos sujeitos, neste caso, “Tempo”.\n\npulse_mauchly: Esta linha de código armazena os resultados do teste de Mauchly na variável pulse_mauchly. Os resultados incluem estatísticas relacionadas à esfericidade e os valores associados (valor-p).\n\nVamos interpretar os resultados da análise de esfericidade usando o Teste de Mauchly:\n\npulse_mauchly\n\nANOVA Table (type III tests)\n\n$ANOVA\n  Effect DFn DFd    F     p p&lt;.05   ges\n1  Tempo   2  22 3.48 0.049     * 0.024\n\n$`Mauchly's Test for Sphericity`\n  Effect     W    p p&lt;.05\n1  Tempo 0.781 0.29      \n\n$`Sphericity Corrections`\n  Effect  GGe      DF[GG] p[GG] p[GG]&lt;.05   HFe      DF[HF] p[HF] p[HF]&lt;.05\n1  Tempo 0.82 1.64, 18.04 0.061           0.945 1.89, 20.78 0.052          \n\n\nANOVA Table (type III tests): Effect (Efeito): “Tempo”. DFn e DFd: Graus de liberdade para o numerador (DFn) e denominador (DFd) da estatística F. F e p: Estatística F e valor p associado ao efeito “Tempo”. p&lt;.05: Indica se o valor p é menor que 0,05, sugerindo significância estatística. ges (generalized eta-squared): Uma medida da força do efeito.\n\nInterpretação: O efeito “Tempo” apresentou uma estatística F de 3,48 com um valor p de 0,049, indicando uma possível significância estatística. O valor p é menor que 0,05, sugerindo que há diferenças significativas entre os níveis de tempo.\n\nMauchly’s Test for Sphericity: Effect (Efeito): “Tempo”. W (Estátistica de Mauchly): 0,781. p: Valor p associado ao teste de Mauchly.\n\nInterpretação: O teste de Mauchly avalia a esfericidade. Para o efeito “Tempo”, o valor p é 0,29, indicando que não há evidência estatística para rejeitar a esfericidade. Ou seja, a esfericidade não é violada.\n\nSphericity Corrections: Effect (Efeito): “Tempo”. GGe (Greenhouse-Geisser epsilon): 0,82. DF[GG] e p[GG]: Graus de liberdade e valor p corrigidos pelo método Greenhouse-Geisser. HFe (Huynh-Feldt epsilon): 0,945. DF[HF] e p[HF]: Graus de liberdade e valor p corrigidos pelo método Huynh-Feldt.\n\nInterpretação: Se a esfericidade fosse violada, você usaria essas correções para ajustar os graus de liberdade e valores p. Os valores de GGe e HFe estão próximos de 1, indicando que a esfericidade não foi severamente violada. Os valores p corrigidos são 0,061 (GGe) e 0,052 (HFe), indicando que mesmo com a correção, o efeito “Tempo” pode ainda ser significativo.\n\n\n\nEsfericidade da Variável “Resp”\nDa mesma forma, vamos verificar a esfericidade da variável “resp” usando o teste de Mauchly.\n\nresp_mauchly = anova_test(data = bd_long, \n                          dv = resp, \n                          wid = ID,\n                          within = Tempo)\n\nresp_mauchly \n\nANOVA Table (type III tests)\n\n$ANOVA\n  Effect DFn DFd     F     p p&lt;.05  ges\n1  Tempo   2  22 0.344 0.713       0.01\n\n$`Mauchly's Test for Sphericity`\n  Effect     W     p p&lt;.05\n1  Tempo 0.501 0.032     *\n\n$`Sphericity Corrections`\n  Effect   GGe      DF[GG] p[GG] p[GG]&lt;.05   HFe      DF[HF] p[HF] p[HF]&lt;.05\n1  Tempo 0.667 1.33, 14.68 0.629           0.725 1.45, 15.94 0.646          \n\n\nVamos interpretar os resultados da segunda análise de esfericidade:\nANOVA Table (type III tests): Effect (Efeito): “Tempo”. DFn e DFd: Graus de liberdade para o numerador (DFn) e denominador (DFd) da estatística F. F e p: Estatística F e valor p associado ao efeito “Tempo”. p&lt;.05: Indica se o valor p é menor que 0,05, sugerindo significância estatística. ges (generalized eta-squared): Uma medida da força do efeito.\n\nInterpretação: O efeito “Tempo” apresentou uma estatística F de 0,344 com um valor p de 0,713, indicando que não há evidência estatística para rejeitar a hipótese nula. O valor p é maior que 0,05, sugerindo que não há diferenças significativas entre os níveis de tempo.\n\nMauchly’s Test for Sphericity: Effect (Efeito): “Tempo”. W (Estátistica de Mauchly): 0,501. p e p&lt;.05: Valor p associado ao teste de Mauchly e indicação de significância.\n\nInterpretação: O teste de Mauchly indica que a esfericidade foi violada, pois o valor p é menor que 0,05. Isso sugere que as covariâncias das diferenças entre os níveis de tempo não são iguais.\n\nSphericity Corrections: Effect (Efeito): “Tempo”. GGe (Greenhouse-Geisser epsilon): 0,667. DF[GG] e p[GG]: Graus de liberdade e valor p corrigidos pelo método Greenhouse-Geisser. HFe (Huynh-Feldt epsilon): 0,725. DF[HF] e p[HF]: Graus de liberdade e valor p corrigidos pelo método Huynh-Feldt.\n\nInterpretação: As correções (GGe e HFe) sugerem que, mesmo com a correção para a violação da esfericidade, o efeito “Tempo” não é significativo. Os valores p corrigidos são 0,629 (GGe) e 0,646 (HFe), indicando que a falta de esfericidade afeta a significância do efeito “Tempo”.\n\nOs resultados indicam que a esfericidade foi violada, e mesmo com as correções, não há evidências significativas para o efeito “Tempo”. Isso destaca a importância de considerar a esfericidade ao interpretar os resultados de análises de variância com medidas repetidas.\n\n\nGGe (Greenhouse-Geisser epsilon) e o HFe (Huynh-Feldt epsilon)\nO GGe (Greenhouse-Geisser epsilon) e o HFe (Huynh-Feldt epsilon) são coeficientes de correção usados em análises de variância com medidas repetidas para lidar com a violação da esfericidade intra-sujeitos. Esses coeficientes ajustam os graus de liberdade dos testes estatísticos para compensar a falta de esfericidade, ajudando a evitar conclusões incorretas sobre a significância dos efeitos.\n\nGreenhouse-Geisser epsilon (GGe): Este coeficiente é uma estimativa da magnitude da não esfericidade intra-sujeitos. O GGe é usado para corrigir os graus de liberdade dos testes estatísticos, tornando-os mais conservadores quando a esfericidade é violada. Um GGe próximo de 1 indica menos violação da esfericidade.\nHuynh-Feldt epsilon (HFe): Similar ao GGe, o HFe é outro coeficiente de correção. Ele é um ajuste mais conservador que o GGe. Seu valor próximo de 1 indica menos violação da esfericidade. O HFe é geralmente mais utilizado quando os tamanhos amostrais são pequenos.\n\nNo contexto da variável Resp:\n\nGGe: 0,667 - Indica que, após a correção de Greenhouse-Geisser, os graus de liberdade foram reduzidos em cerca de 33% para compensar a violação da esfericidade intra-sujeitos.\nHFe: 0,725 - Similar ao GGe, o HFe fornece outra correção mais conservadora. Neste caso, os graus de liberdade são reduzidos em aproximadamente 27,5%.\n\nJá no contexto da variável Pulse:\n\nGGe = 0,82 - Indica que, após a correção de Greenhouse-Geisser, os graus de liberdade foram reduzidos em cerca de 18% para compensar a violação da esfericidade intra-sujeitos.\nHFe = 0,945 - Indica que, após a correção de Huynh-Feldt, os graus de liberdade foram reduzidos em cerca de 5,5% para compensar a violação da esfericidade intra-sujeitos.\n\nAgora finalmente vamos para a lista de exercícios, começando com o GLM e continuando na sequencia com o GEE e GMM."
  },
  {
    "objectID": "lista_1.html#glm",
    "href": "lista_1.html#glm",
    "title": "1  Lista 1 - GLM, GEE e GMM",
    "section": "1.1 GLM",
    "text": "1.1 GLM\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAnálise para a Variável “resp”\nVamos ajustar o seguinte modelo de medidas repetidas para a variável dependente “resp”:\n\\[ resp = \\beta_0 + \\beta_1drug + \\beta_2Tempo + \\beta_3drug*Tempo + \\varepsilon \\]\n\nmodelo1_resp = lm(resp ~ drug + Tempo + drug*Tempo, data = bd_long) \n\nsummary(modelo1_resp)\n\n\nCall:\nlm(formula = resp ~ drug + Tempo + drug * Tempo, data = bd_long)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.15000 -0.05000 -0.03333  0.05000  0.15000 \n\nCoefficients:\n                     Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)         3.350e+00  2.635e-02 127.124  &lt; 2e-16 ***\ndrugPlacebo        -1.167e-01  3.727e-02  -3.130  0.00387 ** \nTempo2              1.667e-02  3.727e-02   0.447  0.65793    \nTempo3             -1.667e-02  3.727e-02  -0.447  0.65793    \ndrugPlacebo:Tempo2  1.904e-15  5.270e-02   0.000  1.00000    \ndrugPlacebo:Tempo3  3.333e-02  5.270e-02   0.632  0.53188    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.06455 on 30 degrees of freedom\nMultiple R-squared:  0.4559,    Adjusted R-squared:  0.3652 \nF-statistic: 5.027 on 5 and 30 DF,  p-value: 0.001836\n\n\nComo houve diferença apenas entre os grupos que receberam a droga e o placebo, não vamos realizar o post hoc\n\nPressupostos do modelo lm(resp)\n\ncheck_model(modelo1_resp, check = c(\"pp_check\", \"linearity\"))\n\n\n\n\n\nPosterior Predictive Checks: utilizadas para identificar discrepâncias sistemáticas entre dados reais e simulados, auxiliando a avaliar se o tipo de modelo (família de distribuição) se ajusta adequadamente aos dados.\nLinearity Assumption: o gráfico de Linearidade verifica a suposição de relação linear. No entanto, a dispersão dos pontos também indica possíveis heterocedasticidades (ou seja, variância não constante, daí o termo “ncv” para este gráfico), mostrando se os resíduos têm padrões não lineares. Esse gráfico ajuda a observar se os preditores têm uma relação não linear com o resultado, indicada aproximadamente pela linha de referência. Uma linha reta e horizontal sugere que a especificação do modelo parece estar adequada. Contudo, se a linha for em forma de U, alguns preditores provavelmente devem ser modelados como termos quadráticos.\n\n\ncheck_model(modelo1_resp, check = c(\"homogeneity\", \"outliers\"))\n\n\n\n\n\nHomogeneity of Variance: verifica a suposição de variância igual (homocedasticidade). O padrão desejado é que os pontos se espalhem igualmente acima e abaixo de uma linha reta horizontal, sem desvios aparentes.\nInfluential Observations: identifica observações influentes. Se algum ponto estiver fora da distância de Cook (linhas tracejadas), é considerado uma observação influente.\n\n\ncheck_model(modelo1_resp, check = c(\"vif\", \"normality\"))\n\n\n\n\nMulticollinearity: verifica possíveis problemas de multicolinearidade entre os preditores. Em resumo, a multicolinearidade significa que, uma vez conhecido o efeito de um preditor, o valor de conhecer o outro preditor é relativamente baixo. Isso pode ocorrer quando uma terceira variável não observada tem um efeito causal em cada um dos dois preditores associados ao resultado. Nesses casos, a relação relevante seria entre a variável não observada e o resultado.\nNormality of Residuals: determina se os resíduos do modelo de regressão têm uma distribuição normal. Geralmente, os pontos devem seguir a linha. Desvios (principalmente nas caudas) indicam que o modelo não prevê bem o resultado para a faixa que apresenta maiores desvios da linha. Para modelos lineares generalizados, é exibido um gráfico Q-Q meio-normal dos resíduos padronizados de desvio absoluto, mas a interpretação do gráfico permanece a mesma.\n\n\nConclusão sobre os pressupostos\nFica nítido que o modelo violou diversos pressupostos. Ao fim do capítulo você encontrará uma lista de ações que podem ser tomadas para cada uma das violações do modelo. Caso tudo mais falhe, apenas aceite que você tem um modelo ruim.\n\n\n\n\n\n\nTudo em um painel só!\n\n\n\nVocê pode utilizar a função check_model() sem especificar o parâmetro check. O resultado é um único painel com todas as análises. Nos exemplos anteriores os plots apareceram separados por questões didáticas e de formatação. Veja abaixo como fica o plot em painel.\n\n\n\ncheck_model(modelo1_resp)\n\n\n\n\n\n\nPlot do modelo lm(resp)\nAgora vamos fazer um plot do modelo.\n\nvisualize(modelo1_resp, plot = \"model\")\n\n\n\n\nO código visualize(modelo1_resp, plot = \"model\") usa a função visualize do pacote flexplot para criar um gráfico que visualiza o modelo estatístico denominado modelo1_resp. Este gráfico é uma representação visual do modelo, ajudando a compreender a relação entre as variáveis independentes e a variável dependente no contexto da análise estatística em questão.\n\n\nEscrevendo os Resultados com a função report()\n\n\n\n\n\n\nGrandes poderes…\n\n\n\nPodemos utilizar a função report() do pacote easystat que gerar um texto formatado para publicação e em inglês com os principais resultados de diversos modelos lineares! Com isso conseguimos diminuir erros de digitação, confusão com os estimadores e uma maior reprodutibilidade. Mas lembre-se! É fundamental você treinar como escrever os resultados. Use o poder do report() com sabedoria e sempre revise o texto gerado!\n\n\n\n\nResultados\n\nreport(modelo1_resp)\n\nWe fitted a linear model (estimated using OLS) to predict resp with drug and\nTempo (formula: resp ~ drug + Tempo + drug * Tempo). The model explains a\nstatistically significant and substantial proportion of variance (R2 = 0.46,\nF(5, 30) = 5.03, p = 0.002, adj. R2 = 0.37). The model's intercept,\ncorresponding to drug = New Drug and Tempo = 1, is at 3.35 (95% CI [3.30,\n3.40], t(30) = 127.12, p &lt; .001). Within this model:\n\n  - The effect of drug [Placebo] is statistically significant and negative (beta\n= -0.12, 95% CI [-0.19, -0.04], t(30) = -3.13, p = 0.004; Std. beta = -1.44,\n95% CI [-2.38, -0.50])\n  - The effect of Tempo [2] is statistically non-significant and positive (beta =\n0.02, 95% CI [-0.06, 0.09], t(30) = 0.45, p = 0.658; Std. beta = 0.21, 95% CI\n[-0.73, 1.15])\n  - The effect of Tempo [3] is statistically non-significant and negative (beta =\n-0.02, 95% CI [-0.09, 0.06], t(30) = -0.45, p = 0.658; Std. beta = -0.21, 95%\nCI [-1.15, 0.73])\n  - The effect of drug [Placebo] × Tempo [2] is statistically non-significant and\npositive (beta = 1.90e-15, 95% CI [-0.11, 0.11], t(30) = 3.61e-14, p &gt; .999;\nStd. beta = -1.65e-15, 95% CI [-1.33, 1.33])\n  - The effect of drug [Placebo] × Tempo [3] is statistically non-significant and\npositive (beta = 0.03, 95% CI [-0.07, 0.14], t(30) = 0.63, p = 0.532; Std. beta\n= 0.41, 95% CI [-0.92, 1.74])\n\nStandardized parameters were obtained by fitting the model on a standardized\nversion of the dataset. 95% Confidence Intervals (CIs) and p-values were\ncomputed using a Wald t-distribution approximation.\n\n\n\n\n\nAnálise para a Variável “pulse”\nAgora, ajustaremos o mesmo modelo para a variável dependente “pulse”:\n\\[ pulse= \\beta_0 + \\beta_1drug + \\beta_2Tempo + \\beta_3drug*Tempo + \\varepsilon \\]\n\n# Ajustando o modelo \nmodelo1_pulse = glm(pulse ~ drug + Tempo + drug*Tempo, data = bd_long) \n\nsummary(modelo1_pulse) \n\n\nCall:\nglm(formula = pulse ~ drug + Tempo + drug * Tempo, data = bd_long)\n\nCoefficients:\n                   Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)         2.20000    0.04389  50.131  &lt; 2e-16 ***\ndrugPlacebo         0.46667    0.06206   7.519 2.21e-08 ***\nTempo2              0.01667    0.06206   0.269    0.790    \nTempo3              0.08333    0.06206   1.343    0.189    \ndrugPlacebo:Tempo2  0.13333    0.08777   1.519    0.139    \ndrugPlacebo:Tempo3  0.03333    0.08777   0.380    0.707    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for gaussian family taken to be 0.01155556)\n\n    Null deviance: 2.89889  on 35  degrees of freedom\nResidual deviance: 0.34667  on 30  degrees of freedom\nAIC: -50.981\n\nNumber of Fisher Scoring iterations: 2\n\n\nDescrição dos resultados\n\nPressupostos do modelo\n\ncheck_model(modelo1_pulse, check = c(\"pp_check\", \"linearity\"))\n\n\n\n\n\ncheck_model(modelo1_pulse, check = c(\"homogeneity\", \"outliers\"))\n\n\n\n\n\ncheck_model(modelo1_pulse, check = c(\"vif\", \"normality\"))\n\n\n\n\nA interpretação dos resultados é a mesma para o modelo com a variável resp.\n\n\nPlot do modelo lm(pulse)\nAgora vamos fazer um plot do modelo.\n\nvisualize(modelo1_pulse, plot = \"model\")\n\n\n\n\n\n\nResultados\n\nreport(modelo1_pulse)\n\nWe fitted a linear model (estimated using ML) to predict pulse with drug and\nTempo (formula: pulse ~ drug + Tempo + drug * Tempo). The model's explanatory\npower is substantial (R2 = 0.88). The model's intercept, corresponding to drug\n= New Drug and Tempo = 1, is at 2.20 (95% CI [2.11, 2.29], t(30) = 50.13, p &lt;\n.001). Within this model:\n\n  - The effect of drug [Placebo] is statistically significant and positive (beta\n= 0.47, 95% CI [0.35, 0.59], t(30) = 7.52, p &lt; .001; Std. beta = 1.62, 95% CI\n[1.20, 2.04])\n  - The effect of Tempo [2] is statistically non-significant and positive (beta =\n0.02, 95% CI [-0.10, 0.14], t(30) = 0.27, p = 0.788; Std. beta = 0.06, 95% CI\n[-0.36, 0.48])\n  - The effect of Tempo [3] is statistically non-significant and positive (beta =\n0.08, 95% CI [-0.04, 0.20], t(30) = 1.34, p = 0.179; Std. beta = 0.29, 95% CI\n[-0.13, 0.71])\n  - The effect of drug [Placebo] × Tempo [2] is statistically non-significant and\npositive (beta = 0.13, 95% CI [-0.04, 0.31], t(30) = 1.52, p = 0.129; Std. beta\n= 0.46, 95% CI [-0.13, 1.06])\n  - The effect of drug [Placebo] × Tempo [3] is statistically non-significant and\npositive (beta = 0.03, 95% CI [-0.14, 0.21], t(30) = 0.38, p = 0.704; Std. beta\n= 0.12, 95% CI [-0.48, 0.71])\n\nStandardized parameters were obtained by fitting the model on a standardized\nversion of the dataset. 95% Confidence Intervals (CIs) and p-values were\ncomputed using a Wald t-distribution approximation."
  },
  {
    "objectID": "lista_1.html#gee",
    "href": "lista_1.html#gee",
    "title": "1  Lista 1 - GLM, GEE e GMM",
    "section": "1.2 GEE",
    "text": "1.2 GEE\n\nAnálise para a Variável “Resp”\nRealizaremos uma análise usando Generalized Estimating Equations (GEE) para a variável “resp”.\n\nbd_long$ID = as.factor(bd_long$ID) \n\nbd_long$Tempo = as.factor(bd_long$Tempo) \n\n\n# Ajustando o modelo GEE para \"resp\" \nmodelo_gee_resp &lt;- geeglm(resp ~ drug + Tempo + drug*Tempo,\n                          data = bd_long,\n                          id = ID,\n                          family = gaussian,\n                          corstr = \"unstructured\")\n\n\nsummary(modelo_gee_resp)\n\n\nCall:\ngeeglm(formula = resp ~ drug + Tempo + drug * Tempo, family = gaussian, \n    data = bd_long, id = ID, corstr = \"unstructured\")\n\n Coefficients:\n                     Estimate    Std.err      Wald Pr(&gt;|W|)    \n(Intercept)         3.350e+00  2.041e-02 26934.000  &lt; 2e-16 ***\ndrugPlacebo        -1.167e-01  2.805e-02    17.294  3.2e-05 ***\nTempo2              1.667e-02  2.805e-02     0.353    0.552    \nTempo3             -1.667e-02  2.805e-02     0.353    0.552    \ndrugPlacebo:Tempo2  4.022e-18  3.967e-02     0.000    1.000    \ndrugPlacebo:Tempo3  3.333e-02  5.693e-02     0.343    0.558    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nCorrelation structure = unstructured \nEstimated Scale Parameters:\n\n            Estimate   Std.err\n(Intercept) 0.003472 0.0007618\n  Link = identity \n\nEstimated Correlation Parameters:\n            Estimate Std.err\nalpha.1:2 -9.252e-18 0.19596\nalpha.1:3 -2.400e-01 0.27321\nalpha.2:3  7.600e-01 0.09074\nNumber of clusters:   12  Maximum cluster size: 3 \n\n\n\nPressupostos do modelo GEE (resp)\nAgora vamos fazer um plot do histograma dos resíduos do modelo\n\ncheck_model(modelo_gee_resp) \n\n\n\n\n\n\nPlot do modelo GEE (resp)\nAgora vamos fazer um plot do modelo.\n\nvisualize(modelo_gee_resp, plot = \"model\")\n\n\n\n\n\n\nResultados do modelo\n\n\n\n\n\n\nWarning\n\n\n\nA função report() não funciona para modelos GEE. Então treine para escrever os seus resultados!\n\n\n\n\n\n\n\n\nAnálise para a Variável “Pulse”\nAgora, realizaremos uma análise GEE para a variável “pulse”.\n\nmodelo_gee_pulse &lt;- geeglm(pulse ~ drug + Tempo + drug*Tempo, \n                           data = bd_long,         \n                           id = ID,                 \n                           family = gaussian,       \n                           corstr = \"unstructured\")  \n\nsummary(modelo_gee_pulse) \n\n\nCall:\ngeeglm(formula = pulse ~ drug + Tempo + drug * Tempo, family = gaussian, \n    data = bd_long, id = ID, corstr = \"unstructured\")\n\n Coefficients:\n                   Estimate Std.err    Wald Pr(&gt;|W|)    \n(Intercept)          2.2000  0.0408 2904.00   &lt;2e-16 ***\ndrugPlacebo          0.4667  0.0509   84.00   &lt;2e-16 ***\nTempo2               0.0167  0.0366    0.21   0.6492    \nTempo3               0.0833  0.0684    1.49   0.2230    \ndrugPlacebo:Tempo2   0.1333  0.0419   10.11   0.0015 ** \ndrugPlacebo:Tempo3   0.0333  0.0877    0.14   0.7038    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nCorrelation structure = unstructured \nEstimated Scale Parameters:\n\n            Estimate Std.err\n(Intercept)  0.00963 0.00168\n  Link = identity \n\nEstimated Correlation Parameters:\n          Estimate Std.err\nalpha.1:2    0.721   0.169\nalpha.1:3   -0.288   0.208\nalpha.2:3    0.115   0.267\nNumber of clusters:   12  Maximum cluster size: 3 \n\n\n\nPressupostos do modelo GEE (pulse)\nAgora vamos fazer um plot do histograma dos resíduos do modelo\n\ncheck_model(modelo_gee_pulse)\n\n\n\n\n\n\nPlot do modelo GEE (pulse)\nAgora vamos fazer um plot do modelo.\n\nvisualize(modelo_gee_pulse, plot = \"model\")\n\n\n\n\n\n\nResultados do modelo\n\n\n\n\n\n\nWarning\n\n\n\nA função report() não funciona para modelos GEE. Então treine para escrever os seus resultados!"
  },
  {
    "objectID": "lista_1.html#gmm",
    "href": "lista_1.html#gmm",
    "title": "1  Lista 1 - GLM, GEE e GMM",
    "section": "1.3 GMM",
    "text": "1.3 GMM\n\nAnálise para a Variável “resp”\nAgora, realizaremos uma análise usando Generalized Mixed Models (GMM) para a variável “resp”.\n\nmodelo_gmm_resp = lme(   fixed = resp ~ drug + Tempo + drug * Tempo,  \n                         random = ~1|ID, \n                         data = bd_long ) \n\n\nsummary(modelo_gmm_resp) \n\nLinear mixed-effects model fit by REML\n  Data: bd_long \n    AIC   BIC logLik\n  -53.4 -42.2   34.7\n\nRandom effects:\n Formula: ~1 | ID\n        (Intercept) Residual\nStdDev:      0.0269   0.0587\n\nFixed effects:  resp ~ drug + Tempo + drug * Tempo \n                   Value Std.Error DF t-value p-value\n(Intercept)         3.35    0.0264 20   127.1  0.0000\ndrugPlacebo        -0.12    0.0373 10    -3.1  0.0107\nTempo2              0.02    0.0339 20     0.5  0.6282\nTempo3             -0.02    0.0339 20    -0.5  0.6282\ndrugPlacebo:Tempo2  0.00    0.0479 20     0.0  1.0000\ndrugPlacebo:Tempo3  0.03    0.0479 20     0.7  0.4947\n Correlation: \n                   (Intr) drgPlc Tempo2 Tempo3 drP:T2\ndrugPlacebo        -0.707                            \nTempo2             -0.643  0.455                     \nTempo3             -0.643  0.455  0.500              \ndrugPlacebo:Tempo2  0.455 -0.643 -0.707 -0.354       \ndrugPlacebo:Tempo3  0.455 -0.643 -0.354 -0.707  0.500\n\nStandardized Within-Group Residuals:\n   Min     Q1    Med     Q3    Max \n-2.263 -0.560 -0.257  0.685  2.190 \n\nNumber of Observations: 36\nNumber of Groups: 12 \n\n\n\nPressupostos do modelo GMM (resp)\nAgora vamos fazer um plot do histograma dos resíduos do modelo\n\ncheck_model(modelo_gmm_resp)\n\n\n\n\n\n\nPlot do modelo GMM (resp)\nAgora vamos fazer um plot do modelo.\n\n\n\n\n\n\nDica!\n\n\n\nA função visualize() as vezes não funciona com determinados modelos. Vamos fazer o gráfico na mão utilizando a função ggplot() do pacote ggplot2\n\n\n\n# Vamos guardar os resultados do modelo em uma variável\nmeans_ci_gmm_resp = emmeans(modelo_gmm_resp, specs = ~drug:Tempo)\n\n# Código para criar nosso gráfico\nggplot(as.data.frame(means_ci_gmm_resp), aes(x = Tempo, y = emmean, color = drug)) +\n  geom_errorbar(aes(ymin = lower.CL, ymax = upper.CL), width = 0.2, position = position_dodge(0.8)) +\n  geom_point(position = position_dodge(0.8), size = 3) +\n  labs(title = \"Distribuição normal\",\n       x = \"Tempo\",\n       y = \"Resp\") +\n  theme_minimal()\n\n\n\n\n\n\nResultados do modelo\n\nreport(modelo_gmm_resp)\n\nWe fitted a linear mixed model (estimated using REML and nlminb optimizer) to\npredict resp with drug and Tempo (formula: resp ~ drug + Tempo + drug * Tempo).\nThe model included ID as random effect (formula: ~1 | ID). The model's total\nexplanatory power is substantial (conditional R2 = 0.52) and the part related\nto the fixed effects alone (marginal R2) is of 0.42. The model's intercept,\ncorresponding to drug = New Drug and Tempo = 1, is at 3.35 (95% CI [3.30,\n3.40], t(20) = 127.12, p &lt; .001). Within this model:\n\n  - The effect of drug [Placebo] is statistically significant and negative (beta\n= -0.12, 95% CI [-0.20, -0.03], t(10) = -3.13, p = 0.011; Std. beta = -1.44,\n95% CI [-2.47, -0.42])\n  - The effect of Tempo [2] is statistically non-significant and positive (beta =\n0.02, 95% CI [-0.05, 0.09], t(20) = 0.49, p = 0.628; Std. beta = 0.21, 95% CI\n[-0.67, 1.08])\n  - The effect of Tempo [3] is statistically non-significant and negative (beta =\n-0.02, 95% CI [-0.09, 0.05], t(20) = -0.49, p = 0.628; Std. beta = -0.21, 95%\nCI [-1.08, 0.67])\n  - The effect of drug [Placebo] × Tempo [2] is statistically non-significant and\nnegative (beta = -6.16e-16, 95% CI [-0.10, 0.10], t(20) = -1.29e-14, p &gt; .999;\nStd. beta = -3.14e-16, 95% CI [-1.23, 1.23])\n  - The effect of drug [Placebo] × Tempo [3] is statistically non-significant and\npositive (beta = 0.03, 95% CI [-0.07, 0.13], t(20) = 0.70, p = 0.495; Std. beta\n= 0.41, 95% CI [-0.82, 1.65])\n\nStandardized parameters were obtained by fitting the model on a standardized\nversion of the dataset. 95% Confidence Intervals (CIs) and p-values were\ncomputed using a Wald t-distribution approximation.\n\n\n\n\n\nAnálise para a Variável “Pulse”\nAgora, realizaremos uma análise GMM para a variável “pulse”.\n\n# Ajustando o modelo GMM para \"pulse\" \nmodelo_gmm_pulse = lme(   fixed = pulse ~ drug + Tempo + drug * Tempo,  \n                          random = ~1|ID,  \n                          data = bd_long ) \n\nsummary(modelo_gmm_pulse) \n\nLinear mixed-effects model fit by REML\n  Data: bd_long \n    AIC   BIC logLik\n  -22.9 -11.6   19.4\n\nRandom effects:\n Formula: ~1 | ID\n        (Intercept) Residual\nStdDev:      0.0459   0.0972\n\nFixed effects:  pulse ~ drug + Tempo + drug * Tempo \n                   Value Std.Error DF t-value p-value\n(Intercept)        2.200    0.0439 20    50.1   0.000\ndrugPlacebo        0.467    0.0621 10     7.5   0.000\nTempo2             0.017    0.0561 20     0.3   0.769\nTempo3             0.083    0.0561 20     1.5   0.153\ndrugPlacebo:Tempo2 0.133    0.0793 20     1.7   0.108\ndrugPlacebo:Tempo3 0.033    0.0793 20     0.4   0.679\n Correlation: \n                   (Intr) drgPlc Tempo2 Tempo3 drP:T2\ndrugPlacebo        -0.707                            \nTempo2             -0.639  0.452                     \nTempo3             -0.639  0.452  0.500              \ndrugPlacebo:Tempo2  0.452 -0.639 -0.707 -0.354       \ndrugPlacebo:Tempo3  0.452 -0.639 -0.354 -0.707  0.500\n\nStandardized Within-Group Residuals:\n   Min     Q1    Med     Q3    Max \n-1.783 -0.629 -0.178  0.630  1.476 \n\nNumber of Observations: 36\nNumber of Groups: 12 \n\n\n\nPressupostos do modelo GMM (pulse)\nAgora vamos fazer um plot do histograma dos resíduos do modelo\n\ncheck_model(modelo_gmm_pulse)\n\n\n\n\n\n\nPlot do modelo GMM (pulse)\nAgora vamos fazer um plot do modelo utilizando mais uma vez a função ggplot()\n\n# Vamos guardar os resultados do modelo em uma variável\nmeans_ci_gmm_pulse = emmeans(modelo_gmm_pulse, specs = ~drug:Tempo)\n\n# Código para criar nosso gráfico\nggplot(as.data.frame(means_ci_gmm_pulse), aes(x = Tempo, y = emmean, color = drug)) +\n  geom_errorbar(aes(ymin = lower.CL, ymax = upper.CL), width = 0.2, position = position_dodge(0.8)) +\n  geom_point(position = position_dodge(0.8), size = 3) +\n  labs(title = \"Distribuição normal\",\n       x = \"Tempo\",\n       y = \"Resp\") +\n  theme_minimal()\n\n\n\n\n\n\nResultados do modelo\n\nreport(modelo_gmm_pulse)\n\nWe fitted a linear mixed model (estimated using REML and nlminb optimizer) to\npredict pulse with drug and Tempo (formula: pulse ~ drug + Tempo + drug *\nTempo). The model included ID as random effect (formula: ~1 | ID). The model's\ntotal explanatory power is substantial (conditional R2 = 0.89) and the part\nrelated to the fixed effects alone (marginal R2) is of 0.86. The model's\nintercept, corresponding to drug = New Drug and Tempo = 1, is at 2.20 (95% CI\n[2.11, 2.29], t(20) = 50.13, p &lt; .001). Within this model:\n\n  - The effect of drug [Placebo] is statistically significant and positive (beta\n= 0.47, 95% CI [0.33, 0.60], t(10) = 7.52, p &lt; .001; Std. beta = 1.62, 95% CI\n[1.14, 2.10])\n  - The effect of Tempo [2] is statistically non-significant and positive (beta =\n0.02, 95% CI [-0.10, 0.13], t(20) = 0.30, p = 0.769; Std. beta = 0.06, 95% CI\n[-0.35, 0.46])\n  - The effect of Tempo [3] is statistically non-significant and positive (beta =\n0.08, 95% CI [-0.03, 0.20], t(20) = 1.49, p = 0.153; Std. beta = 0.29, 95% CI\n[-0.12, 0.70])\n  - The effect of drug [Placebo] × Tempo [2] is statistically non-significant and\npositive (beta = 0.13, 95% CI [-0.03, 0.30], t(20) = 1.68, p = 0.108; Std. beta\n= 0.46, 95% CI [-0.11, 1.04])\n  - The effect of drug [Placebo] × Tempo [3] is statistically non-significant and\npositive (beta = 0.03, 95% CI [-0.13, 0.20], t(20) = 0.42, p = 0.679; Std. beta\n= 0.12, 95% CI [-0.46, 0.69])\n\nStandardized parameters were obtained by fitting the model on a standardized\nversion of the dataset. 95% Confidence Intervals (CIs) and p-values were\ncomputed using a Wald t-distribution approximation."
  },
  {
    "objectID": "lista_1.html#violação-dos-pressupostos-o-que-pode-ser-feito",
    "href": "lista_1.html#violação-dos-pressupostos-o-que-pode-ser-feito",
    "title": "1  Lista 1 - GLM, GEE e GMM",
    "section": "1.4 Violação dos pressupostos: o que pode ser feito?",
    "text": "1.4 Violação dos pressupostos: o que pode ser feito?\n\nMulticolinearidade: Identifique quais variáveis independentes estão altamente correlacionadas entre si. Considere remover uma das variáveis altamente correlacionadas ou combinar variáveis para criar índices compostos.\nNormalidade dos Resíduos: Verifique a presença de padrões nos resíduos e considere transformações nos dados, como a transformação logarítmica. Considere a utilização de modelos mais robustos que não dependam da normalidade dos resíduos.\nHomogeneidade de Variância: Se a variância dos resíduos não é constante, considere transformações nos dados ou na variável dependente.\nOutliers: Identifique e investigue pontos de dados que se destacam nos resíduos. Avalie se a exclusão dos outliers é justificada ou se é necessário aplicar transformações aos dados. Considere modelos mais robustos que não sejam sensíveis a outliers.\nLinearidade: Se a relação entre variáveis independentes e dependentes não é linear, considere transformações nos dados ou nas variáveis. Utilize técnicas de modelagem não linear.\nPosterior Predictive Checks: Se houver discrepâncias entre dados reais e simulados nos checks pós-predição, reveja a especificação do modelo. Considere ajustes nas distribuições ou estruturas do modelo para melhorar o ajuste."
  },
  {
    "objectID": "lista_1.html#conclusão",
    "href": "lista_1.html#conclusão",
    "title": "1  Lista 1 - GLM, GEE e GMM",
    "section": "1.5 Conclusão",
    "text": "1.5 Conclusão\nNeste tutorial, exploramos como conduzir análises estatísticas no R utilizando diferentes abordagens, incluindo modelos de medidas repetidas, Generalized Estimating Equations (GEE) e Generalized Mixed Models (GMM). Essas técnicas nos permitem entender melhor o efeito do tempo e do grupo sobre as variáveis “resp” e “pulse” em nosso conjunto de dados.\nLembre-se de que as tabelas e resultados aqui apresentados são apenas parte da análise completa. Assista aos vídeos das aulas para entender melhor a teoria."
  },
  {
    "objectID": "lista_1.html#lista-1-resolvida-no-spss",
    "href": "lista_1.html#lista-1-resolvida-no-spss",
    "title": "1  Lista 1 - GLM, GEE e GMM",
    "section": "1.6 Lista 1 resolvida no SPSS",
    "text": "1.6 Lista 1 resolvida no SPSS"
  },
  {
    "objectID": "lista_1.html#referências",
    "href": "lista_1.html#referências",
    "title": "1  Lista 1 - GLM, GEE e GMM",
    "section": "1.7 Referências",
    "text": "1.7 Referências\n\nMauchly’s Test of Sphericity in R\nPivoting multiple variables: A simpler (more complex?) way\nWide to long format part 2 - Pivoting with multivariate data"
  },
  {
    "objectID": "lista_1.html#versões-dos-pacotes",
    "href": "lista_1.html#versões-dos-pacotes",
    "title": "1  Lista 1 - GLM, GEE e GMM",
    "section": "1.8 Versões dos pacotes",
    "text": "1.8 Versões dos pacotes\n\nreport(sessionInfo())\n\nAnalyses were conducted using the R Statistical language (version 4.3.1; R Core\nTeam, 2023) on Windows 11 x64 (build 22621), using the packages lme4 (version\n1.1.34; Bates D et al., 2015), Matrix (version 1.6.0; Bates D et al., 2023),\neffectsize (version 0.8.6; Ben-Shachar MS et al., 2020), flexplot (version\n0.20.5; Fife D, 2024), effects (version 4.2.2; Fox J, Weisberg S, 2019),\ncarData (version 3.0.5; Fox J et al., 2022), mvtnorm (version 1.2.3; Genz A,\nBretz F, 2009), geepack (version 1.3.9; Halekoh U et al., 2006), TH.data\n(version 1.1.2; Hothorn T, 2023), multcomp (version 1.4.25; Hothorn T et al.,\n2008), rstatix (version 0.7.2; Kassambara A, 2023), emmeans (version 1.8.8;\nLenth R, 2023), sjstats (version 0.18.2; Lüdecke D, 2022), parameters (version\n0.21.3; Lüdecke D et al., 2020), performance (version 0.10.8; Lüdecke D et al.,\n2021), easystats (version 0.6.0; Lüdecke D et al., 2022), see (version 0.8.1;\nLüdecke D et al., 2021), insight (version 0.19.6; Lüdecke D et al., 2019),\nbayestestR (version 0.13.1; Makowski D et al., 2019), modelbased (version\n0.8.6; Makowski D et al., 2020), report (version 0.5.7; Makowski D et al.,\n2023), correlation (version 0.8.4; Makowski D et al., 2022), datawizard\n(version 0.9.0; Patil I et al., 2022), nlme (version 3.1.163; Pinheiro J et\nal., 2023), foreign (version 0.8.85; R Core Team, 2023), rempsyc (version\n0.1.6; Thériault R, 2023), survival (version 3.5.7; Therneau T, 2023), MASS\n(version 7.3.60; Venables WN, Ripley BD, 2002), ggplot2 (version 3.4.4; Wickham\nH, 2016), dplyr (version 1.1.3; Wickham H et al., 2023) and tidyr (version\n1.3.0; Wickham H et al., 2023).\n\nReferences\n----------\n  - Bates D, Mächler M, Bolker B, Walker S (2015). \"Fitting Linear Mixed-Effects\nModels Using lme4.\" _Journal of Statistical Software_, *67*(1), 1-48.\ndoi:10.18637/jss.v067.i01 &lt;https://doi.org/10.18637/jss.v067.i01&gt;.\n  - Bates D, Maechler M, Jagan M (2023). _Matrix: Sparse and Dense Matrix Classes\nand Methods_. R package version 1.6-0,\n&lt;https://CRAN.R-project.org/package=Matrix&gt;.\n  - Ben-Shachar MS, Lüdecke D, Makowski D (2020). \"effectsize: Estimation of\nEffect Size Indices and Standardized Parameters.\" _Journal of Open Source\nSoftware_, *5*(56), 2815. doi:10.21105/joss.02815\n&lt;https://doi.org/10.21105/joss.02815&gt;, &lt;https://doi.org/10.21105/joss.02815&gt;.\n  - Fife D (2024). _flexplot: Graphically Based Data Analysis Using 'flexplot'_.\nR package version 0.20.5.\n  - Fox J, Weisberg S (2019). _An R Companion to Applied Regression_, 3rd\nedition. Sage, Thousand Oaks CA.\n&lt;https://socialsciences.mcmaster.ca/jfox/Books/Companion/index.html&gt;. Fox J,\nWeisberg S (2018). \"Visualizing Fit and Lack of Fit in Complex Regression\nModels with Predictor Effect Plots and Partial Residuals.\" _Journal of\nStatistical Software_, *87*(9), 1-27. doi:10.18637/jss.v087.i09\n&lt;https://doi.org/10.18637/jss.v087.i09&gt;. Fox J (2003). \"Effect Displays in R\nfor Generalised Linear Models.\" _Journal of Statistical Software_, *8*(15),\n1-27. doi:10.18637/jss.v008.i15 &lt;https://doi.org/10.18637/jss.v008.i15&gt;. Fox J,\nHong J (2009). \"Effect Displays in R for Multinomial and Proportional-Odds\nLogit Models: Extensions to the effects Package.\" _Journal of Statistical\nSoftware_, *32*(1), 1-24. doi:10.18637/jss.v032.i01\n&lt;https://doi.org/10.18637/jss.v032.i01&gt;.\n  - Fox J, Weisberg S, Price B (2022). _carData: Companion to Applied Regression\nData Sets_. R package version 3.0-5,\n&lt;https://CRAN.R-project.org/package=carData&gt;.\n  - Genz A, Bretz F (2009). _Computation of Multivariate Normal and t\nProbabilities_, series Lecture Notes in Statistics. Springer-Verlag,\nHeidelberg. ISBN 978-3-642-01688-2.\n  - Halekoh U, Højsgaard S, Yan J (2006). \"The R Package geepack for Generalized\nEstimating Equations.\" _Journal of Statistical Software_, *15/2*, 1-11. Yan J,\nFine JP (2004). \"Estimating Equations for Association Structures.\" _Statistics\nin Medicine_, *23*, 859-880. Yan J (2002). \"geepack: Yet Another Package for\nGeneralized Estimating Equations.\" _R-News_, *2/3*, 12-14.\n  - Hothorn T (2023). _TH.data: TH's Data Archive_. R package version 1.1-2,\n&lt;https://CRAN.R-project.org/package=TH.data&gt;.\n  - Hothorn T, Bretz F, Westfall P (2008). \"Simultaneous Inference in General\nParametric Models.\" _Biometrical Journal_, *50*(3), 346-363.\n  - Kassambara A (2023). _rstatix: Pipe-Friendly Framework for Basic Statistical\nTests_. R package version 0.7.2, &lt;https://CRAN.R-project.org/package=rstatix&gt;.\n  - Lenth R (2023). _emmeans: Estimated Marginal Means, aka Least-Squares Means_.\nR package version 1.8.8, &lt;https://CRAN.R-project.org/package=emmeans&gt;.\n  - Lüdecke D (2022). _sjstats: Statistical Functions for Regression Models\n(Version 0.18.2)_. doi:10.5281/zenodo.1284472\n&lt;https://doi.org/10.5281/zenodo.1284472&gt;,\n&lt;https://CRAN.R-project.org/package=sjstats&gt;.\n  - Lüdecke D, Ben-Shachar M, Patil I, Makowski D (2020). \"Extracting, Computing\nand Exploring the Parameters of Statistical Models using R.\" _Journal of Open\nSource Software_, *5*(53), 2445. doi:10.21105/joss.02445\n&lt;https://doi.org/10.21105/joss.02445&gt;.\n  - Lüdecke D, Ben-Shachar M, Patil I, Waggoner P, Makowski D (2021).\n\"performance: An R Package for Assessment, Comparison and Testing of\nStatistical Models.\" _Journal of Open Source Software_, *6*(60), 3139.\ndoi:10.21105/joss.03139 &lt;https://doi.org/10.21105/joss.03139&gt;.\n  - Lüdecke D, Ben-Shachar M, Patil I, Wiernik B, Makowski D (2022). \"easystats:\nFramework for Easy Statistical Modeling, Visualization, and Reporting.\" _CRAN_.\nR package, &lt;https://easystats.github.io/easystats/&gt;.\n  - Lüdecke D, Patil I, Ben-Shachar M, Wiernik B, Waggoner P, Makowski D (2021).\n\"see: An R Package for Visualizing Statistical Models.\" _Journal of Open Source\nSoftware_, *6*(64), 3393. doi:10.21105/joss.03393\n&lt;https://doi.org/10.21105/joss.03393&gt;.\n  - Lüdecke D, Waggoner P, Makowski D (2019). \"insight: A Unified Interface to\nAccess Information from Model Objects in R.\" _Journal of Open Source Software_,\n*4*(38), 1412. doi:10.21105/joss.01412 &lt;https://doi.org/10.21105/joss.01412&gt;.\n  - Makowski D, Ben-Shachar M, Lüdecke D (2019). \"bayestestR: Describing Effects\nand their Uncertainty, Existence and Significance within the Bayesian\nFramework.\" _Journal of Open Source Software_, *4*(40), 1541.\ndoi:10.21105/joss.01541 &lt;https://doi.org/10.21105/joss.01541&gt;,\n&lt;https://joss.theoj.org/papers/10.21105/joss.01541&gt;.\n  - Makowski D, Ben-Shachar M, Patil I, Lüdecke D (2020). \"Estimation of\nModel-Based Predictions, Contrasts and Means.\" _CRAN_.\n&lt;https://github.com/easystats/modelbased&gt;.\n  - Makowski D, Lüdecke D, Patil I, Thériault R, Ben-Shachar M, Wiernik B (2023).\n\"Automated Results Reporting as a Practical Tool to Improve Reproducibility and\nMethodological Best Practices Adoption.\" _CRAN_.\n&lt;https://easystats.github.io/report/&gt;.\n  - Makowski D, Wiernik B, Patil I, Lüdecke D, Ben-Shachar M (2022).\n\"correlation: Methods for Correlation Analysis.\" Version 0.8.3,\n&lt;https://CRAN.R-project.org/package=correlation&gt;. Makowski D, Ben-Shachar M,\nPatil I, Lüdecke D (2020). \"Methods and Algorithms for Correlation Analysis in\nR.\" _Journal of Open Source Software_, *5*(51), 2306. doi:10.21105/joss.02306\n&lt;https://doi.org/10.21105/joss.02306&gt;,\n&lt;https://joss.theoj.org/papers/10.21105/joss.02306&gt;.\n  - Patil I, Makowski D, Ben-Shachar M, Wiernik B, Bacher E, Lüdecke D (2022).\n\"datawizard: An R Package for Easy Data Preparation and Statistical\nTransformations.\" _Journal of Open Source Software_, *7*(78), 4684.\ndoi:10.21105/joss.04684 &lt;https://doi.org/10.21105/joss.04684&gt;.\n  - Pinheiro J, Bates D, R Core Team (2023). _nlme: Linear and Nonlinear Mixed\nEffects Models_. R package version 3.1-163,\n&lt;https://CRAN.R-project.org/package=nlme&gt;. Pinheiro JC, Bates DM (2000).\n_Mixed-Effects Models in S and S-PLUS_. Springer, New York. doi:10.1007/b98882\n&lt;https://doi.org/10.1007/b98882&gt;.\n  - R Core Team (2023). _foreign: Read Data Stored by 'Minitab', 'S', 'SAS',\n'SPSS', 'Stata', 'Systat', 'Weka', 'dBase', ..._. R package version 0.8-85,\n&lt;https://CRAN.R-project.org/package=foreign&gt;.\n  - R Core Team (2023). _R: A Language and Environment for Statistical\nComputing_. R Foundation for Statistical Computing, Vienna, Austria.\n&lt;https://www.R-project.org/&gt;.\n  - Thériault R (2023). \"rempsyc: Convenience functions for psychology.\" _Journal\nof Open Source Software_, *8*(87), 5466. doi:10.21105/joss.05466\n&lt;https://doi.org/10.21105/joss.05466&gt;, &lt;https://doi.org/10.21105/joss.05466&gt;.\n  - Therneau T (2023). _A Package for Survival Analysis in R_. R package version\n3.5-7, &lt;https://CRAN.R-project.org/package=survival&gt;. Terry M. Therneau,\nPatricia M. Grambsch (2000). _Modeling Survival Data: Extending the Cox Model_.\nSpringer, New York. ISBN 0-387-98784-3.\n  - Venables WN, Ripley BD (2002). _Modern Applied Statistics with S_, Fourth\nedition. Springer, New York. ISBN 0-387-95457-0,\n&lt;https://www.stats.ox.ac.uk/pub/MASS4/&gt;.\n  - Wickham H (2016). _ggplot2: Elegant Graphics for Data Analysis_.\nSpringer-Verlag New York. ISBN 978-3-319-24277-4,\n&lt;https://ggplot2.tidyverse.org&gt;.\n  - Wickham H, François R, Henry L, Müller K, Vaughan D (2023). _dplyr: A Grammar\nof Data Manipulation_. R package version 1.1.3,\n&lt;https://CRAN.R-project.org/package=dplyr&gt;.\n  - Wickham H, Vaughan D, Girlich M (2023). _tidyr: Tidy Messy Data_. R package\nversion 1.3.0, &lt;https://CRAN.R-project.org/package=tidyr&gt;."
  },
  {
    "objectID": "lista_2.html#introdução",
    "href": "lista_2.html#introdução",
    "title": "2  Lista 2 - GEE",
    "section": "2.1 Introdução",
    "text": "2.1 Introdução\nNa lista 2 vamos utilizar mais uma vez o banco de dados New Drug com medidas de resp e pulse. Não se esqueça de transformá-lo para o formato long como no exercício anterior.\n\n# Carregar o banco de dados e armazena na variável original_wide\n\noriginal_wide = read.spss(\"bd_New drug_respiratory&pulse.sav\", to.data.frame=TRUE) \n\n\n# Renomear as colunas do banco de dados para facilitar a conversão para o formato longo.\n\nbd &lt;- original_wide %&gt;%   rename_with(~gsub(\"(resp|pulse)(\\\\d+)\", \"\\\\1_\\\\2\", .), -drug) %&gt;%  mutate(ID = row_number()) %&gt;% dplyr::select(ID, everything())  \n\n\n# Organizar os dados para o formato longo\n\nbd_long = pivot_longer(bd, cols=resp_1:pulse_3, names_to = c(\".value\", \"Tempo\"),   names_pattern = \"(.+)_(.+)\")  \n\nPrimeiras linhas do banco de dados depois de transformado.\n\nhead(bd_long)\n\n# A tibble: 6 × 5\n     ID drug     Tempo  resp pulse\n  &lt;int&gt; &lt;fct&gt;    &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt;\n1     1 New Drug 1       3.4   2.2\n2     1 New Drug 2       3.3   2.1\n3     1 New Drug 3       3.3   2.1\n4     2 New Drug 1       3.4   2.2\n5     2 New Drug 2       3.4   2.1\n6     2 New Drug 3       3.3   2.2"
  },
  {
    "objectID": "lista_2.html#exercícios",
    "href": "lista_2.html#exercícios",
    "title": "2  Lista 2 - GEE",
    "section": "2.2 Exercícios",
    "text": "2.2 Exercícios\n\na) GEE com a VD “Pulse”\nUtilize um GEE para verificar o efeito de tempo e grupo sobre os resultados de resp e pulse. Faça 3 modelos para cada variável dependente (com as distribuições Normal, Gamma e Tweedie) e cole aqui apenas as tabelas relevantes para a análise.\n\nDistribuição normal\n\nCriando o modelo\n\nmodelo_gee_pulse_normal &lt;- geeglm(pulse ~ drug + Tempo + drug*Tempo, \n                           data = bd_long,         \n                           id = ID,                 \n                           family = gaussian, #Distribuição normal      \n                           corstr = \"unstructured\")\n\n\n\nResumo do modelo e contrastes\n\nsummary(modelo_gee_pulse_normal)\n\n\nCall:\ngeeglm(formula = pulse ~ drug + Tempo + drug * Tempo, family = gaussian, \n    data = bd_long, id = ID, corstr = \"unstructured\")\n\n Coefficients:\n                   Estimate Std.err     Wald Pr(&gt;|W|)    \n(Intercept)         2.20000 0.04082 2904.000  &lt; 2e-16 ***\ndrugPlacebo         0.46667 0.05092   84.000  &lt; 2e-16 ***\nTempo2              0.01667 0.03664    0.207  0.64921    \nTempo3              0.08333 0.06838    1.485  0.22297    \ndrugPlacebo:Tempo2  0.13333 0.04194   10.105  0.00148 ** \ndrugPlacebo:Tempo3  0.03333 0.08767    0.145  0.70377    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nCorrelation structure = unstructured \nEstimated Scale Parameters:\n\n            Estimate  Std.err\n(Intercept)  0.00963 0.001676\n  Link = identity \n\nEstimated Correlation Parameters:\n          Estimate Std.err\nalpha.1:2   0.7212  0.1690\nalpha.1:3  -0.2885  0.2076\nalpha.2:3   0.1154  0.2665\nNumber of clusters:   12  Maximum cluster size: 3 \n\nemmeans(modelo_gee_pulse_normal, pairwise ~ drug*Tempo)\n\n$emmeans\n drug     Tempo emmean     SE  df asymp.LCL asymp.UCL\n New Drug 1       2.20 0.0408 Inf      2.12      2.28\n Placebo  1       2.67 0.0304 Inf      2.61      2.73\n New Drug 2       2.22 0.0549 Inf      2.11      2.32\n Placebo  2       2.82 0.0280 Inf      2.76      2.87\n New Drug 3       2.28 0.0436 Inf      2.20      2.37\n Placebo  3       2.78 0.0366 Inf      2.71      2.86\n\nCovariance estimate used: vbeta \nConfidence level used: 0.95 \n\n$contrasts\n contrast                          estimate     SE  df z.ratio p.value\n New Drug Tempo1 - Placebo Tempo1   -0.4667 0.0509 Inf  -9.165  &lt;.0001\n New Drug Tempo1 - New Drug Tempo2  -0.0167 0.0366 Inf  -0.455  0.9976\n New Drug Tempo1 - Placebo Tempo2   -0.6167 0.0495 Inf -12.449  &lt;.0001\n New Drug Tempo1 - New Drug Tempo3  -0.0833 0.0684 Inf  -1.219  0.8279\n New Drug Tempo1 - Placebo Tempo3   -0.5833 0.0549 Inf -10.634  &lt;.0001\n Placebo Tempo1 - New Drug Tempo2    0.4500 0.0627 Inf   7.173  &lt;.0001\n Placebo Tempo1 - Placebo Tempo2    -0.1500 0.0204 Inf  -7.348  &lt;.0001\n Placebo Tempo1 - New Drug Tempo3    0.3833 0.0531 Inf   7.213  &lt;.0001\n Placebo Tempo1 - Placebo Tempo3    -0.1167 0.0549 Inf  -2.127  0.2733\n New Drug Tempo2 - Placebo Tempo2   -0.6000 0.0616 Inf  -9.738  &lt;.0001\n New Drug Tempo2 - New Drug Tempo3  -0.0667 0.0609 Inf  -1.095  0.8834\n New Drug Tempo2 - Placebo Tempo3   -0.5667 0.0660 Inf  -8.590  &lt;.0001\n Placebo Tempo2 - New Drug Tempo3    0.5333 0.0518 Inf  10.292  &lt;.0001\n Placebo Tempo2 - Placebo Tempo3     0.0333 0.0509 Inf   0.655  0.9867\n New Drug Tempo3 - Placebo Tempo3   -0.5000 0.0569 Inf  -8.783  &lt;.0001\n\nP value adjustment: tukey method for comparing a family of 6 estimates \n\n\n\n\nVerificando os pressupostos\n\n# Plotar o diagnóstico do modelo GEE para a variável 'pulse'\n\ncheck_model(modelo_gee_pulse_normal)\n\nConverting missing values (`NA`) into regular values currently not\n  possible for variables of class `NULL`.\n\n\n\n\n\n\n\nPlot dos resultados\n\n# Salvando os resultados do modelo em uma variável\n\nmeans_ci_normal = emmeans(modelo_gee_pulse_normal, specs = ~drug:Tempo)\n\n\n# Plotar as médias e intervalos de confiança\n\nggplot(as.data.frame(means_ci_normal), aes(x = Tempo, y = emmean, color = drug)) +\n  geom_errorbar(aes(ymin = asymp.LCL, ymax = asymp.UCL), width = 0.2, position = position_dodge(0.8)) +\n  geom_point(position = position_dodge(0.8), size = 3) +\n  labs(title = \"Distribuição Normal\",\n       x = \"Tempo\",\n       y = \"Pulse\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\nDistribuição gamma\n\nCriando o modelo\n\nmodelo_gee_pulse_gamma &lt;- geeglm(pulse ~ drug + Tempo + drug*Tempo, \n                           data = bd_long,         \n                           id = ID,                 \n                           family = Gamma(link = \"identity\"), #Distribuição Gamma      \n                           corstr = \"unstructured\")\n\n\n\nResumo do modelo e contrastes\n\nsummary(modelo_gee_pulse_gamma)\n\n\nCall:\ngeeglm(formula = pulse ~ drug + Tempo + drug * Tempo, family = Gamma(link = \"identity\"), \n    data = bd_long, id = ID, corstr = \"unstructured\")\n\n Coefficients:\n                   Estimate Std.err    Wald Pr(&gt;|W|)    \n(Intercept)          2.2000  0.0408 2904.00   &lt;2e-16 ***\ndrugPlacebo          0.4667  0.0509   84.00   &lt;2e-16 ***\nTempo2               0.0167  0.0366    0.21   0.6492    \nTempo3               0.0833  0.0684    1.49   0.2230    \ndrugPlacebo:Tempo2   0.1333  0.0419   10.11   0.0015 ** \ndrugPlacebo:Tempo3   0.0333  0.0877    0.14   0.7038    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nCorrelation structure = unstructured \nEstimated Scale Parameters:\n\n            Estimate  Std.err\n(Intercept)  0.00172 0.000372\n  Link = identity \n\nEstimated Correlation Parameters:\n          Estimate Std.err\nalpha.1:2    0.745   0.178\nalpha.1:3   -0.279   0.208\nalpha.2:3    0.156   0.279\nNumber of clusters:   12  Maximum cluster size: 3 \n\nemmeans(modelo_gee_pulse_gamma, pairwise ~ drug*Tempo)\n\n$emmeans\n drug     Tempo emmean     SE  df asymp.LCL asymp.UCL\n New Drug 1       2.20 0.0408 Inf      2.12      2.28\n Placebo  1       2.67 0.0304 Inf      2.61      2.73\n New Drug 2       2.22 0.0549 Inf      2.11      2.32\n Placebo  2       2.82 0.0281 Inf      2.76      2.87\n New Drug 3       2.28 0.0436 Inf      2.20      2.37\n Placebo  3       2.78 0.0366 Inf      2.71      2.85\n\nCovariance estimate used: vbeta \nConfidence level used: 0.95 \n\n$contrasts\n contrast                          estimate     SE  df z.ratio p.value\n New Drug Tempo1 - Placebo Tempo1    -0.467 0.0509 Inf  -9.170  &lt;.0001\n New Drug Tempo1 - New Drug Tempo2   -0.017 0.0366 Inf  -0.450  0.9980\n New Drug Tempo1 - Placebo Tempo2    -0.617 0.0495 Inf -12.450  &lt;.0001\n New Drug Tempo1 - New Drug Tempo3   -0.083 0.0684 Inf  -1.220  0.8280\n New Drug Tempo1 - Placebo Tempo3    -0.583 0.0549 Inf -10.630  &lt;.0001\n Placebo Tempo1 - New Drug Tempo2     0.450 0.0627 Inf   7.170  &lt;.0001\n Placebo Tempo1 - Placebo Tempo2     -0.150 0.0204 Inf  -7.350  &lt;.0001\n Placebo Tempo1 - New Drug Tempo3     0.383 0.0531 Inf   7.210  &lt;.0001\n Placebo Tempo1 - Placebo Tempo3     -0.117 0.0549 Inf  -2.130  0.2730\n New Drug Tempo2 - Placebo Tempo2    -0.600 0.0616 Inf  -9.740  &lt;.0001\n New Drug Tempo2 - New Drug Tempo3   -0.067 0.0609 Inf  -1.100  0.8830\n New Drug Tempo2 - Placebo Tempo3    -0.567 0.0660 Inf  -8.590  &lt;.0001\n Placebo Tempo2 - New Drug Tempo3     0.533 0.0518 Inf  10.290  &lt;.0001\n Placebo Tempo2 - Placebo Tempo3      0.033 0.0509 Inf   0.650  0.9870\n New Drug Tempo3 - Placebo Tempo3    -0.500 0.0569 Inf  -8.780  &lt;.0001\n\nP value adjustment: tukey method for comparing a family of 6 estimates \n\n\n\n\nVerificando os pressupostos\n\n# Plotar o diagnóstico do modelo GEE para a variável 'pulse'\n\ncheck_model(modelo_gee_pulse_gamma)\n\nConverting missing values (`NA`) into regular values currently not\n  possible for variables of class `NULL`.\n\n\n\n\n\n\n\nPlot dos resultados\n\n# Salvando os resultados do modelo em uma variável\n\nmeans_ci_gamma = emmeans(modelo_gee_pulse_gamma, specs = ~drug:Tempo)\n\n\n# Plotar as médias e intervalos de confiança\n\nggplot(as.data.frame(means_ci_gamma), aes(x = Tempo, y = emmean, color = drug)) +\n  geom_errorbar(aes(ymin = asymp.LCL, ymax = asymp.UCL), width = 0.2, position = position_dodge(0.8)) +\n  geom_point(position = position_dodge(0.8), size = 3) +\n  labs(title = \"Distribuição Gamma\",\n       x = \"Tempo\",\n       y = \"Pulse\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\nDistribuição tweedie\n\nCriando o modelo\n\nmodelo_gee_pulse_tweedie &lt;- glm(pulse ~ drug + Tempo + drug*Tempo, \n                           data = bd_long,\n                          # id = ID, \n                           family = tweedie(var.power=2, link.power = 0),\n                          contrasts = )\n\n\n\n\n\n\n\nAviso!\n\n\n\nUtilizamos a função glm para criar o modelo Tweedie. Estamos trabalhando para criar o modelo com a função GEE. Por hora utilize o SPSS🤮.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nResumo do modelo e contrastes\n\nsummary(modelo_gee_pulse_tweedie)\n\n\nCall:\nglm(formula = pulse ~ drug + Tempo + drug * Tempo, family = tweedie(var.power = 2, \n    link.power = 0), data = bd_long)\n\nCoefficients:\n                   Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)         0.78846    0.01857   42.47  &lt; 2e-16 ***\ndrugPlacebo         0.19237    0.02626    7.33  3.7e-08 ***\nTempo2              0.00755    0.02626    0.29     0.78    \nTempo3              0.03718    0.02626    1.42     0.17    \ndrugPlacebo:Tempo2  0.04718    0.03713    1.27     0.21    \ndrugPlacebo:Tempo3  0.00564    0.03713    0.15     0.88    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for Tweedie family taken to be 0.00207)\n\n    Null deviance: 0.473395  on 35  degrees of freedom\nResidual deviance: 0.062212  on 30  degrees of freedom\nAIC: NA\n\nNumber of Fisher Scoring iterations: 3\n\nemmeans(modelo_gee_pulse_tweedie, pairwise ~ drug*Tempo)\n\n$emmeans\n drug     Tempo emmean     SE  df asymp.LCL asymp.UCL\n New Drug 1      0.788 0.0186 Inf     0.752     0.825\n Placebo  1      0.981 0.0186 Inf     0.944     1.017\n New Drug 2      0.796 0.0186 Inf     0.760     0.832\n Placebo  2      1.036 0.0186 Inf     0.999     1.072\n New Drug 3      0.826 0.0186 Inf     0.789     0.862\n Placebo  3      1.024 0.0186 Inf     0.987     1.060\n\nResults are given on the mu^0 (not the response) scale. \nConfidence level used: 0.95 \n\n$contrasts\n contrast                          estimate     SE  df z.ratio p.value\n New Drug Tempo1 - Placebo Tempo1   -0.1924 0.0263 Inf  -7.330  &lt;.0001\n New Drug Tempo1 - New Drug Tempo2  -0.0075 0.0263 Inf  -0.290  1.0000\n New Drug Tempo1 - Placebo Tempo2   -0.2471 0.0263 Inf  -9.410  &lt;.0001\n New Drug Tempo1 - New Drug Tempo3  -0.0372 0.0263 Inf  -1.420  0.7170\n New Drug Tempo1 - Placebo Tempo3   -0.2352 0.0263 Inf  -8.960  &lt;.0001\n Placebo Tempo1 - New Drug Tempo2    0.1848 0.0263 Inf   7.040  &lt;.0001\n Placebo Tempo1 - Placebo Tempo2    -0.0547 0.0263 Inf  -2.080  0.2950\n Placebo Tempo1 - New Drug Tempo3    0.1552 0.0263 Inf   5.910  &lt;.0001\n Placebo Tempo1 - Placebo Tempo3    -0.0428 0.0263 Inf  -1.630  0.5780\n New Drug Tempo2 - Placebo Tempo2   -0.2395 0.0263 Inf  -9.120  &lt;.0001\n New Drug Tempo2 - New Drug Tempo3  -0.0296 0.0263 Inf  -1.130  0.8700\n New Drug Tempo2 - Placebo Tempo3   -0.2276 0.0263 Inf  -8.670  &lt;.0001\n Placebo Tempo2 - New Drug Tempo3    0.2099 0.0263 Inf   7.990  &lt;.0001\n Placebo Tempo2 - Placebo Tempo3     0.0119 0.0263 Inf   0.450  0.9980\n New Drug Tempo3 - Placebo Tempo3   -0.1980 0.0263 Inf  -7.540  &lt;.0001\n\nNote: contrasts are still on the mu^0 scale \nP value adjustment: tukey method for comparing a family of 6 estimates \n\n\n\n\nVerificando os pressupostos\n\n# Plotar o diagnóstico do modelo GEE para a variável 'pulse'\n\ncheck_model(modelo_gee_pulse_tweedie)\n\n\n\n\n\n\nPlot dos resultados\n\n# Salvando os resultados do modelo em uma variável\n\nmeans_ci_tweedie = emmeans(modelo_gee_pulse_tweedie, specs = ~drug:Tempo)\n\n\n# Plotar as médias e intervalos de confiança\n\nggplot(as.data.frame(means_ci_tweedie), aes(x = Tempo, y = emmean, color = drug)) +\n  geom_errorbar(aes(ymin = asymp.LCL, ymax = asymp.UCL), width = 0.2, position = position_dodge(0.8)) +\n  geom_point(position = position_dodge(0.8), size = 3) +\n  labs(title = \"Distribuição Tweedie\",\n       x = \"Tempo\",\n       y = \"Pulse\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\nb) QIC\nCompare cada um dos modelos com diferentes distribuições utilizando o QIC (Quasi Likehood Independence Criterion). Os modelos têm diferença entre si nos resultados?\n\n\n\n\n\n\nNota\n\n\n\nA função QIC() não funciona para modelos gerados com as funções glm e lm, apenas com o GEE. Resolveremos em breve! Por hora utilize o SPSS🤮.\n\n\n\nQIC(modelo_gee_pulse_normal)\n\n      QIC      QICu Quasi Lik       CIC    params      QICC \n   12.347    12.347    -0.173     6.000     6.000   102.347 \n\nQIC(modelo_gee_pulse_gamma)\n\n      QIC      QICu Quasi Lik       CIC    params      QICC \n    125.2     125.2     -56.6       6.0       6.0     215.2 \n\n#QIC(modelo_gee_pulse_tweedie)\n\n\n\nc) Sumarizando os resultados\n\n\n\n\n\n\nNota\n\n\n\nA função report() não funciona para modelos gerados com as funções GEE. Aproveite para treinar a escrita no formato de uma publicação acadêmica.\n\n\n\nResutados com distribuição Tweedie\n\nreport(modelo_gee_pulse_tweedie)\n\nWe fitted a general linear model (Tweedie family with a mu^0 link) (estimated\nusing ML) to predict pulse with drug and Tempo (formula: pulse ~ drug + Tempo +\ndrug * Tempo). The model's explanatory power is substantial (Nagelkerke's R2 =\n0.87). The model's intercept, corresponding to drug = New Drug and Tempo = 1,\nis at 0.79 (95% CI [0.75, 0.83], p &lt; .001). Within this model:\n\n  - The effect of drug [Placebo] is statistically significant and positive (beta\n= 0.19, 95% CI [0.14, 0.24], p &lt; .001; Std. beta = 0.19, 95% CI [0.14, 0.24])\n  - The effect of Tempo [2] is statistically non-significant and positive (beta =\n7.55e-03, 95% CI [-0.04, 0.06], p = 0.774; Std. beta = 7.55e-03, 95% CI [-0.04,\n0.06])\n  - The effect of Tempo [3] is statistically non-significant and positive (beta =\n0.04, 95% CI [-0.01, 0.09], p = 0.157; Std. beta = 0.04, 95% CI [-0.01, 0.09])\n  - The effect of drug [Placebo] × Tempo [2] is statistically non-significant and\npositive (beta = 0.05, 95% CI [-0.03, 0.12], p = 0.204; Std. beta = 0.05, 95%\nCI [-0.03, 0.12])\n  - The effect of drug [Placebo] × Tempo [3] is statistically non-significant and\npositive (beta = 5.64e-03, 95% CI [-0.07, 0.08], p = 0.879; Std. beta =\n5.64e-03, 95% CI [-0.07, 0.08])\n\nStandardized parameters were obtained by fitting the model on a standardized\nversion of the dataset. 95% Confidence Intervals (CIs) and p-values were\ncomputed using a Wald z-distribution approximation."
  },
  {
    "objectID": "lista_2.html#considerações-finais",
    "href": "lista_2.html#considerações-finais",
    "title": "2  Lista 2 - GEE",
    "section": "2.3 Considerações finais",
    "text": "2.3 Considerações finais\nRealizamos todas as análises para a VD Pulse! Agora faça as análises para a variável Reps!\n\n\n\n\n\n\nDica!\n\n\n\nNão faça apenas um copy/paste dos scripts! Treine escrever os códigos e lembre-se de mudar o nome das variáveis do modelo para que não ocorra nenhum conflito! Compare seus resultados com os da aula prática."
  },
  {
    "objectID": "lista_2.html#lista-2-resolvida-no-spss",
    "href": "lista_2.html#lista-2-resolvida-no-spss",
    "title": "2  Lista 2 - GEE",
    "section": "2.4 Lista 2 resolvida no SPSS",
    "text": "2.4 Lista 2 resolvida no SPSS"
  },
  {
    "objectID": "lista_2.html#referências",
    "href": "lista_2.html#referências",
    "title": "2  Lista 2 - GEE",
    "section": "2.5 Referências",
    "text": "2.5 Referências"
  },
  {
    "objectID": "lista_2.html#versões-dos-pacotes",
    "href": "lista_2.html#versões-dos-pacotes",
    "title": "2  Lista 2 - GEE",
    "section": "2.6 Versões dos pacotes",
    "text": "2.6 Versões dos pacotes\n\nreport(sessionInfo())\n\nAnalyses were conducted using the R Statistical language (version 4.3.1; R Core\nTeam, 2023) on Windows 11 x64 (build 22621), using the packages lme4 (version\n1.1.34; Bates D et al., 2015), Matrix (version 1.6.0; Bates D et al., 2023),\neffectsize (version 0.8.6; Ben-Shachar MS et al., 2020), gee (version 4.13.26;\nCarey VJ, 2023), pwr (version 1.3.0; Champely S, 2020), htmltools (version\n0.5.7; Cheng J et al., 2023), fitdistrplus (version 1.1.11; Delignette-Muller\nML, Dutang C, 2015), tweedie (version 2.3.5; Dunn PK, Smyth GK, 2005), tm\n(version 0.7.11; Feinerer I, Hornik K, 2023), flexplot (version 0.20.5; Fife D,\n2024), effects (version 4.2.2; Fox J, Weisberg S, 2019), car (version 3.1.2;\nFox J, Weisberg S, 2019), carData (version 3.0.5; Fox J et al., 2022), mvtnorm\n(version 1.2.3; Genz A, Bretz F, 2009), statmod (version 1.5.0; Giner G, Smyth\nGK, 2016), geepack (version 1.3.9; Halekoh U et al., 2006), NLP (version 0.2.1;\nHornik K, 2020), TH.data (version 1.1.2; Hothorn T, 2023), multcomp (version\n1.4.25; Hothorn T et al., 2008), rstatix (version 0.7.2; Kassambara A, 2023),\nemmeans (version 1.8.8; Lenth R, 2023), sjstats (version 0.18.2; Lüdecke D,\n2022), parameters (version 0.21.3; Lüdecke D et al., 2020), performance\n(version 0.10.8; Lüdecke D et al., 2021), easystats (version 0.6.0; Lüdecke D\net al., 2022), see (version 0.8.1; Lüdecke D et al., 2021), insight (version\n0.19.6; Lüdecke D et al., 2019), survey (version 4.2.1; Lumley T, 2023),\nbayestestR (version 0.13.1; Makowski D et al., 2019), modelbased (version\n0.8.6; Makowski D et al., 2020), report (version 0.5.7; Makowski D et al.,\n2023), correlation (version 0.8.4; Makowski D et al., 2022), datawizard\n(version 0.9.0; Patil I et al., 2022), nlme (version 3.1.163; Pinheiro J et\nal., 2023), foreign (version 0.8.85; R Core Team, 2023), GGally (version 2.2.0;\nSchloerke B et al., 2023), rempsyc (version 0.1.6; Thériault R, 2023), survival\n(version 3.5.7; Therneau T, 2023), MASS (version 7.3.60; Venables WN, Ripley\nBD, 2002), ggplot2 (version 3.4.4; Wickham H, 2016), dplyr (version 1.1.3;\nWickham H et al., 2023), tidyr (version 1.3.0; Wickham H et al., 2023) and mime\n(version 0.12; Xie Y, 2021).\n\nReferences\n----------\n  - Bates D, Mächler M, Bolker B, Walker S (2015). \"Fitting Linear Mixed-Effects\nModels Using lme4.\" _Journal of Statistical Software_, *67*(1), 1-48.\ndoi:10.18637/jss.v067.i01 &lt;https://doi.org/10.18637/jss.v067.i01&gt;.\n  - Bates D, Maechler M, Jagan M (2023). _Matrix: Sparse and Dense Matrix Classes\nand Methods_. R package version 1.6-0,\n&lt;https://CRAN.R-project.org/package=Matrix&gt;.\n  - Ben-Shachar MS, Lüdecke D, Makowski D (2020). \"effectsize: Estimation of\nEffect Size Indices and Standardized Parameters.\" _Journal of Open Source\nSoftware_, *5*(56), 2815. doi:10.21105/joss.02815\n&lt;https://doi.org/10.21105/joss.02815&gt;, &lt;https://doi.org/10.21105/joss.02815&gt;.\n  - Carey VJ (2023). _gee: Generalized Estimation Equation Solver_. R package\nversion 4.13-26, &lt;https://CRAN.R-project.org/package=gee&gt;.\n  - Champely S (2020). _pwr: Basic Functions for Power Analysis_. R package\nversion 1.3-0, &lt;https://CRAN.R-project.org/package=pwr&gt;.\n  - Cheng J, Sievert C, Schloerke B, Chang W, Xie Y, Allen J (2023). _htmltools:\nTools for HTML_. R package version 0.5.7,\n&lt;https://CRAN.R-project.org/package=htmltools&gt;.\n  - Delignette-Muller ML, Dutang C (2015). \"fitdistrplus: An R Package for\nFitting Distributions.\" _Journal of Statistical Software_, *64*(4), 1-34.\ndoi:10.18637/jss.v064.i04 &lt;https://doi.org/10.18637/jss.v064.i04&gt;.\n  - Dunn PK, Smyth GK (2005). \"Series evaluation of Tweedie exponential\ndispersion models.\" _Statistics and Computing_, *15*(4), 267-280. Dunn PK,\nSmyth GK (2008). \"Evaluation of Tweedie exponential dispersion models using\nFourier inversion.\" _Statistics and Computing_, *18*(1), 73-86. Dunn PK (2022).\n_Tweedie: Evaluation of Tweedie Exponential Family Models_. R package version\n2.3.5.\n  - Feinerer I, Hornik K (2023). _tm: Text Mining Package_. R package version\n0.7-11, &lt;https://CRAN.R-project.org/package=tm&gt;. Feinerer I, Hornik K, Meyer D\n(2008). \"Text Mining Infrastructure in R.\" _Journal of Statistical Software_,\n*25*(5), 1-54. doi:10.18637/jss.v025.i05\n&lt;https://doi.org/10.18637/jss.v025.i05&gt;.\n  - Fife D (2024). _flexplot: Graphically Based Data Analysis Using 'flexplot'_.\nR package version 0.20.5.\n  - Fox J, Weisberg S (2019). _An R Companion to Applied Regression_, 3rd\nedition. Sage, Thousand Oaks CA.\n&lt;https://socialsciences.mcmaster.ca/jfox/Books/Companion/index.html&gt;. Fox J,\nWeisberg S (2018). \"Visualizing Fit and Lack of Fit in Complex Regression\nModels with Predictor Effect Plots and Partial Residuals.\" _Journal of\nStatistical Software_, *87*(9), 1-27. doi:10.18637/jss.v087.i09\n&lt;https://doi.org/10.18637/jss.v087.i09&gt;. Fox J (2003). \"Effect Displays in R\nfor Generalised Linear Models.\" _Journal of Statistical Software_, *8*(15),\n1-27. doi:10.18637/jss.v008.i15 &lt;https://doi.org/10.18637/jss.v008.i15&gt;. Fox J,\nHong J (2009). \"Effect Displays in R for Multinomial and Proportional-Odds\nLogit Models: Extensions to the effects Package.\" _Journal of Statistical\nSoftware_, *32*(1), 1-24. doi:10.18637/jss.v032.i01\n&lt;https://doi.org/10.18637/jss.v032.i01&gt;.\n  - Fox J, Weisberg S (2019). _An R Companion to Applied Regression_, Third\nedition. Sage, Thousand Oaks CA.\n&lt;https://socialsciences.mcmaster.ca/jfox/Books/Companion/&gt;.\n  - Fox J, Weisberg S, Price B (2022). _carData: Companion to Applied Regression\nData Sets_. R package version 3.0-5,\n&lt;https://CRAN.R-project.org/package=carData&gt;.\n  - Genz A, Bretz F (2009). _Computation of Multivariate Normal and t\nProbabilities_, series Lecture Notes in Statistics. Springer-Verlag,\nHeidelberg. ISBN 978-3-642-01688-2.\n  - Giner G, Smyth GK (2016). \"statmod: probability calculations for the inverse\nGaussian distribution.\" _R Journal_, *8*(1), 339-351. Phipson B, Smyth GK\n(2010). \"Permutation p-values should never be zero: calculating exact p-values\nwhen permutations are randomly drawn.\" _Statistical Applications in Genetics\nand Molecular Biology_, *9*(1), Article 39. Hu Y, Smyth GK (2009). \"ELDA:\nextreme limiting dilution analysis for comparing depleted and enriched\npopulations in stem cell and other assays.\" _Journal of Immunological Methods_,\n*347*(1), 70-78. Smyth GK (2005). \"Optimization and nonlinear equations.\"\n_Encyclopedia of Biostatistics_, 3088-3095. Smyth GK (2005). \"Numerical\nintegration.\" _Encyclopedia of Biostatistics_, 3088-3095. Smyth GK (2002). \"An\nefficient algorithm for REML in heteroscedastic regression.\" _Journal of\nComputational and Graphical Statistics_, *11*, 836-847. Dunn PK, Smyth GK\n(1996). \"Randomized quantile residuals.\" _J. Comput. Graph. Statist_, *5*,\n236-244.\n  - Halekoh U, Højsgaard S, Yan J (2006). \"The R Package geepack for Generalized\nEstimating Equations.\" _Journal of Statistical Software_, *15/2*, 1-11. Yan J,\nFine JP (2004). \"Estimating Equations for Association Structures.\" _Statistics\nin Medicine_, *23*, 859-880. Yan J (2002). \"geepack: Yet Another Package for\nGeneralized Estimating Equations.\" _R-News_, *2/3*, 12-14.\n  - Hornik K (2020). _NLP: Natural Language Processing Infrastructure_. R package\nversion 0.2-1, &lt;https://CRAN.R-project.org/package=NLP&gt;.\n  - Hothorn T (2023). _TH.data: TH's Data Archive_. R package version 1.1-2,\n&lt;https://CRAN.R-project.org/package=TH.data&gt;.\n  - Hothorn T, Bretz F, Westfall P (2008). \"Simultaneous Inference in General\nParametric Models.\" _Biometrical Journal_, *50*(3), 346-363.\n  - Kassambara A (2023). _rstatix: Pipe-Friendly Framework for Basic Statistical\nTests_. R package version 0.7.2, &lt;https://CRAN.R-project.org/package=rstatix&gt;.\n  - Lenth R (2023). _emmeans: Estimated Marginal Means, aka Least-Squares Means_.\nR package version 1.8.8, &lt;https://CRAN.R-project.org/package=emmeans&gt;.\n  - Lüdecke D (2022). _sjstats: Statistical Functions for Regression Models\n(Version 0.18.2)_. doi:10.5281/zenodo.1284472\n&lt;https://doi.org/10.5281/zenodo.1284472&gt;,\n&lt;https://CRAN.R-project.org/package=sjstats&gt;.\n  - Lüdecke D, Ben-Shachar M, Patil I, Makowski D (2020). \"Extracting, Computing\nand Exploring the Parameters of Statistical Models using R.\" _Journal of Open\nSource Software_, *5*(53), 2445. doi:10.21105/joss.02445\n&lt;https://doi.org/10.21105/joss.02445&gt;.\n  - Lüdecke D, Ben-Shachar M, Patil I, Waggoner P, Makowski D (2021).\n\"performance: An R Package for Assessment, Comparison and Testing of\nStatistical Models.\" _Journal of Open Source Software_, *6*(60), 3139.\ndoi:10.21105/joss.03139 &lt;https://doi.org/10.21105/joss.03139&gt;.\n  - Lüdecke D, Ben-Shachar M, Patil I, Wiernik B, Makowski D (2022). \"easystats:\nFramework for Easy Statistical Modeling, Visualization, and Reporting.\" _CRAN_.\nR package, &lt;https://easystats.github.io/easystats/&gt;.\n  - Lüdecke D, Patil I, Ben-Shachar M, Wiernik B, Waggoner P, Makowski D (2021).\n\"see: An R Package for Visualizing Statistical Models.\" _Journal of Open Source\nSoftware_, *6*(64), 3393. doi:10.21105/joss.03393\n&lt;https://doi.org/10.21105/joss.03393&gt;.\n  - Lüdecke D, Waggoner P, Makowski D (2019). \"insight: A Unified Interface to\nAccess Information from Model Objects in R.\" _Journal of Open Source Software_,\n*4*(38), 1412. doi:10.21105/joss.01412 &lt;https://doi.org/10.21105/joss.01412&gt;.\n  - Lumley T (2023). \"survey: analysis of complex survey samples.\" R package\nversion 4.2. Lumley T (2004). \"Analysis of Complex Survey Samples.\" _Journal of\nStatistical Software_, *9*(1), 1-19. R package verson 2.2. Lumley T (2010).\n_Complex Surveys: A Guide to Analysis Using R: A Guide to Analysis Using R_.\nJohn Wiley and Sons.\n  - Makowski D, Ben-Shachar M, Lüdecke D (2019). \"bayestestR: Describing Effects\nand their Uncertainty, Existence and Significance within the Bayesian\nFramework.\" _Journal of Open Source Software_, *4*(40), 1541.\ndoi:10.21105/joss.01541 &lt;https://doi.org/10.21105/joss.01541&gt;,\n&lt;https://joss.theoj.org/papers/10.21105/joss.01541&gt;.\n  - Makowski D, Ben-Shachar M, Patil I, Lüdecke D (2020). \"Estimation of\nModel-Based Predictions, Contrasts and Means.\" _CRAN_.\n&lt;https://github.com/easystats/modelbased&gt;.\n  - Makowski D, Lüdecke D, Patil I, Thériault R, Ben-Shachar M, Wiernik B (2023).\n\"Automated Results Reporting as a Practical Tool to Improve Reproducibility and\nMethodological Best Practices Adoption.\" _CRAN_.\n&lt;https://easystats.github.io/report/&gt;.\n  - Makowski D, Wiernik B, Patil I, Lüdecke D, Ben-Shachar M (2022).\n\"correlation: Methods for Correlation Analysis.\" Version 0.8.3,\n&lt;https://CRAN.R-project.org/package=correlation&gt;. Makowski D, Ben-Shachar M,\nPatil I, Lüdecke D (2020). \"Methods and Algorithms for Correlation Analysis in\nR.\" _Journal of Open Source Software_, *5*(51), 2306. doi:10.21105/joss.02306\n&lt;https://doi.org/10.21105/joss.02306&gt;,\n&lt;https://joss.theoj.org/papers/10.21105/joss.02306&gt;.\n  - Patil I, Makowski D, Ben-Shachar M, Wiernik B, Bacher E, Lüdecke D (2022).\n\"datawizard: An R Package for Easy Data Preparation and Statistical\nTransformations.\" _Journal of Open Source Software_, *7*(78), 4684.\ndoi:10.21105/joss.04684 &lt;https://doi.org/10.21105/joss.04684&gt;.\n  - Pinheiro J, Bates D, R Core Team (2023). _nlme: Linear and Nonlinear Mixed\nEffects Models_. R package version 3.1-163,\n&lt;https://CRAN.R-project.org/package=nlme&gt;. Pinheiro JC, Bates DM (2000).\n_Mixed-Effects Models in S and S-PLUS_. Springer, New York. doi:10.1007/b98882\n&lt;https://doi.org/10.1007/b98882&gt;.\n  - R Core Team (2023). _foreign: Read Data Stored by 'Minitab', 'S', 'SAS',\n'SPSS', 'Stata', 'Systat', 'Weka', 'dBase', ..._. R package version 0.8-85,\n&lt;https://CRAN.R-project.org/package=foreign&gt;.\n  - R Core Team (2023). _R: A Language and Environment for Statistical\nComputing_. R Foundation for Statistical Computing, Vienna, Austria.\n&lt;https://www.R-project.org/&gt;.\n  - Schloerke B, Cook D, Larmarange J, Briatte F, Marbach M, Thoen E, Elberg A,\nCrowley J (2023). _GGally: Extension to 'ggplot2'_. R package version 2.2.0,\n&lt;https://CRAN.R-project.org/package=GGally&gt;.\n  - Thériault R (2023). \"rempsyc: Convenience functions for psychology.\" _Journal\nof Open Source Software_, *8*(87), 5466. doi:10.21105/joss.05466\n&lt;https://doi.org/10.21105/joss.05466&gt;, &lt;https://doi.org/10.21105/joss.05466&gt;.\n  - Therneau T (2023). _A Package for Survival Analysis in R_. R package version\n3.5-7, &lt;https://CRAN.R-project.org/package=survival&gt;. Terry M. Therneau,\nPatricia M. Grambsch (2000). _Modeling Survival Data: Extending the Cox Model_.\nSpringer, New York. ISBN 0-387-98784-3.\n  - Venables WN, Ripley BD (2002). _Modern Applied Statistics with S_, Fourth\nedition. Springer, New York. ISBN 0-387-95457-0,\n&lt;https://www.stats.ox.ac.uk/pub/MASS4/&gt;.\n  - Wickham H (2016). _ggplot2: Elegant Graphics for Data Analysis_.\nSpringer-Verlag New York. ISBN 978-3-319-24277-4,\n&lt;https://ggplot2.tidyverse.org&gt;.\n  - Wickham H, François R, Henry L, Müller K, Vaughan D (2023). _dplyr: A Grammar\nof Data Manipulation_. R package version 1.1.3,\n&lt;https://CRAN.R-project.org/package=dplyr&gt;.\n  - Wickham H, Vaughan D, Girlich M (2023). _tidyr: Tidy Messy Data_. R package\nversion 1.3.0, &lt;https://CRAN.R-project.org/package=tidyr&gt;.\n  - Xie Y (2021). _mime: Map Filenames to MIME Types_. R package version 0.12,\n&lt;https://CRAN.R-project.org/package=mime&gt;."
  },
  {
    "objectID": "lista_3.html#pacotes-que-vamos-utilizar",
    "href": "lista_3.html#pacotes-que-vamos-utilizar",
    "title": "3  Lista 3 - Matriz de Covariância",
    "section": "3.1 Pacotes que vamos utilizar",
    "text": "3.1 Pacotes que vamos utilizar\n\nlibrary(emmeans)\nlibrary(nlme)\nlibrary(flexplot)\nlibrary(foreign)\nlibrary(dplyr)\nlibrary(multcomp)\nlibrary(effects)\nlibrary(performance)\nlibrary(easystats)"
  },
  {
    "objectID": "lista_3.html#instruções-e-carregando-o-banco-de-dados",
    "href": "lista_3.html#instruções-e-carregando-o-banco-de-dados",
    "title": "3  Lista 3 - Matriz de Covariância",
    "section": "3.2 Instruções e carregando o banco de dados",
    "text": "3.2 Instruções e carregando o banco de dados\nVamos utilizar um GMM para verificar o efeito de tempo e grupo sobre os resultados de resp (o banco já está no formato correto). Porém, antes disso vamos avaliar qual a melhor matriz de covariância que o modelo deve aplicar aos dados.\n\ndataset = read.spss(\"bd_New drug_respiratory&pulseRESHAPE.sav\", to.data.frame=TRUE)\n\n\n\n\n\n\n\nMuito importante!\n\n\n\nSEMPRE verifique o tipo das variáveis no banco de dados. Elas podem ser fatores, números íntegros, números decimais, etc. As análises mudam MUITO dependendo do tipo de variável que utilizamos no modelo de regressão linear!\n\n\nPara verificar o tipo das variáveis podemos utilizar a função glimpse().\n\nglimpse(dataset)\n\nRows: 36\nColumns: 5\n$ Sujeito &lt;dbl&gt; 1, 1, 1, 2, 2, 2, 3, 3, 3, 4, 4, 4, 5, 5, 5, 6, 6, 6, 7, 7, 7,…\n$ drug    &lt;fct&gt; New Drug, New Drug, New Drug, New Drug, New Drug, New Drug, Ne…\n$ Tempo   &lt;dbl&gt; 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3,…\n$ resp    &lt;dbl&gt; 3.4, 3.3, 3.3, 3.4, 3.4, 3.3, 3.3, 3.4, 3.4, 3.4, 3.4, 3.4, 3.…\n$ pulse   &lt;dbl&gt; 2.2, 2.1, 2.1, 2.2, 2.1, 2.2, 2.3, 2.4, 2.3, 2.3, 2.4, 2.3, 2.…\n\n\nNotem que a variável Tempo está como &lt;dbl&gt;, indicando que é uma variável contínua. Vejam a aula prática em que o Altay explica que os tempos de coleta na verdade são fatores e não indicam uma ordem ou um contínuo. Seria como dizer que as amostras foram coletadas nos Tempos “X”, “Y” e “Z”.\nPara transformar a variável Tempo em um fator podemos utilizar o seguinte código:\n\ndataset$Tempo = as.factor(dataset$Tempo)\n\nRodando novamente a função glimpse() é possível observar que agora sim temos a variável Tempo como &lt;fct&gt;, indicando que ela é do tipo fator .\n\nglimpse(dataset)\n\nRows: 36\nColumns: 5\n$ Sujeito &lt;dbl&gt; 1, 1, 1, 2, 2, 2, 3, 3, 3, 4, 4, 4, 5, 5, 5, 6, 6, 6, 7, 7, 7,…\n$ drug    &lt;fct&gt; New Drug, New Drug, New Drug, New Drug, New Drug, New Drug, Ne…\n$ Tempo   &lt;fct&gt; 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3,…\n$ resp    &lt;dbl&gt; 3.4, 3.3, 3.3, 3.4, 3.4, 3.3, 3.3, 3.4, 3.4, 3.4, 3.4, 3.4, 3.…\n$ pulse   &lt;dbl&gt; 2.2, 2.1, 2.1, 2.2, 2.1, 2.2, 2.3, 2.4, 2.3, 2.3, 2.4, 2.3, 2.…\n\n\n\n\n\n\n\n\nDica\n\n\n\nFaça os modelos antes e depois de transformar a variável Tempo em um fator e compare os resultados.\n\n\nAgora sim podemos realizar nossas análises e comparar com os resultados do SPSS."
  },
  {
    "objectID": "lista_3.html#a-criando-os-modelos-para-a-variável-resp",
    "href": "lista_3.html#a-criando-os-modelos-para-a-variável-resp",
    "title": "3  Lista 3 - Matriz de Covariância",
    "section": "3.3 a) Criando os modelos para a variável Resp",
    "text": "3.3 a) Criando os modelos para a variável Resp\nHá diversos pacotes no R que podemos alterar a matriz de covariância do modelo. Optamos por escolher a função lme() do pacote nlme por ela ter de forma bem direta todas as matrizes escolhidas na aula prática utilizando o SPSS. Recomendamos também o pacote geepackpara outras matrizes.\n\nMatriz simétrica\n\nmodel_resp_sim = lme(\n  fixed = resp ~ 1 + drug + Tempo + drug * Tempo, \n  random =~ 1|Sujeito, \n  correlation = corCompSymm(form = ~1|Sujeito), # Aqui definimos a matriz\n  data = dataset)\n\n\n\nMatriz Ar(1)\n\nmodel_resp_AR1 = lme(\n  fixed = resp ~ Tempo + drug + Tempo * drug,\n  random = ~1|Sujeito,\n  correlation = corAR1(form = ~ 1|Sujeito), # Aqui definimos a matriz\n  data = dataset)\n\n\n\nMatriz Diagonal (identidade)\n\nmodel_resp_Iden = lme(\n  fixed = resp ~ drug + Tempo + drug * Tempo,\n  random = ~1|Sujeito,\n  correlation = corIdent(form = ~ 1|Sujeito), # Aqui definimos a matriz\n  data = dataset)\n\n\n\nMatriz Não estruturada (Unstructured)\n\nmodel_resp_Uns = lme(\n  fixed = resp ~ drug + Tempo + drug * Tempo,\n  random = ~1|Sujeito,\n  correlation = corSymm(form = ~ 1|Sujeito), # Aqui definimos a matriz\n  data = dataset)"
  },
  {
    "objectID": "lista_3.html#b-comparando-os-valores-de-aic-e-bic",
    "href": "lista_3.html#b-comparando-os-valores-de-aic-e-bic",
    "title": "3  Lista 3 - Matriz de Covariância",
    "section": "3.4 b) Comparando os valores de AIC e BIC",
    "text": "3.4 b) Comparando os valores de AIC e BIC\nPodemos colocar os resultados dos valores de AIC e BIC dos modelos em um dataframe para poder compará-los.\n\n# Crie um dataframe\ndf_aderencia &lt;- data.frame(\n  Modelo = c(\"model_resp_sim\", \"model_resp_AR1\", \"model_resp_Iden\", \"model_resp_Uns\"),\n  AIC = c(AIC(model_resp_sim), AIC(model_resp_AR1), AIC(model_resp_Iden), AIC(model_resp_Uns)),\n  BIC = c(BIC(model_resp_sim), BIC(model_resp_AR1), BIC(model_resp_Iden), BIC(model_resp_Uns))\n)\n\n# Arredonde os valores para 3 casas decimais\ndf_aderencia$AIC &lt;- round(df_aderencia$AIC, 3)\ndf_aderencia$BIC &lt;- round(df_aderencia$BIC, 3)\n\n# Adicione um asterisco às células correspondentes aos menores valores de AIC e BIC\ndf_aderencia$AIC &lt;- ifelse(df_aderencia$AIC == min(df_aderencia$AIC), paste0(df_aderencia$AIC, \"*\"), df_aderencia$AIC)\ndf_aderencia$BIC &lt;- ifelse(df_aderencia$BIC == min(df_aderencia$BIC), paste0(df_aderencia$BIC, \"*\"), df_aderencia$BIC)\n\n\n# Exiba o dataframe\nprint(df_aderencia)\n\n           Modelo     AIC      BIC\n1  model_resp_sim -51.363  -38.752\n2  model_resp_AR1  -54.3*   -41.69\n3 model_resp_Iden -53.363 -42.153*\n4  model_resp_Uns -53.455  -38.042\n\n\n\n\n\n\n\n\nDica!\n\n\n\nPodemos utilizar a função compare_performance para comparar diversos valores de aderência dos modelos!\n\n\n\ncompare_performance(model_resp_sim,\n                    model_resp_AR1,\n                    model_resp_Iden,\n                    model_resp_Uns,\n                    metrics = c(\"AIC\",\"BIC\"),\n                    rank = TRUE)\n\n# Comparison of Model Performance Indices\n\nName            | Model | AIC weights | BIC weights | Performance-Score\n-----------------------------------------------------------------------\nmodel_resp_AR1  |   lme |       0.394 |       0.419 |            98.26%\nmodel_resp_Iden |   lme |       0.184 |       0.432 |            67.80%\nmodel_resp_Uns  |   lme |       0.354 |       0.077 |            44.62%\nmodel_resp_sim  |   lme |       0.068 |       0.072 |             0.00%\n\n\nDas duas formas constatamos que o modelo com a matriz de covariância AR1 apresentou os melhores índices de aderência. Note que os valores de AIC e BIC apresentados na saída da função compare_factors aparecem ponderados. Os valores são calculados dividindo o peso AIC/BIC de um modelo pelo peso AIC/BIC dos outros modelos ajustados."
  },
  {
    "objectID": "lista_3.html#c-resultado-do-modelo-escolhido---ar1",
    "href": "lista_3.html#c-resultado-do-modelo-escolhido---ar1",
    "title": "3  Lista 3 - Matriz de Covariância",
    "section": "3.5 c) Resultado do modelo escolhido - AR1",
    "text": "3.5 c) Resultado do modelo escolhido - AR1\nA matriz de covariância AR(1) é uma escolha adequada para o exemplo da droga e do placebo devido à sua capacidade de capturar a dependência temporal nas respostas dos pacientes em estudos longitudinais. Essa matriz reflete a ideia de que as observações próximas no tempo têm uma correlação mais forte, enquanto as observações mais distantes têm uma correlação mais fraca. Isso é consistente com a possibilidade de que os efeitos da droga persistam ao longo do tempo, mas diminuam com o passar dos dias após a administração.\n\nreport(model_resp_AR1)\n\nWe fitted a linear mixed model (estimated using REML and nlminb optimizer) to\npredict resp with Tempo, drug and Sujeito (formula: resp ~ Tempo + drug + Tempo\n* drug). The model included Sujeito as random effect (formula: ~1 | Sujeito).\nThe model's total explanatory power is substantial (conditional R2 = 0.41) and\nthe part related to the fixed effects alone (marginal R2) is of 0.41. The\nmodel's intercept, corresponding to Tempo = 1 and drug = New Drug, is at 3.35\n(95% CI [3.29, 3.41], t(20) = 125.70, p &lt; .001). Within this model:\n\n  - The effect of Tempo [2] is statistically non-significant and positive (beta =\n0.02, 95% CI [-0.04, 0.08], t(20) = 0.59, p = 0.559; Std. beta = 0.21, 95% CI\n[-0.52, 0.93])\n  - The effect of Tempo [3] is statistically non-significant and negative (beta =\n-0.02, 95% CI [-0.09, 0.05], t(20) = -0.49, p = 0.627; Std. beta = -0.21, 95%\nCI [-1.07, 0.66])\n  - The effect of drug [Placebo] is statistically significant and negative (beta\n= -0.12, 95% CI [-0.20, -0.03], t(10) = -3.10, p = 0.011; Std. beta = -1.44,\n95% CI [-2.48, -0.40])\n  - The effect of Tempo [2] × drug [Placebo] is statistically non-significant and\npositive (beta = 8.08e-17, 95% CI [-0.08, 0.08], t(20) = 2.04e-15, p &gt; .999;\nStd. beta = -1.43e-15, 95% CI [-1.02, 1.02])\n  - The effect of Tempo [3] × drug [Placebo] is statistically non-significant and\npositive (beta = 0.03, 95% CI [-0.07, 0.13], t(20) = 0.70, p = 0.493; Std. beta\n= 0.41, 95% CI [-0.82, 1.64])\n\nStandardized parameters were obtained by fitting the model on a standardized\nversion of the dataset. 95% Confidence Intervals (CIs) and p-values were\ncomputed using a Wald t-distribution approximation.\n\n\nFaça as análises para a variável Pulse! Lembre-se de não ficar apenas copiando e colando os scripts e mude os nomes das variáveis!"
  },
  {
    "objectID": "lista_3.html#extras",
    "href": "lista_3.html#extras",
    "title": "3  Lista 3 - Matriz de Covariância",
    "section": "3.6 Extras!",
    "text": "3.6 Extras!\n\nGráfico do modelo em uma linha\nJá vimos algumas formas de apresentar os gráficos dos modelos. A ideia ao longo destes tutoriais é oferecer várias ferramentas para você poder escolher a mais adequada para seus objetivos. Vamos ver uma forma bem prática de criar um gráfico do nosso modelo escolhido com a função plot() em conjunto com a função allEffects()!\n\nplot(allEffects(model_resp_AR1))\n\n\n\n\n\n\nMudando a referência de um fator\nNa análise dos modelos observamos que o grupo “New Drug” foi escolhido como referência. Isso é evidenciado pelo fato de que apenas os valores dos estimadores para o grupo “Placebo” são apresentados nos resultados. O R escolhe, por padrão, o valor de referência inicial com base na ordem alfabética dos níveis da variável categórica. Nesse caso, “New Drug” é escolhido como referência por ser o primeiro nível alfabeticamente.\nCaso queira confirmar qual é o valor de referência de uma variável, basta utiliza a função levels(), que já vem instalada com o R.\n\nlevels(dataset$drug)\n\n[1] \"New Drug\" \"Placebo\" \n\n\nPodemos alterar facilmente qual será o grupo de referência de nossas análises utilizando a função relevel(), que também já vem instalada no pacote base do R.\n\ndataset$drug &lt;- relevel(dataset$drug, ref = \"Placebo\")\nlevels(dataset$drug)\n\n[1] \"Placebo\"  \"New Drug\"\n\n\nNote agora que “Placebo” aparece em primeiro lugar, indicando o novo valor de referência. Escreva um novo modelo e compare os resultados com os anteriores."
  },
  {
    "objectID": "lista_3.html#lista-2-resolvida-no-spss",
    "href": "lista_3.html#lista-2-resolvida-no-spss",
    "title": "3  Lista 3 - Matriz de Covariância",
    "section": "3.7 Lista 2 resolvida no SPSS",
    "text": "3.7 Lista 2 resolvida no SPSS"
  },
  {
    "objectID": "lista_3.html#referências",
    "href": "lista_3.html#referências",
    "title": "3  Lista 3 - Matriz de Covariância",
    "section": "3.8 Referências",
    "text": "3.8 Referências\nhttps://bcheggeseth.github.io/CorrelatedData/marginal-models.html"
  },
  {
    "objectID": "lista_3.html#versões-dos-pacotes",
    "href": "lista_3.html#versões-dos-pacotes",
    "title": "3  Lista 3 - Matriz de Covariância",
    "section": "3.9 Versões dos pacotes",
    "text": "3.9 Versões dos pacotes\n\nreport(sessionInfo())\n\nAnalyses were conducted using the R Statistical language (version 4.3.1; R Core\nTeam, 2023) on Windows 11 x64 (build 22621), using the packages effectsize\n(version 0.8.6; Ben-Shachar MS et al., 2020), flexplot (version 0.20.5; Fife D,\n2024), effects (version 4.2.2; Fox J, Weisberg S, 2019), carData (version\n3.0.5; Fox J et al., 2022), mvtnorm (version 1.2.3; Genz A, Bretz F, 2009),\nTH.data (version 1.1.2; Hothorn T, 2023), multcomp (version 1.4.25; Hothorn T\net al., 2008), emmeans (version 1.8.8; Lenth R, 2023), parameters (version\n0.21.3; Lüdecke D et al., 2020), performance (version 0.10.8; Lüdecke D et al.,\n2021), easystats (version 0.6.0; Lüdecke D et al., 2022), see (version 0.8.1;\nLüdecke D et al., 2021), insight (version 0.19.6; Lüdecke D et al., 2019),\nbayestestR (version 0.13.1; Makowski D et al., 2019), modelbased (version\n0.8.6; Makowski D et al., 2020), report (version 0.5.7; Makowski D et al.,\n2023), correlation (version 0.8.4; Makowski D et al., 2022), datawizard\n(version 0.9.0; Patil I et al., 2022), nlme (version 3.1.163; Pinheiro J et\nal., 2023), foreign (version 0.8.85; R Core Team, 2023), survival (version\n3.5.7; Therneau T, 2023), MASS (version 7.3.60; Venables WN, Ripley BD, 2002)\nand dplyr (version 1.1.3; Wickham H et al., 2023).\n\nReferences\n----------\n  - Ben-Shachar MS, Lüdecke D, Makowski D (2020). \"effectsize: Estimation of\nEffect Size Indices and Standardized Parameters.\" _Journal of Open Source\nSoftware_, *5*(56), 2815. doi:10.21105/joss.02815\n&lt;https://doi.org/10.21105/joss.02815&gt;, &lt;https://doi.org/10.21105/joss.02815&gt;.\n  - Fife D (2024). _flexplot: Graphically Based Data Analysis Using 'flexplot'_.\nR package version 0.20.5.\n  - Fox J, Weisberg S (2019). _An R Companion to Applied Regression_, 3rd\nedition. Sage, Thousand Oaks CA.\n&lt;https://socialsciences.mcmaster.ca/jfox/Books/Companion/index.html&gt;. Fox J,\nWeisberg S (2018). \"Visualizing Fit and Lack of Fit in Complex Regression\nModels with Predictor Effect Plots and Partial Residuals.\" _Journal of\nStatistical Software_, *87*(9), 1-27. doi:10.18637/jss.v087.i09\n&lt;https://doi.org/10.18637/jss.v087.i09&gt;. Fox J (2003). \"Effect Displays in R\nfor Generalised Linear Models.\" _Journal of Statistical Software_, *8*(15),\n1-27. doi:10.18637/jss.v008.i15 &lt;https://doi.org/10.18637/jss.v008.i15&gt;. Fox J,\nHong J (2009). \"Effect Displays in R for Multinomial and Proportional-Odds\nLogit Models: Extensions to the effects Package.\" _Journal of Statistical\nSoftware_, *32*(1), 1-24. doi:10.18637/jss.v032.i01\n&lt;https://doi.org/10.18637/jss.v032.i01&gt;.\n  - Fox J, Weisberg S, Price B (2022). _carData: Companion to Applied Regression\nData Sets_. R package version 3.0-5,\n&lt;https://CRAN.R-project.org/package=carData&gt;.\n  - Genz A, Bretz F (2009). _Computation of Multivariate Normal and t\nProbabilities_, series Lecture Notes in Statistics. Springer-Verlag,\nHeidelberg. ISBN 978-3-642-01688-2.\n  - Hothorn T (2023). _TH.data: TH's Data Archive_. R package version 1.1-2,\n&lt;https://CRAN.R-project.org/package=TH.data&gt;.\n  - Hothorn T, Bretz F, Westfall P (2008). \"Simultaneous Inference in General\nParametric Models.\" _Biometrical Journal_, *50*(3), 346-363.\n  - Lenth R (2023). _emmeans: Estimated Marginal Means, aka Least-Squares Means_.\nR package version 1.8.8, &lt;https://CRAN.R-project.org/package=emmeans&gt;.\n  - Lüdecke D, Ben-Shachar M, Patil I, Makowski D (2020). \"Extracting, Computing\nand Exploring the Parameters of Statistical Models using R.\" _Journal of Open\nSource Software_, *5*(53), 2445. doi:10.21105/joss.02445\n&lt;https://doi.org/10.21105/joss.02445&gt;.\n  - Lüdecke D, Ben-Shachar M, Patil I, Waggoner P, Makowski D (2021).\n\"performance: An R Package for Assessment, Comparison and Testing of\nStatistical Models.\" _Journal of Open Source Software_, *6*(60), 3139.\ndoi:10.21105/joss.03139 &lt;https://doi.org/10.21105/joss.03139&gt;.\n  - Lüdecke D, Ben-Shachar M, Patil I, Wiernik B, Makowski D (2022). \"easystats:\nFramework for Easy Statistical Modeling, Visualization, and Reporting.\" _CRAN_.\nR package, &lt;https://easystats.github.io/easystats/&gt;.\n  - Lüdecke D, Patil I, Ben-Shachar M, Wiernik B, Waggoner P, Makowski D (2021).\n\"see: An R Package for Visualizing Statistical Models.\" _Journal of Open Source\nSoftware_, *6*(64), 3393. doi:10.21105/joss.03393\n&lt;https://doi.org/10.21105/joss.03393&gt;.\n  - Lüdecke D, Waggoner P, Makowski D (2019). \"insight: A Unified Interface to\nAccess Information from Model Objects in R.\" _Journal of Open Source Software_,\n*4*(38), 1412. doi:10.21105/joss.01412 &lt;https://doi.org/10.21105/joss.01412&gt;.\n  - Makowski D, Ben-Shachar M, Lüdecke D (2019). \"bayestestR: Describing Effects\nand their Uncertainty, Existence and Significance within the Bayesian\nFramework.\" _Journal of Open Source Software_, *4*(40), 1541.\ndoi:10.21105/joss.01541 &lt;https://doi.org/10.21105/joss.01541&gt;,\n&lt;https://joss.theoj.org/papers/10.21105/joss.01541&gt;.\n  - Makowski D, Ben-Shachar M, Patil I, Lüdecke D (2020). \"Estimation of\nModel-Based Predictions, Contrasts and Means.\" _CRAN_.\n&lt;https://github.com/easystats/modelbased&gt;.\n  - Makowski D, Lüdecke D, Patil I, Thériault R, Ben-Shachar M, Wiernik B (2023).\n\"Automated Results Reporting as a Practical Tool to Improve Reproducibility and\nMethodological Best Practices Adoption.\" _CRAN_.\n&lt;https://easystats.github.io/report/&gt;.\n  - Makowski D, Wiernik B, Patil I, Lüdecke D, Ben-Shachar M (2022).\n\"correlation: Methods for Correlation Analysis.\" Version 0.8.3,\n&lt;https://CRAN.R-project.org/package=correlation&gt;. Makowski D, Ben-Shachar M,\nPatil I, Lüdecke D (2020). \"Methods and Algorithms for Correlation Analysis in\nR.\" _Journal of Open Source Software_, *5*(51), 2306. doi:10.21105/joss.02306\n&lt;https://doi.org/10.21105/joss.02306&gt;,\n&lt;https://joss.theoj.org/papers/10.21105/joss.02306&gt;.\n  - Patil I, Makowski D, Ben-Shachar M, Wiernik B, Bacher E, Lüdecke D (2022).\n\"datawizard: An R Package for Easy Data Preparation and Statistical\nTransformations.\" _Journal of Open Source Software_, *7*(78), 4684.\ndoi:10.21105/joss.04684 &lt;https://doi.org/10.21105/joss.04684&gt;.\n  - Pinheiro J, Bates D, R Core Team (2023). _nlme: Linear and Nonlinear Mixed\nEffects Models_. R package version 3.1-163,\n&lt;https://CRAN.R-project.org/package=nlme&gt;. Pinheiro JC, Bates DM (2000).\n_Mixed-Effects Models in S and S-PLUS_. Springer, New York. doi:10.1007/b98882\n&lt;https://doi.org/10.1007/b98882&gt;.\n  - R Core Team (2023). _foreign: Read Data Stored by 'Minitab', 'S', 'SAS',\n'SPSS', 'Stata', 'Systat', 'Weka', 'dBase', ..._. R package version 0.8-85,\n&lt;https://CRAN.R-project.org/package=foreign&gt;.\n  - R Core Team (2023). _R: A Language and Environment for Statistical\nComputing_. R Foundation for Statistical Computing, Vienna, Austria.\n&lt;https://www.R-project.org/&gt;.\n  - Therneau T (2023). _A Package for Survival Analysis in R_. R package version\n3.5-7, &lt;https://CRAN.R-project.org/package=survival&gt;. Terry M. Therneau,\nPatricia M. Grambsch (2000). _Modeling Survival Data: Extending the Cox Model_.\nSpringer, New York. ISBN 0-387-98784-3.\n  - Venables WN, Ripley BD (2002). _Modern Applied Statistics with S_, Fourth\nedition. Springer, New York. ISBN 0-387-95457-0,\n&lt;https://www.stats.ox.ac.uk/pub/MASS4/&gt;.\n  - Wickham H, François R, Henry L, Müller K, Vaughan D (2023). _dplyr: A Grammar\nof Data Manipulation_. R package version 1.1.3,\n&lt;https://CRAN.R-project.org/package=dplyr&gt;."
  },
  {
    "objectID": "lista_4.html#pacotes-que-vamos-utilizar",
    "href": "lista_4.html#pacotes-que-vamos-utilizar",
    "title": "4  Lista 4 - GMM e ICC",
    "section": "4.1 Pacotes que vamos utilizar",
    "text": "4.1 Pacotes que vamos utilizar\n\n# Seu código R aqui\nlibrary(emmeans)\nlibrary(lme4)\nlibrary(nlme)\nlibrary(flexplot)\nlibrary(foreign)\nlibrary(dplyr)\nlibrary(multcomp)\nlibrary(effects)\nlibrary(sjstats)\nlibrary(tm)\nlibrary(report)\nlibrary(ggplot2)\nlibrary(forcats)\nlibrary(performance)\nlibrary(rempsyc)\nlibrary(easystats)\nlibrary(fitdistrplus)\nlibrary(sjPlot)\nlibrary(kableExtra)\nlibrary(psychometric)\nlibrary(misty)\n\n\ndataset = read.spss(\"THKS2.sav\", to.data.frame=TRUE)\n\nComo já mencionado no capítulo anterior, é muito importante averiguar os tipos de variáveis antes de começar as análises. Para isso vamos utilizar a função glimpse().\n\nglimpse(dataset)\n\nRows: 1,600\nColumns: 5\n$ SchoolID &lt;dbl&gt; 404, 404, 404, 404, 404, 404, 404, 404, 404, 404, 404, 404, 4…\n$ ClassID  &lt;dbl&gt; 404101, 404101, 404101, 404101, 404101, 404101, 404101, 40410…\n$ PreTHKS  &lt;dbl&gt; 1, 2, 4, 3, 1, 1, 2, 0, 1, 2, 2, 1, 1, 0, 4, 1, 2, 1, 2, 2, 2…\n$ PosTHKS  &lt;dbl&gt; 3, 4, 2, 3, 2, 1, 3, 5, 2, 3, 4, 3, 1, 0, 4, 5, 3, 3, 4, 2, 3…\n$ Group    &lt;fct&gt; Curriculum & TV, Curriculum & TV, Curriculum & TV, Curriculum…\n\n\nAo analisar os arquivos provenientes de outros programas, percebe-se que todas as variáveis numéricas são tratadas como contínuas. No entanto, todas as variáveis no banco de dados são, na verdade, categóricas. Portanto, é necessário modificar o tipo das variáveis antes de iniciar as análises. Para isso vamos utilizar a função as.factor() nas 4 variáveis contínuas.\n\ndataset$SchoolID = as.factor(dataset$SchoolID)\ndataset$ClassID = as.factor(dataset$ClassID)\ndataset$PreTHKS = as.integer(dataset$PreTHKS)\ndataset$PosTHKS = as.integer(dataset$PosTHKS)\n\nRodando novamente a função glimpse() podemos verificar se a mudança aconteceu.\n\nglimpse(dataset)\n\nRows: 1,600\nColumns: 5\n$ SchoolID &lt;fct&gt; 404, 404, 404, 404, 404, 404, 404, 404, 404, 404, 404, 404, 4…\n$ ClassID  &lt;fct&gt; 404101, 404101, 404101, 404101, 404101, 404101, 404101, 40410…\n$ PreTHKS  &lt;int&gt; 1, 2, 4, 3, 1, 1, 2, 0, 1, 2, 2, 1, 1, 0, 4, 1, 2, 1, 2, 2, 2…\n$ PosTHKS  &lt;int&gt; 3, 4, 2, 3, 2, 1, 3, 5, 2, 3, 4, 3, 1, 0, 4, 5, 3, 3, 4, 2, 3…\n$ Group    &lt;fct&gt; Curriculum & TV, Curriculum & TV, Curriculum & TV, Curriculum…\n\n\nPodemos também calcular o número de alunos por classe também. Isso será bem útil para uma análise Extra no fim do capítulo.\n\ndataset$Tamanho_Classe &lt;- ave(dataset$PreTHKS, dataset$SchoolID, dataset$ClassID, FUN = length)"
  },
  {
    "objectID": "lista_4.html#a-modelos-hierárquicos",
    "href": "lista_4.html#a-modelos-hierárquicos",
    "title": "4  Lista 4 - GMM e ICC",
    "section": "4.2 a) Modelos hierárquicos",
    "text": "4.2 a) Modelos hierárquicos\n\n\n\n\n\n\nExercício\n\n\n\nCom base no desenho apresentado, qual é a pergunta que este estudo quer responder?\n\n\nPara abordar as questões específicas relacionadas ao banco de dados THKS2 utilizando um modelo linear GMM hierárquico, precisamos formular perguntas específicas que desejamos responder com a análise. Dado que o THKS é a variável dependente e foi avaliado antes e depois da implementação dos diferentes grupos de intervenção, podemos considerar algumas perguntas relevantes:\n\nEfeito geral da intervenção: Como a média da escala THKS varia entre os grupos “Curriculum & TV”, “Curriculum”, “TV” e “Neither” após a implementação das intervenções?\nDiferenças entre grupos específicos: Há diferenças significativas nas mudanças médias da escala THKS entre os grupos “Curriculum & TV”, “Curriculum”, “TV” e “Neither”?\nVariação entre escolas e salas de aula: A variação nas médias da escala THKS é significativa entre as escolas ou entre as salas de aula, considerando o efeito das intervenções?\n\nA análise gráfica pode ser fundamental para avaliar a validade da escolha de um modelo hierárquico. Ao comparar as médias do PreTHKS e do PosTHKS para diferentes escolas e salas de aula, os gráficos podem revelar padrões ou tendências que indicam se há variação sistemática ou não nas médias entre esses níveis hierárquicos. A identificação de padrões específicos pode orientar a decisão de usar um modelo hierárquico para capturar a estrutura aninhada dos dados.\nVamos criar um gráfico das médias de THKS entre as escolas antes e depois das intervenções.\n\nMédia por Escola\n\n# Instale o pacote ggplot2 se ainda não o tiver instalado\n# install.packages(\"ggplot2\")\n\n\n# Crie um novo dataframe para armazenar a média das notas por escola\nmedia_por_escola &lt;- aggregate(cbind(PosTHKS, PreTHKS) ~ SchoolID, data = dataset, FUN = mean)\n\n# Transforme os dados em formato longo (tidy)\nmedia_por_escola_long &lt;- tidyr::pivot_longer(media_por_escola, cols = c(\"PreTHKS\", \"PosTHKS\"), names_to = \"tempo\", values_to = \"media\")\n\n# Crie um gráfico de dispersão com uma linha contínua conectando as médias das notas\nggplot(data = media_por_escola_long, aes(x = forcats::fct_rev(tempo), y = media, color = SchoolID, group = SchoolID)) +\n  geom_point() +\n  geom_line() +\n  labs(title = \"Médias por Escola\",\n       x = \"\",\n       y = \"Valores das médias de THKS\") +\n  theme_minimal() +\n  theme(legend.position = \"right\")  # Posição da leg\n\n\n\n\nObserve no gráfico que o efeito da intervenção é basicamente constante. Antes da intervenção a média de THKS era menor e após a intervenção a média aumentou em praticamente todas as escolas analisadas.\nVamos fazer o mesmo mas separando as médias por classes.\n\n\nMédia por classe\n\n# Instale o pacote ggplot2 se ainda não o tiver instalado\n# install.packages(\"ggplot2\")\n\n\n# Crie um novo dataframe para armazenar a média das notas por escola\nmedia_por_classe &lt;- aggregate(cbind(PreTHKS, PosTHKS) ~ ClassID, data = dataset, FUN = mean)\n\n# Transforme os dados em formato longo (tidy)\nmedia_por_classe_long &lt;- tidyr::pivot_longer(media_por_classe, cols = c(\"PreTHKS\", \"PosTHKS\"), names_to = \"tempo\", values_to = \"media\")\n\n# Crie um gráfico de dispersão com uma linha contínua conectando as médias das notas\nggplot(data = media_por_classe_long, aes(x = forcats::fct_rev(tempo), y = media, color = ClassID, group = ClassID)) +\n  geom_point() +\n  geom_line() +\n  labs(title = \"Médias por Classe\",\n       x = \"\",\n       y = \"Média de Notas\") +\n  #scale_color_manual(values = rainbow(length(top_50_escolas))) +  # Ajuste as cores manualmente\n  theme_minimal() +\n  theme(legend.position = \"none\")  # Posição da legenda\n\n\n\n\nObservamos que, em alguns casos, a média de THKS diminui após a intervenção, enquanto em outros ocorre um aumento. A falta de um padrão claro sugere que a classe também desempenha um papel na resposta à intervenção, indicando a necessidade de utilizar modelos hierárquicos com fatores aleatórios nessa variável.\n\n\nMédia por Grupo\n\n# Instale o pacote ggplot2 se ainda não o tiver instalado\n# install.packages(\"ggplot2\")\nhead(dataset)\n\n  SchoolID ClassID PreTHKS PosTHKS           Group Tamanho_Classe\n1      404  404101       1       3 Curriculum & TV             11\n2      404  404101       2       4 Curriculum & TV             11\n3      404  404101       4       2 Curriculum & TV             11\n4      404  404101       3       3 Curriculum & TV             11\n5      404  404101       1       2 Curriculum & TV             11\n6      404  404101       1       1 Curriculum & TV             11\n\n# Crie um novo dataframe para armazenar a média das notas por escola\nmedia_por_grupo &lt;- aggregate(cbind(PosTHKS, PreTHKS) ~ Group, data = dataset, FUN = mean)\n\n# Transforme os dados em formato longo (tidy)\nmedia_por_grupo_long &lt;- tidyr::pivot_longer(media_por_grupo, cols = c(\"PreTHKS\", \"PosTHKS\"), names_to = \"tempo\", values_to = \"media\")\n\n# Crie um gráfico de dispersão com uma linha contínua conectando as médias das notas\nggplot(data = media_por_grupo_long, aes(x = forcats::fct_rev(tempo), y = media, color = Group, group = Group)) +\n  geom_point() +\n  geom_line() +\n  labs(title = \"Médias por Grupo\",\n       x = \"\",\n       y = \"Valores das médias de THKS\") +\n  theme_minimal() +\n  theme(legend.position = \"right\")  # Posição da leg\n\n\n\n\nOs grupos também parecem ter um padrão constante de aumento na média de THKS após a intervenção, indicano que não há necessidade de colocar essa variável como efeito aleatório."
  },
  {
    "objectID": "lista_4.html#b-efeitos-fixos-e-aleatórios",
    "href": "lista_4.html#b-efeitos-fixos-e-aleatórios",
    "title": "4  Lista 4 - GMM e ICC",
    "section": "4.3 b) Efeitos fixos e aleatórios",
    "text": "4.3 b) Efeitos fixos e aleatórios\n\n\n\n\n\n\nExercício\n\n\n\nDentre os efeitos observados – Grupo, Classe e Escola – quais são efeitos fixos e aleatórios pelo menos do ponto de vista teórico?\n\n\nos gráficos são apenas uma das diversas maneiras de verificar a necessidade ou não de efeitos aleatórios. Mais a frente vamos ver outras métricas que podemos nos ajudar com a decisão.\nCom base nos gráficos anteriores, podemos inferir que a classe é um efeito aleatório, enquanto a escola e o grupo são efeitos fixos. Para seguir a abordagem prática exemplificada durante a aula no SPSS, iremos construir vários modelos considerando efeitos fixos e aleatórios. Posteriormente, compararemos os índices de aderência e os resultados obtidos, com o intuito de selecionar o modelo mais adequado para os nossos dados."
  },
  {
    "objectID": "lista_4.html#c-glm-univariado",
    "href": "lista_4.html#c-glm-univariado",
    "title": "4  Lista 4 - GMM e ICC",
    "section": "4.4 c) GLM univariado",
    "text": "4.4 c) GLM univariado\n\n\n\n\n\n\nExercício\n\n\n\nFaça um GLM univariado tendo o THKS pós como VD e os grupos, escolas e classes como variáveis independentes. Coloque as variáveis como efeitos fixos e aleatórios adequadamente conforme a questão anterior. Descreva os resultados encontrados.\n\n\nCaso queira repetir o modelo que o Altay apresentou no vídeo, execute o código abaixo. Assim como no SPSS, no R os valores serão calculados por muito tempo e o modelo não vai convergir.\n\n\n\n\n\n\nPor conta e risco!\n\n\n\n\n\nmodelo1 &lt;- lm(PosTHKS ~ Group * SchoolID * ClassID * PreTHKS, data=dataset)"
  },
  {
    "objectID": "lista_4.html#d-componentes-da-variância-e-icc",
    "href": "lista_4.html#d-componentes-da-variância-e-icc",
    "title": "4  Lista 4 - GMM e ICC",
    "section": "4.5 d) Componentes da variância e ICC",
    "text": "4.5 d) Componentes da variância e ICC\n\n\n\n\n\n\nExercício\n\n\n\nUtilizando o “Variance Components”, verifique se Classe e Escola podem ser considerados fatores aleatórios. Utilize o ICC (Coeficiente de Correlação Intraclasse) como critério para decidir.\n\n\nVamos utilizar a função lmer() do pacote lme4 para criar nossos primeiro modelo com efeitos fixos e aleatórios (modelo 1). Em seguida vamos extrair os componentes da variância dos resultados.\n\nmodelo_1 = lmer(PosTHKS ~ 1 + Group * PreTHKS + # Efeitos fixos\n                  (1|SchoolID:ClassID) + # intercepto aleatório da classe aninhado na escola\n                  (1|SchoolID), # intercepto aleatório apenas da escola\n                data = dataset, \n                REML = TRUE) # Método de estimação dos parâmetros\n\nImportante notar em nosso modelo que os efeitos fixos estão fora dos parênteses, ao passo que os efeitos aleatórios (SchooID e ClassID) estão contidos dentro dos parênteses. Essa estrutura informa à função lmer quais variáveis têm efeitos fixos e quais têm efeitos aleatórios.\nQuanto os métodos de estimação dos parâmetros, não deixe de ler a seção “Section 4.7”\nO primeiro passo para mostrar os componentes da variância é extrair os valores do modelo utilizando a função VarCorr. Vamos guardar a saída da função em um data-frame, tornando a visualização mais acessível. Em seguida, utilizaremos os estimadores de variância desejados no cálculo do ICC.\n\nvar_modelo_1 = as.data.frame(VarCorr(modelo_1))\nvar_modelo_1\n\n               grp        var1 var2       vcov     sdcor\n1 SchoolID:ClassID (Intercept) &lt;NA&gt; 0.06467071 0.2543044\n2         SchoolID (Intercept) &lt;NA&gt; 0.03844644 0.1960776\n3         Residual        &lt;NA&gt; &lt;NA&gt; 1.59946785 1.2647007\n\n\nOs valores que precisamos para calcular o ICC estão na coluna vcov.\nvamos agora armazenar os valores desejados em outras variáveis.\n\nvar_classe_1 = var_modelo_1$vcov[1] # classe\nvar_escola_1 = var_modelo_1$vcov[2] # school\nvar_erro_1 = var_modelo_1$vcov[3] # total\n\nO que fizemos aqui foi acessar o data-frame (comp_var_modelo_1), indicar a coluna que queremos acessar O cifrão ($vcoc) e a linha em que se encontra o valor, indicada pelo número dentra das chaves [].\nTudo o que precisamos fazer agora é calcular o ICC, que se dá pela seguinte fórmula:\n\\[\nICC = \\frac{\\sigma^2_{\\text{entre grupos}}}{\\sigma^2_{\\text{entre grupos}} + \\sigma^2_{\\text{do erro}}}\n\\]\n\nICC Escola (modelo 1)\nVamos primeiro calcular o ICC da Escola.\n\n# ICC Escola\nicc_escola_1 = var_escola_1 / (var_escola_1 + var_erro_1)\nround(icc_escola_1, 3)\n\n[1] 0.023\n\n\nArredondando o valor do cálculo temos que o valor do ICC da escola é de 0,023, ou de aproximadamente 2,3%. Se um valor de 5% fosse estabelecido para considerar uma variabilidade significativa entre os grupos, o ICC de 0,023 seria bastante baixo em relação a esse limiar.\n\n\nICC Classe (modelo 1)\nPara calcular o ICC da classe temos:\n\n# ICC Classe\nicc_class_1 = var_classe_1 / (var_classe_1 + var_erro_1)\nround(icc_class_1, 3)\n\n[1] 0.039\n\n\nAqui também temos um valor de ICC abaixo dos 5%, indicando que, por esse critério, a Classe também não deveria ser considerada como um fator aletaório.\nUma manipulação viável para avaliar o ICC exclusivamente a partir das variáveis que você considera como aleatórias é incluir apenas essas variáveis no modelo, excluindo todas as outras que tenham efeito fixo. Vamos refazer todos os passos anteriores, apenas mudando o modelo (modelo 2).\n\nmodelo_2 = lmer(PosTHKS ~ 1 +\n                  (1|SchoolID:ClassID) +\n                  (1|SchoolID), \n                data = dataset, \n                REML = TRUE) # Método de estimação dos parâmetros\n\n\nvar_modelo_2 = as.data.frame(VarCorr(modelo_2))\nvar_modelo_2\n\n               grp        var1 var2       vcov     sdcor\n1 SchoolID:ClassID (Intercept) &lt;NA&gt; 0.08497895 0.2915115\n2         SchoolID (Intercept) &lt;NA&gt; 0.11659673 0.3414626\n3         Residual        &lt;NA&gt; &lt;NA&gt; 1.72359029 1.3128558\n\n\n\nvar_classe_2 = var_modelo_2$vcov[1] # classe\nvar_escola_2 = var_modelo_2$vcov[2] # escola\nvar_erro_2 = var_modelo_2$vcov[3] # total\n\n\n\nICC Escola (modelo 2)\nCalculando o ICC da escola para o modelo 2 temos\n\n# ICC escola\n\nicc_school_2 = var_escola_2 / (var_escola_2 + var_erro_2)\nround(icc_school_2, 3)\n\n[1] 0.063\n\n\nAgora temos que o ICC da escola é maior que 5%, indicando que a variável é uma boa candidata para ser designada tendo efeito aleatório.\n\n\nICC Classe (modelo 2)\n\n# ICC classe\n\nicc_class_2 = var_classe_2 / (var_classe_2 + var_erro_2)\nround(icc_class_2, 3)\n\n[1] 0.047\n\n\nJá a classe continua com um valor de ICC abaixo dos 5%\n\n\nICC com função\nPodemos utilizar a função multilevel.icc do pacote misty para não precisar calcular na mão o ICC. Digno de nota que a função não aceita efeitos fixos, portanto teremos APENAS o ICC do modelo com efeitos aleatórios. Além disso a função pode assumir 3 tipos:\n\nICC(1) - Mostra quanto da variação ocorre entre os grupos (nível 2) e entre os grupos de grupos (nível 3), que é semelhante ao que calculamos na mão.\n\n\nmultilevel.icc(PosTHKS, # Variável dependente\n               data = dataset, # Banco de dados\n               cluster = c(\"SchoolID\", \"ClassID\")) # Ordem dos clusters importa. Primeiro o L3 e depois o L2\n\n       L3        L2 \n0.0605645 0.0441411 \n\n\n\nICC(1b) - Representa a correlação esperada entre dois elementos escolhidos aleatoriamente no mesmo grupo.\n\n\nmultilevel.icc(PosTHKS, \n               data = dataset, \n               cluster = c(\"SchoolID\", \"ClassID\"),\n               type = \"1b\")\n\n       L3        L2 \n0.0605645 0.1607378 \n\n\n\nICC(2) Indica quão confiáveis são as médias dos grupos (nível 2 e 3). Ou seja, o quão representativas são as médias dos grupos em relação às diferenças individuais dentro desses grupos.\n\n\nmultilevel.icc(PosTHKS, data = dataset, cluster = c(\"SchoolID\", \"ClassID\"),\ntype = \"2\")\n\n       L3        L2 \n0.7092913 0.3688212 \n\n\nNotem que a primeira fórmula apresenta resultado similar ao que calculamos na mão.\n\n\n\n\n\n\nImportante!\n\n\n\nNão existe um conceito fechado de como definir se uma variável deve ser considerada ou não como efeito aleatório. A teoria deve sempre prevalecer sobre os demais critérios.\n\n\nPelo critério teórico, vamos assumir que tanto escola quanto classe terão efeito aleatório em nosso modelo final."
  },
  {
    "objectID": "lista_4.html#e-interpretando-os-resultados",
    "href": "lista_4.html#e-interpretando-os-resultados",
    "title": "4  Lista 4 - GMM e ICC",
    "section": "4.6 e) Interpretando os resultados",
    "text": "4.6 e) Interpretando os resultados\n\n\n\n\n\n\nExercício\n\n\n\nRealize um Modelo Misto Hierárquico (caso os fatores aleatórios sejam relevantes com base em d). Descreva os resultados adequadamente e verifique qual combinação de fatores aleatórios é a mais adequada para explicar a variação dos resultados do THKS (com base no ICC).\n\n\n\nVerificando a referência do Grupo\nPara seguir os passos do vídeo feito pelo Altay no SPSS primeiro temos que ajustar o nível de referência da variável Grupo. No SPSS a referência é o grupo que não fez nada (Neither). Para verificar qual o nível de referência aqui no R vamos utilizar a função levels().\n\nlevels(dataset$Group)\n\n[1] \"Curriculum & TV\" \"Curriculum\"      \"TV\"              \"Neither\"        \n\n\nO nível de referência é sempre primeiro que aparece na lista, no caso “Curriculum & TV”.\nVamos mudar para que a referência seja “Neither”, utilizando a função relevel.\n\ndataset$Group &lt;- relevel(dataset$Group, ref = \"Neither\")\nlevels(dataset$Group)\n\n[1] \"Neither\"         \"Curriculum & TV\" \"Curriculum\"      \"TV\"             \n\n\nAgora sim podemos seguir com nossa análise.\n\n\nCriando o modelo\nAo contrário do SPSS, não enfrentaremos problemas de convergência em nossos modelos se a matriz de covariância não for modificada. Para demonstrar que alterar a matriz de covariância não afeta significativamente os coeficientes, podemos criar dois modelos para verificação:\n\na) modelo com matriz de covariância simétrica;\nb) modelo com matriz de covariância diagonal (padrão caso não definamos explicitamente a matriz).\n\nA função lmer() não oferece uma maneira direta de modificar a matriz de covariância. Portanto, da mesma forma que fizemos na Lista de Exercícios 3, vamos utilizar a função lme().\n\n# Modelo a)\nmodelo_a = lme(\n  fixed = PosTHKS ~ 1 + PreTHKS + Group, \n  random =~ 1|SchoolID/ClassID,\n  correlation = corCompSymm(form = ~1|SchoolID/ClassID), # Aqui definimos a matriz simétrica\n  data = dataset, \n  method = \"REML\")\n\n# Armazenando os valores dos coeficientes do modelo a) em uma variável\ncoef_a = modelo_a$coefficients$fixed\n\n# Modelo b)\nmodelo_b = lme(\n  fixed = PosTHKS ~ 1 + PreTHKS + Group, \n  random =~ 1|SchoolID/ClassID,\n  data = dataset, \n  method = \"REML\") # Matriz diagonal por padrão\n\n# Armazenando os valores dos coeficientes do modelo b) em uma variável\ncoef_b = modelo_b$coefficients$fixed\n\n\n# Criar um dataframe\ndf_coeficientes &lt;- data.frame(Modelo_a = coef_a,\n                              Modelo_b = coef_b)\ndf_coeficientes\n\n                      Modelo_a  Modelo_b\n(Intercept)          1.7019847 1.7019852\nPreTHKS              0.3053629 0.3053628\nGroupCurriculum & TV 0.4924670 0.4924662\nGroupCurriculum      0.6413248 0.6413260\nGroupTV              0.1820783 0.1820802\n\n\nPodemos observar que os valores mudam apenas depois da 3 casa após a vírgula. Portanto podemos construir os modelos sem alterar a matriz de covariância neste caso específico.\n\nVamos ao modelo:\n\nmodelo_3 = lme(\n  fixed = PosTHKS ~ 1 + PreTHKS + Group, \n  random =~ 1|SchoolID/ClassID,\n  data = dataset, \n  method = \"REML\")\n\n# Escolhi utilizar o lme() por ele apresentar mais resultados na saída da função anova()\n\n\n\nICC do modelo\nNão encontramos uma maneira fácil de mostrar o ICC para modelos de 3 níveis com variáveis independentes fixas. Por isso mostramos como calcular na mão o ICC anteriormente. Podemos acessar os valores de variância do modelo com a seguinte função:\n\nkable(VarCorr(modelo_3)) # O kable é só pra deixar com um visual melhor a saída.\n\n\n\n\n\nVariance\nStdDev\n\n\n\n\nSchoolID =\npdLogChol(1)\n\n\n\n(Intercept)\n0.03864002\n0.1965706\n\n\nClassID =\npdLogChol(1)\n\n\n\n(Intercept)\n0.06466151\n0.2542863\n\n\nResidual\n1.60229394\n1.2658175\n\n\n\n\n\n\n\nAgora queremos acessar cada variância separadamente. Para isso executamos o scritp a seguir.\n\nvar_escola = VarCorr(modelo_3)[2] # Variancia da Escola\n\nvar_classe = VarCorr(modelo_3)[4] # Variancia da Classe\n\nvar_res = VarCorr(modelo_3)[5] # Variancia do resíduo\n\nSe você tentar fazer contas com essas variáveis vai notar algo bem estranho\n\nvar_classe + var_res\n\nIsso acontece porque elas saíram como caracteres (símbolos, letras…) e não como números!\n\ntypeof(var_classe)\n\n[1] \"character\"\n\n\nVamos resolver isso transformando elas para números\n\nvar_escola = as.numeric(var_escola)\nvar_classe = as.numeric(var_classe)\nvar_res = as.numeric(var_res)\n\nAgora sim!\n\ntypeof(var_escola)\n\n[1] \"double\"\n\n\nCalculando o ICC da Escola temos:\n\nvar_escola/(var_escola+var_res) #ICC da escola\n\n[1] 0.02354758\n\n\nICC da classe:\n\nvar_classe/(var_classe+var_res)\n\n[1] 0.03879018\n\n\n\n\nPressupostos do modelo\nComo já vimos, parte importante de analisar os modelos é verificar os pressupostos. Não entraremos em detalhes, vamos apenas vislumbrar quandos todos os pressupostos são atendidos! O melhor de tudo, usando apenas 3 palavras na linha de código, graças à função check_model().\n\ncheck_model(modelo_3)\n\nConverting missing values (`NA`) into regular values currently not\n  possible for variables of class `NULL`.\n\n\n\n\n\nQue beleza, não? Resíduos normais, baixa colinearidade e ótima linearidade do modelo! Podemos interpretar os resultados com tranquilidade!\n\n\nResultados\nVamos verificar se o efeito do grupo é significante, que é a principal variável dependente do nosso modelo. Para isso podemos utilizar a função anova() que é muito versátil para diversas ocasiões.\n\nkable(anova(modelo_3)) #função kable apenas para deixar mais bonita a tabela\n\n\n\n\n\nnumDF\ndenDF\nF-value\np-value\n\n\n\n\n(Intercept)\n1\n1464\n2240.036555\n0.0000000\n\n\nPreTHKS\n1\n1464\n136.795261\n0.0000000\n\n\nGroup\n3\n24\n6.610438\n0.0020567\n\n\n\n\n\n\n\nBoa! Descobrimos que o efeito do grupo é significativo. Agora precisamos saber entre quais grupos está a diferença e de quanto ela é.\nPara tanto vamos utilizar mais uma vez a função summary().\n\nsummary(modelo_3)\n\nLinear mixed-effects model fit by REML\n  Data: dataset \n       AIC      BIC    logLik\n  5389.335 5432.332 -2686.668\n\nRandom effects:\n Formula: ~1 | SchoolID\n        (Intercept)\nStdDev:   0.1965706\n\n Formula: ~1 | ClassID %in% SchoolID\n        (Intercept) Residual\nStdDev:   0.2542863 1.265817\n\nFixed effects:  PosTHKS ~ 1 + PreTHKS + Group \n                         Value  Std.Error   DF   t-value p-value\n(Intercept)          1.7019852 0.12543004 1464 13.569199  0.0000\nPreTHKS              0.3053628 0.02589132 1464 11.794021  0.0000\nGroupCurriculum & TV 0.4924662 0.15864165   24  3.104268  0.0048\nGroupCurriculum      0.6413260 0.16094729   24  3.984696  0.0005\nGroupTV              0.1820802 0.15724054   24  1.157972  0.2583\n Correlation: \n                     (Intr) PrTHKS GrC&TV GrpCrr\nPreTHKS              -0.442                     \nGroupCurriculum & TV -0.649  0.029              \nGroupCurriculum      -0.634  0.015  0.496       \nGroupTV              -0.645  0.008  0.508  0.501\n\nStandardized Within-Group Residuals:\n        Min          Q1         Med          Q3         Max \n-2.49874557 -0.69757194 -0.01721254  0.68240735  3.14602049 \n\nNumber of Observations: 1600\nNumber of Groups: \n             SchoolID ClassID %in% SchoolID \n                   28                   135 \n\n\nComo vocês já podem ter percebido as saídas da função summary() no R não geram as saídas mais fáceis de interpretar, como podemos ver no exemplo abaixo.\nAgora que você enfrentou a busca nos detalhes desse fascinante output gerado pela função summary, é com satisfação que compartilhamos a boa notícia de que muitos desenvolvedores compartilham da sua experiência e criaram vários pacotes para aprimorar a visualização dos resultados. Ao longo dos exercícios, apresentaremos algumas abordagens para alcançar isso. No final da seção de modelos lineares, você encontrará um glossário que ajudará na geração de outputs mais amigáveis e formatados para publicações acadêmicas.\nPor hora, vamos compartilhar uma abordagem mais “na mão” para melhorar a visualização dos resultados, para caso algum pacote não atenda completamente às suas necessidades.\n\n# Resumo do modelo\n\nresumo_modelo &lt;- summary(modelo_3)\n\n# Extração de estimadores, intervalos de confiança e p-valores\n\ncoeficientes &lt;- resumo_modelo$coefficients$fixed # essa linha varia muito dependendo do modelo\nintervalos_confianca &lt;- intervals(modelo_3, which = \"fixed\") # Função `confint()` pode ser utilizadas para outros modelos\np_valores &lt;- resumo_modelo$tTable[, \"p-value\"]\n\n# Criar um data frame\n\nresultados_modelo &lt;- data.frame(\n  Estimador = round(coeficientes, 3),\n  IC_Inf = round(intervalos_confianca$fixed[, 1], 3),\n  IC_Sup = round(intervalos_confianca$fixed[, 2], 3),\n  p = round(p_valores, 3)\n)\n\n# Apresentando os resultados\nkable(resultados_modelo)\n\n\n\n\n\nEstimador\nIC_Inf\nIC_Sup\np\n\n\n\n\n(Intercept)\n1.702\n1.456\n1.702\n0.000\n\n\nPreTHKS\n0.305\n0.255\n0.305\n0.000\n\n\nGroupCurriculum & TV\n0.492\n0.165\n0.492\n0.005\n\n\nGroupCurriculum\n0.641\n0.309\n0.641\n0.001\n\n\nGroupTV\n0.182\n-0.142\n0.182\n0.258\n\n\n\n\n\n\n\n\nMelhorou um pouco né? Achou muito trabalhoso??\nQue tal fazer tudo em uma linha de código e ainda com correção de Bonferroni!?\n\nemmeans(modelo_3, pairwise ~ Group, adjust = \"bonferroni\") # por padrão temos a correção de Tukey\n\n$emmeans\n Group           emmean    SE df lower.CL upper.CL\n Neither           2.33 0.113 27     2.10     2.56\n Curriculum & TV   2.83 0.112 24     2.60     3.06\n Curriculum        2.98 0.115 24     2.74     3.21\n TV                2.52 0.110 24     2.29     2.74\n\nDegrees-of-freedom method: containment \nConfidence level used: 0.95 \n\n$contrasts\n contrast                     estimate    SE df t.ratio p.value\n Neither - Curriculum & TV      -0.492 0.159 24  -3.104  0.0290\n Neither - Curriculum           -0.641 0.161 24  -3.985  0.0033\n Neither - TV                   -0.182 0.157 24  -1.158  1.0000\n Curriculum & TV - Curriculum   -0.149 0.160 24  -0.928  1.0000\n Curriculum & TV - TV            0.310 0.157 24   1.981  0.3550\n Curriculum - TV                 0.459 0.159 24   2.888  0.0485\n\nDegrees-of-freedom method: containment \nP value adjustment: bonferroni method for 6 tests \n\n\nOs valores estão negativos porque ajustamos o nível de referência da variável Group para “Neither”. No resultado temos que “Curriculum” apresenta a maior média geral. Logo seria interessante deixá-lo como variável de referência, caso queira que seus estimadores fiquem positivo. Já vimos como fazer isso anteriormente!\nTente modificar a referência para “Curriculum”, mas CUIDADO! Não se esqueça de criar o modelo novamente, caso contrário os resultados ficarão errados!\nPara acessar apenas os resultados de contraste podemos fazer o seguinte:\n\nemmeans(modelo_3, pairwise ~ Group, adjust = \"bonferroni\")$contrasts\n\n contrast                     estimate    SE df t.ratio p.value\n Neither - Curriculum & TV      -0.492 0.159 24  -3.104  0.0290\n Neither - Curriculum           -0.641 0.161 24  -3.985  0.0033\n Neither - TV                   -0.182 0.157 24  -1.158  1.0000\n Curriculum & TV - Curriculum   -0.149 0.160 24  -0.928  1.0000\n Curriculum & TV - TV            0.310 0.157 24   1.981  0.3550\n Curriculum - TV                 0.459 0.159 24   2.888  0.0485\n\nDegrees-of-freedom method: containment \nP value adjustment: bonferroni method for 6 tests"
  },
  {
    "objectID": "lista_4.html#sec-extras",
    "href": "lista_4.html#sec-extras",
    "title": "4  Lista 4 - GMM e ICC",
    "section": "4.7 Extras!",
    "text": "4.7 Extras!\n\nMétodos de estimação dos parâmetros do modelo\nO REML (Residual Maximum Likelihood) e o ML (Maximum Likelihood) são duas abordagens distintas para a estimação de parâmetros em modelos de regressão linear mista (ou modelos hierárquicos). Ambas são baseadas no método da máxima verossimilhança, mas diferem na maneira como tratam os graus de liberdade.\nMaximum Likelihood (ML):\nNa abordagem ML, o foco é maximizar a verossimilhança do modelo, considerando tanto os efeitos fixos quanto os efeitos aleatórios. O ML leva em conta todos os parâmetros do modelo para maximizar a probabilidade de observar os dados dados os parâmetros. É mais adequado quando o interesse principal é fazer inferências sobre os parâmetros fixos do modelo.\nResidual Maximum Likelihood (REML):\nA abordagem REML é uma variação do ML que remove os efeitos fixos do modelo antes de calcular a verossimilhança. O REML estima a verossimilhança condicional dos efeitos aleatórios, removendo a contribuição dos efeitos fixos. Ele tende a ser mais eficiente na estimação dos efeitos aleatórios, especialmente em amostras pequenas, e fornece estimativas menos enviesadas para a variância dos efeitos aleatórios. O REML é frequentemente preferido quando o foco está na estimação dos parâmetros aleatórios e quando a inferência sobre os parâmetros fixos não é o objetivo principal.\n\n\nExtraindo valores de summary\nPodemos extrair diversos valores individualmente da função summary().\n\n\nTamanho da classe importa?\n\ntheme_set(theme_bw(base_size = 7, base_family = \"\")) \n\nggplot(data = dataset, aes(x = Tamanho_Classe, y=PosTHKS))+\n  facet_grid(~SchoolID)+\n  coord_cartesian(ylim=c(0,30))+\n  geom_point()+\n  geom_smooth(method = \"lm\", se = TRUE)+\n  xlab(\"Tamanho da Classe\")+ylab(\"PosTHKS\")+\n  theme(legend.position = \"top\")\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\nPlot.Means&lt;-dataset %&gt;% group_by(SchoolID) %&gt;%  \n  dplyr::summarize(PosTHKSM = mean(PosTHKS, na.rm=TRUE),\n                   Tamanho_CLasseM=mean(Tamanho_Classe, na.rm=TRUE))\n\n\n\nggplot(data = Plot.Means, aes(x = reorder(SchoolID, -PosTHKSM), y=PosTHKSM))+\n  geom_point(aes(size = Tamanho_CLasseM))+\n  xlab(\"\")+ylab(\"PosTHKS\")+\n  theme_bw()+\n  theme(legend.position = \"top\")\n\n\n\n\n\n\nComparando modelos\nPodemos comparar diversos modelos utilizando a função model.comparison() do pacote flexplot.\n\nmodel.comparison(modelo_1, modelo_2)\n\nrefitting model(s) with ML (instead of REML)\n\n\n$statistics\n              aic      bic bayes.factor      p\nmodelo_1 5400.422 5459.578 2.090546e+16 &lt;2e-16\nmodelo_2 5513.224 5534.735 0.000000e+00       \n\n$predicted_differences\n   0%   25%   50%   75%  100% \n0.001 0.113 0.243 0.436 1.310 \n\n$r_squared_change\n   Residual (Intercept) (Intercept) \n 0.07201389  0.67026142  0.23897964 \n\n# O modelo 1 apresenta melhores resultados\n\n\n\nPlot do modelo\nCriando um gráfico com os coeficientes gerados pelo modelo.\n\n# Com a correção de Bonferroni\nresults_modelo_3 = emmeans(modelo_3, pairwise ~ Group, adjust = \"bonferroni\")\n\n\nggplot(as.data.frame(results_modelo_3$emmeans), aes(x = Group, y = emmean, color = Group)) +\n  geom_errorbar(aes(ymin = lower.CL, ymax = upper.CL), width = 0.2, position = position_dodge(0.8)) +\n  geom_point(position = position_dodge(0.8), size = 3) +\n  labs(title = \"Distribuição normal\",\n       x = \"Tratamento\",\n       y = \"THKS\") +\n  theme_minimal() +\n  theme(legend.position = \"none\") \n\n\n\n\n\n\nFunção para calcular o ICC\nCaso você queira calcular o ICC para diferentes modelos de 3 níveis, sugiro criar uma função que faça o trabalho repetitivo ao invés de ficar calculando tudo sempre na mão.\n\n\n\n\n\n\nImportante\n\n\n\nFunciona apenas para modelos gerados pela função lme().\n\n\n\n# Criando minha própria função\n\nicc_lme_3nv = function(modelo) {\n  # Extração da variância entre grupos e total\n  var_escola = as.numeric(VarCorr(modelo)[2])\n  var_classe = as.numeric(VarCorr(modelo)[4])\n  var_total = as.numeric(VarCorr(modelo)[5])\n\n  # Cálculo do ICC\n  icc_escola = var_escola/(var_escola+var_res)\n  icc_classe = var_classe/(var_classe+var_res)\n  \n  # Retorna o valor do ICC \n  return(list(\"ICC-Escola\" = icc_escola, \"ICC-Classe\" = icc_classe))\n}\n\n# Uso\n# icc_lme_3nv(modelo) - basta substitui \"modelo\" pelo nome da variável que você escolheu para salvar seu modelo."
  },
  {
    "objectID": "lista_4.html#observações",
    "href": "lista_4.html#observações",
    "title": "4  Lista 4 - GMM e ICC",
    "section": "4.8 Observações",
    "text": "4.8 Observações\nTreine criar mais modelos multinível, inclusive com apenas 2 níveis. Inclusive, se for utilzar a função lmer(), MUITO CUIDADO!\nEste modelo:\n\nmodelo_5b = lmer(PosTHKS ~ 1 + Group +\n                   (1|SchoolID:ClassID),\n                 dataset,\n                 REML = TRUE)\n\nÉ diferente deste modelo:\n\nmodelo_5b = lmer(PosTHKS ~ 1 + Group +\n                   (1|SchoolID) + # Escola como efeito aleatório\n                   (1|SchoolID:ClassID), # Classe como efeito aleatório\n                 dataset,\n                 REML = TRUE)\n\nCom a função lmer() precisamos indicar no modelo que queremos Escola e Classe como efeito aleatórios em linhas separadas!"
  },
  {
    "objectID": "lista_4.html#lista-4-resolvida-no-spss",
    "href": "lista_4.html#lista-4-resolvida-no-spss",
    "title": "4  Lista 4 - GMM e ICC",
    "section": "4.9 Lista 4 resolvida no SPSS",
    "text": "4.9 Lista 4 resolvida no SPSS"
  },
  {
    "objectID": "lista_4.html#referências",
    "href": "lista_4.html#referências",
    "title": "4  Lista 4 - GMM e ICC",
    "section": "4.10 Referências",
    "text": "4.10 Referências\nhttps://lmudge13.github.io/sample_code/mixed_effects.html # Tabelas e gráficos de modelos lme\nhttps://rpsychologist.com/r-guide-longitudinal-lme-lmer#three-level-models\nhttps://search.r-project.org/CRAN/refmans/misty/html/multilevel.icc.html\nhttps://www.rdocumentation.org/packages/psychometric/versions/2.4/topics/ICC.lme\nhttps://www.alexanderdemos.org/Mixed5.html\nhttps://cran.r-project.org/web/packages/rempsyc/vignettes/assumptions.html#categorical-predictors # pressupostos dos modelos com variáveis categóricas como preditoras."
  },
  {
    "objectID": "lista_4.html#versões-dos-pacotes",
    "href": "lista_4.html#versões-dos-pacotes",
    "title": "4  Lista 4 - GMM e ICC",
    "section": "4.11 Versões dos pacotes",
    "text": "4.11 Versões dos pacotes\n\nreport(sessionInfo())\n\nAnalyses were conducted using the R Statistical language (version 4.3.1; R Core\nTeam, 2023) on Windows 11 x64 (build 22621), using the packages lme4 (version\n1.1.34; Bates D et al., 2015), Matrix (version 1.6.0; Bates D et al., 2023),\neffectsize (version 0.8.6; Ben-Shachar MS et al., 2020), multilevel (version\n2.7; Bliese P, 2022), fitdistrplus (version 1.1.11; Delignette-Muller ML,\nDutang C, 2015), tm (version 0.7.11; Feinerer I, Hornik K, 2023), flexplot\n(version 0.20.5; Fife D, 2024), psychometric (version 2.4; Fletcher TD, 2023),\neffects (version 4.2.2; Fox J, Weisberg S, 2019), carData (version 3.0.5; Fox J\net al., 2022), mvtnorm (version 1.2.3; Genz A, Bretz F, 2009), NLP (version\n0.2.1; Hornik K, 2020), TH.data (version 1.1.2; Hothorn T, 2023), multcomp\n(version 1.4.25; Hothorn T et al., 2008), emmeans (version 1.8.8; Lenth R,\n2023), sjstats (version 0.18.2; Lüdecke D, 2022), sjPlot (version 2.8.15;\nLüdecke D, 2023), parameters (version 0.21.3; Lüdecke D et al., 2020),\nperformance (version 0.10.8; Lüdecke D et al., 2021), easystats (version 0.6.0;\nLüdecke D et al., 2022), see (version 0.8.1; Lüdecke D et al., 2021), insight\n(version 0.19.6; Lüdecke D et al., 2019), bayestestR (version 0.13.1; Makowski\nD et al., 2019), modelbased (version 0.8.6; Makowski D et al., 2020), report\n(version 0.5.7; Makowski D et al., 2023), correlation (version 0.8.4; Makowski\nD et al., 2022), datawizard (version 0.9.0; Patil I et al., 2022), nlme\n(version 3.1.163; Pinheiro J et al., 2023), foreign (version 0.8.85; R Core\nTeam, 2023), rempsyc (version 0.1.6; Thériault R, 2023), survival (version\n3.5.7; Therneau T, 2023), MASS (version 7.3.60; Venables WN, Ripley BD, 2002),\nggplot2 (version 3.4.4; Wickham H, 2016), forcats (version 1.0.0; Wickham H,\n2023), dplyr (version 1.1.3; Wickham H et al., 2023), purrr (version 1.0.2;\nWickham H, Henry L, 2023), misty (version 0.6.1; Yanagida T, 2024) and\nkableExtra (version 1.3.4; Zhu H, 2021).\n\nReferences\n----------\n  - Bates D, Mächler M, Bolker B, Walker S (2015). \"Fitting Linear Mixed-Effects\nModels Using lme4.\" _Journal of Statistical Software_, *67*(1), 1-48.\ndoi:10.18637/jss.v067.i01 &lt;https://doi.org/10.18637/jss.v067.i01&gt;.\n  - Bates D, Maechler M, Jagan M (2023). _Matrix: Sparse and Dense Matrix Classes\nand Methods_. R package version 1.6-0,\n&lt;https://CRAN.R-project.org/package=Matrix&gt;.\n  - Ben-Shachar MS, Lüdecke D, Makowski D (2020). \"effectsize: Estimation of\nEffect Size Indices and Standardized Parameters.\" _Journal of Open Source\nSoftware_, *5*(56), 2815. doi:10.21105/joss.02815\n&lt;https://doi.org/10.21105/joss.02815&gt;, &lt;https://doi.org/10.21105/joss.02815&gt;.\n  - Bliese P (2022). _multilevel: Multilevel Functions_. R package version 2.7,\n&lt;https://CRAN.R-project.org/package=multilevel&gt;.\n  - Delignette-Muller ML, Dutang C (2015). \"fitdistrplus: An R Package for\nFitting Distributions.\" _Journal of Statistical Software_, *64*(4), 1-34.\ndoi:10.18637/jss.v064.i04 &lt;https://doi.org/10.18637/jss.v064.i04&gt;.\n  - Feinerer I, Hornik K (2023). _tm: Text Mining Package_. R package version\n0.7-11, &lt;https://CRAN.R-project.org/package=tm&gt;. Feinerer I, Hornik K, Meyer D\n(2008). \"Text Mining Infrastructure in R.\" _Journal of Statistical Software_,\n*25*(5), 1-54. doi:10.18637/jss.v025.i05\n&lt;https://doi.org/10.18637/jss.v025.i05&gt;.\n  - Fife D (2024). _flexplot: Graphically Based Data Analysis Using 'flexplot'_.\nR package version 0.20.5.\n  - Fletcher TD (2023). _psychometric: Applied Psychometric Theory_. R package\nversion 2.4, &lt;https://CRAN.R-project.org/package=psychometric&gt;.\n  - Fox J, Weisberg S (2019). _An R Companion to Applied Regression_, 3rd\nedition. Sage, Thousand Oaks CA.\n&lt;https://socialsciences.mcmaster.ca/jfox/Books/Companion/index.html&gt;. Fox J,\nWeisberg S (2018). \"Visualizing Fit and Lack of Fit in Complex Regression\nModels with Predictor Effect Plots and Partial Residuals.\" _Journal of\nStatistical Software_, *87*(9), 1-27. doi:10.18637/jss.v087.i09\n&lt;https://doi.org/10.18637/jss.v087.i09&gt;. Fox J (2003). \"Effect Displays in R\nfor Generalised Linear Models.\" _Journal of Statistical Software_, *8*(15),\n1-27. doi:10.18637/jss.v008.i15 &lt;https://doi.org/10.18637/jss.v008.i15&gt;. Fox J,\nHong J (2009). \"Effect Displays in R for Multinomial and Proportional-Odds\nLogit Models: Extensions to the effects Package.\" _Journal of Statistical\nSoftware_, *32*(1), 1-24. doi:10.18637/jss.v032.i01\n&lt;https://doi.org/10.18637/jss.v032.i01&gt;.\n  - Fox J, Weisberg S, Price B (2022). _carData: Companion to Applied Regression\nData Sets_. R package version 3.0-5,\n&lt;https://CRAN.R-project.org/package=carData&gt;.\n  - Genz A, Bretz F (2009). _Computation of Multivariate Normal and t\nProbabilities_, series Lecture Notes in Statistics. Springer-Verlag,\nHeidelberg. ISBN 978-3-642-01688-2.\n  - Hornik K (2020). _NLP: Natural Language Processing Infrastructure_. R package\nversion 0.2-1, &lt;https://CRAN.R-project.org/package=NLP&gt;.\n  - Hothorn T (2023). _TH.data: TH's Data Archive_. R package version 1.1-2,\n&lt;https://CRAN.R-project.org/package=TH.data&gt;.\n  - Hothorn T, Bretz F, Westfall P (2008). \"Simultaneous Inference in General\nParametric Models.\" _Biometrical Journal_, *50*(3), 346-363.\n  - Lenth R (2023). _emmeans: Estimated Marginal Means, aka Least-Squares Means_.\nR package version 1.8.8, &lt;https://CRAN.R-project.org/package=emmeans&gt;.\n  - Lüdecke D (2022). _sjstats: Statistical Functions for Regression Models\n(Version 0.18.2)_. doi:10.5281/zenodo.1284472\n&lt;https://doi.org/10.5281/zenodo.1284472&gt;,\n&lt;https://CRAN.R-project.org/package=sjstats&gt;.\n  - Lüdecke D (2023). _sjPlot: Data Visualization for Statistics in Social\nScience_. R package version 2.8.15,\n&lt;https://CRAN.R-project.org/package=sjPlot&gt;.\n  - Lüdecke D, Ben-Shachar M, Patil I, Makowski D (2020). \"Extracting, Computing\nand Exploring the Parameters of Statistical Models using R.\" _Journal of Open\nSource Software_, *5*(53), 2445. doi:10.21105/joss.02445\n&lt;https://doi.org/10.21105/joss.02445&gt;.\n  - Lüdecke D, Ben-Shachar M, Patil I, Waggoner P, Makowski D (2021).\n\"performance: An R Package for Assessment, Comparison and Testing of\nStatistical Models.\" _Journal of Open Source Software_, *6*(60), 3139.\ndoi:10.21105/joss.03139 &lt;https://doi.org/10.21105/joss.03139&gt;.\n  - Lüdecke D, Ben-Shachar M, Patil I, Wiernik B, Makowski D (2022). \"easystats:\nFramework for Easy Statistical Modeling, Visualization, and Reporting.\" _CRAN_.\nR package, &lt;https://easystats.github.io/easystats/&gt;.\n  - Lüdecke D, Patil I, Ben-Shachar M, Wiernik B, Waggoner P, Makowski D (2021).\n\"see: An R Package for Visualizing Statistical Models.\" _Journal of Open Source\nSoftware_, *6*(64), 3393. doi:10.21105/joss.03393\n&lt;https://doi.org/10.21105/joss.03393&gt;.\n  - Lüdecke D, Waggoner P, Makowski D (2019). \"insight: A Unified Interface to\nAccess Information from Model Objects in R.\" _Journal of Open Source Software_,\n*4*(38), 1412. doi:10.21105/joss.01412 &lt;https://doi.org/10.21105/joss.01412&gt;.\n  - Makowski D, Ben-Shachar M, Lüdecke D (2019). \"bayestestR: Describing Effects\nand their Uncertainty, Existence and Significance within the Bayesian\nFramework.\" _Journal of Open Source Software_, *4*(40), 1541.\ndoi:10.21105/joss.01541 &lt;https://doi.org/10.21105/joss.01541&gt;,\n&lt;https://joss.theoj.org/papers/10.21105/joss.01541&gt;.\n  - Makowski D, Ben-Shachar M, Patil I, Lüdecke D (2020). \"Estimation of\nModel-Based Predictions, Contrasts and Means.\" _CRAN_.\n&lt;https://github.com/easystats/modelbased&gt;.\n  - Makowski D, Lüdecke D, Patil I, Thériault R, Ben-Shachar M, Wiernik B (2023).\n\"Automated Results Reporting as a Practical Tool to Improve Reproducibility and\nMethodological Best Practices Adoption.\" _CRAN_.\n&lt;https://easystats.github.io/report/&gt;.\n  - Makowski D, Wiernik B, Patil I, Lüdecke D, Ben-Shachar M (2022).\n\"correlation: Methods for Correlation Analysis.\" Version 0.8.3,\n&lt;https://CRAN.R-project.org/package=correlation&gt;. Makowski D, Ben-Shachar M,\nPatil I, Lüdecke D (2020). \"Methods and Algorithms for Correlation Analysis in\nR.\" _Journal of Open Source Software_, *5*(51), 2306. doi:10.21105/joss.02306\n&lt;https://doi.org/10.21105/joss.02306&gt;,\n&lt;https://joss.theoj.org/papers/10.21105/joss.02306&gt;.\n  - Patil I, Makowski D, Ben-Shachar M, Wiernik B, Bacher E, Lüdecke D (2022).\n\"datawizard: An R Package for Easy Data Preparation and Statistical\nTransformations.\" _Journal of Open Source Software_, *7*(78), 4684.\ndoi:10.21105/joss.04684 &lt;https://doi.org/10.21105/joss.04684&gt;.\n  - Pinheiro J, Bates D, R Core Team (2023). _nlme: Linear and Nonlinear Mixed\nEffects Models_. R package version 3.1-163,\n&lt;https://CRAN.R-project.org/package=nlme&gt;. Pinheiro JC, Bates DM (2000).\n_Mixed-Effects Models in S and S-PLUS_. Springer, New York. doi:10.1007/b98882\n&lt;https://doi.org/10.1007/b98882&gt;.\n  - R Core Team (2023). _foreign: Read Data Stored by 'Minitab', 'S', 'SAS',\n'SPSS', 'Stata', 'Systat', 'Weka', 'dBase', ..._. R package version 0.8-85,\n&lt;https://CRAN.R-project.org/package=foreign&gt;.\n  - R Core Team (2023). _R: A Language and Environment for Statistical\nComputing_. R Foundation for Statistical Computing, Vienna, Austria.\n&lt;https://www.R-project.org/&gt;.\n  - Thériault R (2023). \"rempsyc: Convenience functions for psychology.\" _Journal\nof Open Source Software_, *8*(87), 5466. doi:10.21105/joss.05466\n&lt;https://doi.org/10.21105/joss.05466&gt;, &lt;https://doi.org/10.21105/joss.05466&gt;.\n  - Therneau T (2023). _A Package for Survival Analysis in R_. R package version\n3.5-7, &lt;https://CRAN.R-project.org/package=survival&gt;. Terry M. Therneau,\nPatricia M. Grambsch (2000). _Modeling Survival Data: Extending the Cox Model_.\nSpringer, New York. ISBN 0-387-98784-3.\n  - Venables WN, Ripley BD (2002). _Modern Applied Statistics with S_, Fourth\nedition. Springer, New York. ISBN 0-387-95457-0,\n&lt;https://www.stats.ox.ac.uk/pub/MASS4/&gt;.\n  - Wickham H (2016). _ggplot2: Elegant Graphics for Data Analysis_.\nSpringer-Verlag New York. ISBN 978-3-319-24277-4,\n&lt;https://ggplot2.tidyverse.org&gt;.\n  - Wickham H (2023). _forcats: Tools for Working with Categorical Variables\n(Factors)_. R package version 1.0.0,\n&lt;https://CRAN.R-project.org/package=forcats&gt;.\n  - Wickham H, François R, Henry L, Müller K, Vaughan D (2023). _dplyr: A Grammar\nof Data Manipulation_. R package version 1.1.3,\n&lt;https://CRAN.R-project.org/package=dplyr&gt;.\n  - Wickham H, Henry L (2023). _purrr: Functional Programming Tools_. R package\nversion 1.0.2, &lt;https://CRAN.R-project.org/package=purrr&gt;.\n  - Yanagida T (2024). _misty: Miscellaneous Functions 'T. Yanagida'_. R package\nversion 0.6.1, &lt;https://CRAN.R-project.org/package=misty&gt;.\n  - Zhu H (2021). _kableExtra: Construct Complex Table with 'kable' and Pipe\nSyntax_. R package version 1.3.4,\n&lt;https://CRAN.R-project.org/package=kableExtra&gt;."
  },
  {
    "objectID": "lista_5.html#carregando-os-dados-e-modificando-o-tipo-de-variável",
    "href": "lista_5.html#carregando-os-dados-e-modificando-o-tipo-de-variável",
    "title": "5  Lista 5 - Generalized Linear Model Aula Prática",
    "section": "5.1 Carregando os dados e modificando o tipo de variável",
    "text": "5.1 Carregando os dados e modificando o tipo de variável\n\noriginal = read.spss(\"Dados Amostra.sav\", to.data.frame=TRUE)"
  },
  {
    "objectID": "lista_5.html#boas-práticas",
    "href": "lista_5.html#boas-práticas",
    "title": "5  Lista 5 - Generalized Linear Model Aula Prática",
    "section": "5.2 Boas práticas",
    "text": "5.2 Boas práticas\nTer um clone do banco de dados e manter ele no formato original. Podemos ir comparando todas as mudanças de maneira ágil. Vamos também já verificar os tipos de variáveis que temos no banco de dados e realizar mudanças, caso necessário.\n\ndb = original\nkable(head(db))\n\n\n\n\nid\nchilds\nage\neduc\nsex\nlife\ntvhours\nattsprts\ntempo_obs\naderencia\n\n\n\n\n188\n2\n76\n14\nFemale\nRoutine\n5\nNA\n123\nSIM\n\n\n730\n2\n48\n12\nFemale\nRoutine\n1\nNA\n424\nSIM\n\n\n855\n0\n19\n13\nMale\nExciting\n1\nNA\n124\nSIM\n\n\n866\n0\n38\n16\nFemale\nExciting\nNA\nNA\n500\nSIM\n\n\n1165\n3\n54\n16\nFemale\nNA\n3\nNA\n500\nSIM\n\n\n1225\n2\n53\nNA\nFemale\nDull\n4\nNA\n500\nSIM\n\n\n\n\n\n\n\nNão queremos que o número de filhos (childs), idade (age), nível escolaridade (educ) e horas de TV (tvhours) sejam categóricas. Vamos alterar para que sejam numéricas com a função as.numeric().\n\n# Modificando o tipo das variáveis. Apenas Life, Sex, attsprts e aderencia devem ser categóricas.\ndb$childs = as.integer(db$childs)\ndb$age = as.numeric(db$age)\ndb$educ = as.numeric(db$educ)\ndb$tvhours = as.numeric(db$tvhours)\n\nObservando como elas estão agora, podemos também utilizar a função glimpse().\n\nglimpse(db)\n\nRows: 1,500\nColumns: 10\n$ id        &lt;dbl&gt; 188, 730, 855, 866, 1165, 1225, 1294, 1339, 1343, 168, 1390,…\n$ childs    &lt;int&gt; 3, 3, 1, 1, 4, 3, 4, NA, NA, 1, 3, 2, 1, 1, 1, 3, 1, 2, 5, 4…\n$ age       &lt;dbl&gt; 59, 31, 2, 21, 37, 36, 48, 35, 55, 65, 38, 26, 27, 26, 28, 6…\n$ educ      &lt;dbl&gt; 13, 11, 12, 15, 15, NA, 11, 11, 8, 14, 11, 10, 15, 15, 14, 1…\n$ sex       &lt;fct&gt; Female, Female, Male, Female, Female, Female, Male, Female, …\n$ life      &lt;fct&gt; Routine, Routine, Exciting, Exciting, NA, Dull, NA, NA, NA, …\n$ tvhours   &lt;dbl&gt; 6, 2, 2, NA, 4, 5, 2, NA, NA, 3, 3, 5, 6, 3, 5, 5, 5, 4, 7, …\n$ attsprts  &lt;fct&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, No, No, No, No, …\n$ tempo_obs &lt;dbl&gt; 123.0000, 424.0000, 124.0000, 500.0000, 500.0000, 500.0000, …\n$ aderencia &lt;fct&gt; SIM, SIM, SIM, SIM, SIM, SIM, SIM, SIM, SIM, SIM, SIM, SIM, …"
  },
  {
    "objectID": "lista_5.html#verificando-a-representatividade-dos-dados",
    "href": "lista_5.html#verificando-a-representatividade-dos-dados",
    "title": "5  Lista 5 - Generalized Linear Model Aula Prática",
    "section": "5.3 Verificando a representatividade dos dados",
    "text": "5.3 Verificando a representatividade dos dados\n\nxtabs(~ attsprts + sex, data = db)\n\n        sex\nattsprts Male Female\n     Yes  384    407\n     No   254    444\n\nxtabs(~ attsprts + life, data = db)\n\n        life\nattsprts Dull Routine Exciting\n     Yes   16     226      281\n     No    48     230      190\n\nxtabs(~ attsprts + aderencia , data = db)\n\n        aderencia\nattsprts Não SIM\n     Yes 750  41\n     No    0 698"
  },
  {
    "objectID": "lista_5.html#a-e-b-glzm---praticar-ou-não-esportes",
    "href": "lista_5.html#a-e-b-glzm---praticar-ou-não-esportes",
    "title": "5  Lista 5 - Generalized Linear Model Aula Prática",
    "section": "5.4 a) e b) GLzM - Praticar ou não esportes",
    "text": "5.4 a) e b) GLzM - Praticar ou não esportes\n\n\n\n\n\n\nExercício\n\n\n\nVerifique qual o efeito do sexo, o que as pessoas acham da vida (life), número de filhos, idade, anos de escolaridade e horas de tv sobre o fato dela praticar ou não esportes (Attsports). Faça um GLzM e descreva os resultados adequadamente.\n\n\nVerificando quais os níveis de referência.\n\nlevels(db$attsprts)\n\n[1] \"Yes\" \"No\" \n\nlevels(db$sex)\n\n[1] \"Male\"   \"Female\"\n\nlevels(db$life)\n\n[1] \"Dull\"     \"Routine\"  \"Exciting\"\n\nlevels(db$aderencia)\n\n[1] \"Não\" \"SIM\"\n\n\nPara os resultados ficarem similares aos da aula prática, vamos modificar o nível de referência da variável attsprts para “No”\n\ndb$attsprts =  relevel(db$attsprts, ref = \"No\")\nlevels(db$attsprts)\n\n[1] \"No\"  \"Yes\""
  },
  {
    "objectID": "lista_5.html#criando-o-modelo",
    "href": "lista_5.html#criando-o-modelo",
    "title": "5  Lista 5 - Generalized Linear Model Aula Prática",
    "section": "5.5 Criando o modelo",
    "text": "5.5 Criando o modelo\n\nmodelo_1 &lt;- glm(attsprts ~ 1 + sex + life + childs + educ + tvhours +  age,\n                data = db,\n                family = \"binomial\")\n                #na.action = na.exclude -&gt; para remover os NAs"
  },
  {
    "objectID": "lista_5.html#resultados-do-modelo",
    "href": "lista_5.html#resultados-do-modelo",
    "title": "5  Lista 5 - Generalized Linear Model Aula Prática",
    "section": "5.6 Resultados do modelo",
    "text": "5.6 Resultados do modelo\nVamos começar mais uma vez vendo o resultado que a função summary() nos oferece.\n\nsummary(modelo_1)\n\n\nCall:\nglm(formula = attsprts ~ 1 + sex + life + childs + educ + tvhours + \n    age, family = \"binomial\", data = db)\n\nCoefficients:\n              Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)  -1.625849   0.560416  -2.901  0.00372 ** \nsexFemale    -0.452288   0.145961  -3.099  0.00194 ** \nlifeRoutine   0.649746   0.333770   1.947  0.05157 .  \nlifeExciting  0.787760   0.336597   2.340  0.01926 *  \nchilds        0.121782   0.049603   2.455  0.01408 *  \neduc          0.200783   0.029138   6.891 5.55e-12 ***\ntvhours      -0.097926   0.039787  -2.461  0.01384 *  \nage          -0.036856   0.004969  -7.417 1.20e-13 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 1352.4  on 977  degrees of freedom\nResidual deviance: 1143.6  on 970  degrees of freedom\n  (522 observations deleted due to missingness)\nAIC: 1159.6\n\nNumber of Fisher Scoring iterations: 4\n\n\nNovamente não é o melhor dos mundos mas temos os valores de p e podemos observar quais variáveis deram resultados significativos.\nPara melhorar a visualização e trazer os resultados em Odds Ratio podemos utilizar a função tab_model() do pacote sjPlot.\n\ntab_model(modelo_1, \n          show.se = TRUE,\n          show.aic = TRUE, \n          show.loglik=TRUE,\n          show.ci = FALSE)\n\n\n\n\n \nattsprts\n\n\nPredictors\nOdds Ratios\nstd. Error\np\n\n\n(Intercept)\n0.20\n0.11\n0.004\n\n\nsex [Female]\n0.64\n0.09\n0.002\n\n\nlife [Routine]\n1.92\n0.64\n0.052\n\n\nlife [Exciting]\n2.20\n0.74\n0.019\n\n\nchilds\n1.13\n0.06\n0.014\n\n\neduc\n1.22\n0.04\n&lt;0.001\n\n\ntvhours\n0.91\n0.04\n0.014\n\n\nage\n0.96\n0.00\n&lt;0.001\n\n\nObservations\n978\n\n\nR2 Tjur\n0.194\n\n\nAIC\n1159.552\n\n\nlog-Likelihood\n-571.776\n\n\n\n\n\n\n\nBem melhor!\n\n\n\n\n\n\nDica!\n\n\n\nVeja a seção Section 5.10 para uma explicação sobre correções para os valores de p, como Bonferroni, Holm, Hochberg e Hommel.\n\n\nPara não precisar ficar mudando a referência e conseguir interpretar valores menores que 1, podemos utilizar a função estimates() do pacote flexplot.\n\nestimates(modelo_1)\n\n             raw.coefficients    OR inverse.OR standardized.OR\n(Intercept)            -1.626 0.197      5.083           1.000\nsexFemale              -0.452 0.636      1.572           0.799\nlifeRoutine             0.650 1.915      0.522           1.383\nlifeExciting            0.788 2.198      0.455           1.482\nchilds                  0.122 1.130      0.885           1.230\neduc                    0.201 1.222      0.818           1.837\ntvhours                -0.098 0.907      1.103           0.821\nage                    -0.037 0.964      1.038           0.527\n             inverse.standardized.OR Prediction Difference (+/- 1 SD)\n(Intercept)                    1.000                             &lt;NA&gt;\nsexFemale                      1.251      -0.11 (relative to sexMale)\nlifeRoutine                    0.723      0.16 (relative to lifeDull)\nlifeExciting                   0.675      0.19 (relative to lifeDull)\nchilds                         0.813                              0.1\neduc                           0.544                             0.29\ntvhours                        1.219                              0.1\nage                            1.899                              0.3\n\n\nNa coluna “inverse.OR” temos os valores invertendo a ordem das referências. No caso da variável sexo, podemos observar que o valor de odds ratio para “Female” quando comparado com “Male” (Female - Male) é de 0,636. O Inverse.OR nos mostra o valor caso o nível de referência fosse invertido (Male - Female).\nA interpretação do resultado, levando em conta o inverse.OR, também será invertida. Lembrando sempre que o valor de referência para a VD é “Não fazer esportes” (sedentarismo). Portanto podemos escrever um parágrafo de resultados assim:\n“Pessoas do sexo feminino tem 1,57 mais chance de pertencer ao grupo que faz exercícios em relação à pessoas do sexo masculino.”\nCaso fique na dúvida, podemos sempre mudar o nível de referência da variável independente de interesse, rodar novamente o modelo e comparar os resultados.\n\n# Alterando o nível de referência\n\ndb$sex = relevel(db$sex, ref =  \"Female\")\n\n\n# Verificando se a troca ocorreu\n\nlevels(db$sex)\n\n[1] \"Female\" \"Male\"  \n\n\n\n# Rodando novamente o modelo\n\nmodelo_1b &lt;- glm(attsprts ~ 1 + sex + life + childs + educ + tvhours +  age,\n                data = db,\n                family = \"binomial\")\n                #na.action = na.exclude -&gt; para remover os NAs\n\n\nestimates(modelo_1b)\n\n             raw.coefficients    OR inverse.OR standardized.OR\n(Intercept)            -2.078 0.125      7.990           1.000\nsexMale                 0.452 1.572      0.636           1.251\nlifeRoutine             0.650 1.915      0.522           1.383\nlifeExciting            0.788 2.198      0.455           1.482\nchilds                  0.122 1.130      0.885           1.230\neduc                    0.201 1.222      0.818           1.837\ntvhours                -0.098 0.907      1.103           0.821\nage                    -0.037 0.964      1.038           0.527\n             inverse.standardized.OR Prediction Difference (+/- 1 SD)\n(Intercept)                    1.000                             &lt;NA&gt;\nsexMale                        0.799     0.11 (relative to sexFemale)\nlifeRoutine                    0.723      0.16 (relative to lifeDull)\nlifeExciting                   0.675      0.19 (relative to lifeDull)\nchilds                         0.813                              0.1\neduc                           0.544                             0.29\ntvhours                        1.219                              0.1\nage                            1.899                              0.3\n\n\nPodemos observar que o valor de OR para “Male” quando comparado com “Female” (Male - Female) é idêntico ao inverse.OR quando a referência era “Male”.\nAgora temos que interpretar de forma direta os resultados e ficaria assim:\n“Pessoas do sexo masculino tem 1,57 mais chance de pertencer ao grupo que não faz exercícios em relação à pessoas do sexo feminino”\n\n\n\n\n\n\nCuidado!\n\n\n\nPercebam que é fácil se enrolar com a descrição dos resultados. Faça da maneira que se sentir mais a vontade dentre as duas apresentadas e verifique sempre o nível de referência das variáveis."
  },
  {
    "objectID": "lista_5.html#c-comparando-modelos",
    "href": "lista_5.html#c-comparando-modelos",
    "title": "5  Lista 5 - Generalized Linear Model Aula Prática",
    "section": "5.7 c) Comparando modelos",
    "text": "5.7 c) Comparando modelos\n\n\n\n\n\n\nExercício\n\n\n\nOs resultados das questões A e B são similares? Se sim, porque? Se não, qual dos modelos é mais adequado?\n\n\nAqui no R vamos apenas criar o modelo com a função do GzLM. Você pode criar um modelo com o módulo de regressão logística no Jamovi e comparar os resultados apresentados anteriormente."
  },
  {
    "objectID": "lista_5.html#d-e-e-número-de-filhos-vd",
    "href": "lista_5.html#d-e-e-número-de-filhos-vd",
    "title": "5  Lista 5 - Generalized Linear Model Aula Prática",
    "section": "5.8 d) e e) Número de filhos (VD)",
    "text": "5.8 d) e e) Número de filhos (VD)\n\n\n\n\n\n\nExercício\n\n\n\nVerifique o efeito do sexo, opinião sobre a vida (life) e prática de exercícios (attsports) sobre o número de filhos. Controle os resultados para idade e anos de escolaridade. Faça um GLM Univariado e um GLzM para a mesma pergunta\n\n\nPodemos utilizar a mesma função glm() para criar os dois modelos.\n\nModelo GLM\n\nmodelo_2 &lt;- glm(childs ~ 1 + sex + life + attsprts + age + educ,\n                data = db)\n\nComo estamos analisando um modelo linear univariado assumindo que a distribuição da VD é normal, podemos interpretar diretamente os estimadores que são retornados pela função summary.\n\nkable(summary(modelo_2)$coef)\n\n\n\n\n\nEstimate\nStd. Error\nt value\nPr(&gt;|t|)\n\n\n\n\n(Intercept)\n2.8726230\n0.2926723\n9.8151502\n0.0000000\n\n\nsexMale\n-0.1863170\n0.0989903\n-1.8821732\n0.0601095\n\n\nlifeRoutine\n-0.3467610\n0.2066828\n-1.6777451\n0.0937167\n\n\nlifeExciting\n-0.2098896\n0.2104225\n-0.9974676\n0.3187845\n\n\nattsprtsYes\n0.2586856\n0.1075859\n2.4044569\n0.0163818\n\n\nage\n0.0387229\n0.0029938\n12.9342252\n0.0000000\n\n\neduc\n-0.0822842\n0.0178006\n-4.6225436\n0.0000043\n\n\n\n\n\n\n\nE chamar a função report() para gerar os resultados.\n\nreport(modelo_2)\n\nWe fitted a linear model (estimated using ML) to predict childs with sex, life,\nattsprts, age and educ (formula: childs ~ 1 + sex + life + attsprts + age +\neduc). The model's explanatory power is moderate (R2 = 0.20). The model's\nintercept, corresponding to sex = Female, life = Dull, attsprts = No, age = 0\nand educ = 0, is at 2.87 (95% CI [2.30, 3.45], t(977) = 9.82, p &lt; .001). Within\nthis model:\n\n  - The effect of sex [Male] is statistically non-significant and negative (beta\n= -0.19, 95% CI [-0.38, 7.70e-03], t(977) = -1.88, p = 0.060; Std. beta =\n-0.11, 95% CI [-0.22, 4.53e-03])\n  - The effect of life [Routine] is statistically non-significant and negative\n(beta = -0.35, 95% CI [-0.75, 0.06], t(977) = -1.68, p = 0.093; Std. beta =\n-0.20, 95% CI [-0.44, 0.03])\n  - The effect of life [Exciting] is statistically non-significant and negative\n(beta = -0.21, 95% CI [-0.62, 0.20], t(977) = -1.00, p = 0.319; Std. beta =\n-0.12, 95% CI [-0.37, 0.12])\n  - The effect of attsprts [Yes] is statistically significant and positive (beta\n= 0.26, 95% CI [0.05, 0.47], t(977) = 2.40, p = 0.016; Std. beta = 0.15, 95% CI\n[0.03, 0.28])\n  - The effect of age is statistically significant and positive (beta = 0.04, 95%\nCI [0.03, 0.04], t(977) = 12.93, p &lt; .001; Std. beta = 0.40, 95% CI [0.34,\n0.46])\n  - The effect of educ is statistically significant and negative (beta = -0.08,\n95% CI [-0.12, -0.05], t(977) = -4.62, p &lt; .001; Std. beta = -0.15, 95% CI\n[-0.21, -0.08])\n\nStandardized parameters were obtained by fitting the model on a standardized\nversion of the dataset. 95% Confidence Intervals (CIs) and p-values were\ncomputed using a Wald t-distribution approximation.\n\n\n\n\nModelo Poisson\n\nmodelo_3 &lt;- glm(childs ~ 1 + sex + life + attsprts + age + educ,\n                data = db,\n                family = \"poisson\")\n\n\n\nComparando AIC os modelos\nPodemos comparar os índices de aderência dos dois modelos para verificar qual se ajusta melhor aos dados.\n\nAIC(modelo_2, modelo_3)\n\n         df      AIC\nmodelo_2  8 3630.810\nmodelo_3  7 3498.782\n\n\n\nBIC(modelo_2, modelo_3)\n\n         df      BIC\nmodelo_2  8 3669.943\nmodelo_3  7 3533.024\n\n\nPodemos observar que tanto o AIC quanto o BIC favorecem o modelo_3 com distribuição Poisson.\n\n\nResultados\nSempre começando com a boa e velha função summary().\n\nsummary(modelo_3)\n\n\nCall:\nglm(formula = childs ~ 1 + sex + life + attsprts + age + educ, \n    family = \"poisson\", data = db)\n\nCoefficients:\n              Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)   0.988656   0.110271   8.966  &lt; 2e-16 ***\nsexMale      -0.067072   0.039024  -1.719   0.0857 .  \nlifeRoutine  -0.102725   0.074303  -1.383   0.1668    \nlifeExciting -0.052165   0.075989  -0.686   0.4924    \nattsprtsYes   0.095588   0.042782   2.234   0.0255 *  \nage           0.013111   0.001144  11.462  &lt; 2e-16 ***\neduc         -0.026711   0.006805  -3.925 8.67e-05 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for poisson family taken to be 1)\n\n    Null deviance: 951.59  on 983  degrees of freedom\nResidual deviance: 757.85  on 977  degrees of freedom\n  (516 observations deleted due to missingness)\nAIC: 3498.8\n\nNumber of Fisher Scoring iterations: 4\n\n\nTemos que idade (age), nível de educação (educ) e praticar esportes (attsportsYes) são significativos.\nE agora podemos utilizando mais uma vez a função estimates() para ver os valores de de cada variável exp(B). Reparem que aqui não teremos as Odds Ratio, mas sim uma coluna chamada multiplicative.coef, que no caso de modelos Poisson de desenho transversal é a razão de prevalência. A maneira de interpretar é a mesma da regressão logística.\n\nestimates(modelo_3)\n\n             raw.coefficients multiplicative.coef std.mult.coef\n(Intercept)             0.989               2.688         1.000\nsexMale                -0.067               0.935         0.967\nlifeRoutine            -0.103               0.902         0.950\nlifeExciting           -0.052               0.949         0.974\nattsprtsYes             0.096               1.100         1.049\nage                     0.013               1.013         1.257\neduc                   -0.027               0.974         0.922\n             Prediction Difference (+/- 1 SD)\n(Intercept)                              &lt;NA&gt;\nsexMale         -0.17 (relative to sexFemale)\nlifeRoutine      -0.26 (relative to lifeDull)\nlifeExciting     -0.14 (relative to lifeDull)\nattsprtsYes     0.24 (relative to attsprtsNo)\nage                                      1.12\neduc                                     0.39\n\n\n\nexp(modelo_3$coefficients)\n\n (Intercept)      sexMale  lifeRoutine lifeExciting  attsprtsYes          age \n   2.6876196    0.9351281    0.9023752    0.9491727    1.1003059    1.0131971 \n        educ \n   0.9736426 \n\n\nEscrevendo o parágrafo de um dos resultados temos algo como:\n“Pessoas que pertencem ao grupo que fazem esportes tem 10% a mais de chance de terem um filho quando comparadas com pessoas que são sedentárias.\nNo caso do nível educacional precisamos calcular o exp(B) inverso e ter cuidado na interpretação do resultado.\n\nkable(exp(-coef(modelo_3)))\n\n\n\n\n\nx\n\n\n\n\n(Intercept)\n0.3720765\n\n\nsexMale\n1.0693722\n\n\nlifeRoutine\n1.1081865\n\n\nlifeExciting\n1.0535491\n\n\nattsprtsYes\n0.9088382\n\n\nage\n0.9869748\n\n\neduc\n1.0270709\n\n\n\n\n\n\n\nTemos que para cada nível a mais de educação a chance de ter filhos diminui em aproximadamente 3%.\n\n\n\n\n\n\nCuidado!\n\n\n\nNão recomendamos utilizar a função report() para modelos Poisson e de regressão logística. Os resultados apresenta\n\n\n\nreport(modelo_3)\n\nWe fitted a poisson model (estimated using ML) to predict childs with sex,\nlife, attsprts, age and educ (formula: childs ~ 1 + sex + life + attsprts + age\n+ educ). The model's explanatory power is substantial (Nagelkerke's R2 = 0.29).\nThe model's intercept, corresponding to sex = Female, life = Dull, attsprts =\nNo, age = 0 and educ = 0, is at 0.99 (95% CI [0.77, 1.20], p &lt; .001). Within\nthis model:\n\n  - The effect of sex [Male] is statistically non-significant and negative (beta\n= -0.07, 95% CI [-0.14, 9.25e-03], p = 0.086; Std. beta = -0.07, 95% CI [-0.14,\n9.25e-03])\n  - The effect of life [Routine] is statistically non-significant and negative\n(beta = -0.10, 95% CI [-0.25, 0.05], p = 0.167; Std. beta = -0.10, 95% CI\n[-0.25, 0.05])\n  - The effect of life [Exciting] is statistically non-significant and negative\n(beta = -0.05, 95% CI [-0.20, 0.10], p = 0.492; Std. beta = -0.05, 95% CI\n[-0.20, 0.10])\n  - The effect of attsprts [Yes] is statistically significant and positive (beta\n= 0.10, 95% CI [0.01, 0.18], p = 0.025; Std. beta = 0.10, 95% CI [0.01, 0.18])\n  - The effect of age is statistically significant and positive (beta = 0.01, 95%\nCI [0.01, 0.02], p &lt; .001; Std. beta = 0.23, 95% CI [0.19, 0.27])\n  - The effect of educ is statistically significant and negative (beta = -0.03,\n95% CI [-0.04, -0.01], p &lt; .001; Std. beta = -0.08, 95% CI [-0.12, -0.04])\n\nStandardized parameters were obtained by fitting the model on a standardized\nversion of the dataset. 95% Confidence Intervals (CIs) and p-values were\ncomputed using a Wald z-distribution approximation.\n\n\nCrie mais modelos com interações entre as variáveis para praticar. Compare os índices de aderência dos modelos e depois descreva o que melhor se adequa aos dados."
  },
  {
    "objectID": "lista_5.html#lista-5-resolvida-no-spss",
    "href": "lista_5.html#lista-5-resolvida-no-spss",
    "title": "5  Lista 5 - Generalized Linear Model Aula Prática",
    "section": "5.9 Lista 5 resolvida no SPSS",
    "text": "5.9 Lista 5 resolvida no SPSS"
  },
  {
    "objectID": "lista_5.html#sec-extrasV",
    "href": "lista_5.html#sec-extrasV",
    "title": "5  Lista 5 - Generalized Linear Model Aula Prática",
    "section": "5.10 Extras!",
    "text": "5.10 Extras!\n\nResultados dos modelos na unha\n\nmodelo_4 &lt;- glm(childs ~ sex * life * attsprts + age + educ,\n                data = db,\n                family = \"poisson\")\n\n\n# Obter o resumo estatístico do modelo\nresumo_modelo &lt;- summary(modelo_4)\n\n# Extrair os valores de p e os coeficientes\nvalores_p &lt;- resumo_modelo$coefficients[, \"Pr(&gt;|z|)\"]\ncoeficientes &lt;- resumo_modelo$coefficients[, \"Estimate\"]\n\n# Calcular os asteriscos para os níveis de significância\nasteriscos &lt;- ifelse(valores_p &lt; 0.001, \"***\", \n            ifelse(valores_p &lt; 0.01, \"**\", \n            ifelse(valores_p &lt; 0.05, \"*\", \"\")))\n\n# Calcular as estimativas de RR e intervalos de confiança\nRP &lt;- exp(coef(modelo_4))\nIC &lt;- exp(confint(modelo_4))\n\nWaiting for profiling to be done...\n\n# Criar o dataframe parametros_modelo_2\nparametros_modelo_4 &lt;- data.frame(\n  RP = round(RP, 2),\n  IC_Lower = round(IC[, 1], 2),\n  IC_Upper = round(IC[, 2], 2),\n  Valores_p = round(valores_p, 4),\n  Significância = asteriscos\n)\n\nparametros_modelo_4\n\n                                   RP IC_Lower IC_Upper Valores_p Significância\n(Intercept)                      2.67     2.09     3.39    0.0000           ***\nsexMale                          0.87     0.61     1.21    0.4045              \nlifeRoutine                      0.91     0.74     1.12    0.3565              \nlifeExciting                     0.93     0.76     1.15    0.5210              \nattsprtsYes                      1.19     0.81     1.72    0.3573              \nage                              1.01     1.01     1.02    0.0000           ***\neduc                             0.97     0.96     0.99    0.0002           ***\nsexMale:lifeRoutine              1.12     0.78     1.64    0.5468              \nsexMale:lifeExciting             1.03     0.71     1.53    0.8619              \nsexMale:attsprtsYes              1.03     0.51     2.01    0.9373              \nlifeRoutine:attsprtsYes          0.91     0.61     1.38    0.6476              \nlifeExciting:attsprtsYes         0.93     0.63     1.40    0.7128              \nsexMale:lifeRoutine:attsprtsYes  0.88     0.43     1.84    0.7297              \nsexMale:lifeExciting:attsprtsYes 1.07     0.52     2.23    0.8600              \n\n\n\n\nPressupostos dos modelos Poisson\n\nplot(modelo_3, which = 1:6)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOverdispersion\n\ndispersiontest(modelo_3, trafo = 1)\n\n\n    Overdispersion test\n\ndata:  modelo_3\nz = -5.1887, p-value = 1\nalternative hypothesis: true alpha is greater than 0\nsample estimates:\n     alpha \n-0.2078915 \n\n\nPodemos também chamar a correção de Bonferroni para sermos mais conservadores com nossos resutlados.\n\ntab_model(modelo_1, \n          show.se = TRUE,\n          show.aic = TRUE, \n          show.loglik=TRUE,\n          show.ci = FALSE, \n          p.adjust = \"bonferroni\")\n\n\n\n\n \nattsprts\n\n\nPredictors\nOdds Ratios\nstd. Error\np\n\n\n(Intercept)\n0.20\n0.11\n0.030\n\n\nsex [Female]\n0.64\n0.09\n0.016\n\n\nlife [Routine]\n1.92\n0.64\n0.413\n\n\nlife [Exciting]\n2.20\n0.74\n0.154\n\n\nchilds\n1.13\n0.06\n0.113\n\n\neduc\n1.22\n0.04\n&lt;0.001\n\n\ntvhours\n0.91\n0.04\n0.111\n\n\nage\n0.96\n0.00\n&lt;0.001\n\n\nObservations\n978\n\n\nR2 Tjur\n0.194\n\n\nAIC\n1159.552\n\n\nlog-Likelihood\n-571.776\n\n\n\n\n\n\n\nA correção de Bonferroni é um método utilizado para controlar o erro tipo I (falso positivo) em testes de hipóteses múltiplos. Quando você realiza vários testes simultaneamente, há um aumento no risco de obter resultados significativos simplesmente devido ao acaso (erro tipo I).\nO método de Bonferroni ajusta os valores-p obtidos nos testes individuais para reduzir a probabilidade global de cometer um erro tipo I. A correção é feita dividindo o nível de significância (geralmente 0,05) pelo número total de testes realizados. Cada teste individual deve, então, ter um valor de significância ajustado para compensar o número de comparações.\nA fórmula para a correção de Bonferroni é:\n\\[\nValor_-p_-Ajustado = Valor_-de_-Significância_-Original/ Número_-Total_-de_-Testes\n\\] Por exemplo, suponha que você esteja conduzindo 5 testes de hipóteses e deseje manter um nível global de significância de 0,05. A correção de Bonferroni ajustaria o valor de significância para cada teste individual, resultando em 0,05/5=0,010,05/5=0,01.\nContudo, é importante destacar que a correção de Bonferroni tende a ser conservadora, o que significa que pode aumentar a probabilidade de erro tipo II (falso negativo), dificultando a detecção de diferenças ou efeitos reais. Existem alternativas menos conservadoras, como as correções de Holm ou Hochberg, que buscam um equilíbrio entre controle de erro e poder estatístico. A escolha da correção a ser utilizada depende do contexto específico da análise.\n\ntidy(modelo_1, exponentiate = TRUE, \n                       conf.int = TRUE)\n\n# A tibble: 8 × 7\n  term         estimate std.error statistic  p.value conf.low conf.high\n  &lt;chr&gt;           &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;\n1 (Intercept)     0.197   0.560       -2.90 3.72e- 3   0.0646     0.583\n2 sexFemale       0.636   0.146       -3.10 1.94e- 3   0.477      0.846\n3 lifeRoutine     1.92    0.334        1.95 5.16e- 2   1.01       3.77 \n4 lifeExciting    2.20    0.337        2.34 1.93e- 2   1.15       4.34 \n5 childs          1.13    0.0496       2.46 1.41e- 2   1.03       1.25 \n6 educ            1.22    0.0291       6.89 5.55e-12   1.16       1.30 \n7 tvhours         0.907   0.0398      -2.46 1.38e- 2   0.838      0.980\n8 age             0.964   0.00497     -7.42 1.20e-13   0.954      0.973\n\n\n\n\n\nPseudo R²\nFunção para calcular todos os três R2\nComentando cada linha temos:\n\ndev&lt;-LogModel$deviance extrai o desvio do modelo (−2LL(new)) do modelo inserido na função\ne chama isso de dev.\nnullDev&lt;-LogModel$null.deviance extrai o desvio da linha de base (−2LL(linha de base)) do modelo inserido a função e as chamadas são nullDev.\nmodelN&lt;-length(LogModel$fitted.values) usa a função length() no valor ajustado para calcular a amostra size, que ele chama de modelN.\nR.l &lt;- 1 - dev/nullDev calcula a medida de Hosmer e Lemeshow (R2L) usando os valores extraídos do\nmodelo e o chama de R.l.\nR.cs&lt;- 1- exp ( -(nullDev - dev)/modelN): calcula a medida de Cox e Snell (R2CS) usando os valores extraídos do modelo e o chama de R.cs.\nR.n &lt;- R.cs / ( 1 - ( exp (-(nullDev / modelN)))) calcula a medida de Nagelkerke (R2N) usando os valores extraídos do modelo e o chama de R.n.\n\n\nlogisticPseudoR2s &lt;- function(LogModel) {\n  dev &lt;- LogModel$deviance\n  nullDev &lt;- LogModel$null.deviance\n  modelN &lt;- length(LogModel$fitted.values)\n  R.l &lt;- 1 - dev / nullDev\n  R.cs &lt;- 1- exp ( -(nullDev - dev) / modelN)\n  R.n &lt;- R.cs / ( 1 - ( exp (-(nullDev / modelN))))\n  resultados &lt;- data.frame(\n  Metodo = c(\"Hosmer-Lemeshow\", \"Cox-Snell\", \"Nagelkerke\"),\n  Pseudo_R2 = c(round(R.l, 3), round(R.cs, 3), round(R.n, 3)))\n  return(resultados)\n}\n\nlogisticPseudoR2s(modelo_3)\n\n           Metodo Pseudo_R2\n1 Hosmer-Lemeshow     0.204\n2       Cox-Snell     0.179\n3      Nagelkerke     0.288\n\n#exp(modelo_1$coefficients)\n\nO R² (R-squared) em modelos de regressão linear é uma métrica que representa a proporção da variabilidade da variável dependente que é explicada pelo modelo. No entanto, ao lidar com modelos de regressão logística ou outros modelos generalizados, a interpretação direta do R² torna-se mais complexa devido à natureza da função de ligação utilizada.\nPor isso, foi desenvolvido o Pseudo R² como uma medida análoga ao R², mas adaptada para modelos logísticos. Existem várias versões de Pseudo R², e a interpretação pode variar dependendo da versão específica utilizada. Aqui, abordarei uma interpretação geral.\n\n\nDiferenças principais entre R² e Pseudo R²:\nInterpretação Direta: R² (em modelos lineares): Representa a proporção da variância explicada pela variável independente(s). Pseudo R² (em modelos logísticos): Oferece uma medida análoga, mas a interpretação é menos direta, pois está relacionada à verossimilhança e à diferença entre a verossimilhança do modelo ajustado e a verossimilhança de um modelo nulo.\nIntervalo de Valores: R² (em modelos lineares): Pode variar de 0 a 1, indicando a porcentagem da variabilidade explicada pela variável independente. Pseudo R² (em modelos logísticos): Pode variar de 0 a 1, mas o significado exato depende da versão específica. Em alguns casos, um Pseudo R² mais alto indica um melhor ajuste, mas a interpretação exata pode variar.\n\n\nQuando usar poisson e bin negativa?\nComparar AIC/BIC Variância maior que a média -&gt; Usar bin negativa Poisson overdisperssion = Evento muito raro, com muitos zeros no banco."
  },
  {
    "objectID": "lista_5.html#referências",
    "href": "lista_5.html#referências",
    "title": "5  Lista 5 - Generalized Linear Model Aula Prática",
    "section": "5.11 Referências",
    "text": "5.11 Referências\nhttps://www.youtube.com/watch?v=QPY4zuxs1W0\nhttps://bookdown.org/drki_musa/dataanalysis/poisson-regression.html#prepare-r-environment-for-analysis-1"
  },
  {
    "objectID": "lista_5.html#versões-dos-pacotes",
    "href": "lista_5.html#versões-dos-pacotes",
    "title": "5  Lista 5 - Generalized Linear Model Aula Prática",
    "section": "5.12 Versões dos pacotes",
    "text": "5.12 Versões dos pacotes\n\nreport(sessionInfo())\n\nAnalyses were conducted using the R Statistical language (version 4.3.1; R Core\nTeam, 2023) on Windows 11 x64 (build 22621), using the packages lme4 (version\n1.1.34; Bates D et al., 2015), Matrix (version 1.6.0; Bates D et al., 2023),\neffectsize (version 0.8.6; Ben-Shachar MS et al., 2020), fitdistrplus (version\n1.1.11; Delignette-Muller ML, Dutang C, 2015), tm (version 0.7.11; Feinerer I,\nHornik K, 2023), flexplot (version 0.20.5; Fife D, 2024), effects (version\n4.2.2; Fox J, Weisberg S, 2019), car (version 3.1.2; Fox J, Weisberg S, 2019),\ncarData (version 3.0.5; Fox J et al., 2022), mvtnorm (version 1.2.3; Genz A,\nBretz F, 2009), lubridate (version 1.9.3; Grolemund G, Wickham H, 2011), NLP\n(version 0.2.1; Hornik K, 2020), TH.data (version 1.1.2; Hothorn T, 2023),\nmultcomp (version 1.4.25; Hothorn T et al., 2008), AER (version 1.2.10; Kleiber\nC, Zeileis A, 2008), emmeans (version 1.8.8; Lenth R, 2023), sjstats (version\n0.18.2; Lüdecke D, 2022), sjPlot (version 2.8.15; Lüdecke D, 2023), parameters\n(version 0.21.3; Lüdecke D et al., 2020), performance (version 0.10.8; Lüdecke\nD et al., 2021), easystats (version 0.6.0; Lüdecke D et al., 2022), see\n(version 0.8.1; Lüdecke D et al., 2021), insight (version 0.19.6; Lüdecke D et\nal., 2019), bayestestR (version 0.13.1; Makowski D et al., 2019), modelbased\n(version 0.8.6; Makowski D et al., 2020), report (version 0.5.7; Makowski D et\nal., 2023), correlation (version 0.8.4; Makowski D et al., 2022), tibble\n(version 3.2.1; Müller K, Wickham H, 2023), datawizard (version 0.9.0; Patil I\net al., 2022), nlme (version 3.1.163; Pinheiro J et al., 2023), foreign\n(version 0.8.85; R Core Team, 2023), broom (version 1.0.5; Robinson D et al.,\n2023), gtsummary (version 1.7.2; Sjoberg D et al., 2021), rempsyc (version\n0.1.6; Thériault R, 2023), survival (version 3.5.7; Therneau T, 2023), MASS\n(version 7.3.60; Venables WN, Ripley BD, 2002), ggplot2 (version 3.4.4; Wickham\nH, 2016), forcats (version 1.0.0; Wickham H, 2023), stringr (version 1.5.1;\nWickham H, 2023), tidyverse (version 2.0.0; Wickham H et al., 2019), dplyr\n(version 1.1.3; Wickham H et al., 2023), purrr (version 1.0.2; Wickham H, Henry\nL, 2023), readr (version 2.1.4; Wickham H et al., 2023), tidyr (version 1.3.0;\nWickham H et al., 2023), zoo (version 1.8.12; Zeileis A, Grothendieck G, 2005),\nlmtest (version 0.9.40; Zeileis A, Hothorn T, 2002), sandwich (version 3.1.0;\nZeileis A et al., 2020) and kableExtra (version 1.3.4; Zhu H, 2021).\n\nReferences\n----------\n  - Bates D, Mächler M, Bolker B, Walker S (2015). \"Fitting Linear Mixed-Effects\nModels Using lme4.\" _Journal of Statistical Software_, *67*(1), 1-48.\ndoi:10.18637/jss.v067.i01 &lt;https://doi.org/10.18637/jss.v067.i01&gt;.\n  - Bates D, Maechler M, Jagan M (2023). _Matrix: Sparse and Dense Matrix Classes\nand Methods_. R package version 1.6-0,\n&lt;https://CRAN.R-project.org/package=Matrix&gt;.\n  - Ben-Shachar MS, Lüdecke D, Makowski D (2020). \"effectsize: Estimation of\nEffect Size Indices and Standardized Parameters.\" _Journal of Open Source\nSoftware_, *5*(56), 2815. doi:10.21105/joss.02815\n&lt;https://doi.org/10.21105/joss.02815&gt;, &lt;https://doi.org/10.21105/joss.02815&gt;.\n  - Delignette-Muller ML, Dutang C (2015). \"fitdistrplus: An R Package for\nFitting Distributions.\" _Journal of Statistical Software_, *64*(4), 1-34.\ndoi:10.18637/jss.v064.i04 &lt;https://doi.org/10.18637/jss.v064.i04&gt;.\n  - Feinerer I, Hornik K (2023). _tm: Text Mining Package_. R package version\n0.7-11, &lt;https://CRAN.R-project.org/package=tm&gt;. Feinerer I, Hornik K, Meyer D\n(2008). \"Text Mining Infrastructure in R.\" _Journal of Statistical Software_,\n*25*(5), 1-54. doi:10.18637/jss.v025.i05\n&lt;https://doi.org/10.18637/jss.v025.i05&gt;.\n  - Fife D (2024). _flexplot: Graphically Based Data Analysis Using 'flexplot'_.\nR package version 0.20.5.\n  - Fox J, Weisberg S (2019). _An R Companion to Applied Regression_, 3rd\nedition. Sage, Thousand Oaks CA.\n&lt;https://socialsciences.mcmaster.ca/jfox/Books/Companion/index.html&gt;. Fox J,\nWeisberg S (2018). \"Visualizing Fit and Lack of Fit in Complex Regression\nModels with Predictor Effect Plots and Partial Residuals.\" _Journal of\nStatistical Software_, *87*(9), 1-27. doi:10.18637/jss.v087.i09\n&lt;https://doi.org/10.18637/jss.v087.i09&gt;. Fox J (2003). \"Effect Displays in R\nfor Generalised Linear Models.\" _Journal of Statistical Software_, *8*(15),\n1-27. doi:10.18637/jss.v008.i15 &lt;https://doi.org/10.18637/jss.v008.i15&gt;. Fox J,\nHong J (2009). \"Effect Displays in R for Multinomial and Proportional-Odds\nLogit Models: Extensions to the effects Package.\" _Journal of Statistical\nSoftware_, *32*(1), 1-24. doi:10.18637/jss.v032.i01\n&lt;https://doi.org/10.18637/jss.v032.i01&gt;.\n  - Fox J, Weisberg S (2019). _An R Companion to Applied Regression_, Third\nedition. Sage, Thousand Oaks CA.\n&lt;https://socialsciences.mcmaster.ca/jfox/Books/Companion/&gt;.\n  - Fox J, Weisberg S, Price B (2022). _carData: Companion to Applied Regression\nData Sets_. R package version 3.0-5,\n&lt;https://CRAN.R-project.org/package=carData&gt;.\n  - Genz A, Bretz F (2009). _Computation of Multivariate Normal and t\nProbabilities_, series Lecture Notes in Statistics. Springer-Verlag,\nHeidelberg. ISBN 978-3-642-01688-2.\n  - Grolemund G, Wickham H (2011). \"Dates and Times Made Easy with lubridate.\"\n_Journal of Statistical Software_, *40*(3), 1-25.\n&lt;https://www.jstatsoft.org/v40/i03/&gt;.\n  - Hornik K (2020). _NLP: Natural Language Processing Infrastructure_. R package\nversion 0.2-1, &lt;https://CRAN.R-project.org/package=NLP&gt;.\n  - Hothorn T (2023). _TH.data: TH's Data Archive_. R package version 1.1-2,\n&lt;https://CRAN.R-project.org/package=TH.data&gt;.\n  - Hothorn T, Bretz F, Westfall P (2008). \"Simultaneous Inference in General\nParametric Models.\" _Biometrical Journal_, *50*(3), 346-363.\n  - Kleiber C, Zeileis A (2008). _Applied Econometrics with R_. Springer-Verlag,\nNew York. ISBN 978-0-387-77316-2, &lt;https://CRAN.R-project.org/package=AER&gt;.\n  - Lenth R (2023). _emmeans: Estimated Marginal Means, aka Least-Squares Means_.\nR package version 1.8.8, &lt;https://CRAN.R-project.org/package=emmeans&gt;.\n  - Lüdecke D (2022). _sjstats: Statistical Functions for Regression Models\n(Version 0.18.2)_. doi:10.5281/zenodo.1284472\n&lt;https://doi.org/10.5281/zenodo.1284472&gt;,\n&lt;https://CRAN.R-project.org/package=sjstats&gt;.\n  - Lüdecke D (2023). _sjPlot: Data Visualization for Statistics in Social\nScience_. R package version 2.8.15,\n&lt;https://CRAN.R-project.org/package=sjPlot&gt;.\n  - Lüdecke D, Ben-Shachar M, Patil I, Makowski D (2020). \"Extracting, Computing\nand Exploring the Parameters of Statistical Models using R.\" _Journal of Open\nSource Software_, *5*(53), 2445. doi:10.21105/joss.02445\n&lt;https://doi.org/10.21105/joss.02445&gt;.\n  - Lüdecke D, Ben-Shachar M, Patil I, Waggoner P, Makowski D (2021).\n\"performance: An R Package for Assessment, Comparison and Testing of\nStatistical Models.\" _Journal of Open Source Software_, *6*(60), 3139.\ndoi:10.21105/joss.03139 &lt;https://doi.org/10.21105/joss.03139&gt;.\n  - Lüdecke D, Ben-Shachar M, Patil I, Wiernik B, Makowski D (2022). \"easystats:\nFramework for Easy Statistical Modeling, Visualization, and Reporting.\" _CRAN_.\nR package, &lt;https://easystats.github.io/easystats/&gt;.\n  - Lüdecke D, Patil I, Ben-Shachar M, Wiernik B, Waggoner P, Makowski D (2021).\n\"see: An R Package for Visualizing Statistical Models.\" _Journal of Open Source\nSoftware_, *6*(64), 3393. doi:10.21105/joss.03393\n&lt;https://doi.org/10.21105/joss.03393&gt;.\n  - Lüdecke D, Waggoner P, Makowski D (2019). \"insight: A Unified Interface to\nAccess Information from Model Objects in R.\" _Journal of Open Source Software_,\n*4*(38), 1412. doi:10.21105/joss.01412 &lt;https://doi.org/10.21105/joss.01412&gt;.\n  - Makowski D, Ben-Shachar M, Lüdecke D (2019). \"bayestestR: Describing Effects\nand their Uncertainty, Existence and Significance within the Bayesian\nFramework.\" _Journal of Open Source Software_, *4*(40), 1541.\ndoi:10.21105/joss.01541 &lt;https://doi.org/10.21105/joss.01541&gt;,\n&lt;https://joss.theoj.org/papers/10.21105/joss.01541&gt;.\n  - Makowski D, Ben-Shachar M, Patil I, Lüdecke D (2020). \"Estimation of\nModel-Based Predictions, Contrasts and Means.\" _CRAN_.\n&lt;https://github.com/easystats/modelbased&gt;.\n  - Makowski D, Lüdecke D, Patil I, Thériault R, Ben-Shachar M, Wiernik B (2023).\n\"Automated Results Reporting as a Practical Tool to Improve Reproducibility and\nMethodological Best Practices Adoption.\" _CRAN_.\n&lt;https://easystats.github.io/report/&gt;.\n  - Makowski D, Wiernik B, Patil I, Lüdecke D, Ben-Shachar M (2022).\n\"correlation: Methods for Correlation Analysis.\" Version 0.8.3,\n&lt;https://CRAN.R-project.org/package=correlation&gt;. Makowski D, Ben-Shachar M,\nPatil I, Lüdecke D (2020). \"Methods and Algorithms for Correlation Analysis in\nR.\" _Journal of Open Source Software_, *5*(51), 2306. doi:10.21105/joss.02306\n&lt;https://doi.org/10.21105/joss.02306&gt;,\n&lt;https://joss.theoj.org/papers/10.21105/joss.02306&gt;.\n  - Müller K, Wickham H (2023). _tibble: Simple Data Frames_. R package version\n3.2.1, &lt;https://CRAN.R-project.org/package=tibble&gt;.\n  - Patil I, Makowski D, Ben-Shachar M, Wiernik B, Bacher E, Lüdecke D (2022).\n\"datawizard: An R Package for Easy Data Preparation and Statistical\nTransformations.\" _Journal of Open Source Software_, *7*(78), 4684.\ndoi:10.21105/joss.04684 &lt;https://doi.org/10.21105/joss.04684&gt;.\n  - Pinheiro J, Bates D, R Core Team (2023). _nlme: Linear and Nonlinear Mixed\nEffects Models_. R package version 3.1-163,\n&lt;https://CRAN.R-project.org/package=nlme&gt;. Pinheiro JC, Bates DM (2000).\n_Mixed-Effects Models in S and S-PLUS_. Springer, New York. doi:10.1007/b98882\n&lt;https://doi.org/10.1007/b98882&gt;.\n  - R Core Team (2023). _foreign: Read Data Stored by 'Minitab', 'S', 'SAS',\n'SPSS', 'Stata', 'Systat', 'Weka', 'dBase', ..._. R package version 0.8-85,\n&lt;https://CRAN.R-project.org/package=foreign&gt;.\n  - R Core Team (2023). _R: A Language and Environment for Statistical\nComputing_. R Foundation for Statistical Computing, Vienna, Austria.\n&lt;https://www.R-project.org/&gt;.\n  - Robinson D, Hayes A, Couch S (2023). _broom: Convert Statistical Objects into\nTidy Tibbles_. R package version 1.0.5,\n&lt;https://CRAN.R-project.org/package=broom&gt;.\n  - Sjoberg D, Whiting K, Curry M, Lavery J, Larmarange J (2021). \"Reproducible\nSummary Tables with the gtsummary Package.\" _The R Journal_, *13*, 570-580.\ndoi:10.32614/RJ-2021-053 &lt;https://doi.org/10.32614/RJ-2021-053&gt;,\n&lt;https://doi.org/10.32614/RJ-2021-053&gt;.\n  - Thériault R (2023). \"rempsyc: Convenience functions for psychology.\" _Journal\nof Open Source Software_, *8*(87), 5466. doi:10.21105/joss.05466\n&lt;https://doi.org/10.21105/joss.05466&gt;, &lt;https://doi.org/10.21105/joss.05466&gt;.\n  - Therneau T (2023). _A Package for Survival Analysis in R_. R package version\n3.5-7, &lt;https://CRAN.R-project.org/package=survival&gt;. Terry M. Therneau,\nPatricia M. Grambsch (2000). _Modeling Survival Data: Extending the Cox Model_.\nSpringer, New York. ISBN 0-387-98784-3.\n  - Venables WN, Ripley BD (2002). _Modern Applied Statistics with S_, Fourth\nedition. Springer, New York. ISBN 0-387-95457-0,\n&lt;https://www.stats.ox.ac.uk/pub/MASS4/&gt;.\n  - Wickham H (2016). _ggplot2: Elegant Graphics for Data Analysis_.\nSpringer-Verlag New York. ISBN 978-3-319-24277-4,\n&lt;https://ggplot2.tidyverse.org&gt;.\n  - Wickham H (2023). _forcats: Tools for Working with Categorical Variables\n(Factors)_. R package version 1.0.0,\n&lt;https://CRAN.R-project.org/package=forcats&gt;.\n  - Wickham H (2023). _stringr: Simple, Consistent Wrappers for Common String\nOperations_. R package version 1.5.1,\n&lt;https://CRAN.R-project.org/package=stringr&gt;.\n  - Wickham H, Averick M, Bryan J, Chang W, McGowan LD, François R, Grolemund G,\nHayes A, Henry L, Hester J, Kuhn M, Pedersen TL, Miller E, Bache SM, Müller K,\nOoms J, Robinson D, Seidel DP, Spinu V, Takahashi K, Vaughan D, Wilke C, Woo K,\nYutani H (2019). \"Welcome to the tidyverse.\" _Journal of Open Source Software_,\n*4*(43), 1686. doi:10.21105/joss.01686 &lt;https://doi.org/10.21105/joss.01686&gt;.\n  - Wickham H, François R, Henry L, Müller K, Vaughan D (2023). _dplyr: A Grammar\nof Data Manipulation_. R package version 1.1.3,\n&lt;https://CRAN.R-project.org/package=dplyr&gt;.\n  - Wickham H, Henry L (2023). _purrr: Functional Programming Tools_. R package\nversion 1.0.2, &lt;https://CRAN.R-project.org/package=purrr&gt;.\n  - Wickham H, Hester J, Bryan J (2023). _readr: Read Rectangular Text Data_. R\npackage version 2.1.4, &lt;https://CRAN.R-project.org/package=readr&gt;.\n  - Wickham H, Vaughan D, Girlich M (2023). _tidyr: Tidy Messy Data_. R package\nversion 1.3.0, &lt;https://CRAN.R-project.org/package=tidyr&gt;.\n  - Zeileis A, Grothendieck G (2005). \"zoo: S3 Infrastructure for Regular and\nIrregular Time Series.\" _Journal of Statistical Software_, *14*(6), 1-27.\ndoi:10.18637/jss.v014.i06 &lt;https://doi.org/10.18637/jss.v014.i06&gt;.\n  - Zeileis A, Hothorn T (2002). \"Diagnostic Checking in Regression\nRelationships.\" _R News_, *2*(3), 7-10.\n&lt;https://CRAN.R-project.org/doc/Rnews/&gt;.\n  - Zeileis A, Köll S, Graham N (2020). \"Various Versatile Variances: An\nObject-Oriented Implementation of Clustered Covariances in R.\" _Journal of\nStatistical Software_, *95*(1), 1-36. doi:10.18637/jss.v095.i01\n&lt;https://doi.org/10.18637/jss.v095.i01&gt;. Zeileis A (2004). \"Econometric\nComputing with HC and HAC Covariance Matrix Estimators.\" _Journal of\nStatistical Software_, *11*(10), 1-17. doi:10.18637/jss.v011.i10\n&lt;https://doi.org/10.18637/jss.v011.i10&gt;. Zeileis A (2006). \"Object-Oriented\nComputation of Sandwich Estimators.\" _Journal of Statistical Software_,\n*16*(9), 1-16. doi:10.18637/jss.v016.i09\n&lt;https://doi.org/10.18637/jss.v016.i09&gt;.\n  - Zhu H (2021). _kableExtra: Construct Complex Table with 'kable' and Pipe\nSyntax_. R package version 1.3.4,\n&lt;https://CRAN.R-project.org/package=kableExtra&gt;."
  },
  {
    "objectID": "survival.html",
    "href": "survival.html",
    "title": "SURVIVAL",
    "section": "",
    "text": "A análise de sobrevida é uma técnica estatística utilizada para investigar o tempo até a ocorrência de um evento, como a falha de um dispositivo, o desenvolvimento de uma doença ou a morte. No contexto da análise de sobrevida, a regressão de Cox, também conhecida como modelo de riscos proporcionais de Cox, é uma ferramenta essencial. Essa abordagem, desenvolvida por David R. Cox, permite avaliar a influência de variáveis independentes no tempo até o evento de interesse, mantendo a suposição de proporções constantes de risco ao longo do tempo. No ambiente estatístico R, a implementação da análise de sobrevida e da Cox regression é amplamente realizada por meio de pacotes como “survival” e “survminer”. Essas ferramentas possibilitam a modelagem e visualização de dados de sobrevida, oferecendo uma compreensão mais aprofundada dos fatores que influenciam a taxa de ocorrência de eventos ao longo do tempo."
  },
  {
    "objectID": "lista_6.html#carregando-pacotes",
    "href": "lista_6.html#carregando-pacotes",
    "title": "6  Lista 6 - Kaplan-Meier e Cox Regression",
    "section": "6.1 Carregando pacotes",
    "text": "6.1 Carregando pacotes\n\nlibrary(tidyverse)\nlibrary(flexplot)\nlibrary(foreign)\nlibrary(dplyr)\nlibrary(tm)\nlibrary(ggplot2)\nlibrary(forcats)\nlibrary(rempsyc)\nlibrary(easystats)\nlibrary(kableExtra)\nlibrary(gtsummary)\n\n#Específicos para survival\nlibrary(survival)\nlibrary(ggsurvfit)\nlibrary(survminer)\nlibrary(broom)\nlibrary(survMisc)\nlibrary(PHInfiniteEstimates)\nlibrary(coin)\nlibrary(condSURV)"
  },
  {
    "objectID": "lista_6.html#limpando-o-ambiente",
    "href": "lista_6.html#limpando-o-ambiente",
    "title": "6  Lista 6 - Kaplan-Meier e Cox Regression",
    "section": "6.2 Limpando o ambiente",
    "text": "6.2 Limpando o ambiente\nQuando executamos diversos comandos no R muitas vezes acabamos deixando o ambiente meio “sujo”. Cheio de variáveis que não estamos mais utilizando, ou pacotes que estão carregados e não serão utilizados no momento.\nEm longas sessões utilizando o R é sempre bom dar uma limpada no ambiente entre um projeto e outro. Para isso podemos executar o código abaixo:\n\n# Limpa o ambiente\nrm(list = ls(all.names = TRUE)) # will clear all objects including hidden objects\ngc() # free up memory and report the memory usage\n\n          used  (Mb) gc trigger  (Mb) max used  (Mb)\nNcells 3170881 169.4    4805995 256.7  4805995 256.7\nVcells 5390829  41.2   10154066  77.5  8395055  64.1\n\noptions(max.print = .Machine$integer.max, scipen = 999, stringsAsFactors = F, dplyr.summarise.inform = F) # avoid truncated output in R console and scientific notation\n\n# Set seed\nset.seed(42)"
  },
  {
    "objectID": "lista_6.html#definindo-um-tema-para-os-gráficos",
    "href": "lista_6.html#definindo-um-tema-para-os-gráficos",
    "title": "6  Lista 6 - Kaplan-Meier e Cox Regression",
    "section": "6.3 Definindo um tema para os gráficos",
    "text": "6.3 Definindo um tema para os gráficos\nPreenhcer todos os parâmetros da função ggplot() é uma tarefa morosa e repetitiva. Podemos criar um tema para todos os nossos gráficos e assim manter a consistência nas figuras e não precisar ficar escrevendo toda hora aquele parâmetro para mudar a espessura da linha do eixo X…\nUma vez definido o tema, podemos apenas chamá-lo dentro da função ggplot para repetir o padrão. Vamos armazenar todas as informações da padronização em uma variável com o código a seguir:\n\nmeu_tema &lt;- theme(plot.title = element_text(size = rel(2)),\n                  panel.grid.major.y = element_line(colour = 'gray'),\n                  panel.grid.minor.y = element_line(colour = 'gray'),\n                  panel.grid.major.x = element_blank(),\n                  panel.grid.minor.x = element_blank(),\n                  plot.background = element_rect(fill = NULL, colour = 'white'),\n                  panel.background = element_rect(fill = 'white'),\n                  # Axis stuff\n                  axis.line = element_line(colour = 'black', linewidth = 1),\n                  axis.text = element_text(colour = \"black\", face = 'bold'),\n                  axis.text.x = element_text(size = rel(1)),\n                  axis.text.y = element_text(size = rel(1)),\n                  axis.title = element_text(size = rel(1.2)),\n                  axis.ticks = element_line(colour = 'black', linewidth = 1.2),\n                  # Legend stuff\n                  legend.position = \"bottom\",\n                  legend.margin = margin(6, 6, 6, 6),\n                  legend.title = element_text(face = 'bold'),\n                  legend.background = element_blank(),\n                  legend.box.background = element_rect(colour = \"black\"))\n\nVamos utilizar o tema em nossos gráficos mais adiante!"
  },
  {
    "objectID": "lista_6.html#sec-carrega_dados",
    "href": "lista_6.html#sec-carrega_dados",
    "title": "6  Lista 6 - Kaplan-Meier e Cox Regression",
    "section": "6.4 Carregando os dados e modificando o tipo de variável",
    "text": "6.4 Carregando os dados e modificando o tipo de variável\nComo de costume, vamos carregar os dados e ver os tipos das variáveis que temos no banco de dados.\n\noriginal = read.spss(\"teste Cox tempo dep Tx.sav\", to.data.frame=TRUE)\nglimpse(original)\n\nRows: 124\nColumns: 5\n$ id    &lt;chr&gt; \"13758618I                     \", \"13750502G                    …\n$ t_seg &lt;dbl&gt; 99, 98, 97, 97, 97, 96, 92, 90, 89, 87, 83, 83, 82, 82, 80, 77, …\n$ t_tx  &lt;dbl&gt; 22, 81, NA, 25, 93, 5, 1, 30, 88, 28, 30, 13, 49, NA, NA, 10, NA…\n$ tx    &lt;fct&gt; sim, sim, não, sim, sim, sim, sim, sim, sim, sim, sim, sim, sim,…\n$ obito &lt;fct&gt; não, não, não, não, não, não, não, não, sim, não, não, não, não,…\n\n\n\n\n\n\n\n\nCuidado!\n\n\n\nA variável do evento (óbito em nosso exemplo) PRECISA ser recodificada para uma variável numérica binária, ou seja, 1 e 0 caso queira realizar a análise de sobrevida.\n\n\nNa seção Section 6.16, exploraremos as distinções entre conduzir as análises com os fatores “sim” e “não” versus os números 1 e 0.\nInicialmente, ajustaremos a variável para aceitar os valores 1 e 0, representando a ocorrência do evento e a censura, respectivamente. Para isso, empregaremos o operador pipe %&gt;% para duplicar a base de dados original e efetuar a modificação no mesmo script. O operador pipe é útil para executar várias operações em uma única sequência de código.\n\ndb &lt;- original %&gt;%\n  mutate(\n    obito = as.integer(obito == \"sim\") # para transformar sim e não em 1 e 0, respectivamente\n  )\n\nglimpse(db)\n\nRows: 124\nColumns: 5\n$ id    &lt;chr&gt; \"13758618I                     \", \"13750502G                    …\n$ t_seg &lt;dbl&gt; 99, 98, 97, 97, 97, 96, 92, 90, 89, 87, 83, 83, 82, 82, 80, 77, …\n$ t_tx  &lt;dbl&gt; 22, 81, NA, 25, 93, 5, 1, 30, 88, 28, 30, 13, 49, NA, NA, 10, NA…\n$ tx    &lt;fct&gt; sim, sim, não, sim, sim, sim, sim, sim, sim, sim, sim, sim, sim,…\n$ obito &lt;int&gt; 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n\n\nPronto, agora temos que óbito assumiu os valores de números 1 e 0.\nOutra análise exploratória importante a fazer nos dados é observar se há dados faltantes (NA) e onde eles estão, caso estejam presentes. Se uma variável tiver muitos NAs, vamos precisar de cautela para inserir a variável na análise.\n\n# Verificando NAs\ndata.frame(\n  nas_t_seg = sum(is.na(db$t_seg)),\n  nas_t_seg = sum(is.na(db$t_tx)),\n  nas_tx = sum(is.na(db$tx)),\n  nas_obito = sum(is.na(db$obito))\n)\n\n  nas_t_seg nas_t_seg.1 nas_tx nas_obito\n1         0          64      0         0\n\n\n\nkable(report(db))\n\n\n\n\n\nVariable\nLevel\nn_Obs\npercentage_Obs\npercentage_Missing\nMean\nSD\nMedian\nMAD\nMin\nMax\nSkewness\nKurtosis\nn_Entries\nn_Missing\n\n\n\n\n3\nid\nNA\n124\n\n0.00\n\n\n\n\n\n\n\n\n124.00\n0\n\n\n5\nt_seg\nNA\n124\n\n0.00\n45.22\n24.08\n42.00\n19.27\n0.00\n99.00\n0.38\n-0.19\n\n\n\n\n6\nt_tx\nNA\n124\n\n51.61\n19.90\n20.05\n\n16.31\n1.00\n93.00\n1.99\n4.70\n\n\n\n\n1\ntx\nsim\n60\n48.39\n\n\n\n\n\n\n\n\n\n\n\n\n\n2\ntx\nnão\n64\n51.61\n\n\n\n\n\n\n\n\n\n\n\n\n\n4\nobito\nNA\n124\n\n0.00\n0.27\n0.45\n0.00\n0.00\n0.00\n1.00\n1.02\n-0.97\n\n\n\n\n\n\n\n\n\nO número de NAs na variável t_tx é alto (51.61%) pelo simples motivo de que pessoas que não fizeram transplante não possuem a marca do tempo que fizeram o transplante. Em todo caso podemos verificar se existem indivíduos que fizeram o transplante mas não possuem a marca do tempo em que fizeram o transplante.\n\ndb %&gt;%\n  filter(tx == \"sim\" & is.na(t_tx))\n\n[1] id    t_seg t_tx  tx    obito\n&lt;0 linhas&gt; (ou row.names de comprimento 0)\n\n\nO código acima filtra os dados de pessoas que fizeram o transplante (tx sim) e que tenham NA na coluna t_tx. Como o resultado volta com zero elementos, podemos concluir que todas as pessoas que fizeram o transplante, possuem a marca do horário em que o transplante foi feito.\nNa tabela acima podemos perceber também que a porcentagem de pessoas que não fizeram o transplante (51.61) é a mesma porcentagem de dados faltantes (missing) da variável t_tx (51.61)\nPor fim, podemos ver quantas pessoas morreram pela causa de morte do desfecho durante o período de observação.\n\nkable(table(db$obito))\n\n\n\n\nVar1\nFreq\n\n\n\n\n0\n90\n\n\n1\n34\n\n\n\n\n\n\n\nLembrando que 1 é o evento, que no nosso exemplo é ocorrência do óbito\nVamos agora às análises."
  },
  {
    "objectID": "lista_6.html#criando-a-estrutura-de-dados",
    "href": "lista_6.html#criando-a-estrutura-de-dados",
    "title": "6  Lista 6 - Kaplan-Meier e Cox Regression",
    "section": "6.5 Criando a estrutura de dados",
    "text": "6.5 Criando a estrutura de dados\nIniciamos especificando para a função Surv() as colunas referentes ao tempo observado e aos eventos de interesse, que, neste caso, são os óbitos.\n\nsurv_obj &lt;- Surv(time = db$t_seg, event = db$obito)"
  },
  {
    "objectID": "lista_6.html#a-tábua-de-vida",
    "href": "lista_6.html#a-tábua-de-vida",
    "title": "6  Lista 6 - Kaplan-Meier e Cox Regression",
    "section": "6.6 a) Tábua de vida",
    "text": "6.6 a) Tábua de vida\n\n\n\n\n\n\nExercício\n\n\n\nFaça duas tábuas de vida em função da variável óbito comparando grupos que fizeram ou não transplante: Ambas com período 0 até 99 meses. A primeira dividida em períodos de 20 meses e a segunda com períodos de 1 mês. Faça um parágrafo descrevendo as diferenças nos gráficos.\n\n\nAgora vamos criar a tabela de vida. Por enquanto, não faremos a separação dos dados por grupos.\n\nfit1 &lt;- survfit(surv_obj ~ 1, data = db)\n\nA função summary() também pode ser utilizada para verificar os resultados dos modelos de sobrevida.\n\nsummary(fit1)\n\nCall: survfit(formula = surv_obj ~ 1, data = db)\n\n time n.risk n.event survival std.err lower 95% CI upper 95% CI\n    0    124       2    0.984  0.0113        0.962        1.000\n    3    121       2    0.968  0.0159        0.937        0.999\n    4    119       2    0.951  0.0194        0.914        0.990\n    6    117       1    0.943  0.0208        0.903        0.985\n    8    116       2    0.927  0.0234        0.882        0.974\n   11    114       1    0.919  0.0246        0.872        0.968\n   13    113       1    0.911  0.0257        0.862        0.962\n   16    110       1    0.902  0.0268        0.851        0.956\n   19    108       1    0.894  0.0278        0.841        0.950\n   24    106       2    0.877  0.0297        0.821        0.937\n   25    104       1    0.869  0.0306        0.811        0.931\n   26    103       1    0.860  0.0314        0.801        0.924\n   27    102       1    0.852  0.0323        0.791        0.917\n   29    101       1    0.843  0.0330        0.781        0.911\n   34     89       3    0.815  0.0358        0.748        0.888\n   36     82       1    0.805  0.0367        0.736        0.880\n   38     70       1    0.794  0.0379        0.723        0.871\n   40     68       1    0.782  0.0391        0.709        0.862\n   41     65       2    0.758  0.0414        0.681        0.844\n   44     59       1    0.745  0.0427        0.666        0.834\n   45     55       1    0.731  0.0440        0.650        0.823\n   46     53       1    0.718  0.0453        0.634        0.812\n   49     47       1    0.702  0.0468        0.616        0.800\n   58     32       1    0.680  0.0502        0.589        0.786\n   66     24       1    0.652  0.0556        0.552        0.771\n   89      9       1    0.580  0.0843        0.436        0.771\n\n\nE a função função tidy_survfit() nos oferece uma tabela bem mais completa.\n\ntidy_survfit(fit1)\n\n# A tibble: 63 × 14\n    time n.risk n.event n.censor cum.event cum.censor estimate std.error\n   &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;      &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;\n 1     0    124       2        1         2          1    0.984    0.0115\n 2     3    121       2        0         4          1    0.968    0.0165\n 3     4    119       2        0         6          1    0.951    0.0204\n 4     6    117       1        0         7          1    0.943    0.0221\n 5     8    116       2        0         9          1    0.927    0.0253\n 6    11    114       1        0        10          1    0.919    0.0268\n 7    13    113       1        0        11          1    0.911    0.0282\n 8    14    112       0        1        11          2    0.911    0.0282\n 9    15    111       0        1        11          3    0.911    0.0282\n10    16    110       1        0        12          3    0.902    0.0297\n# ℹ 53 more rows\n# ℹ 6 more variables: conf.high &lt;dbl&gt;, conf.low &lt;dbl&gt;, estimate_type &lt;chr&gt;,\n#   estimate_type_label &lt;chr&gt;, monotonicity_type &lt;chr&gt;, conf.level &lt;dbl&gt;"
  },
  {
    "objectID": "lista_6.html#b-kaplan-meier",
    "href": "lista_6.html#b-kaplan-meier",
    "title": "6  Lista 6 - Kaplan-Meier e Cox Regression",
    "section": "6.7 b) Kaplan-Meier",
    "text": "6.7 b) Kaplan-Meier\n\n\n\n\n\n\nExercício\n\n\n\nFaça uma curva de Kaplan-meyer comparando os grupos que fizeram vs não fizeram transplante em relação ao óbito. Analise o gráfico e as saídas do teste.\n\n\nPara produzir um gráfico Kaplan-Meier simples podemos utilizar a função plot().\n\nplot(fit1)\n\n\n\n\nMeio pobrezinho e sem cor ne?\nPodemos melhorar utilizando a função ggsurvfit(), do pacote com o mesmo nome.\n\nfit1_km = ggsurvfit(fit1, linewidth = 1) +\n  labs(x = 'Dias', y = 'Overall survival') +\n  add_confidence_interval() +\n  add_risktable() +\n  scale_ggsurvfit() \n\nfit1_km\n\n\n\n\nAté aqui estamos vendo o gráfico da sobrevida sem separar por grupos. A seguir vamos comparar entre os grupos que receberam ou não o transplante de rins."
  },
  {
    "objectID": "lista_6.html#separando-por-transplante-e-nos-tempos-0-20-40-60-80",
    "href": "lista_6.html#separando-por-transplante-e-nos-tempos-0-20-40-60-80",
    "title": "6  Lista 6 - Kaplan-Meier e Cox Regression",
    "section": "6.8 Separando por transplante e nos tempos 0, 20, 40, 60, 80",
    "text": "6.8 Separando por transplante e nos tempos 0, 20, 40, 60, 80\nQueremos comparar a sobrevida entre quem fez e não fez o transplante. Para isso podemos especificar no modelo que o transplante (tx) será uma das variáveis independentes.\n\nfit2 = survfit(surv_obj ~ tx, # basta colocar tx como uma variável preditora no modelo\n               data = db) \n\n\nsummary(fit2)\n\nCall: survfit(formula = surv_obj ~ tx, data = db)\n\n                tx=sim \n time n.risk n.event survival std.err lower 95% CI upper 95% CI\n    3     59       1    0.983  0.0168        0.951        1.000\n    4     58       1    0.966  0.0236        0.921        1.000\n   24     57       1    0.949  0.0286        0.895        1.000\n   26     56       1    0.932  0.0327        0.870        0.999\n   29     55       1    0.915  0.0363        0.847        0.989\n   38     44       1    0.894  0.0410        0.818        0.978\n   41     41       1    0.873  0.0454        0.788        0.966\n   45     37       1    0.849  0.0499        0.757        0.953\n   49     32       1    0.823  0.0550        0.722        0.938\n   66     19       1    0.779  0.0670        0.658        0.922\n   89      8       1    0.682  0.1083        0.499        0.931\n\n                tx=não \n time n.risk n.event survival std.err lower 95% CI upper 95% CI\n    0     64       2    0.969  0.0217        0.927        1.000\n    3     62       1    0.953  0.0264        0.903        1.000\n    4     61       1    0.938  0.0303        0.880        0.999\n    6     60       1    0.922  0.0335        0.858        0.990\n    8     59       2    0.891  0.0390        0.817        0.970\n   11     57       1    0.875  0.0413        0.798        0.960\n   13     56       1    0.859  0.0435        0.778        0.949\n   16     53       1    0.843  0.0456        0.758        0.937\n   19     51       1    0.827  0.0476        0.738        0.925\n   24     49       1    0.810  0.0495        0.718        0.913\n   25     48       1    0.793  0.0513        0.699        0.900\n   27     47       1    0.776  0.0529        0.679        0.887\n   34     38       3    0.715  0.0594        0.607        0.841\n   36     35       1    0.694  0.0611        0.584        0.825\n   40     26       1    0.668  0.0643        0.553        0.806\n   41     24       1    0.640  0.0674        0.520        0.786\n   44     21       1    0.609  0.0707        0.485        0.765\n   46     18       1    0.575  0.0745        0.447        0.742\n   58     11       1    0.523  0.0841        0.382        0.717\n\n\nA função summary() aceita um parâmetro com intervalos específicos para aparecer nos resultados. Vamos utilizar a função seq() para criar uma sequência de números que vai do 0 ao 100 com intervalos de 20 em 20.\n\n# Cria o intervalo de tempo\n\ntempos_específicos &lt;- seq(0, 100, by = 20) # sequencia de 0 a 100 em intervalos de 20.\n\nAplicando o intervalo na função temos o seguinte script:\n\nsummary(fit2, times = tempos_específicos)\n\nCall: survfit(formula = surv_obj ~ tx, data = db)\n\n                tx=sim \n time n.risk n.event survival std.err lower 95% CI upper 95% CI\n    0     60       0    1.000  0.0000        1.000        1.000\n   20     57       2    0.966  0.0236        0.921        1.000\n   40     42       4    0.894  0.0410        0.818        0.978\n   60     21       3    0.823  0.0550        0.722        0.938\n   80     12       1    0.779  0.0670        0.658        0.922\n\n                tx=não \n time n.risk n.event survival std.err lower 95% CI upper 95% CI\n    0     64       2    0.969  0.0217        0.927        1.000\n   20     50       9    0.827  0.0476        0.738        0.925\n   40     26       8    0.668  0.0643        0.553        0.806\n   60      7       4    0.523  0.0841        0.382        0.717\n   80      3       0    0.523  0.0841        0.382        0.717\n\n\nPodemos nos perguntar também qual é a probabilidade de sobreviver após um certo tempo. Para obter a resposta basta ajustar o parâmetro times da função summary() para o tempo desejado.\n\nsummary(fit2, times = 75)\n\nCall: survfit(formula = surv_obj ~ tx, data = db)\n\n                tx=sim \n        time       n.risk      n.event     survival      std.err lower 95% CI \n      75.000       14.000       10.000        0.779        0.067        0.658 \nupper 95% CI \n       0.922 \n\n                tx=não \n        time       n.risk      n.event     survival      std.err lower 95% CI \n     75.0000       4.0000      23.0000       0.5232       0.0841       0.3818 \nupper 95% CI \n      0.7169 \n\n\nNa análise do tempo de sobrevivência neste modelo, observamos o seguinte:\nPara o grupo que realizou o transplante (tx=sim):\n\nAos 75 meses, havia 14 indivíduos em risco.\n10 eventos ocorreram até esse momento.\nA taxa de sobrevivência foi de 0.779, com um desvio padrão de 0.067.\nO intervalo de confiança de 95% para a taxa de sobrevivência variou de 0.658 a 0.922.\n\nPara o grupo que não realizou o transplante (tx=não):\n\nAos 75 meses, havia 4 indivíduos em risco.\n23 eventos ocorreram até esse momento.\nA taxa de sobrevivência foi de 0.5232, com um desvio padrão de 0.0841.\nO intervalo de confiança de 95% para a taxa de sobrevivência variou de 0.3818 a 0.7169.\n\nPodemos ainda calcular quantas vezes a probabilidade de sobrevivência é maior no grupo que realizou o transplante em comparação com o grupo que não o fez.\n\nsummary(fit2, times = 75)$surv[1] / summary(fit2, times = 75)$surv[2]\n\n[1] 1.489431\n\n\nO resultado revela que a probabilidade de sobrevivência no grupo que fez o transplante é aproximadamente 1.5 vezes maior do que no grupo que não o realizou.\n\nKaplan-Meir do novo modelo\nVamos salvar o plot padrão do segundo modelo para adicionar mais alguns parâmetros e incrementar a visualização dos resultados.\n\nfit2_km = ggsurvfit(fit2, linewidth = 1) +\n  labs(x = 'Tempo (meses)', y = '% Probabilidade de sobrevivência') +\n  add_confidence_interval() +\n  #add_risktable() + \n  scale_ggsurvfit() \n\nfit2_km\n\n\n\n\nCom o plot salvo, podemos adicionar mais elementos aos poucos, como as linhas tracejadas para enfatizar diferenças.\n\nfit2_km +\n  geom_vline(xintercept = 75, \n             linetype = 'dashed', \n             colour = 'red', \n             size = 1) + # adiciona a linha vermelha vertical \n  geom_hline(yintercept = summary(fit2, times = 75)$surv, \n             linetype = 'dashed', \n             colour = 'red', size = 1) # adiciona as linhas vermelhas horizontais.\n\n\n\n\n\n\nPorcentagem fixa, tempos diferentes\nA função ggsurvfit oferece vários parâmetros interessantes. Um deles, bastante útil, permite traçar uma linha para comparar o tempo em que a probabilidade de sobrevivência X ocorre entre grupos diferentes.\nEm quanto tempo será que a probabilidade de sobrevida chega a 75% nos dois grupos? Vamos utilizar o parâmetro add_quantile() para ter uma estimativa gráfica.\n\nfit2 %&gt;% \n  ggsurvfit(linewidth = 1) +\n  labs(x = 'Tempo (meses)', y = '% Probabilidade de sobrevivência') +\n  add_confidence_interval() +\n  #  add_risktable() +\n  add_quantile(y_value = 0.75, color = \"gray50\", linewidth = 0.75) +\n  scale_ggsurvfit()\n\n\n\n\nAo examinarmos a imagem, observamos que o grupo que não passou pelo transplante atinge uma probabilidade de sobrevida de 75% em aproximadamente 35 meses. Por outro lado, no grupo que se submeteu ao transplante, essa mesma probabilidade só ocorre por volta do 90º mês, sendo ainda maior antes desse período.\n\n\nEscolhendo um intervalo de tempo\nCaso você queira apresentar apenas um período específico de tempo em sua análise, podemos fazer isso utilizando o parâmetro coord_cartesian().\n\nggsurvfit(fit2, linewidth = 1) +\n  labs(x = 'Tempo (meses)', y = '% Probabilidade de sobrevivência') +\n  add_confidence_interval() +\n  # add_risktable() +\n  scale_ggsurvfit() + \n  coord_cartesian(xlim = c(0, 60)) # coloque os números que\n\n\n\n\nPersonalize os limites do intervalo de tempo em sua análise ajustando os valores “0” e “60”, de acordo com suas necessidades específicas."
  },
  {
    "objectID": "lista_6.html#comparando-as-curvas",
    "href": "lista_6.html#comparando-as-curvas",
    "title": "6  Lista 6 - Kaplan-Meier e Cox Regression",
    "section": "6.9 Comparando as curvas",
    "text": "6.9 Comparando as curvas\n\nLog-rank: utilizar para comparar o primeiro terço do gráfico\nGehan: utilizar para comparar o meio do gráfico\nTarone: utilizar para comparar o final do gráfico\nPeto-Peto: parecido com o Log-rank, utilizar para comparar o primeiro terço do gráfico\n\nPacote mais indicado para utilizar é o coin.\n\nTipos de testes possíveis\n“logrank”, “Gehan-Breslow”, “Tarone-Ware”, “Peto-Peto”, “Prentice”, “Prentice-Marek”, “Andersen-Borgan-Gill-Keiding”, “Fleming-Harrington”, “Gaugler-Kim-Liao”, “Self”\n\nLog-rank\n\ncoin::logrank_test(surv_obj ~ tx, data = db, type = \"logrank\" ) # padrão é o log-rank\n\n\n    Asymptotic Two-Sample Logrank Test\n\ndata:  surv_obj by tx (sim, não)\nZ = 2.9275, p-value = 0.003417\nalternative hypothesis: true theta is not equal to 1\n\n\n\n\nGehan-Breslow\n\ncoin::logrank_test(surv_obj ~ tx ,data = db, type = \"Gehan-Breslow\")\n\n\n    Asymptotic Two-Sample Gehan-Breslow Test\n\ndata:  surv_obj by tx (sim, não)\nZ = 3.0103, p-value = 0.00261\nalternative hypothesis: true theta is not equal to 1\n\n\n\n\nTarone-Ware\n\ncoin::logrank_test(surv_obj ~ tx ,data = db, type = \"Tarone-Ware\")\n\n\n    Asymptotic Two-Sample Tarone-Ware Test\n\ndata:  surv_obj by tx (sim, não)\nZ = 3.0338, p-value = 0.002415\nalternative hypothesis: true theta is not equal to 1\n\n\n\n\nPeto-Peto\n\ncoin::logrank_test(surv_obj ~ tx ,data = db, type = \"Peto-Peto\")\n\n\n    Asymptotic Two-Sample Peto-Peto Test\n\ndata:  surv_obj by tx (sim, não)\nZ = 2.9857, p-value = 0.002829\nalternative hypothesis: true theta is not equal to 1\n\n\nEm todos os testes a hipótese alternativa sugere que o verdadeiro parâmetro theta não é igual a 1, indicando assim que há diferenças significativas nas curvas de sobrevida entre os dois grupos analisados. Em termos práticos, isso sugere que a probabilidade de sobrevivência varia de maneira estatisticamente significativa entre os grupos que fizeram ou não o transplante."
  },
  {
    "objectID": "lista_6.html#c-cox-regression",
    "href": "lista_6.html#c-cox-regression",
    "title": "6  Lista 6 - Kaplan-Meier e Cox Regression",
    "section": "6.10 c) Cox Regression",
    "text": "6.10 c) Cox Regression\n\n\n\n\n\n\nExercício\n\n\n\nReproduza a análise do item b) com uma Cox Regression. Descreva os resultados\n\n\nCompare com base no resultado da Cox, qual seria a diferença na sobrevida (HR) entre uma pessoa que fez e outra que não fez transplante com 50 meses de observação\nA Regressão de Cox é uma técnica estatística utilizada para analisar a relação entre variáveis explicativas e o tempo até um evento ocorrer, como a morte. Ao contrário de modelos de regressão linear, a Regressão de Cox lida com dados de sobrevida, levando em consideração o tempo até o evento ou a censura. O código apresentado realiza uma Regressão de Cox com a função coxph().\n\n# Cox regression ======================================================\n# Fit the model\ncox_res &lt;- coxph(Surv(time = db$t_seg, event = db$obito) ~ tx, data = db)\n\nO código acima ajusta o modelo de Regressão de Cox. A variável dependente é definida como o tempo (t_seg) até o evento (obito) ocorrer, e a variável independente é tx.\nNotem que dentro da função coxph(), repetimos o código para gerar a tabela de vida.Durante a criação da estrutura dos dados, armazenamos a tabela de vida em uma variável chamada surv_obj. Podemos reutilizá-la na Regressão de Cox, evitando a necessidade de reescrever o código.\nVamos fazer isso!\n\ncox_res_2 = coxph(surv_obj ~ tx, data = db)\n\nBem mais limpo, não? E como vamos escrever mais alguns modelos, é uma boa prática salvar o padrão que se repete em uma variável.\n\nResultados dos modelos\nSabe qual função vamos utilizar para verificar o resultado? Sim, a summary().\nPrimeiro vamos verificar se as duas formas que escrevemos os modelos geram os mesmos resultados.\n\nsummary(cox_res)\n\nCall:\ncoxph(formula = Surv(time = db$t_seg, event = db$obito) ~ tx, \n    data = db)\n\n  n= 124, number of events= 34 \n\n        coef exp(coef) se(coef)     z Pr(&gt;|z|)   \ntxnão 1.0787    2.9409   0.3753 2.874  0.00405 **\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n      exp(coef) exp(-coef) lower .95 upper .95\ntxnão     2.941       0.34     1.409     6.136\n\nConcordance= 0.638  (se = 0.04 )\nLikelihood ratio test= 8.99  on 1 df,   p=0.003\nWald test            = 8.26  on 1 df,   p=0.004\nScore (logrank) test = 9.01  on 1 df,   p=0.003\n\n\n\n\nsummary(cox_res_2)\n\nCall:\ncoxph(formula = surv_obj ~ tx, data = db)\n\n  n= 124, number of events= 34 \n\n        coef exp(coef) se(coef)     z Pr(&gt;|z|)   \ntxnão 1.0787    2.9409   0.3753 2.874  0.00405 **\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n      exp(coef) exp(-coef) lower .95 upper .95\ntxnão     2.941       0.34     1.409     6.136\n\nConcordance= 0.638  (se = 0.04 )\nLikelihood ratio test= 8.99  on 1 df,   p=0.003\nWald test            = 8.26  on 1 df,   p=0.004\nScore (logrank) test = 9.01  on 1 df,   p=0.003\n\n\n\nBoa! Os resultados são idênticos, então podemos manter o padrão de escrevr o modelo utilizando a tábua de vida salva em uma variável.\nEmbora o resultado da função summary() para modelos de Regressão de Cox possa não ser visualmente atraente, ele oferece informações detalhadas sobre como o modelo se ajusta aos dados. Vamos analisar cada componente separadamente:\n\nSumário do Modelo:\n\nCall: Indica a chamada da função utilizada para ajustar o modelo.\nn= 124, number of events= 34: Informa o número total de observações (n) e o número de eventos ocorridos (number of events).\n\nCoeficientes:\n\ncoef: O coeficiente estimado para a variável tx.\nexp(coef): A interpretação deste valor é que, para pessoas do grupo que não fizeram o transplante (txnão), o risco de o evento (morte) ocorrer aumenta em 2.941 vezes.\nse(coef): O erro padrão do coeficiente.\n\nTeste de Hipótese para Coeficientes:\n\nz: O valor z do teste de Wald, indicando quão longe o coeficiente está da média em termos de erros padrão.\nPr(&gt;|z|): O p-valor associado ao teste de Wald. No exemplo, 0.00405 sugere que o efeito da variável tx é estatisticamente significativo.\nSignificância codes: ** indica significância a 0.01.\n\nIntervalo de Confiança para Exp(Coef):\n\nexp(coef) exp(-coef) lower .95 upper .95: O intervalo de confiança de 95% para o efeito da variável tx.\n\nMedidas de Desempenho do Modelo:\n\nConcordance= 0.638: A concordância é uma medida de quão bem o modelo prevê a ordem de eventos.\nLikelihood ratio test= 8.99, p=0.003: O teste de razão de verossimilhança avalia se o modelo é significativamente melhor do que um modelo nulo. O p-valor sugere que o modelo é estatisticamente significativo.\nWald test= 8.26, p=0.004: O teste de Wald também avalia a significância global do modelo.\nScore (logrank) test= 9.01, p=0.003: O teste de log-rank compara as curvas de sobrevivência entre os grupos.\n\n\nE claro que temos formas melhores de visualizar e mostrar os dados mais importantes. Vamos utilizar a função tbl_regression() do pacote gtsummary, que pega um objeto de modelo de regressão e retorna uma tabela formatada pronta para publicação.\n\ntbl_regression(cox_res, exponentiate = TRUE)\n\n\n\n\n\n  \n    \n    \n      Characteristic\n      HR1\n      95% CI1\n      p-value\n    \n  \n  \n    tx\n\n\n\n        sim\n—\n—\n\n        não\n2.94\n1.41, 6.14\n0.004\n  \n  \n  \n    \n      1 HR = Hazard Ratio, CI = Confidence Interval\n    \n  \n\n\n\n\nPra fazer isso aí no word demoraria uns 30 minutos hein? E ficaria feia ainda. Com uma linha de código fizemos miséria!\n\n\nPlots do modelo e do resultado\nTendo ajustado um modelo de Cox aos dados, é possível visualizar a proporção de sobrevivência prevista em qualquer momento para um determinado grupo de risco.\nNeste caso, construímos um novo banco de dados com duas linhas, uma para cada valor de tx.\n\ntx_df &lt;- with(db,\n              data.frame(tx = c(\"sim\", \"não\")\n              )\n)\nkable(tx_df)\n\n\n\n\ntx\n\n\n\n\nsim\n\n\nnão\n\n\n\n\n\n\n\nAgora podemos utilizar o nosso modelo para prever os valores de sobrevida e criar um gráfico da Regressão de Cox.\n\ncox_graph &lt;- survfit(cox_res, newdata = tx_df)\n\nggsurvplot(cox_graph, conf.int = TRUE, legend.labs=c(\"tx=sim\", \"tx=não\"),\n           ggtheme = theme_minimal(),\n           data = db)\n\n\n\n\n\n\n\n\n\n\nCuidado!\n\n\n\nO gráfico do modelo da Regressão de Cox é diferente do gráfico da Kaplan-Meir! O cálculo da regressão distorce os valores e encaixa o modelo aos dados. Observe a diferença!\n\n\n\n# Gráfico da Kaplan-Meir\nfit2_km\n\n\n\n\nNão podemos deixar e fora o gráfico do modelo. Com pouca tinta (e pouco código) vamos mostrar tudo o que a função summary() nos proporcionou. Para isso vamos utilizar a função ggforest() do pacote survminer.\n\nggforest(cox_res, data = db)\n\n\n\n\nSe não escorreu uma lágrima aí do outro lado da tela agora, eu desisto. E olha que utilizamos apenas uma variável independente no modelo!"
  },
  {
    "objectID": "lista_6.html#hazard-ratio-e-risco-relativo-confirmar-o-conteúdo",
    "href": "lista_6.html#hazard-ratio-e-risco-relativo-confirmar-o-conteúdo",
    "title": "6  Lista 6 - Kaplan-Meier e Cox Regression",
    "section": "6.11 Hazard ratio e risco relativo (CONFIRMAR O CONTEÚDO)",
    "text": "6.11 Hazard ratio e risco relativo (CONFIRMAR O CONTEÚDO)\nVocês repararam que tanto na tabela quanto no gráfico com os resultados no modelo aparece o resultado como “Hazard Ratio”… pois bem, isso está errado!\n\n\n\n\n\n\nAtenção!\n\n\n\nO risco relativo compara a probabilidade cumulativa de um evento ocorrer entre dois grupos ao longo de um período específico, enquanto o hazard ratio avalia a razão instantânea de riscos proporcionais entre os grupos, considerando a variação no risco ao longo do tempo. Enquanto o risco relativo se concentra em eventos cumulativos, o hazard ratio destaca as diferenças nas taxas instantâneas de falha, sendo especialmente útil em análises de sobrevida e estudos onde a dinâmica temporal do risco é crucial."
  },
  {
    "objectID": "lista_6.html#d-hazard-ratio",
    "href": "lista_6.html#d-hazard-ratio",
    "title": "6  Lista 6 - Kaplan-Meier e Cox Regression",
    "section": "6.12 d) Hazard Ratio",
    "text": "6.12 d) Hazard Ratio\n\n\n\n\n\n\nExercício\n\n\n\nCompare com base no resultado da Cox, qual seria a diferença na sobrevida (HR) entre uma pessoa que fez e outra que não fez transplante com 50 meses de observação\n\n\nPara de fato calcular o Hazard Ratio precisamos utilizar nosso modelo para prever a sobrevida em um tempo específico de nosso interesse.\nVamos começar salvando nosso modelo em uma variável\n\n# Ajuste do modelo de regressão de Cox\ncox_res &lt;- coxph(Surv(time = t_seg, event = obito) ~ tx, data = db)\n\nAgora vamos criar um conjunto de dados com informações simuladas sobre tempo de seguimento, ocorrência de evento (óbito), e uma variável indicadora de tratamento. Como queremos comparar o tempo de sobrevida entre quem fez ou não o transplante, a única variável que terá valores diferentes será a tx.\n\npred_dat &lt;- data.frame(t_seg = c(41,41),\n                       obito = c(0,0), \n                       tx = c(\"sim\",\"não\")\n                       )\nkable(pred_dat)\n\n\n\n\nt_seg\nobito\ntx\n\n\n\n\n41\n0\nsim\n\n\n41\n0\nnão\n\n\n\n\n\n\n\nA seguir vamos utiliza a função predict() para fazer previsões com base em nosso modelo previamente ajustado (cox_res).\n\npreds &lt;- predict(cox_res, newdata = pred_dat, type = \"survival\", se.fit = TRUE)\n\nSalvamos o resultado da função em uma variável para poder adicionar os resultados das predições em nosso dataframe criado anteriormente (pred_dat). Queremos os resultados da média e do Intervalo de Confiança. Para isso executamos o código a seguir:\n\npred_dat$prob &lt;- preds$fit\npred_dat$lcl &lt;- preds$fit - 1.96*preds$se.fit\npred_dat$ucl &lt;- preds$fit + 1.96*preds$se.fit\nkable(pred_dat)\n\n\n\n\nt_seg\nobito\ntx\nprob\nlcl\nucl\n\n\n\n\n41\n0\nsim\n0.8630231\n0.7805057\n0.9455404\n\n\n41\n0\nnão\n0.6484075\n0.5224067\n0.7744083\n\n\n\n\n\n\n\nPor fim, podemos finalmente verificar o Hazard Ratio no tempo de 41 meses, dividindo a probabilidade de sobrevida do grupo que fez o transplante pela probabilidade de sobrevida do grupo que não fez o transplante.\n\nHR_41 = pred_dat$prob[1] / pred_dat$prob[2] # Diferença na sobrevida (HR) no tempo 41 meses \nHR_41\n\n[1] 1.330989\n\n\n\nTemos que no tempo de 41 meses a probabilidade de sobrevida de quem não fez o transplante é 1.33 menor do que quem fez o transplante.\nCaso tenha interesse em mais pontos, podemos criar vários tempos de interesse em um único dataframe e repetir o código.\n\nmulti_pred_dat &lt;- data.frame(t_seg = c(41,41, 50, 50, 80, 80),\n                       obito = c(0,0,0,0,0,0), \n                       tx = c(\"sim\",\"não\",\"sim\",\"não\",\"sim\",\"não\")\n                       )\n\npreds &lt;- predict(cox_res, newdata = multi_pred_dat, type = \"survival\", se.fit = TRUE)\n\nmulti_pred_dat$prob &lt;- preds$fit\nmulti_pred_dat$lcl &lt;- preds$fit - 1.96*preds$se.fit\nmulti_pred_dat$ucl &lt;- preds$fit + 1.96*preds$se.fit\n\nHR_41 = multi_pred_dat$prob[1] / multi_pred_dat$prob[2] # 41 \nHR_50 = multi_pred_dat$prob[3] / multi_pred_dat$prob[4] # 50 \nHR_80 = multi_pred_dat$prob[5] / multi_pred_dat$prob[6] # 80 \n\ntabela_HR = data.frame(Tempo = c(41, 50, 80),\n                       HR_Não = c(HR_41, HR_50, HR_80))\nkable(tabela_HR)\n\n\n\n\nTempo\nHR_Não\n\n\n\n\n41\n1.330989\n\n\n50\n1.454309\n\n\n80\n1.597592"
  },
  {
    "objectID": "lista_6.html#verificando-os-pressupostos-da-cox-regression",
    "href": "lista_6.html#verificando-os-pressupostos-da-cox-regression",
    "title": "6  Lista 6 - Kaplan-Meier e Cox Regression",
    "section": "6.13 Verificando os pressupostos da Cox regression",
    "text": "6.13 Verificando os pressupostos da Cox regression\nA Regressão de Cox é uma técnica robusta, mas, como qualquer método estatístico, possui alguns pressupostos importantes. Os principais pressupostos da Regressão de Cox são:\n\nProporcionalidade dos Riscos:\n\nO pressuposto fundamental é que os riscos relativos entre dois grupos são constantes ao longo do tempo. Em outras palavras, a razão instantânea de riscos (hazard ratio) entre grupos não muda com o tempo. Este é o pressuposto de proporcionalidade dos riscos.\n\nIndependência Censura:\n\nA censura dos dados deve ser independente da probabilidade de falha. Isso significa que a probabilidade de um evento censurado (ocorrido após o fim do acompanhamento) deve ser a mesma para todos os grupos.\n\nLinearidade no Logaritmo dos Riscos:\n\nA relação entre as variáveis independentes e o logaritmo do risco deve ser linear. Isso é crucial para a interpretação dos coeficientes como log-riscos instantâneos.\n\nAuscência de Colinearidade:\n\nAs variáveis independentes no modelo não devem estar altamente correlacionadas (colinearidade). A colinearidade pode levar a estimativas imprecisas dos coeficientes.\n\nAusência de Efeito de Interferência:\n\nNão deve haver efeito de interferência entre indivíduos, o que significa que o status de um indivíduo não deve influenciar diretamente o tempo de falha de outro indivíduo.\n\nAdequação do Modelo:\n\nO modelo escolhido deve ser apropriado para os dados. Avaliações de adequação, como testes de resíduos, podem ser úteis para verificar a qualidade do ajuste do modelo aos dados.\n\n\nOs pressupostos de 2 a 6 são inerentes ao desenho do experimento e do acompanhamento durante as observações. O único que vamos abordar aqui no tutorial é o de proporcionalidade dos riscos.\n\nProporcionalidade dos riscos\nTemos duas formas de avaliar a proporcionalidade dos riscos\n\n1) Análise do gráfico da Kaplan-Meier\nAo analisar o gráfico de Kaplan-Meier para diferentes grupos, é crucial observar se as curvas de sobrevivência são aproximadamente paralelas ou se cruzam entre si. Se as curvas são paralelas, isso sugere proporcionalidade dos riscos, indicando que as diferenças nas taxas de falha entre os grupos são constantes ao longo do tempo. No entanto, se as curvas se cruzam, isso indica uma possível violação da proporcionalidade dos riscos.\nCruzamentos nas curvas podem indicar mudanças na relação de risco entre os grupos ao longo do tempo. Essa mudança pode ser devido a diferentes dinâmicas de risco em períodos distintos do estudo. Se as curvas se cruzarem, a aplicação da Regressão de Cox não deve ser feita para não gerar interpretações erradas!\n\nfit2_km\n\n\n\n\nPodemos observar que em nosso exemplo as linhas de sobrevida não cruzam, portanto podemos assumir que os riscos são proporcionais pela análise gráfica.\n\n\n2) Resíduos de Schoenfeld\nA segunda forma para se avaliar a suposição de proporcionalidade dos riscos na Regressão de Cox vamos utilizar o teste de Schoenfeld, que verifica se há uma relação sistemática entre os resíduos de Schoenfeld e o tempo, o que indicaria uma violação dessa suposição.\nA ideia central é que, se os resíduos de Schoenfeld não apresentarem uma relação significativa com o tempo, isso sugere que a proporcionalidade dos riscos é razoável. Logo, a hipótese nula é que não há relação entre os resíduos e o tempo, o que indicaria proporcionalidade dos riscos. O teste estatístico avalia se é razoável rejeitar essa hipótese nula.\n\n\n\n\n\n\nImportante!\n\n\n\nVamos torcer para o valor de p ser MAIOR que 0.05!\n\n\nUtilizando a função cox.zph() do pacote survival temos o seguinte código:\n\ntest &lt;- survival::cox.zph(cox_res)\ntest\n\n       chisq df    p\ntx      0.58  1 0.45\nGLOBAL  0.58  1 0.45\n\n\nOk! Temos riscos proporcionais!\nOutra forma de verificar a proporcionalidade dos riscos é com o gráfico dos resíduos de Schoenfeld.\n\n# Plot the Schoenfeld residuals over time for each covariate\nsurvminer::ggcoxzph(test, point.size = 0.1)[1]\n\n$`1`\n\n\n\n\n\nSe os resíduos mostrarem um padrão claro ao longo do tempo, isso pode indicar uma violação da suposição de riscos proporcionais.\nAlgumas dicas para ajudar na interpretação:\n\nSem Padrão (Resíduos Constantes): Se os resíduos aparecerem aleatoriamente espalhados em torno de zero, sem nenhuma tendência ou padrão claro, isso sugere que a suposição de riscos proporcionais é razoável.\nTendência Linear: Uma tendência linear (aumentando ou diminuindo) nos resíduos ao longo do tempo pode sugerir uma violação da suposição de riscos proporcionais. Por exemplo, se os resíduos forem consistentemente positivos ou negativos ao longo do tempo, isso indica um efeito dependente do tempo.\nPadrão Não Linear: Se os resíduos exibirem um padrão não linear ou formatos específicos (por exemplo, formato de U, formato de V), isso pode indicar desvios dos riscos proporcionais.\nParalelismo: Paralelismo significa que a propagação e distribuição dos resíduos são relativamente constantes ao longo do tempo. Se os resíduos aumentarem ou diminuirem ao longo do tempo, isso pode sugerir uma violação da suposição."
  },
  {
    "objectID": "lista_6.html#conlcusões",
    "href": "lista_6.html#conlcusões",
    "title": "6  Lista 6 - Kaplan-Meier e Cox Regression",
    "section": "6.14 Conlcusões",
    "text": "6.14 Conlcusões\nMuito bacana a análise de sobrevida e a Regressão de Cox! Na seção Extras! vamos ver mais algumas formas de plotar os gráficos e avaliar a proporcionalidade dos riscos caso a Variável Independente seja contínua!\nPróximo capitulo: Cox tempo-dependente!"
  },
  {
    "objectID": "lista_6.html#lista-6-resolvida-no-spss",
    "href": "lista_6.html#lista-6-resolvida-no-spss",
    "title": "6  Lista 6 - Kaplan-Meier e Cox Regression",
    "section": "6.15 Lista 6 resolvida no SPSS",
    "text": "6.15 Lista 6 resolvida no SPSS"
  },
  {
    "objectID": "lista_6.html#sec-extrasVI",
    "href": "lista_6.html#sec-extrasVI",
    "title": "6  Lista 6 - Kaplan-Meier e Cox Regression",
    "section": "6.16 Extras!",
    "text": "6.16 Extras!\n\nEvento como fator ou como número\nComo mencionado na seção Section 6.4, o tipo da variável do evento (morte) afeta os resultados tanto da Kaplan-Meir quanto na Regressão de Cox.\nVamos criar alguns modelos utilizando o banco de dados original (variável óbito é um fator) e também o db (variável óbito é binária, 1 e 0).\nVamos começar observando a diferença do tipo da variável nos bancos utilizando a função glimpse():\n\nglimpse(original$obito)\n\n Factor w/ 2 levels \"não\",\"sim\": 1 1 1 1 1 1 1 1 2 1 ...\n\n\n\nglimpse(db$obito)\n\n int [1:124] 0 0 0 0 0 0 0 0 1 0 ...\n\n\nE tem mais! Temos que lembrar que quando deixamos as variáveis como fatores elas sempre possuem um nível de referência. Já verificamos isso em outros exercícios utilizando a função levels().\n\nlevels(original$obito)\n\n[1] \"não\" \"sim\"\n\n\nVeja só! A referência para a variável óbito é o “não”. Para fins didáditcos vamos criar três modelos:\nÓbito como variável binária (banco db) Óbito como fator com nível de referência “não” (banco original) Óbito como fator com nível de referência “sim” (banco original_sim)\n\noriginal_sim = original\noriginal_sim$obito = relevel(original_sim$obito, ref = \"sim\")\n\nAgora vamos repetir todo o procedimento já demonstrado no início das análises, utilizando os três bancos de dados.\n\nsurv_db &lt;- Surv(time = db$t_seg, event = db$obito)\nsurv_oiriginal_não &lt;- Surv(time = original$t_seg, event = original$obito)\nsurv_oiriginal_sim &lt;- Surv(time = original_sim$t_seg, event = original_sim$obito)\n\n\nfit_db &lt;- survfit(surv_db ~ 1, data = db)\nfit_original_não &lt;- survfit(surv_oiriginal_não ~ 1, data = original)\nfit_original_sim &lt;- survfit(surv_oiriginal_sim ~ 1, data = original_sim)\n\n\nplot(fit_db)\n\n\n\nplot(fit_original_não)\n\n\n\nplot(fit_original_sim)\n\n\n\n\n\nggsurvfit(fit_db, linewidth = 1) +\n  ggtitle(\"Binário\") +\n  labs(x = 'Dias', y = 'Overall survival') +\n  add_confidence_interval() +\n    add_risktable() +\n  scale_ggsurvfit() \n\n\n\nggcuminc(fit_original_não, linewidth = 1, type = \"survival\" ) +\n  ggtitle(\"Fator - Lelvel = Não\") +\n  labs(x = 'Dias', y = 'Overall survival') +\n  add_confidence_interval() +\n  add_risktable() +\n  scale_ggsurvfit() \n\nPlotting outcome \"sim\".\n\n\nWarning in ggplot2::geom_step(ggplot2::aes(x = .data$time, y = .data$estimate),\n: Ignoring unknown parameters: `type`\n\n\n\n\nggcuminc(fit_original_sim, linewidth = 1) +\n  ggtitle(\"Fator - Lelvel = Sim\") +\n  labs(x = 'Dias', y = 'Overall survival') +\n  add_confidence_interval() +\n  add_risktable() +\n  scale_ggsurvfit() \n\nPlotting outcome \"não\".\n\n\n\n\n\nComo podemos observar, quando utilizamos a variável de evento como um fator, acabamos analisando o risco cumulativo e não a sobrevida.\n\n\nMais gráficos!\nCom o ggplot2\n\nkm_plot = survfit2(surv_obj ~ tx, data = db) %&gt;%\n  tidy_survfit() %&gt;%\n  ggplot(aes(x = time, y = estimate,\n             min = conf.low, ymax = conf.low,\n             color = strata, fill = strata)) +\n  geom_step()\n\nkm_plot\n\n\n\n\nCom a função ggsurvplot() do pacote survminer.\n\nggsurvplot(fit2, data = db,\n           size = 1,\n           palette = c('#E7B800', '#2e9fdf'),\n           censor.shape = '|', censor.size = 4,\n           conf.int = TRUE,\n           pval = TRUE,\n           risk.table = TRUE,\n           risk.table.col = 'strata',\n           legend.labs = list('0' = 'Transplante = sim', '1' = 'Transplante = não'),\n           risk.table.height = 0.25,\n           ggtheme = theme_bw())\n\n\n\n\nGráficos de proporcionalidade com outras funções\n\nggcoxdiagnostics(cox_res, type = \"dfbeta\", linear.predictions = FALSE)\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\nE um específico para variáveis contínuas.\n\n# Não é importante para variáveis categóricas, mas fica o código para eventual consulta.\nggcoxdiagnostics(cox_res, type = \"deviance\", linear.predictions = FALSE)\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\nPacots alternativos para comparar curvas\n\ngehan.wilcoxon.test(surv_obj ~ tx ,data=db)\n\n\n    Gehan-Wilcoxon\n\ndata:  \n= 9.1531, p-value = 0.002483\nalternative hypothesis: two-sided\n\n\nsurvdiff Com rho = 0 este é o teste log-rank ou Mantel-Haenszel, e com rho = 1 é equivalente à modificação Peto & Peto do teste Gehan-Wilcoxon.\n\nsurvdiff(surv_obj ~ tx, data=db, rho = 2)\n\nCall:\nsurvdiff(formula = surv_obj ~ tx, data = db, rho = 2)\n\n        N Observed Expected (O-E)^2/E (O-E)^2/V\ntx=sim 60      7.4     14.0      3.12      9.19\ntx=não 64     17.9     11.3      3.89      9.19\n\n Chisq= 9.2  on 1 degrees of freedom, p= 0.002 \n\n\n\n\nTabela completa do modelo 2\n\nlife_table2 = survfit2(Surv(time = t_seg, event = obito) ~ tx, data = db) %&gt;%\n  tidy_survfit() \n\nkable(life_table2)\n\n\n\n\ntime\nn.risk\nn.event\nn.censor\ncum.event\ncum.censor\nestimate\nstd.error\nconf.high\nconf.low\nstrata\nestimate_type\nestimate_type_label\nmonotonicity_type\nstrata_label\nconf.level\n\n\n\n\n0\n60\n0\n1\n0\n1\n1.0000000\n0.0000000\n1.0000000\n1.0000000\nsim\nsurvival\nSurvival Probability\ndecreasing\ntx\n0.95\n\n\n3\n59\n1\n0\n1\n1\n0.9830508\n0.0170946\n1.0000000\n0.9506595\nsim\nsurvival\nSurvival Probability\ndecreasing\ntx\n0.95\n\n\n4\n58\n1\n0\n2\n1\n0.9661017\n0.0243866\n1.0000000\n0.9210112\nsim\nsurvival\nSurvival Probability\ndecreasing\ntx\n0.95\n\n\n24\n57\n1\n0\n3\n1\n0.9491525\n0.0301329\n1.0000000\n0.8947194\nsim\nsurvival\nSurvival Probability\ndecreasing\ntx\n0.95\n\n\n26\n56\n1\n0\n4\n1\n0.9322034\n0.0351093\n0.9986097\n0.8702130\nsim\nsurvival\nSurvival Probability\ndecreasing\ntx\n0.95\n\n\n29\n55\n1\n0\n5\n1\n0.9152542\n0.0396152\n0.9891503\n0.8468787\nsim\nsurvival\nSurvival Probability\ndecreasing\ntx\n0.95\n\n\n32\n54\n0\n3\n5\n4\n0.9152542\n0.0396152\n0.9891503\n0.8468787\nsim\nsurvival\nSurvival Probability\ndecreasing\ntx\n0.95\n\n\n34\n51\n0\n1\n5\n5\n0.9152542\n0.0396152\n0.9891503\n0.8468787\nsim\nsurvival\nSurvival Probability\ndecreasing\ntx\n0.95\n\n\n35\n50\n0\n3\n5\n8\n0.9152542\n0.0396152\n0.9891503\n0.8468787\nsim\nsurvival\nSurvival Probability\ndecreasing\ntx\n0.95\n\n\n36\n47\n0\n1\n5\n9\n0.9152542\n0.0396152\n0.9891503\n0.8468787\nsim\nsurvival\nSurvival Probability\ndecreasing\ntx\n0.95\n\n\n37\n46\n0\n2\n5\n11\n0.9152542\n0.0396152\n0.9891503\n0.8468787\nsim\nsurvival\nSurvival Probability\ndecreasing\ntx\n0.95\n\n\n38\n44\n1\n0\n6\n11\n0.8944530\n0.0458029\n0.9784644\n0.8176548\nsim\nsurvival\nSurvival Probability\ndecreasing\ntx\n0.95\n\n\n39\n43\n0\n1\n6\n12\n0.8944530\n0.0458029\n0.9784644\n0.8176548\nsim\nsurvival\nSurvival Probability\ndecreasing\ntx\n0.95\n\n\n40\n42\n0\n1\n6\n13\n0.8944530\n0.0458029\n0.9784644\n0.8176548\nsim\nsurvival\nSurvival Probability\ndecreasing\ntx\n0.95\n\n\n41\n41\n1\n0\n7\n13\n0.8726371\n0.0520352\n0.9663315\n0.7880272\nsim\nsurvival\nSurvival Probability\ndecreasing\ntx\n0.95\n\n\n42\n40\n0\n2\n7\n15\n0.8726371\n0.0520352\n0.9663315\n0.7880272\nsim\nsurvival\nSurvival Probability\ndecreasing\ntx\n0.95\n\n\n44\n38\n0\n1\n7\n16\n0.8726371\n0.0520352\n0.9663315\n0.7880272\nsim\nsurvival\nSurvival Probability\ndecreasing\ntx\n0.95\n\n\n45\n37\n1\n1\n8\n17\n0.8490523\n0.0588083\n0.9527789\n0.7566181\nsim\nsurvival\nSurvival Probability\ndecreasing\ntx\n0.95\n\n\n46\n35\n0\n1\n8\n18\n0.8490523\n0.0588083\n0.9527789\n0.7566181\nsim\nsurvival\nSurvival Probability\ndecreasing\ntx\n0.95\n\n\n48\n34\n0\n2\n8\n20\n0.8490523\n0.0588083\n0.9527789\n0.7566181\nsim\nsurvival\nSurvival Probability\ndecreasing\ntx\n0.95\n\n\n49\n32\n1\n2\n9\n22\n0.8225194\n0.0668317\n0.9376341\n0.7215375\nsim\nsurvival\nSurvival Probability\ndecreasing\ntx\n0.95\n\n\n51\n29\n0\n1\n9\n23\n0.8225194\n0.0668317\n0.9376341\n0.7215375\nsim\nsurvival\nSurvival Probability\ndecreasing\ntx\n0.95\n\n\n52\n28\n0\n1\n9\n24\n0.8225194\n0.0668317\n0.9376341\n0.7215375\nsim\nsurvival\nSurvival Probability\ndecreasing\ntx\n0.95\n\n\n54\n27\n0\n1\n9\n25\n0.8225194\n0.0668317\n0.9376341\n0.7215375\nsim\nsurvival\nSurvival Probability\ndecreasing\ntx\n0.95\n\n\n55\n26\n0\n4\n9\n29\n0.8225194\n0.0668317\n0.9376341\n0.7215375\nsim\nsurvival\nSurvival Probability\ndecreasing\ntx\n0.95\n\n\n57\n22\n0\n1\n9\n30\n0.8225194\n0.0668317\n0.9376341\n0.7215375\nsim\nsurvival\nSurvival Probability\ndecreasing\ntx\n0.95\n\n\n65\n21\n0\n2\n9\n32\n0.8225194\n0.0668317\n0.9376341\n0.7215375\nsim\nsurvival\nSurvival Probability\ndecreasing\ntx\n0.95\n\n\n66\n19\n1\n1\n10\n33\n0.7792289\n0.0859678\n0.9222336\n0.6583990\nsim\nsurvival\nSurvival Probability\ndecreasing\ntx\n0.95\n\n\n67\n17\n0\n1\n10\n34\n0.7792289\n0.0859678\n0.9222336\n0.6583990\nsim\nsurvival\nSurvival Probability\ndecreasing\ntx\n0.95\n\n\n73\n16\n0\n1\n10\n35\n0.7792289\n0.0859678\n0.9222336\n0.6583990\nsim\nsurvival\nSurvival Probability\ndecreasing\ntx\n0.95\n\n\n74\n15\n0\n1\n10\n36\n0.7792289\n0.0859678\n0.9222336\n0.6583990\nsim\nsurvival\nSurvival Probability\ndecreasing\ntx\n0.95\n\n\n75\n14\n0\n1\n10\n37\n0.7792289\n0.0859678\n0.9222336\n0.6583990\nsim\nsurvival\nSurvival Probability\ndecreasing\ntx\n0.95\n\n\n77\n13\n0\n1\n10\n38\n0.7792289\n0.0859678\n0.9222336\n0.6583990\nsim\nsurvival\nSurvival Probability\ndecreasing\ntx\n0.95\n\n\n82\n12\n0\n1\n10\n39\n0.7792289\n0.0859678\n0.9222336\n0.6583990\nsim\nsurvival\nSurvival Probability\ndecreasing\ntx\n0.95\n\n\n83\n11\n0\n2\n10\n41\n0.7792289\n0.0859678\n0.9222336\n0.6583990\nsim\nsurvival\nSurvival Probability\ndecreasing\ntx\n0.95\n\n\n87\n9\n0\n1\n10\n42\n0.7792289\n0.0859678\n0.9222336\n0.6583990\nsim\nsurvival\nSurvival Probability\ndecreasing\ntx\n0.95\n\n\n89\n8\n1\n0\n11\n42\n0.6818253\n0.1588949\n0.9309465\n0.4993689\nsim\nsurvival\nSurvival Probability\ndecreasing\ntx\n0.95\n\n\n90\n7\n0\n1\n11\n43\n0.6818253\n0.1588949\n0.9309465\n0.4993689\nsim\nsurvival\nSurvival Probability\ndecreasing\ntx\n0.95\n\n\n92\n6\n0\n1\n11\n44\n0.6818253\n0.1588949\n0.9309465\n0.4993689\nsim\nsurvival\nSurvival Probability\ndecreasing\ntx\n0.95\n\n\n96\n5\n0\n1\n11\n45\n0.6818253\n0.1588949\n0.9309465\n0.4993689\nsim\nsurvival\nSurvival Probability\ndecreasing\ntx\n0.95\n\n\n97\n4\n0\n2\n11\n47\n0.6818253\n0.1588949\n0.9309465\n0.4993689\nsim\nsurvival\nSurvival Probability\ndecreasing\ntx\n0.95\n\n\n98\n2\n0\n1\n11\n48\n0.6818253\n0.1588949\n0.9309465\n0.4993689\nsim\nsurvival\nSurvival Probability\ndecreasing\ntx\n0.95\n\n\n99\n1\n0\n1\n11\n49\n0.6818253\n0.1588949\n0.9309465\n0.4993689\nsim\nsurvival\nSurvival Probability\ndecreasing\ntx\n0.95\n\n\n0\n64\n2\n0\n2\n0\n0.9687500\n0.0224507\n1.0000000\n0.9270468\nnão\nsurvival\nSurvival Probability\ndecreasing\ntx\n0.95\n\n\n3\n62\n1\n0\n3\n0\n0.9531250\n0.0277208\n1.0000000\n0.9027217\nnão\nsurvival\nSurvival Probability\ndecreasing\ntx\n0.95\n\n\n4\n61\n1\n0\n4\n0\n0.9375000\n0.0322749\n0.9987199\n0.8800328\nnão\nsurvival\nSurvival Probability\ndecreasing\ntx\n0.95\n\n\n6\n60\n1\n0\n5\n0\n0.9218750\n0.0363889\n0.9900254\n0.8584159\nnão\nsurvival\nSurvival Probability\ndecreasing\ntx\n0.95\n\n\n8\n59\n2\n0\n7\n0\n0.8906250\n0.0438048\n0.9704688\n0.8173502\nnão\nsurvival\nSurvival Probability\ndecreasing\ntx\n0.95\n\n\n11\n57\n1\n0\n8\n0\n0.8750000\n0.0472456\n0.9598946\n0.7976136\nnão\nsurvival\nSurvival Probability\ndecreasing\ntx\n0.95\n\n\n13\n56\n1\n0\n9\n0\n0.8593750\n0.0505650\n0.9489071\n0.7782905\nnão\nsurvival\nSurvival Probability\ndecreasing\ntx\n0.95\n\n\n14\n55\n0\n1\n9\n1\n0.8593750\n0.0505650\n0.9489071\n0.7782905\nnão\nsurvival\nSurvival Probability\ndecreasing\ntx\n0.95\n\n\n15\n54\n0\n1\n9\n2\n0.8593750\n0.0505650\n0.9489071\n0.7782905\nnão\nsurvival\nSurvival Probability\ndecreasing\ntx\n0.95\n\n\n16\n53\n1\n0\n10\n2\n0.8431604\n0.0540339\n0.9373546\n0.7584316\nnão\nsurvival\nSurvival Probability\ndecreasing\ntx\n0.95\n\n\n18\n52\n0\n1\n10\n3\n0.8431604\n0.0540339\n0.9373546\n0.7584316\nnão\nsurvival\nSurvival Probability\ndecreasing\ntx\n0.95\n\n\n19\n51\n1\n0\n11\n3\n0.8266278\n0.0575484\n0.9253272\n0.7384562\nnão\nsurvival\nSurvival Probability\ndecreasing\ntx\n0.95\n\n\n22\n50\n0\n1\n11\n4\n0.8266278\n0.0575484\n0.9253272\n0.7384562\nnão\nsurvival\nSurvival Probability\ndecreasing\ntx\n0.95\n\n\n24\n49\n1\n0\n12\n4\n0.8097579\n0.0611309\n0.9128300\n0.7183241\nnão\nsurvival\nSurvival Probability\ndecreasing\ntx\n0.95\n\n\n25\n48\n1\n0\n13\n4\n0.7928879\n0.0646549\n0.9000075\n0.6985178\nnão\nsurvival\nSurvival Probability\ndecreasing\ntx\n0.95\n\n\n27\n47\n1\n0\n14\n4\n0.7760180\n0.0681380\n0.8868924\n0.6790044\nnão\nsurvival\nSurvival Probability\ndecreasing\ntx\n0.95\n\n\n29\n46\n0\n1\n14\n5\n0.7760180\n0.0681380\n0.8868924\n0.6790044\nnão\nsurvival\nSurvival Probability\ndecreasing\ntx\n0.95\n\n\n30\n45\n0\n4\n14\n9\n0.7760180\n0.0681380\n0.8868924\n0.6790044\nnão\nsurvival\nSurvival Probability\ndecreasing\ntx\n0.95\n\n\n31\n41\n0\n1\n14\n10\n0.7760180\n0.0681380\n0.8868924\n0.6790044\nnão\nsurvival\nSurvival Probability\ndecreasing\ntx\n0.95\n\n\n32\n40\n0\n2\n14\n12\n0.7760180\n0.0681380\n0.8868924\n0.6790044\nnão\nsurvival\nSurvival Probability\ndecreasing\ntx\n0.95\n\n\n34\n38\n3\n0\n17\n12\n0.7147534\n0.0830568\n0.8411128\n0.6073768\nnão\nsurvival\nSurvival Probability\ndecreasing\ntx\n0.95\n\n\n36\n35\n1\n5\n18\n17\n0.6943319\n0.0879702\n0.8249877\n0.5843684\nnão\nsurvival\nSurvival Probability\ndecreasing\ntx\n0.95\n\n\n37\n29\n0\n3\n18\n20\n0.6943319\n0.0879702\n0.8249877\n0.5843684\nnão\nsurvival\nSurvival Probability\ndecreasing\ntx\n0.95\n\n\n40\n26\n1\n1\n19\n21\n0.6676268\n0.0963183\n0.8063435\n0.5527738\nnão\nsurvival\nSurvival Probability\ndecreasing\ntx\n0.95\n\n\n41\n24\n1\n0\n20\n21\n0.6398090\n0.1053035\n0.7864748\n0.5204942\nnão\nsurvival\nSurvival Probability\ndecreasing\ntx\n0.95\n\n\n42\n23\n0\n2\n20\n23\n0.6398090\n0.1053035\n0.7864748\n0.5204942\nnão\nsurvival\nSurvival Probability\ndecreasing\ntx\n0.95\n\n\n44\n21\n1\n2\n21\n25\n0.6093419\n0.1160593\n0.7649815\n0.4853680\nnão\nsurvival\nSurvival Probability\ndecreasing\ntx\n0.95\n\n\n46\n18\n1\n2\n22\n27\n0.5754896\n0.1293744\n0.7415854\n0.4465949\nnão\nsurvival\nSurvival Probability\ndecreasing\ntx\n0.95\n\n\n50\n15\n0\n1\n22\n28\n0.5754896\n0.1293744\n0.7415854\n0.4465949\nnão\nsurvival\nSurvival Probability\ndecreasing\ntx\n0.95\n\n\n51\n14\n0\n1\n22\n29\n0.5754896\n0.1293744\n0.7415854\n0.4465949\nnão\nsurvival\nSurvival Probability\ndecreasing\ntx\n0.95\n\n\n54\n13\n0\n1\n22\n30\n0.5754896\n0.1293744\n0.7415854\n0.4465949\nnão\nsurvival\nSurvival Probability\ndecreasing\ntx\n0.95\n\n\n56\n12\n0\n1\n22\n31\n0.5754896\n0.1293744\n0.7415854\n0.4465949\nnão\nsurvival\nSurvival Probability\ndecreasing\ntx\n0.95\n\n\n58\n11\n1\n3\n23\n34\n0.5231723\n0.1607130\n0.7168758\n0.3818086\nnão\nsurvival\nSurvival Probability\ndecreasing\ntx\n0.95\n\n\n60\n7\n0\n1\n23\n35\n0.5231723\n0.1607130\n0.7168758\n0.3818086\nnão\nsurvival\nSurvival Probability\ndecreasing\ntx\n0.95\n\n\n65\n6\n0\n1\n23\n36\n0.5231723\n0.1607130\n0.7168758\n0.3818086\nnão\nsurvival\nSurvival Probability\ndecreasing\ntx\n0.95\n\n\n71\n5\n0\n1\n23\n37\n0.5231723\n0.1607130\n0.7168758\n0.3818086\nnão\nsurvival\nSurvival Probability\ndecreasing\ntx\n0.95\n\n\n77\n4\n0\n1\n23\n38\n0.5231723\n0.1607130\n0.7168758\n0.3818086\nnão\nsurvival\nSurvival Probability\ndecreasing\ntx\n0.95\n\n\n80\n3\n0\n1\n23\n39\n0.5231723\n0.1607130\n0.7168758\n0.3818086\nnão\nsurvival\nSurvival Probability\ndecreasing\ntx\n0.95\n\n\n82\n2\n0\n1\n23\n40\n0.5231723\n0.1607130\n0.7168758\n0.3818086\nnão\nsurvival\nSurvival Probability\ndecreasing\ntx\n0.95\n\n\n97\n1\n0\n1\n23\n41\n0.5231723\n0.1607130\n0.7168758\n0.3818086\nnão\nsurvival\nSurvival Probability\ndecreasing\ntx\n0.95\n\n\n\n\n\n\nsummary(life_table2)\n\n      time           n.risk        n.event          n.censor    \n Min.   : 0.00   Min.   : 1.0   Min.   :0.0000   Min.   :0.000  \n 1st Qu.:28.00   1st Qu.:13.5   1st Qu.:0.0000   1st Qu.:0.000  \n Median :42.00   Median :34.0   Median :0.0000   Median :1.000  \n Mean   :46.25   Mean   :31.9   Mean   :0.4096   Mean   :1.084  \n 3rd Qu.:65.50   3rd Qu.:50.0   3rd Qu.:1.0000   3rd Qu.:1.000  \n Max.   :99.00   Max.   :64.0   Max.   :3.0000   Max.   :5.000  \n   cum.event       cum.censor       estimate        std.error      \n Min.   : 0.00   Min.   : 0.00   Min.   :0.5232   Min.   :0.00000  \n 1st Qu.: 7.00   1st Qu.: 4.00   1st Qu.:0.6818   1st Qu.:0.05056  \n Median :10.00   Median :20.00   Median :0.7929   Median :0.06683  \n Mean   :11.48   Mean   :20.04   Mean   :0.7757   Mean   :0.08234  \n 3rd Qu.:14.00   3rd Qu.:34.50   3rd Qu.:0.8726   3rd Qu.:0.11068  \n Max.   :23.00   Max.   :49.00   Max.   :1.0000   Max.   :0.16071  \n   conf.high         conf.low      strata   estimate_type     \n Min.   :0.7169   Min.   :0.3818   sim:43   Length:83         \n 1st Qu.:0.8869   1st Qu.:0.5099   não:40   Class :character  \n Median :0.9309   Median :0.6985            Mode  :character  \n Mean   :0.9015   Mean   :0.6716                              \n 3rd Qu.:0.9663   3rd Qu.:0.7880                              \n Max.   :1.0000   Max.   :1.0000                              \n estimate_type_label monotonicity_type  strata_label         conf.level  \n Length:83           Length:83          Length:83          Min.   :0.95  \n Class :character    Class :character   Class :character   1st Qu.:0.95  \n Mode  :character    Mode  :character   Mode  :character   Median :0.95  \n                                                           Mean   :0.95  \n                                                           3rd Qu.:0.95  \n                                                           Max.   :0.95  \n\nsummary(life_table2, times = tempos_específicos)\n\n      time           n.risk        n.event          n.censor    \n Min.   : 0.00   Min.   : 1.0   Min.   :0.0000   Min.   :0.000  \n 1st Qu.:28.00   1st Qu.:13.5   1st Qu.:0.0000   1st Qu.:0.000  \n Median :42.00   Median :34.0   Median :0.0000   Median :1.000  \n Mean   :46.25   Mean   :31.9   Mean   :0.4096   Mean   :1.084  \n 3rd Qu.:65.50   3rd Qu.:50.0   3rd Qu.:1.0000   3rd Qu.:1.000  \n Max.   :99.00   Max.   :64.0   Max.   :3.0000   Max.   :5.000  \n   cum.event       cum.censor       estimate        std.error      \n Min.   : 0.00   Min.   : 0.00   Min.   :0.5232   Min.   :0.00000  \n 1st Qu.: 7.00   1st Qu.: 4.00   1st Qu.:0.6818   1st Qu.:0.05056  \n Median :10.00   Median :20.00   Median :0.7929   Median :0.06683  \n Mean   :11.48   Mean   :20.04   Mean   :0.7757   Mean   :0.08234  \n 3rd Qu.:14.00   3rd Qu.:34.50   3rd Qu.:0.8726   3rd Qu.:0.11068  \n Max.   :23.00   Max.   :49.00   Max.   :1.0000   Max.   :0.16071  \n   conf.high         conf.low      strata   estimate_type     \n Min.   :0.7169   Min.   :0.3818   sim:43   Length:83         \n 1st Qu.:0.8869   1st Qu.:0.5099   não:40   Class :character  \n Median :0.9309   Median :0.6985            Mode  :character  \n Mean   :0.9015   Mean   :0.6716                              \n 3rd Qu.:0.9663   3rd Qu.:0.7880                              \n Max.   :1.0000   Max.   :1.0000                              \n estimate_type_label monotonicity_type  strata_label         conf.level  \n Length:83           Length:83          Length:83          Min.   :0.95  \n Class :character    Class :character   Class :character   1st Qu.:0.95  \n Mode  :character    Mode  :character   Mode  :character   Median :0.95  \n                                                           Mean   :0.95  \n                                                           3rd Qu.:0.95  \n                                                           Max.   :0.95  \n\nhead(life_table2)\n\n# A tibble: 6 × 16\n   time n.risk n.event n.censor cum.event cum.censor estimate std.error\n  &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;      &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;\n1     0     60       0        1         0          1    1        0     \n2     3     59       1        0         1          1    0.983    0.0171\n3     4     58       1        0         2          1    0.966    0.0244\n4    24     57       1        0         3          1    0.949    0.0301\n5    26     56       1        0         4          1    0.932    0.0351\n6    29     55       1        0         5          1    0.915    0.0396\n# ℹ 8 more variables: conf.high &lt;dbl&gt;, conf.low &lt;dbl&gt;, strata &lt;fct&gt;,\n#   estimate_type &lt;chr&gt;, estimate_type_label &lt;chr&gt;, monotonicity_type &lt;chr&gt;,\n#   strata_label &lt;chr&gt;, conf.level &lt;dbl&gt;\n\n\n\n\nCódigo não usado\n\n# Create the new data  \nnew_df &lt;- with(db,\n               data.frame(tx = c(\"sim\", \"não\")\n               )\n)\nglimpse(new_df)\n\nRows: 2\nColumns: 1\n$ tx &lt;chr&gt; \"sim\", \"não\"\n\nnew_df$tx = as.factor(new_df$tx)\n\n\n# Survival curves with new data\n#%%%%%%%%%%%%%%%%%%%%%%%%%%%\nfit_cox &lt;- survfit(cox_res, newdata = new_df)\n\n\nggsurvplot(fit_cox, data = db,\n           size = 1,\n           palette = c('#E7B800', '#2e9fdf'),\n           censor.shape = '|', censor.size = 4,\n           conf.int = TRUE,\n           pval = TRUE,\n          # risk.table = TRUE,\n         #  risk.table.col = 'strata',\n           legend.labs = list('0' = 'Transplante = sim', '1' = 'Transplante = não'),\n           risk.table.height = 0.25,\n           ggtheme = theme_bw())\n\nWarning in .pvalue(fit, data = data, method = method, pval = pval, pval.coord = pval.coord, : There are no survival curves to be compared. \n This is a null model.\n\n\n\n\n\n\n\nPara salvar os valores de sobrevida\n\nsurv_fit_cox = survfit(cox_res)\n\n# Extrai os tempos de sobrevida e as estimativas de sobrevida\nsurv_df_cox &lt;- data.frame(time = surv_fit_cox$time, surv = surv_fit_cox$surv)\nsurv_df_cox\n\n   time      surv\n1     0 0.9919270\n2     3 0.9837071\n3     4 0.9754200\n4     6 0.9712508\n5     8 0.9628064\n6    11 0.9585298\n7    13 0.9542158\n8    14 0.9542158\n9    15 0.9542158\n10   16 0.9497436\n11   18 0.9497436\n12   19 0.9451662\n13   22 0.9451662\n14   24 0.9357670\n15   25 0.9310329\n16   26 0.9262516\n17   27 0.9214703\n18   29 0.9166403\n19   30 0.9166403\n20   31 0.9166403\n21   32 0.9166403\n22   34 0.8995899\n23   35 0.8995899\n24   36 0.8936099\n25   37 0.8936099\n26   38 0.8862225\n27   39 0.8862225\n28   40 0.8787730\n29   41 0.8630231\n30   42 0.8630231\n31   44 0.8544152\n32   45 0.8449676\n33   46 0.8354131\n34   48 0.8354131\n35   49 0.8245091\n36   50 0.8245091\n37   51 0.8245091\n38   52 0.8245091\n39   54 0.8245091\n40   55 0.8245091\n41   56 0.8245091\n42   57 0.8245091\n43   58 0.8091983\n44   60 0.8091983\n45   65 0.8091983\n46   66 0.7855423\n47   67 0.7855423\n48   71 0.7855423\n49   73 0.7855423\n50   74 0.7855423\n51   75 0.7855423\n52   77 0.7855423\n53   80 0.7855423\n54   82 0.7855423\n55   83 0.7855423\n56   87 0.7855423\n57   89 0.7169271\n58   90 0.7169271\n59   92 0.7169271\n60   96 0.7169271\n61   97 0.7169271\n62   98 0.7169271\n63   99 0.7169271"
  },
  {
    "objectID": "lista_6.html#referências",
    "href": "lista_6.html#referências",
    "title": "6  Lista 6 - Kaplan-Meier e Cox Regression",
    "section": "6.17 Referências",
    "text": "6.17 Referências\nhttps://bookdown.org/mpfoley1973/survival/semiparametric.html#fitting-the-model-1\nhttps://biostatsquid.com/easy-survival-analysis-r-tutorial/\nhttps://www.youtube.com/watch?v=XrvCCFQRCZE\nhttps://www.youtube.com/watch?v=vX3l36ptrTU&list=PLqzoL9-eJTNDdnKvep_YHIwk2AMqHhuJ0\nhttp://www.sthda.com/english/wiki/cox-proportional-hazards-model"
  },
  {
    "objectID": "lista_6.html#versões-dos-pacotes",
    "href": "lista_6.html#versões-dos-pacotes",
    "title": "6  Lista 6 - Kaplan-Meier e Cox Regression",
    "section": "6.18 Versões dos pacotes",
    "text": "6.18 Versões dos pacotes\n\nreport(sessionInfo())\n\nAnalyses were conducted using the R Statistical language (version 4.3.1; R Core\nTeam, 2023) on Windows 11 x64 (build 22621), using the packages effectsize\n(version 0.8.6; Ben-Shachar MS et al., 2020), lpSolve (version 5.6.19;\nBerkelaar M, others, 2023), survMisc (version 0.5.6; Dardis C, 2022), tm\n(version 0.7.11; Feinerer I, Hornik K, 2023), flexplot (version 0.20.5; Fife D,\n2024), lubridate (version 1.9.3; Grolemund G, Wickham H, 2011), coxphf (version\n1.13.4; Heinze G et al., 2023), NLP (version 0.2.1; Hornik K, 2020), coin\n(version 1.4.3; Hothorn T et al., 2006), ggpubr (version 0.6.0; Kassambara A,\n2023), survminer (version 0.4.9; Kassambara A et al., 2021),\nPHInfiniteEstimates (version 2.9.5; Kolassa JE, Zhang J, 2023), parameters\n(version 0.21.3; Lüdecke D et al., 2020), performance (version 0.10.8; Lüdecke\nD et al., 2021), easystats (version 0.6.0; Lüdecke D et al., 2022), see\n(version 0.8.1; Lüdecke D et al., 2021), insight (version 0.19.6; Lüdecke D et\nal., 2019), bayestestR (version 0.13.1; Makowski D et al., 2019), modelbased\n(version 0.8.6; Makowski D et al., 2020), report (version 0.5.7; Makowski D et\nal., 2023), correlation (version 0.8.4; Makowski D et al., 2022), condSURV\n(version 2.0.4; Meira-Machado L, Sestelo M, 2023), tibble (version 3.2.1;\nMüller K, Wickham H, 2023), datawizard (version 0.9.0; Patil I et al., 2022),\nforeign (version 0.8.85; R Core Team, 2023), nph (version 2.1; Ristl R et al.,\n2021), broom (version 1.0.5; Robinson D et al., 2023), ggsurvfit (version\n1.0.0; Sjoberg D et al., 2023), gtsummary (version 1.7.2; Sjoberg D et al.,\n2021), rempsyc (version 0.1.6; Thériault R, 2023), survival (version 3.5.7;\nTherneau T, 2023), ggplot2 (version 3.4.4; Wickham H, 2016), forcats (version\n1.0.0; Wickham H, 2023), stringr (version 1.5.1; Wickham H, 2023), tidyverse\n(version 2.0.0; Wickham H et al., 2019), dplyr (version 1.1.3; Wickham H et\nal., 2023), purrr (version 1.0.2; Wickham H, Henry L, 2023), readr (version\n2.1.4; Wickham H et al., 2023), tidyr (version 1.3.0; Wickham H et al., 2023)\nand kableExtra (version 1.3.4; Zhu H, 2021).\n\nReferences\n----------\n  - Ben-Shachar MS, Lüdecke D, Makowski D (2020). \"effectsize: Estimation of\nEffect Size Indices and Standardized Parameters.\" _Journal of Open Source\nSoftware_, *5*(56), 2815. doi:10.21105/joss.02815\n&lt;https://doi.org/10.21105/joss.02815&gt;, &lt;https://doi.org/10.21105/joss.02815&gt;.\n  - Berkelaar M, others (2023). _lpSolve: Interface to 'Lp_solve' v. 5.5 to Solve\nLinear/Integer Programs_. R package version 5.6.19,\n&lt;https://CRAN.R-project.org/package=lpSolve&gt;.\n  - Dardis C (2022). _survMisc: Miscellaneous Functions for Survival Data_. R\npackage version 0.5.6, &lt;https://CRAN.R-project.org/package=survMisc&gt;.\n  - Feinerer I, Hornik K (2023). _tm: Text Mining Package_. R package version\n0.7-11, &lt;https://CRAN.R-project.org/package=tm&gt;. Feinerer I, Hornik K, Meyer D\n(2008). \"Text Mining Infrastructure in R.\" _Journal of Statistical Software_,\n*25*(5), 1-54. doi:10.18637/jss.v025.i05\n&lt;https://doi.org/10.18637/jss.v025.i05&gt;.\n  - Fife D (2024). _flexplot: Graphically Based Data Analysis Using 'flexplot'_.\nR package version 0.20.5.\n  - Grolemund G, Wickham H (2011). \"Dates and Times Made Easy with lubridate.\"\n_Journal of Statistical Software_, *40*(3), 1-25.\n&lt;https://www.jstatsoft.org/v40/i03/&gt;.\n  - Heinze G, Ploner M, Jiricka L, Steiner G (2023). _coxphf: Cox Regression with\nFirth's Penalized Likelihood_. R package version 1.13.4,\n&lt;https://CRAN.R-project.org/package=coxphf&gt;.\n  - Hornik K (2020). _NLP: Natural Language Processing Infrastructure_. R package\nversion 0.2-1, &lt;https://CRAN.R-project.org/package=NLP&gt;.\n  - Hothorn T, Hornik K, van de Wiel MA, Zeileis A (2006). \"A Lego system for\nconditional inference.\" _The American Statistician_, *60*(3), 257-263.\ndoi:10.1198/000313006X118430 &lt;https://doi.org/10.1198/000313006X118430&gt;.\nHothorn T, Hornik K, van de Wiel MA, Zeileis A (2008). \"Implementing a class of\npermutation tests: The coin package.\" _Journal of Statistical Software_,\n*28*(8), 1-23. doi:10.18637/jss.v028.i08\n&lt;https://doi.org/10.18637/jss.v028.i08&gt;.\n  - Kassambara A (2023). _ggpubr: 'ggplot2' Based Publication Ready Plots_. R\npackage version 0.6.0, &lt;https://CRAN.R-project.org/package=ggpubr&gt;.\n  - Kassambara A, Kosinski M, Biecek P (2021). _survminer: Drawing Survival\nCurves using 'ggplot2'_. R package version 0.4.9,\n&lt;https://CRAN.R-project.org/package=survminer&gt;.\n  - Kolassa JE, Zhang J (2023). _PHInfiniteEstimates: Tools for Inference in the\nPresence of a Monotone Likelihood_. R package version 2.9.5,\n&lt;https://CRAN.R-project.org/package=PHInfiniteEstimates&gt;.\n  - Lüdecke D, Ben-Shachar M, Patil I, Makowski D (2020). \"Extracting, Computing\nand Exploring the Parameters of Statistical Models using R.\" _Journal of Open\nSource Software_, *5*(53), 2445. doi:10.21105/joss.02445\n&lt;https://doi.org/10.21105/joss.02445&gt;.\n  - Lüdecke D, Ben-Shachar M, Patil I, Waggoner P, Makowski D (2021).\n\"performance: An R Package for Assessment, Comparison and Testing of\nStatistical Models.\" _Journal of Open Source Software_, *6*(60), 3139.\ndoi:10.21105/joss.03139 &lt;https://doi.org/10.21105/joss.03139&gt;.\n  - Lüdecke D, Ben-Shachar M, Patil I, Wiernik B, Makowski D (2022). \"easystats:\nFramework for Easy Statistical Modeling, Visualization, and Reporting.\" _CRAN_.\nR package, &lt;https://easystats.github.io/easystats/&gt;.\n  - Lüdecke D, Patil I, Ben-Shachar M, Wiernik B, Waggoner P, Makowski D (2021).\n\"see: An R Package for Visualizing Statistical Models.\" _Journal of Open Source\nSoftware_, *6*(64), 3393. doi:10.21105/joss.03393\n&lt;https://doi.org/10.21105/joss.03393&gt;.\n  - Lüdecke D, Waggoner P, Makowski D (2019). \"insight: A Unified Interface to\nAccess Information from Model Objects in R.\" _Journal of Open Source Software_,\n*4*(38), 1412. doi:10.21105/joss.01412 &lt;https://doi.org/10.21105/joss.01412&gt;.\n  - Makowski D, Ben-Shachar M, Lüdecke D (2019). \"bayestestR: Describing Effects\nand their Uncertainty, Existence and Significance within the Bayesian\nFramework.\" _Journal of Open Source Software_, *4*(40), 1541.\ndoi:10.21105/joss.01541 &lt;https://doi.org/10.21105/joss.01541&gt;,\n&lt;https://joss.theoj.org/papers/10.21105/joss.01541&gt;.\n  - Makowski D, Ben-Shachar M, Patil I, Lüdecke D (2020). \"Estimation of\nModel-Based Predictions, Contrasts and Means.\" _CRAN_.\n&lt;https://github.com/easystats/modelbased&gt;.\n  - Makowski D, Lüdecke D, Patil I, Thériault R, Ben-Shachar M, Wiernik B (2023).\n\"Automated Results Reporting as a Practical Tool to Improve Reproducibility and\nMethodological Best Practices Adoption.\" _CRAN_.\n&lt;https://easystats.github.io/report/&gt;.\n  - Makowski D, Wiernik B, Patil I, Lüdecke D, Ben-Shachar M (2022).\n\"correlation: Methods for Correlation Analysis.\" Version 0.8.3,\n&lt;https://CRAN.R-project.org/package=correlation&gt;. Makowski D, Ben-Shachar M,\nPatil I, Lüdecke D (2020). \"Methods and Algorithms for Correlation Analysis in\nR.\" _Journal of Open Source Software_, *5*(51), 2306. doi:10.21105/joss.02306\n&lt;https://doi.org/10.21105/joss.02306&gt;,\n&lt;https://joss.theoj.org/papers/10.21105/joss.02306&gt;.\n  - Meira-Machado L, Sestelo M (2023). _condSURV: Estimation of the Conditional\nSurvival Function for Ordered Multivariate Failure Time Data_. R package\nversion 2.0.4, &lt;https://CRAN.R-project.org/package=condSURV&gt;.\n  - Müller K, Wickham H (2023). _tibble: Simple Data Frames_. R package version\n3.2.1, &lt;https://CRAN.R-project.org/package=tibble&gt;.\n  - Patil I, Makowski D, Ben-Shachar M, Wiernik B, Bacher E, Lüdecke D (2022).\n\"datawizard: An R Package for Easy Data Preparation and Statistical\nTransformations.\" _Journal of Open Source Software_, *7*(78), 4684.\ndoi:10.21105/joss.04684 &lt;https://doi.org/10.21105/joss.04684&gt;.\n  - R Core Team (2023). _foreign: Read Data Stored by 'Minitab', 'S', 'SAS',\n'SPSS', 'Stata', 'Systat', 'Weka', 'dBase', ..._. R package version 0.8-85,\n&lt;https://CRAN.R-project.org/package=foreign&gt;.\n  - R Core Team (2023). _R: A Language and Environment for Statistical\nComputing_. R Foundation for Statistical Computing, Vienna, Austria.\n&lt;https://www.R-project.org/&gt;.\n  - Ristl R, Ballarini N, Götte H, Schüler A, Posch M, König F (2021). \"Delayed\ntreatment effects, treatment switching and heterogeneous patient populations:\nHow to design and analyze RCTs in oncology.\" _Pharmaceutical statistics_,\n*20*(1), 129-145.\n  - Robinson D, Hayes A, Couch S (2023). _broom: Convert Statistical Objects into\nTidy Tibbles_. R package version 1.0.5,\n&lt;https://CRAN.R-project.org/package=broom&gt;.\n  - Sjoberg D, Baillie M, Fruechtenicht C, Haesendonckx S, Treis T (2023).\n_ggsurvfit: Flexible Time-to-Event Figures_. R package version 1.0.0,\n&lt;https://CRAN.R-project.org/package=ggsurvfit&gt;.\n  - Sjoberg D, Whiting K, Curry M, Lavery J, Larmarange J (2021). \"Reproducible\nSummary Tables with the gtsummary Package.\" _The R Journal_, *13*, 570-580.\ndoi:10.32614/RJ-2021-053 &lt;https://doi.org/10.32614/RJ-2021-053&gt;,\n&lt;https://doi.org/10.32614/RJ-2021-053&gt;.\n  - Thériault R (2023). \"rempsyc: Convenience functions for psychology.\" _Journal\nof Open Source Software_, *8*(87), 5466. doi:10.21105/joss.05466\n&lt;https://doi.org/10.21105/joss.05466&gt;, &lt;https://doi.org/10.21105/joss.05466&gt;.\n  - Therneau T (2023). _A Package for Survival Analysis in R_. R package version\n3.5-7, &lt;https://CRAN.R-project.org/package=survival&gt;. Terry M. Therneau,\nPatricia M. Grambsch (2000). _Modeling Survival Data: Extending the Cox Model_.\nSpringer, New York. ISBN 0-387-98784-3.\n  - Wickham H (2016). _ggplot2: Elegant Graphics for Data Analysis_.\nSpringer-Verlag New York. ISBN 978-3-319-24277-4,\n&lt;https://ggplot2.tidyverse.org&gt;.\n  - Wickham H (2023). _forcats: Tools for Working with Categorical Variables\n(Factors)_. R package version 1.0.0,\n&lt;https://CRAN.R-project.org/package=forcats&gt;.\n  - Wickham H (2023). _stringr: Simple, Consistent Wrappers for Common String\nOperations_. R package version 1.5.1,\n&lt;https://CRAN.R-project.org/package=stringr&gt;.\n  - Wickham H, Averick M, Bryan J, Chang W, McGowan LD, François R, Grolemund G,\nHayes A, Henry L, Hester J, Kuhn M, Pedersen TL, Miller E, Bache SM, Müller K,\nOoms J, Robinson D, Seidel DP, Spinu V, Takahashi K, Vaughan D, Wilke C, Woo K,\nYutani H (2019). \"Welcome to the tidyverse.\" _Journal of Open Source Software_,\n*4*(43), 1686. doi:10.21105/joss.01686 &lt;https://doi.org/10.21105/joss.01686&gt;.\n  - Wickham H, François R, Henry L, Müller K, Vaughan D (2023). _dplyr: A Grammar\nof Data Manipulation_. R package version 1.1.3,\n&lt;https://CRAN.R-project.org/package=dplyr&gt;.\n  - Wickham H, Henry L (2023). _purrr: Functional Programming Tools_. R package\nversion 1.0.2, &lt;https://CRAN.R-project.org/package=purrr&gt;.\n  - Wickham H, Hester J, Bryan J (2023). _readr: Read Rectangular Text Data_. R\npackage version 2.1.4, &lt;https://CRAN.R-project.org/package=readr&gt;.\n  - Wickham H, Vaughan D, Girlich M (2023). _tidyr: Tidy Messy Data_. R package\nversion 1.3.0, &lt;https://CRAN.R-project.org/package=tidyr&gt;.\n  - Zhu H (2021). _kableExtra: Construct Complex Table with 'kable' and Pipe\nSyntax_. R package version 1.3.4,\n&lt;https://CRAN.R-project.org/package=kableExtra&gt;."
  },
  {
    "objectID": "lista_6_1.html#carregando-pacotes",
    "href": "lista_6_1.html#carregando-pacotes",
    "title": "7  Lista 6.1 - Cox tempo dependente",
    "section": "7.1 Carregando pacotes",
    "text": "7.1 Carregando pacotes\n\nlibrary(tidyverse)\nlibrary(flexplot)\nlibrary(foreign)\nlibrary(dplyr)\nlibrary(tm)\nlibrary(ggplot2)\nlibrary(forcats)\nlibrary(rempsyc)\nlibrary(easystats)\nlibrary(kableExtra)\nlibrary(gtsummary)\n\n#Específicos para survival\nlibrary(survival)\nlibrary(ggsurvfit)\nlibrary(survminer)\nlibrary(broom)\nlibrary(survMisc)\nlibrary(PHInfiniteEstimates)\nlibrary(coin)\nlibrary(condSURV)"
  },
  {
    "objectID": "lista_6_1.html#carregando-os-dados-e-modificando-o-tipo-de-variável",
    "href": "lista_6_1.html#carregando-os-dados-e-modificando-o-tipo-de-variável",
    "title": "7  Lista 6.1 - Cox tempo dependente",
    "section": "7.2 Carregando os dados e modificando o tipo de variável",
    "text": "7.2 Carregando os dados e modificando o tipo de variável\nMantendo as boas práticas das análises, logo após carregar os dados em uma variável, vamos verificar os tipos de variávels que temos em nosso banco.\n\noriginal = read.spss(\"Cox tempo dependente 2_1.sav\", to.data.frame=TRUE)\nglimpse(original)\n\nRows: 628\nColumns: 7\n$ ID            &lt;dbl&gt; 112, 91, 113, 150, 22, 139, 104, 590, 189, 171, 338, 492…\n$ age           &lt;dbl&gt; 35, 33, 35, 31, 33, 43, 25, 35, 29, 27, 35, 23, 24, 23, …\n$ race          &lt;fct&gt; branco, branco, branco, branco, branco, branco, branco, …\n$ treat         &lt;dbl&gt; 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1,…\n$ Tempo_dialise &lt;dbl&gt; 51, 67, 88, 156, 12, 139, 90, 25, 187, 34, 29, 78, 63, 8…\n$ time          &lt;dbl&gt; 1172, 762, 734, 720, 659, 658, 655, 654, 634, 630, 621, …\n$ morte         &lt;fct&gt; Não, Não, Não, Não, Não, Não, Não, Não, Não, Não, Não, N…\n\n\nNovamente podemos observar que o evento de interesse (morte) está como um fator. Vamos modificar como já fizemos a lista 6 e também já vamos ajustar a variável “treat” para que ela seja um fator e não um número.\n\ndb &lt;- original %&gt;%\n  mutate(\n    morte = as.integer(morte == \"Sim\"), # para transformar sim e não em 1 e 0, respectivamente\n    treat = as.factor(treat)\n  )\nglimpse(db)\n\nRows: 628\nColumns: 7\n$ ID            &lt;dbl&gt; 112, 91, 113, 150, 22, 139, 104, 590, 189, 171, 338, 492…\n$ age           &lt;dbl&gt; 35, 33, 35, 31, 33, 43, 25, 35, 29, 27, 35, 23, 24, 23, …\n$ race          &lt;fct&gt; branco, branco, branco, branco, branco, branco, branco, …\n$ treat         &lt;fct&gt; 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1,…\n$ Tempo_dialise &lt;dbl&gt; 51, 67, 88, 156, 12, 139, 90, 25, 187, 34, 29, 78, 63, 8…\n$ time          &lt;dbl&gt; 1172, 762, 734, 720, 659, 658, 655, 654, 634, 630, 621, …\n$ morte         &lt;int&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n\n\nFeito! Vamos também verificar se há presença de dados faltantes e em quais variáveis.\n\n# Verificando NAs\nresumo_nas &lt;- db %&gt;%\n  summarise(\n    nas_age = sum(is.na(age)),\n    nas_race = sum(is.na(race)),\n    nas_treat = sum(is.na(treat)),\n    nas_t_dialise = sum(is.na(Tempo_dialise)),\n    nas_time = sum(is.na(time)),\n    nas_morte = sum(is.na(morte)),\n  )\nkable(resumo_nas)\n\n\n\n\nnas_age\nnas_race\nnas_treat\nnas_t_dialise\nnas_time\nnas_morte\n\n\n\n\n5\n6\n0\n0\n0\n0\n\n\n\n\n\n\n\nAté chegar na Cox tempo dependente, vamos repetir basicamente o que já fizemos no Capítulo 6"
  },
  {
    "objectID": "lista_6_1.html#criando-a-estrutura-de-dados",
    "href": "lista_6_1.html#criando-a-estrutura-de-dados",
    "title": "7  Lista 6.1 - Cox tempo dependente",
    "section": "7.3 Criando a estrutura de dados",
    "text": "7.3 Criando a estrutura de dados\n\n# Create a survival object\nsurv_obj &lt;- Surv(time = db$time, event = db$morte)\n\n\nTábua de vida\n\n# Create survival curve\nfit1 &lt;- survfit(surv_obj ~ treat, data = db)\nkable(head(tidy(fit1)))\n\n\n\n\ntime\nn.risk\nn.event\nn.censor\nestimate\nstd.error\nconf.high\nconf.low\nstrata\n\n\n\n\n3\n320\n2\n0\n0.993750\n0.0044333\n1.0000000\n0.9851526\ntreat=0\n\n\n4\n318\n2\n0\n0.987500\n0.0062894\n0.9997483\n0.9754017\ntreat=0\n\n\n5\n316\n1\n0\n0.984375\n0.0070430\n0.9980575\n0.9708801\ntreat=0\n\n\n6\n315\n2\n0\n0.978125\n0.0083599\n0.9942837\n0.9622289\ntreat=0\n\n\n7\n313\n2\n0\n0.971875\n0.0095097\n0.9901593\n0.9539283\ntreat=0\n\n\n8\n311\n1\n0\n0.968750\n0.0100402\n0.9880024\n0.9498728\ntreat=0\n\n\n\n\n\n\n\n\n\nGráfico Kaplan-Meir\n\nkm_plot = survfit2(surv_obj ~ treat, data = db) %&gt;%\n  tidy_survfit() %&gt;%\n  ggplot(aes(x = time, y = estimate,\n             min = conf.low, ymax = conf.low,\n             color = strata, fill = strata)) +\n  geom_step()\nkm_plot\n\n\n\n\nPodemos ajustar as configurações do eixo X para exibir uma escala temporal com intervalos de 50 unidades.\n\n# km_plot2 = fit1 %&gt;%\n#   tidy_survfit() %&gt;%\n#   ggplot(aes(x = time, y = estimate,\n#              min = conf.low, ymax = conf.low,\n#              color = strata, fill = strata)) +\n#   geom_step()\n\nkm_plot2 = fit1 %&gt;%\n  tidy_survfit() %&gt;%\n  ggplot(aes(x = time, y = estimate,\n             min = conf.low, ymax = conf.low,\n             color = strata, fill = strata)) +\n  geom_step() +\n  scale_x_continuous(breaks = seq(0, max(fit1$time), by = 50))\n\n\nkm_plot2\n\n\n\n\n\n\nTabela com Sobrevida em tempos espcíficos.\n\ntbl_survfit_ex3 &lt;-\n  list(\n    survfit(surv_obj ~ 1, db),\n    survfit(surv_obj ~ treat, db)\n  ) %&gt;%\n  tbl_survfit(times = c(100, 600))\ntbl_survfit_ex3\n\n\n\n\n\n  \n    \n    \n      Characteristic\n      Time 100\n      Time 600\n    \n  \n  \n    Overall\n66% (63%, 70%)\n19% (16%, 22%)\n    treat\n\n\n        0\n61% (56%, 66%)\n16% (13%, 21%)\n        1\n72% (67%, 77%)\n21% (17%, 26%)\n  \n  \n  \n\n\n\n\n\n\nLog-rank\n\ncoin::logrank_test(surv_obj ~ treat, data = db, type = \"logrank\" ) # padrão é o log-rank\n\n\n    Asymptotic Two-Sample Logrank Test\n\ndata:  surv_obj by treat (0, 1)\nZ = -2.5984, p-value = 0.009365\nalternative hypothesis: true theta is not equal to 1\n\n\n\n\nGehan-Breslow\n\ncoin::logrank_test(surv_obj ~ treat ,data = db, type = \"Gehan-Breslow\")\n\n\n    Asymptotic Two-Sample Gehan-Breslow Test\n\ndata:  surv_obj by treat (0, 1)\nZ = -3.0713, p-value = 0.002132\nalternative hypothesis: true theta is not equal to 1\n\n\n\n\nTarone-Ware\n\ncoin::logrank_test(surv_obj ~ treat ,data = db, type = \"Tarone-Ware\")\n\n\n    Asymptotic Two-Sample Tarone-Ware Test\n\ndata:  surv_obj by treat (0, 1)\nZ = -2.9622, p-value = 0.003055\nalternative hypothesis: true theta is not equal to 1\n\n\n\n\nPeto-Peto\n\ncoin::logrank_test(surv_obj ~ treat ,data = db, type = \"Peto-Peto\")\n\n\n    Asymptotic Two-Sample Peto-Peto Test\n\ndata:  surv_obj by treat (0, 1)\nZ = -3.0608, p-value = 0.002207\nalternative hypothesis: true theta is not equal to 1"
  },
  {
    "objectID": "lista_6_1.html#cox-regression",
    "href": "lista_6_1.html#cox-regression",
    "title": "7  Lista 6.1 - Cox tempo dependente",
    "section": "7.4 Cox regression",
    "text": "7.4 Cox regression\n\n# Cox regression ======================================================\n# Fit the model\n\ncox_res &lt;- coxph(Surv(time = db$time, event = db$morte) ~ treat, data = db)\n### Para testar todas as variáveis\n#cox_res &lt;- coxph(Surv(time = db$time, event = db$morte2) ~ treat + age + Tempo_dialise, data = db)\n\ntbl_regression(cox_res, exponentiate = TRUE)\n\n\n\n\n\n  \n    \n    \n      Characteristic\n      HR1\n      95% CI1\n      p-value\n    \n  \n  \n    treat\n\n\n\n        0\n—\n—\n\n        1\n0.79\n0.67, 0.94\n0.009\n  \n  \n  \n    \n      1 HR = Hazard Ratio, CI = Confidence Interval\n    \n  \n\n\n\n\n\nVerificando os pressupostos da Cox regression\nRelembrando a análise dos riscos proporcionais com base nos resíduos de Schoenfeld:\n\np-val &lt; 0,05: há evidências contra a pressuposto de riscos proporcionais, os HRs não são constantes ao longo do tempo\nchisq: quanto maior o valor, mais forte a violação dos pressupostos"
  },
  {
    "objectID": "lista_6_1.html#plot-dos-resíduos-de-schoenfeld",
    "href": "lista_6_1.html#plot-dos-resíduos-de-schoenfeld",
    "title": "7  Lista 6.1 - Cox tempo dependente",
    "section": "7.5 Plot dos resíduos de Schoenfeld",
    "text": "7.5 Plot dos resíduos de Schoenfeld\n\n# Plot the Schoenfeld residuals over time for each covariate\nsurvminer::ggcoxzph(cox.zph(cox_res), point.size = 0.1)\n\n\n\n\nSe os resíduos mostrarem um padrão claro ao longo do tempo, isso pode indicar uma violação da suposição de riscos proporcionais.\nAlgumas dicas para ajudar na interpretação:\n\nSem Padrão (Resíduos Constantes): Se os resíduos aparecerem aleatoriamente espalhados em torno de zero, sem nenhuma tendência ou padrão claro, isso sugere que a suposição de riscos proporcionais é razoável.\nTendência Linear: Uma tendência linear (aumentando ou diminuindo) nos resíduos ao longo do tempo pode sugerir uma violação da suposição de riscos proporcionais. Por exemplo, se os resíduos forem consistentemente positivos ou negativos ao longo do tempo, isso indica um efeito dependente do tempo.\nPadrão Não Linear: Se os resíduos exibirem um padrão não linear ou formatos específicos (por exemplo, formato de U, formato de V), isso pode indicar desvios dos riscos proporcionais.\nParalelismo: Paralelismo significa que a propagação e distribuição dos resíduos são relativamente constantes ao longo do tempo. Se os resíduos aumentarem ou diminuirem ao longo do tempo, isso pode sugerir uma violação da suposição.\n\n\nggcoxdiagnostics(cox_res, type = \"dfbeta\", linear.predictions = FALSE)\n\nWarning: `gather_()` was deprecated in tidyr 1.2.0.\nℹ Please use `gather()` instead.\nℹ The deprecated feature was likely used in the survminer package.\n  Please report the issue at &lt;https://github.com/kassambara/survminer/issues&gt;.\n\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n# Não é importante para variáveis categóricas, mas fica o código para eventual consulta.\nggcoxdiagnostics(cox_res, type = \"deviance\", linear.predictions = FALSE)\n\n`geom_smooth()` using formula = 'y ~ x'"
  },
  {
    "objectID": "lista_6_1.html#plots-do-modelo",
    "href": "lista_6_1.html#plots-do-modelo",
    "title": "7  Lista 6.1 - Cox tempo dependente",
    "section": "7.6 Plots do modelo",
    "text": "7.6 Plots do modelo\n\nForest plot\n\n# Forest plots ================================================================\n# Visualise your Cox model results\nggforest(cox_res, data = db)\n\n\n\n\n\n\nGráfico de sobrevida\nAssim como fizemos no exercício anterior, precisamos criar um novo banco de dados para visualizar o gráfico da Regressão de Cox:\n\n# Precisa ser feito apenas com uma variável\ncox_res2 &lt;- coxph(Surv(time = db$time, event = db$morte) ~ treat, data = db)\n\n# Criando o novo banco de dados\nnew_df &lt;- with(db,\n               data.frame(treat = c(\"0\", \"1\"))\n)\n\nE precisamos transformar a variável treat em um fator.\n\nnew_df$treat = as.factor(new_df$treat)\nkable(new_df)\n\n\n\n\ntreat\n\n\n\n\n0\n\n\n1\n\n\n\n\n\n\n\nCriando os dados com base no modelo e plotando o gráfico.\n\nfit_cox &lt;- survfit(cox_res2, newdata = new_df)\n\nJ = ggsurvplot(fit_cox, conf.int = TRUE, legend.labs=c(\"tx=sim\", \"tx=não\"),\n           ggtheme = theme_minimal(),\n           data = db)\n\nJ$plot = J$plot +\n  scale_x_continuous(breaks = seq(0, 900, 20))\n\nScale for x is already present.\nAdding another scale for x, which will replace the existing scale.\n\nJ\n\n\n\n\nReparem na distorção do gráfico em relação à Kaplan-Meir\n\nkm_plot"
  },
  {
    "objectID": "lista_6_1.html#cox-tempo-dependente",
    "href": "lista_6_1.html#cox-tempo-dependente",
    "title": "7  Lista 6.1 - Cox tempo dependente",
    "section": "7.7 Cox tempo-dependente",
    "text": "7.7 Cox tempo-dependente\nJá vimos que os riscos não são proporcionais neste caso. Porém, nem tudo está perdido. Podemos finalmente agora falar da Cox Tempo-dependente.\nO primeiro passo é identificar um possível fator que esteja afetando a proporcionalidade dos riscos no estudo. Pela literatura tempos que o tempo em diálise afeta os riscos entre pessoas que fizeram ou não o transplante de rim. Daí a importância de entender bem o fenômeno que estamos estudando. Como bons pesquisadores, também coletamos o tempo em diálise e esses dados estão no banco de dados\n\nglimpse(db$Tempo_dialise)\n\n num [1:628] 51 67 88 156 12 139 90 25 187 34 ...\n\n\nA variável é numérica e contínua, logo ela já está formatada para continuarmos com a análise.\nNão existe regras escritas na pedra para contornar o problema de não proporcionalidade. Vamos mostrar uma abordagem aqui. Não deixe de ver as referências para outros casos.\n\nCovariáveis tempo dependente\nNo R, há diversas formas de indicar uma variável como tempo-dependente. A escolha do método dependerá da natureza da variável independente e da sua relação teórica com o evento em estudo. A função coxph() oferece a opção de utilizar o argumento tt(), o qual especifica qual variável independente será considerada uma covariável tempo-dependente e como o coeficiente associado a ela deve ser modificado ao longo do tempo.\nO modelo deve seguir a seguinte estrutura\ncoxph(Surv(time, event) ~ covariavel1 + covariavel2 + tt(covariavel2), data, tt=function(x,t,…) x*t)\nPodemos substituir o Surv(time, event) pela variável que salvamos com o objeto survival, surv_obj.\nA função tt (function(x,t,…)___) pode assumir alguns modelos. A seguir trazemos três exemplos mais utilizados em diversas análises:\n\nx*t permitirá que o coeficiente mude linearmente com o tempo\nx*log(t) permite que o coeficiente mude com o log do tempo\nx*(t&gt;tempo) permite que o coeficiente assuma 2 valores diferentes, um valor quando t&lt;=tempo e outro valor t&gt;tempo\n\nVamos gerar vários modelos e avaliá-los comparando os índices de ajuste e os resultados obtidos.\n\n\nSem variável tempo dependente\n\ndialise &lt;- coxph(surv_obj ~ treat + Tempo_dialise, \n                          data=db) # corte no 660\n\nsummary(dialise)\n\nCall:\ncoxph(formula = surv_obj ~ treat + Tempo_dialise, data = db)\n\n  n= 628, number of events= 508 \n\n                    coef  exp(coef)   se(coef)       z            Pr(&gt;|z|)    \ntreat1         0.0618983  1.0638541  0.0899990   0.688               0.492    \nTempo_dialise -0.0084493  0.9915863  0.0007709 -10.960 &lt;0.0000000000000002 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n              exp(coef) exp(-coef) lower .95 upper .95\ntreat1           1.0639      0.940    0.8918    1.2691\nTempo_dialise    0.9916      1.008    0.9901    0.9931\n\nConcordance= 0.75  (se = 0.012 )\nLikelihood ratio test= 151.4  on 2 df,   p=&lt;0.0000000000000002\nWald test            = 121.2  on 2 df,   p=&lt;0.0000000000000002\nScore (logrank) test = 120.6  on 2 df,   p=&lt;0.0000000000000002\n\n\n\n\nMudança linear\n\ndialise_linear &lt;- coxph(surv_obj ~ treat + Tempo_dialise + tt(Tempo_dialise),\n                        data=db,\n                          tt=function(x,t,...) x*t) \nsummary(dialise_linear)\n\nCall:\ncoxph(formula = surv_obj ~ treat + Tempo_dialise + tt(Tempo_dialise), \n    data = db, tt = function(x, t, ...) x * t)\n\n  n= 628, number of events= 508 \n\n                          coef    exp(coef)     se(coef)       z\ntreat1            -0.016001236  0.984126103  0.091676088  -0.175\nTempo_dialise     -0.023777102  0.976503346  0.001506128 -15.787\ntt(Tempo_dialise)  0.000070699  1.000070701  0.000005184  13.637\n                             Pr(&gt;|z|)    \ntreat1                          0.861    \nTempo_dialise     &lt;0.0000000000000002 ***\ntt(Tempo_dialise) &lt;0.0000000000000002 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n                  exp(coef) exp(-coef) lower .95 upper .95\ntreat1               0.9841     1.0161    0.8223    1.1778\nTempo_dialise        0.9765     1.0241    0.9736    0.9794\ntt(Tempo_dialise)    1.0001     0.9999    1.0001    1.0001\n\nConcordance= 0.761  (se = 0.009 )\nLikelihood ratio test= 337.6  on 3 df,   p=&lt;0.0000000000000002\nWald test            = 249.3  on 3 df,   p=&lt;0.0000000000000002\nScore (logrank) test = 229.1  on 3 df,   p=&lt;0.0000000000000002\n\n\n\n\nModelo log\n\ndialise_log &lt;- coxph(surv_obj ~ treat + Tempo_dialise + tt(Tempo_dialise),\n                          data=db,\n                          tt=function(x,t,...) x*log(t)) \n\nsummary(dialise_log)\n\nCall:\ncoxph(formula = surv_obj ~ treat + Tempo_dialise + tt(Tempo_dialise), \n    data = db, tt = function(x, t, ...) x * log(t))\n\n  n= 628, number of events= 508 \n\n                       coef exp(coef)  se(coef)      z            Pr(&gt;|z|)    \ntreat1            -0.071106  0.931363  0.092369  -0.77               0.441    \nTempo_dialise     -0.097417  0.907178  0.005942 -16.40 &lt;0.0000000000000002 ***\ntt(Tempo_dialise)  0.017178  1.017326  0.001087  15.80 &lt;0.0000000000000002 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n                  exp(coef) exp(-coef) lower .95 upper .95\ntreat1               0.9314      1.074    0.7771    1.1162\nTempo_dialise        0.9072      1.102    0.8967    0.9178\ntt(Tempo_dialise)    1.0173      0.983    1.0152    1.0195\n\nConcordance= 0.759  (se = 0.01 )\nLikelihood ratio test= 461.5  on 3 df,   p=&lt;0.0000000000000002\nWald test            = 284.6  on 3 df,   p=&lt;0.0000000000000002\nScore (logrank) test = 223.9  on 3 df,   p=&lt;0.0000000000000002\n\n\n\n\nModelo temporal\n\ndialise_tempo_650 &lt;- coxph(surv_obj ~ treat + Tempo_dialise + tt(Tempo_dialise),\n                          data=db,\n                          tt=function(x,t,...) x*(t&gt;650))\n\nsummary(dialise_tempo_650)\n\nCall:\ncoxph(formula = surv_obj ~ treat + Tempo_dialise + tt(Tempo_dialise), \n    data = db, tt = function(x, t, ...) x * (t &gt; 650))\n\n  n= 628, number of events= 508 \n\n                        coef  exp(coef)   se(coef)       z            Pr(&gt;|z|)\ntreat1             0.0617615  1.0637086  0.0900051   0.686               0.493\nTempo_dialise     -0.0084524  0.9915832  0.0007713 -10.958 &lt;0.0000000000000002\ntt(Tempo_dialise)  0.0028519  1.0028560  0.0221016   0.129               0.897\n                     \ntreat1               \nTempo_dialise     ***\ntt(Tempo_dialise)    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n                  exp(coef) exp(-coef) lower .95 upper .95\ntreat1               1.0637     0.9401    0.8917    1.2689\nTempo_dialise        0.9916     1.0085    0.9901    0.9931\ntt(Tempo_dialise)    1.0029     0.9972    0.9603    1.0473\n\nConcordance= 0.75  (se = 0.01 )\nLikelihood ratio test= 151.5  on 3 df,   p=&lt;0.0000000000000002\nWald test            = 121.2  on 3 df,   p=&lt;0.0000000000000002\nScore (logrank) test = 120.6  on 3 df,   p=&lt;0.0000000000000002\n\n\n\n\nÍndices de aderência (AIC e BIC)\nPodemos comparar os modelos computando os valores de AIC e BIC\n\ncombined_df &lt;- data.frame(\n  Model = c(\"dialise\", \"dialise_linear\", \"dialise_log\", \"dialise_tempo_650\"),\n  AIC = c(AIC(dialise), AIC(dialise_linear), AIC(dialise_log), AIC(dialise_tempo_650)),\n  BIC = c(BIC(dialise), BIC(dialise_linear), BIC(dialise_log), BIC(dialise_tempo_650))\n)\n\nkable(combined_df)\n\n\n\n\nModel\nAIC\nBIC\n\n\n\n\ndialise\n5771.688\n5780.149\n\n\ndialise_linear\n5587.564\n5600.256\n\n\ndialise_log\n5463.651\n5476.343\n\n\ndialise_tempo_650\n5773.672\n5786.363\n\n\n\n\n\n\n\nPor esse critério, temos que o melhor modelo é o log em seguida o linear.\n\n\nResíduos de Schoenfeld\nAgora vamos analisar mais uma vez os resíduos de Schoenfeld, mas agora variando pelo “Tempo em Diálise”.\n\ncox_res_T_Cov &lt;- coxph(Surv(time = db$time, event = db$morte) ~ treat + Tempo_dialise, data = db)  \nggcoxzph(cox.zph(cox_res_T_Cov), var =\"Tempo_dialise\") \n\n\n\n\nPodemos observar que o Beta do tempo em diálise tem um aumento linear conforme maior o tempo. O resultado pode indicar que o efeito do tempo sobre a o tempo em diálise pode ser linear.\n\n\nInterpretando os resultados.\nA interpretação dos coeficientes da Cox Tempo-dependente é diferente das outras regressõs.\nVamos interpretar o valor do modelo com mudança linear.\n\nsummary(dialise_linear)\n\nCall:\ncoxph(formula = surv_obj ~ treat + Tempo_dialise + tt(Tempo_dialise), \n    data = db, tt = function(x, t, ...) x * t)\n\n  n= 628, number of events= 508 \n\n                          coef    exp(coef)     se(coef)       z\ntreat1            -0.016001236  0.984126103  0.091676088  -0.175\nTempo_dialise     -0.023777102  0.976503346  0.001506128 -15.787\ntt(Tempo_dialise)  0.000070699  1.000070701  0.000005184  13.637\n                             Pr(&gt;|z|)    \ntreat1                          0.861    \nTempo_dialise     &lt;0.0000000000000002 ***\ntt(Tempo_dialise) &lt;0.0000000000000002 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n                  exp(coef) exp(-coef) lower .95 upper .95\ntreat1               0.9841     1.0161    0.8223    1.1778\nTempo_dialise        0.9765     1.0241    0.9736    0.9794\ntt(Tempo_dialise)    1.0001     0.9999    1.0001    1.0001\n\nConcordance= 0.761  (se = 0.009 )\nLikelihood ratio test= 337.6  on 3 df,   p=&lt;0.0000000000000002\nWald test            = 249.3  on 3 df,   p=&lt;0.0000000000000002\nScore (logrank) test = 229.1  on 3 df,   p=&lt;0.0000000000000002\n\n\nO coeficiente Tempo_dialise = -0.023, deve ser interpretado como o efeito do tempo de diálise no tempo zero. Já o coeficiente tt(Tempo_dialise) = deve ser interpretado como o a mudança do efeito do tempo em diálise a cada unidade de tempo a mais.\n\n\nObservações SPSS e R\nNa aula prática o modelo não é feito com o Tempo em Diálise fora da variável tempo dependente. Já na aula teórica do curso II de 2023, o modelo é escrito como foi feito aqui no R, levando em conta o Tempo em Diálise como uma variável tempo dependente e também como covariável no modelo."
  },
  {
    "objectID": "lista_6_1.html#covariando-para-idade-e-raça",
    "href": "lista_6_1.html#covariando-para-idade-e-raça",
    "title": "7  Lista 6.1 - Cox tempo dependente",
    "section": "7.8 Covariando para idade e raça",
    "text": "7.8 Covariando para idade e raça\nO conjunto de dados ainda possui duas variáveis que não foram incluídas no modelo: idade e raça. Conforme o procedimento padrão, vamos examinar a natureza dessas variáveis. Começando com a idade.\n\nglimpse(db)\n\nRows: 628\nColumns: 7\n$ ID            &lt;dbl&gt; 112, 91, 113, 150, 22, 139, 104, 590, 189, 171, 338, 492…\n$ age           &lt;dbl&gt; 35, 33, 35, 31, 33, 43, 25, 35, 29, 27, 35, 23, 24, 23, …\n$ race          &lt;fct&gt; branco, branco, branco, branco, branco, branco, branco, …\n$ treat         &lt;fct&gt; 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1,…\n$ Tempo_dialise &lt;dbl&gt; 51, 67, 88, 156, 12, 139, 90, 25, 187, 34, 29, 78, 63, 8…\n$ time          &lt;dbl&gt; 1172, 762, 734, 720, 659, 658, 655, 654, 634, 630, 621, …\n$ morte         &lt;int&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n\n\nÓtimo, idade já está como uma variável numérica e contínua e raça está como um fator. Por fim, vamos verificar qual o nível de referência da variável “race”.\n\nlevels(db$race)\n\n[1] \"branco\"      \"negro/pardo\"\n\n\nO nível “branco” está como referência, logo, os resultados do modelo mostrarão os valores dos coeficientes do nível “negro/pardo” em relação ao nível “branco”.\nVamos ao modelo completo.\n\nModelo completo Cox tempo dependente\n\ncox_full_model &lt;- coxph(surv_obj ~ age + race + treat + Tempo_dialise + tt(Tempo_dialise),\n                        data=db,\n                          tt=function(x,t,...) x*t) \nsummary(cox_full_model)\n\nCall:\ncoxph(formula = surv_obj ~ age + race + treat + Tempo_dialise + \n    tt(Tempo_dialise), data = db, tt = function(x, t, ...) x * \n    t)\n\n  n= 617, number of events= 500 \n   (11 observations deleted due to missingness)\n\n                          coef    exp(coef)     se(coef)       z\nage               -0.005531327  0.994483942  0.007272881  -0.761\nracenegro/pardo   -0.342009991  0.710341107  0.108147939  -3.162\ntreat1             0.042207387  1.043110784  0.093368582   0.452\nTempo_dialise     -0.023671737  0.976606241  0.001511519 -15.661\ntt(Tempo_dialise)  0.000068807  1.000068809  0.000005196  13.242\n                              Pr(&gt;|z|)    \nage                            0.44693    \nracenegro/pardo                0.00156 ** \ntreat1                         0.65123    \nTempo_dialise     &lt; 0.0000000000000002 ***\ntt(Tempo_dialise) &lt; 0.0000000000000002 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n                  exp(coef) exp(-coef) lower .95 upper .95\nage                  0.9945     1.0055    0.9804    1.0088\nracenegro/pardo      0.7103     1.4078    0.5747    0.8781\ntreat1               1.0431     0.9587    0.8687    1.2526\nTempo_dialise        0.9766     1.0240    0.9737    0.9795\ntt(Tempo_dialise)    1.0001     0.9999    1.0001    1.0001\n\nConcordance= 0.765  (se = 0.009 )\nLikelihood ratio test= 343.2  on 5 df,   p=&lt;0.0000000000000002\nWald test            = 259.4  on 5 df,   p=&lt;0.0000000000000002\nScore (logrank) test = 243.3  on 5 df,   p=&lt;0.0000000000000002\n\n\nAgora temos que a raça tem um efeito significativo no modelo. Seguindo o vídeo da aula prática, podemos segmentar o banco de dados para as duas raças que temos no banco de dados.\n\n\nSegmentando o banco de dados por raça\n\ndb_branco = db %&gt;%\n  filter(race == \"branco\")\n\ndb_pardo_negro = db %&gt;% \n  filter(race == \"negro/pardo\")\n\n\n\nKM por raça = Branco\n\n# Criando um novo objeto Surv\nsurv_obj_branco &lt;- Surv(time = db_branco$time, event = db_branco$morte)\n\nfit_br = survfit(surv_obj_branco ~ treat, data = db_branco)\nggsurvfit(fit_br)\n\n\n\nggsurvfit(fit_br, linewidth = 1) +\n  labs(x = 'Dias', y = 'Overall survival') +\n  add_confidence_interval() +\n # add_risktable() +\n  scale_ggsurvfit() + \n  biostatsquid_theme #+  coord_cartesian(xlim = c(0, 8))\n\n\n\n\n\n\nModelo completo para brancos\n\n# Escrevendo o modelo\n\ncox_full_model_branco &lt;- coxph(surv_obj_branco ~ age + treat + Tempo_dialise + tt(Tempo_dialise),\n                        data=db_branco,\n                          tt=function(x,t,...) x*t) \n\nsummary(cox_full_model_branco)\n\nCall:\ncoxph(formula = surv_obj_branco ~ age + treat + Tempo_dialise + \n    tt(Tempo_dialise), data = db_branco, tt = function(x, t, \n    ...) x * t)\n\n  n= 464, number of events= 385 \n   (3 observations deleted due to missingness)\n\n                          coef    exp(coef)     se(coef)      z\nage               -0.000811624  0.999188705  0.008137628  -0.10\ntreat1             0.028995294  1.029419750  0.107276897   0.27\nTempo_dialise     -0.024166842  0.976122838  0.001707544 -14.15\ntt(Tempo_dialise)  0.000070240  1.000070242  0.000005841  12.03\n                             Pr(&gt;|z|)    \nage                             0.921    \ntreat1                          0.787    \nTempo_dialise     &lt;0.0000000000000002 ***\ntt(Tempo_dialise) &lt;0.0000000000000002 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n                  exp(coef) exp(-coef) lower .95 upper .95\nage                  0.9992     1.0008    0.9834    1.0153\ntreat1               1.0294     0.9714    0.8342    1.2703\nTempo_dialise        0.9761     1.0245    0.9729    0.9794\ntt(Tempo_dialise)    1.0001     0.9999    1.0001    1.0001\n\nConcordance= 0.78  (se = 0.01 )\nLikelihood ratio test= 286.5  on 4 df,   p=&lt;0.0000000000000002\nWald test            = 201.8  on 4 df,   p=&lt;0.0000000000000002\nScore (logrank) test = 185.6  on 4 df,   p=&lt;0.0000000000000002\n\n\n\n\nKM por raça = negro/pardo\n\n# Criando um novo objeto Surv\n\nsurv_obj_pardo_negro&lt;- Surv(time = db_pardo_negro$time, event = db_pardo_negro$morte)\n\nfit_pn = survfit(surv_obj_pardo_negro ~ treat, data = db_pardo_negro)\n\nggsurvfit(fit_pn, linewidth = 1) +\n  labs(x = 'Dias', y = 'Overall survival') +\n  add_confidence_interval() +\n # add_risktable() +\n  scale_ggsurvfit() + \n  biostatsquid_theme #+  coord_cartesian(xlim = c(0, 8))\n\n\n\n\n\n\nModelo completo para pardo/negro\n\n# Escrevendo o modelo\n\ncox_full_model_pardo_negro &lt;- coxph(surv_obj_pardo_negro ~ age + treat + Tempo_dialise + tt(Tempo_dialise),\n                        data=db_pardo_negro,\n                          tt=function(x,t,...) x*t) \n\nsummary(cox_full_model_pardo_negro)\n\nCall:\ncoxph(formula = surv_obj_pardo_negro ~ age + treat + Tempo_dialise + \n    tt(Tempo_dialise), data = db_pardo_negro, tt = function(x, \n    t, ...) x * t)\n\n  n= 153, number of events= 115 \n   (2 observations deleted due to missingness)\n\n                         coef   exp(coef)    se(coef)      z      Pr(&gt;|z|)    \nage               -0.02336224  0.97690855  0.01673857 -1.396         0.163    \ntreat1             0.07806397  1.08119182  0.19431411  0.402         0.688    \nTempo_dialise     -0.02367178  0.97660620  0.00397339 -5.958 0.00000000256 ***\ntt(Tempo_dialise)  0.00007639  1.00007639  0.00001784  4.282 0.00001853157 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n                  exp(coef) exp(-coef) lower .95 upper .95\nage                  0.9769     1.0236    0.9454    1.0095\ntreat1               1.0812     0.9249    0.7388    1.5824\nTempo_dialise        0.9766     1.0240    0.9690    0.9842\ntt(Tempo_dialise)    1.0001     0.9999    1.0000    1.0001\n\nConcordance= 0.696  (se = 0.025 )\nLikelihood ratio test= 48.53  on 4 df,   p=0.0000000007\nWald test            = 39.77  on 4 df,   p=0.00000005\nScore (logrank) test = 42.56  on 4 df,   p=0.00000001"
  },
  {
    "objectID": "lista_6_1.html#lista-6.1-resolvida-no-spss",
    "href": "lista_6_1.html#lista-6.1-resolvida-no-spss",
    "title": "7  Lista 6.1 - Cox tempo dependente",
    "section": "7.9 Lista 6.1 resolvida no SPSS",
    "text": "7.9 Lista 6.1 resolvida no SPSS"
  },
  {
    "objectID": "lista_6_1.html#extras",
    "href": "lista_6_1.html#extras",
    "title": "7  Lista 6.1 - Cox tempo dependente",
    "section": "7.10 Extras",
    "text": "7.10 Extras\n\nMais gráficos\nE utilizar nosso tema para personalizar e padronizar.\n\nfit2_km &lt;- ggsurvfit(fit1, linewidth = 1) +\n  labs(x = 'Dias', y = 'Porcentagem de sobrevida') +\n  add_confidence_interval() +\n # add_risktable() +\n  scale_ggsurvfit() + \n  biostatsquid_theme #+  coord_cartesian(xlim = c(0, 8))\n\nfit2_km\n\n\n\n\nCuidado com o p-value do gráfico a seguir, ele se refere apenas ao Log-rank\n\nggsurvplot(fit1, data = db,\n           size = 1,\n           palette = c('#E7B800', '#2e9fdf'),\n           censor.shape = '|', censor.size = 4,\n           conf.int = TRUE,\n           pval = TRUE, # CUIDADO, apenas log-rank\n          # risk.table = TRUE,\n         #  risk.table.col = 'strata',\n           legend.labs = list('0' = 'Transplante = sim', '1' = 'Transplante = não'),\n           risk.table.height = 0.25,\n           ggtheme = theme_bw())\n\n\n\n\n\n\nCox tempo dependente log\n\ncox_full_model_2 &lt;- coxph(surv_obj ~ age + race + treat + Tempo_dialise + tt(Tempo_dialise),\n                        data=db,\n                          tt=function(x,t,...) x*log(t)) \nsummary(cox_full_model_2)\n\nCall:\ncoxph(formula = surv_obj ~ age + race + treat + Tempo_dialise + \n    tt(Tempo_dialise), data = db, tt = function(x, t, ...) x * \n    log(t))\n\n  n= 617, number of events= 500 \n   (11 observations deleted due to missingness)\n\n                       coef exp(coef)  se(coef)       z             Pr(&gt;|z|)\nage               -0.005656  0.994360  0.007318  -0.773              0.43960\nracenegro/pardo   -0.296846  0.743159  0.108704  -2.731              0.00632\ntreat1            -0.007682  0.992348  0.094183  -0.082              0.93499\nTempo_dialise     -0.096272  0.908217  0.005996 -16.056 &lt; 0.0000000000000002\ntt(Tempo_dialise)  0.016885  1.017028  0.001098  15.383 &lt; 0.0000000000000002\n                     \nage                  \nracenegro/pardo   ** \ntreat1               \nTempo_dialise     ***\ntt(Tempo_dialise) ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n                  exp(coef) exp(-coef) lower .95 upper .95\nage                  0.9944     1.0057    0.9802    1.0087\nracenegro/pardo      0.7432     1.3456    0.6006    0.9196\ntreat1               0.9923     1.0077    0.8251    1.1935\nTempo_dialise        0.9082     1.1011    0.8976    0.9190\ntt(Tempo_dialise)    1.0170     0.9833    1.0148    1.0192\n\nConcordance= 0.764  (se = 0.009 )\nLikelihood ratio test= 459.7  on 5 df,   p=&lt;0.0000000000000002\nWald test            = 290.9  on 5 df,   p=&lt;0.0000000000000002\nScore (logrank) test = 237.8  on 5 df,   p=&lt;0.0000000000000002\n\nAIC(cox_full_model_2)\n\n[1] 5356.724"
  },
  {
    "objectID": "lista_6_1.html#referencias",
    "href": "lista_6_1.html#referencias",
    "title": "7  Lista 6.1 - Cox tempo dependente",
    "section": "7.11 Referencias",
    "text": "7.11 Referencias\nhttps://stats.oarc.ucla.edu/wp-content/uploads/2022/05/survival_r.html#(48)\nhttps://www.youtube.com/watch?v=Y_83HXuHMdc\nhttps://youtu.be/Y_83HXuHMdc?t=9151"
  },
  {
    "objectID": "lista_6_1.html#códigos-não-utilizados",
    "href": "lista_6_1.html#códigos-não-utilizados",
    "title": "7  Lista 6.1 - Cox tempo dependente",
    "section": "7.12 Códigos não utilizados",
    "text": "7.12 Códigos não utilizados\n\n# Ajustando o banco de dados\n\ndb3 = db\n\n\n# db3$time = pmax(0.5, db3$time - 0) caso eu tenha zeros no tempo de morte\n# db3$time660 = as.integer(db3$time660)\n# head(db3)\n\n# db3$time660 = as.integer(db3$time660)\n\ndb3 &lt;- tmerge(\n  data1 = db3,\n  data2 = db3,\n  id = ID,\n # death = event(T1, delta1), caso tenha dois eventos de morte independentes. Duas doenças diferentes, por exemplo\n  death = event(time, morte),\n  T_Cov = tdc(Tempo_dialise) # indicando a covariavel tempo-dependente\n)\n\nhead(db3)\n\n   ID age   race treat Tempo_dialise time morte tstart tstop death T_Cov\n1 112  35 branco     1            51 1172     0      0    51     0     0\n2 112  35 branco     1            51 1172     0     51  1172     0     1\n3  91  33 branco     0            67  762     0      0    67     0     0\n4  91  33 branco     0            67  762     0     67   762     0     1\n5 113  35 branco     0            88  734     0      0    88     0     0\n6 113  35 branco     0            88  734     0     88   734     0     1\n\n\n\n# Duvida para Altay - colocar o evento como morte2 ou death\ncox_model_T_Cov &lt;- coxph(Surv(time = tstart, time2 = tstop, event = morte) ~ treat + T_Cov, data = db3)\n\nsummary(cox_model_T_Cov)\n\nCall:\ncoxph(formula = Surv(time = tstart, time2 = tstop, event = morte) ~ \n    treat + T_Cov, data = db3)\n\n  n= 1174, number of events= 934 \n\n           coef exp(coef) se(coef)      z Pr(&gt;|z|)   \ntreat1 -0.17205   0.84194  0.06668 -2.580  0.00987 **\nT_Cov   0.03829   1.03903  0.08493  0.451  0.65210   \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n       exp(coef) exp(-coef) lower .95 upper .95\ntreat1    0.8419     1.1877    0.7388    0.9595\nT_Cov     1.0390     0.9624    0.8797    1.2272\n\nConcordance= 0.539  (se = 0.01 )\nLikelihood ratio test= 7.53  on 2 df,   p=0.02\nWald test            = 7.53  on 2 df,   p=0.02\nScore (logrank) test = 7.54  on 2 df,   p=0.02\n\ndb3 %&gt;% \n  coxph(Surv(time = tstart, time2 = tstop, event = death) ~ treat + age + race + T_Cov, data = .) %&gt;% \n  gtsummary::tbl_regression(exp = TRUE)\n\n\n\n\n\n  \n    \n    \n      Characteristic\n      HR1\n      95% CI1\n      p-value\n    \n  \n  \n    treat\n\n\n\n        0\n—\n—\n\n        1\n1.05\n0.88, 1.25\n0.6\n    age\n1.00\n0.98, 1.01\n0.5\n    race\n\n\n\n        branco\n—\n—\n\n        negro/pardo\n0.68\n0.55, 0.84\n&lt;0.001\n    T_Cov\n13.6\n10.1, 18.4\n&lt;0.001\n  \n  \n  \n    \n      1 HR = Hazard Ratio, CI = Confidence Interval\n    \n  \n\n\n\n\n\nTempo em diálise como covariante tempo-dependente\n\n# Ajustando o banco de dados\n\ndb2 = db\n\n\n#db2$time = pmax(0.5, db2$time - 0)\n\n\ndb2 &lt;- tmerge(\n  data1 = db,\n  data2 = db,\n  id = ID,\n # death = event(T1, delta1), caso tenha dois eventos de morte independentes. Duas doenças diferentes, por exemplo\n  death = event(time, morte),\n  T_Tempo_dialise = tdc(Tempo_dialise) # indicando a covariavel tempo-dependente\n)\nhead(db2)\n\n   ID age   race treat Tempo_dialise time morte tstart tstop death\n1 112  35 branco     1            51 1172     0      0    51     0\n2 112  35 branco     1            51 1172     0     51  1172     0\n3  91  33 branco     0            67  762     0      0    67     0\n4  91  33 branco     0            67  762     0     67   762     0\n5 113  35 branco     0            88  734     0      0    88     0\n6 113  35 branco     0            88  734     0     88   734     0\n  T_Tempo_dialise\n1               0\n2               1\n3               0\n4               1\n5               0\n6               1\n\n\n\ncox_model_time_dependent &lt;- coxph(Surv(time = tstart, time2 = tstop, event = death) ~ T_Tempo_dialise + treat, data = db2)\n\nsummary(cox_model_time_dependent)\n\nCall:\ncoxph(formula = Surv(time = tstart, time2 = tstop, event = death) ~ \n    T_Tempo_dialise + treat, data = db2)\n\n  n= 1174, number of events= 508 \n\n                     coef exp(coef)  se(coef)      z            Pr(&gt;|z|)    \nT_Tempo_dialise  2.585761 13.273384  0.150925 17.133 &lt;0.0000000000000002 ***\ntreat1          -0.003201  0.996804  0.089471 -0.036               0.971    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n                exp(coef) exp(-coef) lower .95 upper .95\nT_Tempo_dialise   13.2734    0.07534    9.8745    17.842\ntreat1             0.9968    1.00321    0.8365     1.188\n\nConcordance= 0.699  (se = 0.014 )\nLikelihood ratio test= 382.7  on 2 df,   p=&lt;0.0000000000000002\nWald test            = 294.6  on 2 df,   p=&lt;0.0000000000000002\nScore (logrank) test = 354.7  on 2 df,   p=&lt;0.0000000000000002\n\ndb2 %&gt;% \n  coxph(Surv(time = tstart, time2 = tstop, event = death) ~ T_Tempo_dialise * treat, data = .) %&gt;% \n  gtsummary::tbl_regression(exp = TRUE)\n\n\n\n\n\n  \n    \n    \n      Characteristic\n      HR1\n      95% CI1\n      p-value\n    \n  \n  \n    T_Tempo_dialise\n9.78\n6.78, 14.1\n&lt;0.001\n    treat\n\n\n\n        0\n—\n—\n\n        1\n0.59\n0.38, 0.92\n0.020\n    T_Tempo_dialise * treat\n\n\n\n        T_Tempo_dialise * 1\n1.86\n1.15, 3.02\n0.012\n  \n  \n  \n    \n      1 HR = Hazard Ratio, CI = Confidence Interval"
  },
  {
    "objectID": "lista_6_1.html#versões-dos-pacotes",
    "href": "lista_6_1.html#versões-dos-pacotes",
    "title": "7  Lista 6.1 - Cox tempo dependente",
    "section": "7.13 Versões dos pacotes",
    "text": "7.13 Versões dos pacotes\n\nreport(sessionInfo())\n\nAnalyses were conducted using the R Statistical language (version 4.3.1; R Core\nTeam, 2023) on Windows 11 x64 (build 22621), using the packages effectsize\n(version 0.8.6; Ben-Shachar MS et al., 2020), lpSolve (version 5.6.19;\nBerkelaar M, others, 2023), survMisc (version 0.5.6; Dardis C, 2022), tm\n(version 0.7.11; Feinerer I, Hornik K, 2023), flexplot (version 0.20.5; Fife D,\n2024), lubridate (version 1.9.3; Grolemund G, Wickham H, 2011), coxphf (version\n1.13.4; Heinze G et al., 2023), NLP (version 0.2.1; Hornik K, 2020), coin\n(version 1.4.3; Hothorn T et al., 2006), ggpubr (version 0.6.0; Kassambara A,\n2023), survminer (version 0.4.9; Kassambara A et al., 2021),\nPHInfiniteEstimates (version 2.9.5; Kolassa JE, Zhang J, 2023), parameters\n(version 0.21.3; Lüdecke D et al., 2020), performance (version 0.10.8; Lüdecke\nD et al., 2021), easystats (version 0.6.0; Lüdecke D et al., 2022), see\n(version 0.8.1; Lüdecke D et al., 2021), insight (version 0.19.6; Lüdecke D et\nal., 2019), bayestestR (version 0.13.1; Makowski D et al., 2019), modelbased\n(version 0.8.6; Makowski D et al., 2020), report (version 0.5.7; Makowski D et\nal., 2023), correlation (version 0.8.4; Makowski D et al., 2022), condSURV\n(version 2.0.4; Meira-Machado L, Sestelo M, 2023), tibble (version 3.2.1;\nMüller K, Wickham H, 2023), datawizard (version 0.9.0; Patil I et al., 2022),\nforeign (version 0.8.85; R Core Team, 2023), nph (version 2.1; Ristl R et al.,\n2021), broom (version 1.0.5; Robinson D et al., 2023), ggsurvfit (version\n1.0.0; Sjoberg D et al., 2023), gtsummary (version 1.7.2; Sjoberg D et al.,\n2021), rempsyc (version 0.1.6; Thériault R, 2023), survival (version 3.5.7;\nTherneau T, 2023), ggplot2 (version 3.4.4; Wickham H, 2016), forcats (version\n1.0.0; Wickham H, 2023), stringr (version 1.5.1; Wickham H, 2023), tidyverse\n(version 2.0.0; Wickham H et al., 2019), dplyr (version 1.1.3; Wickham H et\nal., 2023), purrr (version 1.0.2; Wickham H, Henry L, 2023), readr (version\n2.1.4; Wickham H et al., 2023), tidyr (version 1.3.0; Wickham H et al., 2023)\nand kableExtra (version 1.3.4; Zhu H, 2021).\n\nReferences\n----------\n  - Ben-Shachar MS, Lüdecke D, Makowski D (2020). \"effectsize: Estimation of\nEffect Size Indices and Standardized Parameters.\" _Journal of Open Source\nSoftware_, *5*(56), 2815. doi:10.21105/joss.02815\n&lt;https://doi.org/10.21105/joss.02815&gt;, &lt;https://doi.org/10.21105/joss.02815&gt;.\n  - Berkelaar M, others (2023). _lpSolve: Interface to 'Lp_solve' v. 5.5 to Solve\nLinear/Integer Programs_. R package version 5.6.19,\n&lt;https://CRAN.R-project.org/package=lpSolve&gt;.\n  - Dardis C (2022). _survMisc: Miscellaneous Functions for Survival Data_. R\npackage version 0.5.6, &lt;https://CRAN.R-project.org/package=survMisc&gt;.\n  - Feinerer I, Hornik K (2023). _tm: Text Mining Package_. R package version\n0.7-11, &lt;https://CRAN.R-project.org/package=tm&gt;. Feinerer I, Hornik K, Meyer D\n(2008). \"Text Mining Infrastructure in R.\" _Journal of Statistical Software_,\n*25*(5), 1-54. doi:10.18637/jss.v025.i05\n&lt;https://doi.org/10.18637/jss.v025.i05&gt;.\n  - Fife D (2024). _flexplot: Graphically Based Data Analysis Using 'flexplot'_.\nR package version 0.20.5.\n  - Grolemund G, Wickham H (2011). \"Dates and Times Made Easy with lubridate.\"\n_Journal of Statistical Software_, *40*(3), 1-25.\n&lt;https://www.jstatsoft.org/v40/i03/&gt;.\n  - Heinze G, Ploner M, Jiricka L, Steiner G (2023). _coxphf: Cox Regression with\nFirth's Penalized Likelihood_. R package version 1.13.4,\n&lt;https://CRAN.R-project.org/package=coxphf&gt;.\n  - Hornik K (2020). _NLP: Natural Language Processing Infrastructure_. R package\nversion 0.2-1, &lt;https://CRAN.R-project.org/package=NLP&gt;.\n  - Hothorn T, Hornik K, van de Wiel MA, Zeileis A (2006). \"A Lego system for\nconditional inference.\" _The American Statistician_, *60*(3), 257-263.\ndoi:10.1198/000313006X118430 &lt;https://doi.org/10.1198/000313006X118430&gt;.\nHothorn T, Hornik K, van de Wiel MA, Zeileis A (2008). \"Implementing a class of\npermutation tests: The coin package.\" _Journal of Statistical Software_,\n*28*(8), 1-23. doi:10.18637/jss.v028.i08\n&lt;https://doi.org/10.18637/jss.v028.i08&gt;.\n  - Kassambara A (2023). _ggpubr: 'ggplot2' Based Publication Ready Plots_. R\npackage version 0.6.0, &lt;https://CRAN.R-project.org/package=ggpubr&gt;.\n  - Kassambara A, Kosinski M, Biecek P (2021). _survminer: Drawing Survival\nCurves using 'ggplot2'_. R package version 0.4.9,\n&lt;https://CRAN.R-project.org/package=survminer&gt;.\n  - Kolassa JE, Zhang J (2023). _PHInfiniteEstimates: Tools for Inference in the\nPresence of a Monotone Likelihood_. R package version 2.9.5,\n&lt;https://CRAN.R-project.org/package=PHInfiniteEstimates&gt;.\n  - Lüdecke D, Ben-Shachar M, Patil I, Makowski D (2020). \"Extracting, Computing\nand Exploring the Parameters of Statistical Models using R.\" _Journal of Open\nSource Software_, *5*(53), 2445. doi:10.21105/joss.02445\n&lt;https://doi.org/10.21105/joss.02445&gt;.\n  - Lüdecke D, Ben-Shachar M, Patil I, Waggoner P, Makowski D (2021).\n\"performance: An R Package for Assessment, Comparison and Testing of\nStatistical Models.\" _Journal of Open Source Software_, *6*(60), 3139.\ndoi:10.21105/joss.03139 &lt;https://doi.org/10.21105/joss.03139&gt;.\n  - Lüdecke D, Ben-Shachar M, Patil I, Wiernik B, Makowski D (2022). \"easystats:\nFramework for Easy Statistical Modeling, Visualization, and Reporting.\" _CRAN_.\nR package, &lt;https://easystats.github.io/easystats/&gt;.\n  - Lüdecke D, Patil I, Ben-Shachar M, Wiernik B, Waggoner P, Makowski D (2021).\n\"see: An R Package for Visualizing Statistical Models.\" _Journal of Open Source\nSoftware_, *6*(64), 3393. doi:10.21105/joss.03393\n&lt;https://doi.org/10.21105/joss.03393&gt;.\n  - Lüdecke D, Waggoner P, Makowski D (2019). \"insight: A Unified Interface to\nAccess Information from Model Objects in R.\" _Journal of Open Source Software_,\n*4*(38), 1412. doi:10.21105/joss.01412 &lt;https://doi.org/10.21105/joss.01412&gt;.\n  - Makowski D, Ben-Shachar M, Lüdecke D (2019). \"bayestestR: Describing Effects\nand their Uncertainty, Existence and Significance within the Bayesian\nFramework.\" _Journal of Open Source Software_, *4*(40), 1541.\ndoi:10.21105/joss.01541 &lt;https://doi.org/10.21105/joss.01541&gt;,\n&lt;https://joss.theoj.org/papers/10.21105/joss.01541&gt;.\n  - Makowski D, Ben-Shachar M, Patil I, Lüdecke D (2020). \"Estimation of\nModel-Based Predictions, Contrasts and Means.\" _CRAN_.\n&lt;https://github.com/easystats/modelbased&gt;.\n  - Makowski D, Lüdecke D, Patil I, Thériault R, Ben-Shachar M, Wiernik B (2023).\n\"Automated Results Reporting as a Practical Tool to Improve Reproducibility and\nMethodological Best Practices Adoption.\" _CRAN_.\n&lt;https://easystats.github.io/report/&gt;.\n  - Makowski D, Wiernik B, Patil I, Lüdecke D, Ben-Shachar M (2022).\n\"correlation: Methods for Correlation Analysis.\" Version 0.8.3,\n&lt;https://CRAN.R-project.org/package=correlation&gt;. Makowski D, Ben-Shachar M,\nPatil I, Lüdecke D (2020). \"Methods and Algorithms for Correlation Analysis in\nR.\" _Journal of Open Source Software_, *5*(51), 2306. doi:10.21105/joss.02306\n&lt;https://doi.org/10.21105/joss.02306&gt;,\n&lt;https://joss.theoj.org/papers/10.21105/joss.02306&gt;.\n  - Meira-Machado L, Sestelo M (2023). _condSURV: Estimation of the Conditional\nSurvival Function for Ordered Multivariate Failure Time Data_. R package\nversion 2.0.4, &lt;https://CRAN.R-project.org/package=condSURV&gt;.\n  - Müller K, Wickham H (2023). _tibble: Simple Data Frames_. R package version\n3.2.1, &lt;https://CRAN.R-project.org/package=tibble&gt;.\n  - Patil I, Makowski D, Ben-Shachar M, Wiernik B, Bacher E, Lüdecke D (2022).\n\"datawizard: An R Package for Easy Data Preparation and Statistical\nTransformations.\" _Journal of Open Source Software_, *7*(78), 4684.\ndoi:10.21105/joss.04684 &lt;https://doi.org/10.21105/joss.04684&gt;.\n  - R Core Team (2023). _foreign: Read Data Stored by 'Minitab', 'S', 'SAS',\n'SPSS', 'Stata', 'Systat', 'Weka', 'dBase', ..._. R package version 0.8-85,\n&lt;https://CRAN.R-project.org/package=foreign&gt;.\n  - R Core Team (2023). _R: A Language and Environment for Statistical\nComputing_. R Foundation for Statistical Computing, Vienna, Austria.\n&lt;https://www.R-project.org/&gt;.\n  - Ristl R, Ballarini N, Götte H, Schüler A, Posch M, König F (2021). \"Delayed\ntreatment effects, treatment switching and heterogeneous patient populations:\nHow to design and analyze RCTs in oncology.\" _Pharmaceutical statistics_,\n*20*(1), 129-145.\n  - Robinson D, Hayes A, Couch S (2023). _broom: Convert Statistical Objects into\nTidy Tibbles_. R package version 1.0.5,\n&lt;https://CRAN.R-project.org/package=broom&gt;.\n  - Sjoberg D, Baillie M, Fruechtenicht C, Haesendonckx S, Treis T (2023).\n_ggsurvfit: Flexible Time-to-Event Figures_. R package version 1.0.0,\n&lt;https://CRAN.R-project.org/package=ggsurvfit&gt;.\n  - Sjoberg D, Whiting K, Curry M, Lavery J, Larmarange J (2021). \"Reproducible\nSummary Tables with the gtsummary Package.\" _The R Journal_, *13*, 570-580.\ndoi:10.32614/RJ-2021-053 &lt;https://doi.org/10.32614/RJ-2021-053&gt;,\n&lt;https://doi.org/10.32614/RJ-2021-053&gt;.\n  - Thériault R (2023). \"rempsyc: Convenience functions for psychology.\" _Journal\nof Open Source Software_, *8*(87), 5466. doi:10.21105/joss.05466\n&lt;https://doi.org/10.21105/joss.05466&gt;, &lt;https://doi.org/10.21105/joss.05466&gt;.\n  - Therneau T (2023). _A Package for Survival Analysis in R_. R package version\n3.5-7, &lt;https://CRAN.R-project.org/package=survival&gt;. Terry M. Therneau,\nPatricia M. Grambsch (2000). _Modeling Survival Data: Extending the Cox Model_.\nSpringer, New York. ISBN 0-387-98784-3.\n  - Wickham H (2016). _ggplot2: Elegant Graphics for Data Analysis_.\nSpringer-Verlag New York. ISBN 978-3-319-24277-4,\n&lt;https://ggplot2.tidyverse.org&gt;.\n  - Wickham H (2023). _forcats: Tools for Working with Categorical Variables\n(Factors)_. R package version 1.0.0,\n&lt;https://CRAN.R-project.org/package=forcats&gt;.\n  - Wickham H (2023). _stringr: Simple, Consistent Wrappers for Common String\nOperations_. R package version 1.5.1,\n&lt;https://CRAN.R-project.org/package=stringr&gt;.\n  - Wickham H, Averick M, Bryan J, Chang W, McGowan LD, François R, Grolemund G,\nHayes A, Henry L, Hester J, Kuhn M, Pedersen TL, Miller E, Bache SM, Müller K,\nOoms J, Robinson D, Seidel DP, Spinu V, Takahashi K, Vaughan D, Wilke C, Woo K,\nYutani H (2019). \"Welcome to the tidyverse.\" _Journal of Open Source Software_,\n*4*(43), 1686. doi:10.21105/joss.01686 &lt;https://doi.org/10.21105/joss.01686&gt;.\n  - Wickham H, François R, Henry L, Müller K, Vaughan D (2023). _dplyr: A Grammar\nof Data Manipulation_. R package version 1.1.3,\n&lt;https://CRAN.R-project.org/package=dplyr&gt;.\n  - Wickham H, Henry L (2023). _purrr: Functional Programming Tools_. R package\nversion 1.0.2, &lt;https://CRAN.R-project.org/package=purrr&gt;.\n  - Wickham H, Hester J, Bryan J (2023). _readr: Read Rectangular Text Data_. R\npackage version 2.1.4, &lt;https://CRAN.R-project.org/package=readr&gt;.\n  - Wickham H, Vaughan D, Girlich M (2023). _tidyr: Tidy Messy Data_. R package\nversion 1.3.0, &lt;https://CRAN.R-project.org/package=tidyr&gt;.\n  - Zhu H (2021). _kableExtra: Construct Complex Table with 'kable' and Pipe\nSyntax_. R package version 1.3.4,\n&lt;https://CRAN.R-project.org/package=kableExtra&gt;."
  },
  {
    "objectID": "ARIMA.html#fundamentos-do-arima",
    "href": "ARIMA.html#fundamentos-do-arima",
    "title": "ARIMA",
    "section": "Fundamentos do ARIMA:",
    "text": "Fundamentos do ARIMA:\nAutoRegressivo (AR): Refere-se à relação entre uma observação atual e suas observações passadas. O termo “AutoRegressivo” destaca a dependência linear de uma observação em relação a suas antecessoras.\nIntegrated (I): Indica o número de diferenciações necessárias para tornar a série temporal estacionária, ou seja, para remover tendências e padrões sistemáticos. A estacionarização é crucial para garantir a estabilidade do modelo.\nMédia Móvel (MA): Considera os erros residuais das observações anteriores para prever a próxima. O componente “Média Móvel” reflete a média dos erros anteriores, incorporando informações sobre o comportamento recente da série.\nNúmero de observações: O número ideal de observações repetidas para uma única unidade de análise é de pelo menos 40, sendo preferível alcançar 50 observações. Não é necessário ter um grande número de pessoas ou unidades de análise; até mesmo com N = 1, você pode obter várias observações do mesmo indivíduo, tornando o ARIMA uma ferramenta eficaz de análise."
  },
  {
    "objectID": "ARIMA.html#condições-e-pressupostos",
    "href": "ARIMA.html#condições-e-pressupostos",
    "title": "ARIMA",
    "section": "Condições e Pressupostos:",
    "text": "Condições e Pressupostos:\nEstacionariedade: O ARIMA assume que a série temporal seja estacionária, o que significa que a média, a variância e a estrutura de autocorrelação não devem variar significativamente ao longo do tempo. Se a série não for estacionária, é necessário aplicar diferenciação até atingir a estacionariedade.\nIdentificação de Ordem: A escolha adequada dos parâmetros p, d, e q (ordens AR, I, e MA) é crucial. Isso geralmente é feito por meio de análise visual, funções de autocorrelação (ACF) e autocorrelação parcial (PACF), bem como métodos estatísticos como o critério de informação de Akaike (AIC).\nRuído Branco: Os resíduos do modelo ARIMA devem se comportar como um “ruído branco”, ou seja, serem independentes, terem média zero e variância constante. Isso garante que não haja padrões significativos nos erros residuais não capturados pelo modelo.\nAlém dos componentes fundamentais, o ARIMA pode ser estendido para lidar com sazonalidade através do SARIMA (Seasonal ARIMA), que incorpora parâmetros adicionais para modelar padrões recorrentes em determinados intervalos de tempo.\nA adequada compreensão dos fundamentos, condições e pressupostos é essencial para explorar todo o potencial desse método e fazer previsões precisas em uma variedade de contextos."
  },
  {
    "objectID": "ARIMA.html#passo-a-passo-da-arima",
    "href": "ARIMA.html#passo-a-passo-da-arima",
    "title": "ARIMA",
    "section": "Passo a Passo da ARIMA",
    "text": "Passo a Passo da ARIMA\n\nColeta e Exploração de Dados:\n\nInicie coletando dados temporais relevantes para sua análise.\nExplore graficamente a série temporal para identificar padrões, sazonalidades e tendências.\n\nEstacionarização da Série:\n\nDiferencie a série temporal para torná-la estacionária.\nUtilize gráficos, como sequence charts, para visualizar mudanças ao longo do tempo.\n\nIdentificação dos Parâmetros (p, d, q):\n\nAnalise as funções de autocorrelação (ACF) e autocorrelação parcial (PACF) para determinar os valores ideais de p (ordem AR) e q (ordem MA).\nEstabeleça a ordem de diferenciação d necessária para atingir a estacionariedade.\n\nDivisão dos Dados:\n\nSepare os dados em conjuntos de treinamento e teste para avaliar o desempenho do modelo posteriormente.\n\nAjuste do Modelo ARIMA:\n\nUtilize os parâmetros (p, d, q) identificados para ajustar o modelo ARIMA aos dados de treinamento.\nAjuste também os parâmetros sazonais, se aplicável (SARIMA).\n\nValidação do Modelo:\n\nAvalie a qualidade do modelo usando critérios de informação como AIC (Akaike Information Criterion) e BIC (Bayesian Information Criterion) para modelos com os mesmos valores de p, d, e q.\nCalcule o erro médio quadrático (RMSE) para comparar modelos com diferentes configurações de p, d, e q.\n\nPrevisões e Avaliação:\n\nFaça previsões utilizando o modelo ARIMA ajustado nos dados de teste.\nAvalie a precisão das previsões comparando-as com os valores reais.\n\nAjustes Finais e Refinamentos:\n\nSe necessário, ajuste os parâmetros do modelo com base na análise da qualidade das previsões.\nConsidere iterar nos passos anteriores para melhorar a performance do modelo.\n\nInterpretação e Comunicação dos Resultados:\n\nComunique os resultados do modelo de forma clara, destacando as tendências identificadas e a capacidade de previsão.\n\n\nNa lista prática de exercícios vamos analisar dois bancos de dados, um apenas para verificar se o modelo é estacionário ou não e outro para de fato criar modelos ARIMA.\nPara mais informações sobre os parâmetros p, d, q, consulte as referências"
  },
  {
    "objectID": "ARIMA.html#referências",
    "href": "ARIMA.html#referências",
    "title": "ARIMA",
    "section": "Referências",
    "text": "Referências\nhttps://people.duke.edu/~rnau/411arim.htm"
  },
  {
    "objectID": "lista_7.html",
    "href": "lista_7.html",
    "title": "8  Lista 7 - Séries Temporais (ARIMA)",
    "section": "",
    "text": "9 Cigarro"
  },
  {
    "objectID": "lista_7.html#pacotes",
    "href": "lista_7.html#pacotes",
    "title": "8  Lista 7 - Séries Temporais (ARIMA)",
    "section": "8.1 Pacotes",
    "text": "8.1 Pacotes\n\nlibrary(tidyverse)\nlibrary(flexplot)\nlibrary(foreign)\nlibrary(dplyr)\nlibrary(tm)\nlibrary(ggplot2)\nlibrary(forcats)\nlibrary(rempsyc)\nlibrary(easystats)\nlibrary(kableExtra)\n\n#Específicos para series temporais\nlibrary(prophet)\nlibrary(forecast)\nlibrary(tseries)"
  },
  {
    "objectID": "lista_7.html#limpando-o-ambiente",
    "href": "lista_7.html#limpando-o-ambiente",
    "title": "8  Lista 7 - Séries Temporais (ARIMA)",
    "section": "8.2 Limpando o ambiente",
    "text": "8.2 Limpando o ambiente"
  },
  {
    "objectID": "lista_7.html#carregando-os-dados-e-modificando-o-tipo-de-variável",
    "href": "lista_7.html#carregando-os-dados-e-modificando-o-tipo-de-variável",
    "title": "8  Lista 7 - Séries Temporais (ARIMA)",
    "section": "9.1 Carregando os dados e modificando o tipo de variável",
    "text": "9.1 Carregando os dados e modificando o tipo de variável\n\noriginal = read.spss(\"CigarrosROD_1.sav\", to.data.frame=TRUE)\nglimpse(original)\n\nRows: 20\nColumns: 2\n$ Dia         &lt;dbl&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17,…\n$ cigarrosROD &lt;dbl&gt; 6, 10, 4, 13, 4, 11, 4, 6, 4, 15, 5, 14, 5, 21, 10, 31, 13…\n\ndb = original"
  },
  {
    "objectID": "lista_7.html#verificando-se-os-dados-são-estacionários",
    "href": "lista_7.html#verificando-se-os-dados-são-estacionários",
    "title": "8  Lista 7 - Séries Temporais (ARIMA)",
    "section": "9.2 Verificando se os dados são estacionários",
    "text": "9.2 Verificando se os dados são estacionários\nIniciaremos nossa primeira análise para verificar a estacionaridade dos dados por meio de uma abordagem gráfica. Este gráfico simples exibirá o número de cigarros consumidos ao longo do tempo, apresentando uma linha média que atravessa toda a linha temporal. A ideia é observar se os números de cigarros oscilam próximos à média, proporcionando uma visualização intuitiva da estacionariedade dos dados.\n\n# Plot estilizado\n# media_cigarros &lt;- mean(db$cigarrosROD)\n# \n# # Cria o gráfico com ggplot\n# ggplot(data = data.frame(cigarrosROD = db$cigarrosROD), aes(x = seq_along(cigarrosROD), y = cigarrosROD)) +\n#   geom_line(color = \"black\", size = 1) +\n#   geom_point(color = \"black\", size = 3) +\n#   geom_hline(yintercept = media_cigarros, linetype = \"dashed\", color = \"blue\", size = 1) +  # Adiciona a linha média\n#   labs(x = \"Dias\", y = \"Cigarros por dia\") +\n#   scale_x_continuous(breaks = seq_along(db$cigarrosROD), labels = seq_along(db$cigarrosROD)) +\n#   theme_minimal() +\n#   theme(panel.grid = element_blank(),\n#         axis.ticks = element_line())  # Adiciona ticks nos eixos x e y\n\n\nPlot simples\n\nmedia_cigarros &lt;- mean(db$cigarrosROD)\n\n# plot mais simples\nplot.ts(db$cigarrosROD)\nabline(h = media_cigarros, col = \"blue\", lty = 2, lwd = 2)\naxis(1, at = db$Dia, labels = db$Dia)\n\n\n\n\nClaramente os dados desviam bastante da média, logo essa não é uma série estacionária.\n\n\nAdf teste\nPodemos também utilizar o Augmented Dickey-Fuller (ADF) Test para avaliar a estacionaridade em séries temporais. A função para realizar o teste é a adf.test().\nInterpretação do Resultado:\n\nSe a estatística do teste for menor que o valor crítico (p &lt; 0.05), rejeitamos a hipótese nula e concluímos que a série é estacionária.\nSe a estatística do teste for maior que o valor crítico (p &gt; 0.05), falhamos em rejeitar a hipótese nula, sugerindo que a série é não estacionária.\n\n\n# Adf teste\nadf.test(db$cigarrosROD)\n\n\n    Augmented Dickey-Fuller Test\n\ndata:  db$cigarrosROD\nDickey-Fuller = -0.38979, Lag order = 2, p-value = 0.9797\nalternative hypothesis: stationary\n\n\nCorroborando a análise visual, falhamos em rejeitar a hipótese nula, logo podemos assumir que a série temporal em questão não é estacionária. Em seguida vamos ver como podemos ajustar os dados.\n\n\nAutocorrelação\nA função acf() (AutoCorrelation Function) no R é utilizada para calcular e visualizar os coeficientes de autocorrelação em uma série temporal. A autocorrelação mede a correlação entre uma observação e suas observações anteriores em diferentes defasagens (lags de tempo).\n\n# Calcula as autocorrelações e cria o gráfico\n\nautocorrelacoes = acf(db$cigarrosROD, plot = FALSE)\n\nautoplot(autocorrelacoes)\n\n\n\n\n\nggtsdisplay(db$cigarrosROD)\n\n\n\n\nOs valores de lag que tiveram um AFC além do intervalo de confiança (linha tracejada), são candidatos para utilizarmos em nosso modelo ARIMA. Portanto lag 2 e 4 são candidatos. Além disso podemos basear nossa decisão também o teste de Ljung-Box.\n\n\nTeste Ljung-Box\nO Teste Ljung-Box avalia para cada lag se a séria é estacionária ou não. Podemos testar individualmente para cada lag.\n\n# Teste Ljung-Box com lag 2\nBox.test(autocorrelacoes$acf , lag = 3, type = \"Ljung-Box\")\n\n\n    Box-Ljung test\n\ndata:  autocorrelacoes$acf\nX-squared = 8.5179, df = 3, p-value = 0.03644\n\nlag(db$cigarrosROD,1)\n\n [1] NA  6 10  4 13  4 11  4  6  4 15  5 14  5 21 10 31 13 39 16\n\n\nUma outra forma é criar um dataframe com todos os valores de lags calculados na autocorrelação.\n\n# Obtém o número máximo de lags disponíveis\nmax_lags &lt;- length(autocorrelacoes$acf) - 1\n\n# Inicialize os vetores para armazenar os resultados\nlags &lt;- numeric(max_lags)\np_values &lt;- numeric(max_lags)\n\n# Itere sobre os lags\nfor (lag in 1:max_lags) {\n  # Execute o teste de Ljung-Box para o lag atual\n  resultado_teste &lt;- Box.test(autocorrelacoes$acf, lag = lag, type = \"Ljung-Box\")\n  \n  # Armazene os resultados\n  lags[lag] &lt;- lag\n  p_values[lag] &lt;- resultado_teste$p.value\n}\n\n# Crie um dataframe com os resultados\nresultados_df &lt;- data.frame(Lag = lags, P_Value = p_values)\nkable(resultados_df)\n\n\n\n\nLag\nP_Value\n\n\n\n\n1\n0.9409683\n\n\n2\n0.0166341\n\n\n3\n0.0364377\n\n\n4\n0.0200419\n\n\n5\n0.0236724\n\n\n6\n0.0359384\n\n\n7\n0.0197526\n\n\n8\n0.0337181\n\n\n9\n0.0101406\n\n\n10\n0.0150763\n\n\n11\n0.0030557\n\n\n12\n0.0038952\n\n\n13\n0.0006256\n\n\n\n\n\n\n\nOu ainda\n\ntsdiag(auto.arima(db$cigarrosROD))"
  },
  {
    "objectID": "lista_7.html#transformação-variabilidade-e-estacionária",
    "href": "lista_7.html#transformação-variabilidade-e-estacionária",
    "title": "8  Lista 7 - Séries Temporais (ARIMA)",
    "section": "9.3 Transformação variabilidade e estacionária",
    "text": "9.3 Transformação variabilidade e estacionária\nPrimeiro vamos modificar a série para que tenha variabilidade constante\n\nlambda = BoxCox.lambda(db$cigarrosROD)\nlambda\n\n[1] -0.1713367\n\nvar_const = BoxCox(db$cigarrosROD, lambda = lambda)\n\nggtsdisplay(var_const)\n\n\n\n\nE agora podemos ajustar a serie para que ela fique estacionária.\n\nndiffs(var_const)\n\n[1] 1\n\n\n\nestacio = diff(var_const, 1)\nggtsdisplay(estacio)\n\n\n\n\nDe acordo com os resultados, qualquer lag, a não ser o lag 1, poderá ser utilizado para transformar os dados.\nPara decidir devemos levar em conta tanto a análise gráfica da autocorrelação quanto o teste de Ljung-Box.\nLogo os lags 2 e 4 são bons candidatos. Por parcimônia e sem nenhum critério teórico, vamos optar pelo lag menor, ou seja, lag 2."
  },
  {
    "objectID": "lista_7.html#transformando-os-dados-para-estacionários",
    "href": "lista_7.html#transformando-os-dados-para-estacionários",
    "title": "8  Lista 7 - Séries Temporais (ARIMA)",
    "section": "9.4 Transformando os dados para estacionários",
    "text": "9.4 Transformando os dados para estacionários\nPara modificar nossa série temporal utilizando lag 2 vamos utilizar a função diff().\n\n# Log\nlag_2 = diff(db$cigarrosROD, differences = 2) # posso colocar o log da diferença também caso os valores fiquem muito pequenos.\n\n\nPlot\n\nmedia_lag_2 = mean(lag_2)\nplot.ts(lag_2)\nabline(h = media_lag_2, col = \"blue\", lty = 2, lwd = 2)\naxis(1, at = db$Dia, labels = db$Dia)\n\n\n\n\nPronto! Agora os valores estão ocilando em torno da média. Apenas para confirmar que agora temos uma série temporal estacionária, podemos rodar novamente o adf.test.\n\nadf.test(lag_2) # testar com outros valores de K(lag) para verificar o p-value\n\n\n    Augmented Dickey-Fuller Test\n\ndata:  lag_2\nDickey-Fuller = -4.3237, Lag order = 2, p-value = 0.01196\nalternative hypothesis: stationary\n\n\nEsse banco de dados era apenas para transformar os dados não estacionários para estacionários. Vamos agora carregar outro banco de dados e criar o modelo ARIMA."
  },
  {
    "objectID": "lista_7.html#dados-séries-temporais",
    "href": "lista_7.html#dados-séries-temporais",
    "title": "8  Lista 7 - Séries Temporais (ARIMA)",
    "section": "9.5 Dados séries temporais",
    "text": "9.5 Dados séries temporais\n\noriginal_ts = read.spss(\"dados series temporais.sav\", to.data.frame=TRUE)\n\nre-encoding from CP1252\n\ndb_ts = original_ts\n\nglimpse(db_ts)\n\nRows: 120\nColumns: 11\n$ date         &lt;dbl&gt; 12818995200, 12821673600, 12824092800, 12826771200, 12829…\n$ men          &lt;dbl&gt; 11357.92, 10605.95, 16998.57, 6563.75, 6607.69, 9839.00, …\n$ women        &lt;dbl&gt; 16578.93, 18236.13, 43393.55, 30908.49, 28701.58, 29647.5…\n$ horas        &lt;dbl&gt; 7978, 8290, 8029, 7752, 8685, 7847, 7881, 8121, 7811, 870…\n$ divida       &lt;dbl&gt; 73, 88, 65, 85, 74, 87, 79, 72, 83, 111, 74, 105, 66, 59,…\n$ idade        &lt;dbl&gt; 34, 29, 24, 20, 17, 30, 28, 27, 35, 25, 30, 45, 35, 20, 2…\n$ propaganda   &lt;dbl&gt; 22294.48, 27426.47, 27978.66, 28949.65, 22642.27, 27210.6…\n$ escolaridade &lt;dbl&gt; 20, 20, 26, 22, 21, 23, 22, 20, 15, 20, 16, 29, 22, 28, 2…\n$ YEAR_        &lt;dbl&gt; 1989, 1989, 1989, 1989, 1989, 1989, 1989, 1989, 1989, 198…\n$ MONTH_       &lt;dbl&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 1, 2, 3, 4, 5, 6, …\n$ DATE_        &lt;chr&gt; \"JAN 1989\", \"FEB 1989\", \"MAR 1989\", \"APR 1989\", \"MAY 1989…\n\n\n\nPlot simples\n\nmedia_sal_men &lt;- mean(db_ts$men)\ndb_season = ts(db_ts$men,\n               frequency = 12,\n               start = c(1989, 1))\n\nts.plot(db_season)\nabline(h = media_sal_men, col = \"blue\", lty = 2, lwd = 2)\n\n\n\n\n\nseasonplot(db_season,\n           col = rainbow(12),\n           year.labels = TRUE,\n           type = \"o\",\n           pch = 16)\n\n\n\n\n\nggtsdisplay(db_season)\n\n\n\n\nSemelhante ao ARIMA (0,0,0)\n\n\nAdf teste\n\n# Adf teste\nadf.test(db_ts$men, k =1) #já está no formato estacionário\n\nWarning in adf.test(db_ts$men, k = 1): p-value smaller than printed p-value\n\n\n\n    Augmented Dickey-Fuller Test\n\ndata:  db_ts$men\nDickey-Fuller = -6.1931, Lag order = 1, p-value = 0.01\nalternative hypothesis: stationary\n\n\n\n\nLjung-Box\nDescrever\n\n# Teste Ljung-Box com lag 2\nBox.test(db_ts$men , lag = 1, type = \"Ljung-Box\")\n\n\n    Box-Ljung test\n\ndata:  db_ts$men\nX-squared = 19.742, df = 1, p-value = 0.000008865"
  },
  {
    "objectID": "lista_7.html#modelo-arima-100",
    "href": "lista_7.html#modelo-arima-100",
    "title": "8  Lista 7 - Séries Temporais (ARIMA)",
    "section": "9.6 Modelo ARIMA (1,0,0)",
    "text": "9.6 Modelo ARIMA (1,0,0)\n\nmodelo_sal_men = Arima(db_ts$men, order = c(1,0,0))\n\n\nPlot 1 do modelo (1,0,0)\n\n# Supondo que você tenha as séries temporais 'modelo_sal_men$fitted' e 'db_ts$men'\n\n# Cria o gráfico\nplot(modelo_sal_men$x, type = \"l\", col = \"red\", lty = 1, lwd = 2, xlab = \"Tempo\", ylab = \"Salário\")\nlines(modelo_sal_men$fitted, col = \"blue\", lty = 1, lwd = 2)\n\n# Adiciona uma legenda\nlegend(\"topright\", legend = c(\"Real\", \"Modelo\"), col = c(\"red\", \"blue\"), lty = c(1, 1), lwd = 2)\n\n# Adiciona um título ao gráfico\ntitle(main = \"Valores e Reais e do Modelo ARIMA de Salário para Homens\")"
  },
  {
    "objectID": "lista_7.html#modelo-arima-010",
    "href": "lista_7.html#modelo-arima-010",
    "title": "8  Lista 7 - Séries Temporais (ARIMA)",
    "section": "9.7 Modelo ARIMA (0,1,0)",
    "text": "9.7 Modelo ARIMA (0,1,0)\n\nmodelo2_sal_men = Arima(db_ts$men, order = c(0,1,0))\n\n\nPlot 1 do modelo (0,1,0)\n\n# Supondo que você tenha as séries temporais 'modelo2_sal_men$fitted' e 'db_ts$men'\n\n# Cria o gráfico\nplot(modelo2_sal_men$x, type = \"l\", col = \"red\", lty = 1, lwd = 2, xlab = \"Tempo\", ylab = \"Salário\")\nlines(modelo2_sal_men$fitted, col = \"blue\", lty = 1, lwd = 2)\n\n# Adiciona uma legenda\nlegend(\"topright\", legend = c(\"Real\", \"Modelo\"), col = c(\"red\", \"blue\"), lty = c(1, 1), lwd = 2)\n\n# Adiciona um título ao gráfico\ntitle(main = \"Valores e Reais e do Modelo ARIMA de Salário para Homens\")"
  },
  {
    "objectID": "lista_7.html#modelo-autoarima",
    "href": "lista_7.html#modelo-autoarima",
    "title": "8  Lista 7 - Séries Temporais (ARIMA)",
    "section": "9.8 Modelo autoARIMA",
    "text": "9.8 Modelo autoARIMA\nAssim como o SPSS o R também tem uma função que determina automaticamente os parâmetros p, d, q. Vamos verificar qual modelo a função auto.arima()sugere.\n\n# Para verificar qual o modelo sugerido pela função auto.arima\nauto.arima(db_ts$men, trace = TRUE)\n\n\n ARIMA(2,1,2) with drift         : Inf\n ARIMA(0,1,0) with drift         : 2434.823\n ARIMA(1,1,0) with drift         : 2412.096\n ARIMA(0,1,1) with drift         : Inf\n ARIMA(0,1,0)                    : 2432.897\n ARIMA(2,1,0) with drift         : 2411.86\n ARIMA(3,1,0) with drift         : 2408.495\n ARIMA(4,1,0) with drift         : 2407.461\n ARIMA(5,1,0) with drift         : 2408.674\n ARIMA(4,1,1) with drift         : Inf\n ARIMA(3,1,1) with drift         : Inf\n ARIMA(5,1,1) with drift         : Inf\n ARIMA(4,1,0)                    : 2405.816\n ARIMA(3,1,0)                    : 2406.731\n ARIMA(5,1,0)                    : 2407.075\n ARIMA(4,1,1)                    : 2394.525\n ARIMA(3,1,1)                    : 2392.515\n ARIMA(2,1,1)                    : 2392.416\n ARIMA(1,1,1)                    : 2391.073\n ARIMA(0,1,1)                    : 2393.07\n ARIMA(1,1,0)                    : 2410.255\n ARIMA(1,1,2)                    : 2392.894\n ARIMA(0,1,2)                    : 2391.92\n ARIMA(2,1,0)                    : 2410.02\n ARIMA(2,1,2)                    : Inf\n ARIMA(1,1,1) with drift         : Inf\n\n Best model: ARIMA(1,1,1)                    \n\n\nSeries: db_ts$men \nARIMA(1,1,1) \n\nCoefficients:\n         ar1      ma1\n      0.2036  -0.9139\ns.e.  0.1002   0.0347\n\nsigma^2 = 29737029:  log likelihood = -1192.43\nAIC=2390.86   AICc=2391.07   BIC=2399.2\n\n\nA função sugeriu o modelo 1, 1, 1. Vamos verificar os resultados.\n\nmodelo_auto_sal_men = Arima(db_ts$men, order = c(1,1,1))\n\n\nPlot 1 do modelo (1,1,1)\n\n# Supondo que você tenha as séries temporais 'modelo_atuo_sal_men$fitted' e 'db_ts$men'\n\n# Cria o gráfico\nplot(modelo_auto_sal_men$x, type = \"l\", col = \"red\", lty = 1, lwd = 2, xlab = \"Tempo\", ylab = \"Salário\")\nlines(modelo_auto_sal_men$fitted, col = \"blue\", lty = 1, lwd = 2)\n\n# Adiciona uma legenda\nlegend(\"topright\", legend = c(\"Real\", \"Modelo\"), col = c(\"red\", \"blue\"), lty = c(1, 1), lwd = 2)\n\n# Adiciona um título ao gráfico\ntitle(main = \"Valores e Reais e do Modelo ARIMA de Salário para Homens\")"
  },
  {
    "objectID": "lista_7.html#homens---modelo-com-variáveis-independentes",
    "href": "lista_7.html#homens---modelo-com-variáveis-independentes",
    "title": "8  Lista 7 - Séries Temporais (ARIMA)",
    "section": "9.9 Homens - Modelo com variáveis independentes",
    "text": "9.9 Homens - Modelo com variáveis independentes\n\n\n\n\n\n\nAtenção!\n\n\n\nAinda falta modificar os índices p, d, q das variáveis indepentendes como foi feito no SPSS.\n\n\n\nAuto arima\n\n# Defina as variáveis independentes originais\nnomes_variaveis &lt;- c(\"horas\", \"divida\", \"idade\", \"propaganda\", \"escolaridade\")\n\n# Crie a matriz de covariáveis\ncovars &lt;- as.matrix(db_ts[, nomes_variaveis, drop = FALSE])\n\n\n\n# Atribua os nomes diretamente à matriz de covariáveis\ncolnames(covars) &lt;- nomes_variaveis\n\n\n# \n# covars &lt;- cbind(\n#   db_ts$horas,\n#   db_ts$divida,\n#   db_ts$idade,\n#   db_ts$propaganda,\n#   db_ts$escolaridade\n# )\n\nauto.arima(db_ts$men, xreg = covars)\n\nSeries: db_ts$men \nRegression with ARIMA(1,0,0) errors \n\nCoefficients:\n         ar1   intercept   horas   divida     idade  propaganda  escolaridade\n      0.1968  -23753.966  2.0271  34.5286  342.9908      0.2046      -30.3841\ns.e.  0.1000    2752.767  0.2204  20.1900   43.9319      0.0733       41.3101\n\nsigma^2 = 8316739:  log likelihood = -1122.71\nAIC=2261.43   AICc=2262.72   BIC=2283.73\n\n\nModelo sugerido é o c(1,0,0)\n\n# Ajuste o modelo ARIMA com covariáveis\nmodelo_completo = Arima(\n  db_ts$men,\n  order = c(1, 0, 0),\n  xreg = covars, \n)\n\n\n# Defina as variáveis independentes originais\nnomes_variaveis &lt;- c(\"horas\", \"divida\", \"idade\", \"propaganda\", \"escolaridade\")\n\n# Inicialize uma lista para armazenar os modelos ajustados para cada VI\nmodelos_vi &lt;- list()\n\n# Loop através das variáveis independentes\nfor (variavel in nomes_variaveis) {\n  \n  # Selecione a VI específica\n  variavel_ts &lt;- db_ts[, variavel, drop = FALSE]\n  \n  # Ajuste as ordens p, d, q para a VI específica\n  ordens_vi &lt;- c(1, 0, 0)  # p, d, q\n  \n  # Ajuste o modelo ARIMA para a VI específica\n  modelo_vi &lt;- Arima(\n    variavel_ts,\n    order = ordens_vi,\n    include.mean = TRUE,\n    transform.pars = TRUE,\n    fixed = NULL,\n    include.drift = FALSE,\n    method = \"ML\",  # Mude conforme necessário\n    optim.control = list(trace = FALSE, REPORT = 1),\n    kappa = 1\n  )\n  \n  # Adicione o modelo ao vetor de modelos\n  modelos_vi[[variavel]] &lt;- modelo_vi\n}\n\n# Agora, você tem modelos ajustados para cada VI na lista modelos_vi\n\n# Combine os modelos ARIMA para as VI em uma única matriz\ncovars &lt;- cbind(\n  modelos_vi$horas$fitted, \n  modelos_vi$divida$fitted, \n  modelos_vi$idade$fitted, \n  modelos_vi$propaganda$fitted, \n  modelos_vi$escolaridade$fitted\n)\n\n# Ajuste o modelo ARIMA principal com as covariáveis\nmodelo_completo &lt;- Arima(\n  db_ts$men,\n  order = c(1, 0, 0),\n  xreg = covars,\n  seasonal = list(order = c(0, 0, 0)),  # Adapte conforme necessário\n  include.mean = TRUE,\n  transform.pars = TRUE,\n  fixed = NULL,\n  include.drift = FALSE,\n  method = \"ML\",  # Mude conforme necessário\n  optim.control = list(trace = FALSE, REPORT = 1),\n  kappa = 1\n)\n\n\n\nPlot do modelo com VIs\n\n# Criar um dataframe com as séries temporais\ndf_full &lt;- data.frame(\n  Tempo = seq_along(modelo_completo$fitted),\n  Ajustado = modelo_completo$fitted,\n  Real = modelo_completo$x\n)\n\n# Criar o gráfico com ggplot2\nggplot(df_full, aes(x = Tempo)) +\n  geom_line(aes(y = Ajustado, color = \"Ajustado\"), size = 1) +\n  geom_line(aes(y = Real, color = \"Real\"), size = 1) +\n  labs(x = \"Tempo\", y = \"Salário\", title = \"Valores Ajustados e Reais de Salário para Homens ao Longo do Tempo\") +\n  scale_color_manual(values = c(\"Ajustado\" = \"blue\", \"Real\" = \"red\"), guide = \"legend\") +\n  theme_minimal()\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead.\n\n\nDon't know how to automatically pick scale for object of type &lt;ts&gt;. Defaulting\nto continuous.\n\n\n\n\n\n\n\nAIC, BIC e RMSE\n\nperformance(modelo_completo)\n\n# Indices of model performance\n\nAIC      |     AICc |      BIC | R2.modelos_vi$horas$fitted | R2.modelos_vi$divida$fitted | R2.modelos_vi$idade$fitted | R2.modelos_vi$propaganda$fitted | R2.modelos_vi$escolaridade$fitted |     RMSE |    Sigma\n------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n2421.052 | 6925.052 | 2443.352 |                      0.397 |                       0.213 |                      0.722 |                       5.366e-04 |                             0.656 | 5442.460 | 5633.481\n\n\n\n\nResultados\n\n# Visualize o resumo do modelo\nsummary(modelo_completo)\n\nSeries: db_ts$men \nRegression with ARIMA(1,0,0) errors \n\nCoefficients:\n          ar1  intercept  modelos_vi$horas$fitted  modelos_vi$divida$fitted\n      -0.1727   34621.57                   0.7594                 -607.0271\ns.e.   0.1639   40027.85                   1.3741                  316.5860\n      modelos_vi$idade$fitted  modelos_vi$propaganda$fitted\n                     371.3498                        0.1770\ns.e.                 127.6716                        1.0677\n      modelos_vi$escolaridade$fitted\n                            135.8938\ns.e.                         81.0383\n\nsigma^2 = 31455262:  log likelihood = -1202.53\nAIC=2421.05   AICc=2422.35   BIC=2443.35\n\nTraining set error measures:\n                   ME    RMSE      MAE       MPE     MAPE     MASE        ACF1\nTraining set -5.05266 5442.46 3863.789 -11.92625 27.46778 0.826093 0.002906111\n\n# db_ts$horas,       xreg1    \n# db_ts$divida  ,    xreg2\n# db_ts$idade,       xreg3\n# db_ts$propaganda,  xreg4    \n# db_ts$escolaridade xreg5\n\n\nCoeficientes e valores de p\n\nlibrary(lmtest) # pacote para calcular os estimates e valores de p\n\nWarning: package 'lmtest' was built under R version 4.3.2\n\n\nCarregando pacotes exigidos: zoo\n\n\n\nAttaching package: 'zoo'\n\n\nThe following objects are masked from 'package:base':\n\n    as.Date, as.Date.numeric\n\n# Use a função coeftest para obter coeficientes e p-valores\ntest_coef &lt;- coeftest(modelo_completo)\n\n# Acesse os coeficientes estimados e os p-valores\ncoeficientes &lt;- round(test_coef[, \"Estimate\"], 3)\np_valores &lt;- round(test_coef[, \"Pr(&gt;|z|)\"], 3)\n\n# Crie uma nova coluna com asteriscos para valores de p significativos\ntest_coef$Significativo &lt;- ifelse(p_valores &lt; 0.05, \"*\", \"\")\n\nWarning in test_coef$Significativo &lt;- ifelse(p_valores &lt; 0.05, \"*\", \"\"):\nRealizando coerção de LHD para uma lista\n\n# Exiba os resultados\nresultados &lt;- data.frame(Coeficientes = coeficientes, p_valores = paste0(format(p_valores, digits = 3), test_coef$Significativo))\nprint(resultados)\n\n                               Coeficientes p_valores\nar1                                  -0.173     0.292\nintercept                         34621.566     0.387\nmodelos_vi$horas$fitted               0.759     0.581\nmodelos_vi$divida$fitted           -607.027     0.055\nmodelos_vi$idade$fitted             371.350    0.004*\nmodelos_vi$propaganda$fitted          0.177     0.868\nmodelos_vi$escolaridade$fitted      135.894     0.094\n\n\n\n\n\nMulheres - Modelo com variáveis independentes para\n\nVerificar qual o melhor modelo utilizando as VIs no auto.arima\n\n# Supondo que você tenha um dataframe 'db_ts' com as variáveis mencionadas\n\n# Defina as variáveis independentes originais\nnomes_variaveis &lt;- c(\"horas\", \"divida\", \"idade\", \"propaganda\", \"escolaridade\")\n\n# Crie a matriz de covariáveis\ncovars &lt;- as.matrix(db_ts[, nomes_variaveis, drop = FALSE])\n\n# Atribua os nomes diretamente à matriz de covariáveis\ncolnames(covars) &lt;- nomes_variaveis\n\n\n# \n# covars &lt;- cbind(\n#   db_ts$horas,\n#   db_ts$divida,\n#   db_ts$idade,\n#   db_ts$propaganda,\n#   db_ts$escolaridade\n# )\n\nauto.arima(db_ts$women, xreg = covars)\n\nSeries: db_ts$women \nRegression with ARIMA(0,0,1) errors \n\nCoefficients:\n         ma1   intercept   horas   divida     idade  propaganda  escolaridade\n      0.3351  -37941.151  2.6828  90.5433    1.6294      0.9805      445.6786\ns.e.  0.1096    6458.967  0.5145  52.4388  110.2176      0.1693      102.0171\n\nsigma^2 = 49641429:  log likelihood = -1229.95\nAIC=2475.89   AICc=2477.19   BIC=2498.19\n\n\nModelo sugerido é o c(0,0,1)\n\n# Ajuste o modelo ARIMA com covariáveis\nmodelo_completo_women = Arima(\n  db_ts$women,\n  order = c(0, 0, 1),\n  xreg = covars\n)\n\n\n\n# Visualize o resumo do modelo\nsummary(modelo_completo_women)\n\nSeries: db_ts$women \nRegression with ARIMA(0,0,1) errors \n\nCoefficients:\n         ma1   intercept   horas   divida     idade  propaganda  escolaridade\n      0.3351  -37941.151  2.6828  90.5433    1.6294      0.9805      445.6786\ns.e.  0.1096    6458.967  0.5145  52.4388  110.2176      0.1693      102.0171\n\nsigma^2 = 49641429:  log likelihood = -1229.95\nAIC=2475.89   AICc=2477.19   BIC=2498.19\n\nTraining set error measures:\n                     ME     RMSE  MAE       MPE    MAPE      MASE        ACF1\nTraining set -0.1962005 6837.081 4889 -3.414187 14.6811 0.5114592 -0.01923702\n\n\n\n# db_ts$horas,       xreg1    \n# db_ts$divida  ,    xreg2\n# db_ts$idade,       xreg3\n# db_ts$propaganda,  xreg4    \n# db_ts$escolaridade xreg5\n\ncheckresiduals(modelo_completo_women)\n\n\n\n\n\n    Ljung-Box test\n\ndata:  Residuals from Regression with ARIMA(0,0,1) errors\nQ* = 10.048, df = 9, p-value = 0.3466\n\nModel df: 1.   Total lags used: 10\n\n\n\n\nPlot do modelo com VIs\n\n# Criar um dataframe com as séries temporais\ndf_full_women &lt;- data.frame(\n  Tempo = seq_along(modelo_completo_women$fitted),\n  Ajustado = modelo_completo_women$fitted,\n  Real = modelo_completo_women$x\n)\n\n# Criar o gráfico com ggplot2\nggplot(df_full_women, aes(x = Tempo)) +\n  geom_line(aes(y = Ajustado, color = \"Ajustado\"), size = 1) +\n  geom_line(aes(y = Real, color = \"Real\"), size = 1) +\n  labs(x = \"Tempo\", y = \"Salário\", title = \"Valores Ajustados e Reais de Salário para Mulheres ao Longo do Tempo\") +\n  scale_color_manual(values = c(\"Ajustado\" = \"red\", \"Real\" = \"blue\"), guide = \"legend\") +\n  theme_minimal()\n\nDon't know how to automatically pick scale for object of type &lt;ts&gt;. Defaulting\nto continuous.\n\n\n\n\n\n\n\nCoeficientes e valores de p\n\nlibrary(lmtest) # pacote para calcular os estimates e valores de p\n\n\n# Use a função coeftest para obter coeficientes e p-valores\ntest_coef_women &lt;- coeftest(modelo_completo_women)\n\n# Acesse os coeficientes estimados e os p-valores\ncoeficientes_women &lt;- round(test_coef_women[, \"Estimate\"], 3)\np_valores_women &lt;- round(test_coef_women[, \"Pr(&gt;|z|)\"], 3)\n\n# Crie uma nova coluna com asteriscos para valores de p significativos\ntest_coef_women$Significativo &lt;- ifelse(p_valores_women &lt; 0.05, \"*\", \"\")\n\nWarning in test_coef_women$Significativo &lt;- ifelse(p_valores_women &lt; 0.05, :\nRealizando coerção de LHD para uma lista\n\n# Exiba os resultados\nresultados_women &lt;- data.frame(Coeficientes = coeficientes_women, Pvalores = paste0(format(p_valores_women, digits = 3), test_coef_women$Significativo))\nprint(resultados_women)\n\n             Coeficientes Pvalores\nma1                 0.335   0.002*\nintercept      -37941.151   0.000*\nhoras               2.683   0.000*\ndivida             90.543    0.084\nidade               1.629    0.988\npropaganda          0.981   0.000*\nescolaridade      445.679   0.000*"
  },
  {
    "objectID": "lista_7.html#forecast-previsões",
    "href": "lista_7.html#forecast-previsões",
    "title": "8  Lista 7 - Séries Temporais (ARIMA)",
    "section": "9.10 Forecast (previsões)",
    "text": "9.10 Forecast (previsões)\n\nMulheres - 50 anos\n\nwomen_salary_ts = ts(db_ts$women,\n               frequency = 12,\n               start = c(1989, 1))\n\n\nfit_arima_women = auto.arima(women_salary_ts)\n\nfcast_women = forecast(fit_arima_women, h=50)\nautoplot(fcast_women)\n\n\n\n\n\n\nHomens - 50 anos\n\nmen_salary_ts = ts(db_ts$men,\n               frequency = 12,\n               start = c(1989, 1))\n\n\nfit_arima_men = auto.arima(men_salary_ts)\n\nfcast_men = forecast(fit_arima_men, h=50)\nautoplot(fcast_men)"
  },
  {
    "objectID": "lista_7.html#extras",
    "href": "lista_7.html#extras",
    "title": "8  Lista 7 - Séries Temporais (ARIMA)",
    "section": "9.11 Extras",
    "text": "9.11 Extras\n\nMais gráficos\n\nPlot 2 do modelo (1,0,0)\n\nmodelo_sal_men = Arima(db_ts$men, order = c(1,0,0))\n\n# Criar um dataframe com as séries temporais\ndf_100 &lt;- data.frame(\n  Tempo = seq_along(modelo_sal_men$fitted),\n  Ajustado = modelo_sal_men$fitted,\n  Real = modelo_sal_men$x\n)\n\n# Criar o gráfico com ggplot2\nggplot(df_100, aes(x = Tempo)) +\n  geom_line(aes(y = Ajustado, color = \"Ajustado\"), size = 1) +\n  geom_line(aes(y = Real, color = \"Real\"), size = 1) +\n  labs(x = \"Tempo\", y = \"Salário\", title = \"Valores Ajustados e Reais de Salário para Homens ao Longo do Tempo\") +\n  scale_color_manual(values = c(\"Ajustado\" = \"red\", \"Real\" = \"blue\"), guide = \"legend\") +\n  theme_minimal()\n\nDon't know how to automatically pick scale for object of type &lt;ts&gt;. Defaulting\nto continuous.\n\n\n\n\n\n\n\nPlot 2 do modelo (0,1,0)\n\n# Criar um dataframe com as séries temporais\ndf_010 &lt;- data.frame(\n  Tempo = seq_along(modelo2_sal_men$fitted),\n  Ajustado = modelo2_sal_men$fitted,\n  Real = modelo2_sal_men$x\n)\n\n# Criar o gráfico com ggplot2\nggplot(df_010, aes(x = Tempo)) +\n  geom_line(aes(y = Ajustado, color = \"Ajustado\"), size = 1) +\n  geom_line(aes(y = Real, color = \"Real\"), size = 1) +\n  labs(x = \"Tempo\", y = \"Salário\", title = \"Valores Ajustados e Reais de Salário para Homens ao Longo do Tempo\") +\n  scale_color_manual(values = c(\"Ajustado\" = \"red\", \"Real\" = \"blue\"), guide = \"legend\") +\n  theme_minimal()\n\nDon't know how to automatically pick scale for object of type &lt;ts&gt;. Defaulting\nto continuous.\n\n\n\n\n\n\n\nPlot 2 do modelo (1,1,1)\n\nmodelo_atuo_sal_men = Arima(db_ts$men, order = c(1,1,1))\n\n# Criar um dataframe com as séries temporais\ndf_111 &lt;- data.frame(\n  Tempo = seq_along(modelo_atuo_sal_men$fitted),\n  Ajustado = modelo_atuo_sal_men$fitted,\n  Real = modelo_atuo_sal_men$x\n)\n\n# Criar o gráfico com ggplot2\nggplot(df_111, aes(x = Tempo)) +\n  geom_line(aes(y = Ajustado, color = \"Ajustado\"), size = 1) +\n  geom_line(aes(y = Real, color = \"Real\"), size = 1) +\n  labs(x = \"Tempo\", y = \"Salário\", title = \"Valores Ajustados e Reais de Salário para Homens ao Longo do Tempo\") +\n  scale_color_manual(values = c(\"Ajustado\" = \"red\", \"Real\" = \"blue\"), guide = \"legend\") +\n  theme_minimal()\n\nDon't know how to automatically pick scale for object of type &lt;ts&gt;. Defaulting\nto continuous."
  },
  {
    "objectID": "lista_7.html#verificando-resíduos",
    "href": "lista_7.html#verificando-resíduos",
    "title": "8  Lista 7 - Séries Temporais (ARIMA)",
    "section": "9.12 Verificando resíduos",
    "text": "9.12 Verificando resíduos\n\ncheckresiduals(modelo_auto_sal_men)\n\n\n\n\n\n    Ljung-Box test\n\ndata:  Residuals from ARIMA(1,1,1)\nQ* = 10.891, df = 8, p-value = 0.208\n\nModel df: 2.   Total lags used: 10\n\nsummary(modelo_auto_sal_men)\n\nSeries: db_ts$men \nARIMA(1,1,1) \n\nCoefficients:\n         ar1      ma1\n      0.2036  -0.9139\ns.e.  0.1002   0.0347\n\nsigma^2 = 29737029:  log likelihood = -1192.43\nAIC=2390.86   AICc=2391.07   BIC=2399.2\n\nTraining set error measures:\n                   ME     RMSE      MAE       MPE     MAPE      MASE\nTraining set 915.6723 5384.571 3662.003 -5.571742 25.15003 0.7829504\n                    ACF1\nTraining set -0.04692903"
  },
  {
    "objectID": "lista_7.html#lista-7-resolvida-no-spss",
    "href": "lista_7.html#lista-7-resolvida-no-spss",
    "title": "8  Lista 7 - Séries Temporais (ARIMA)",
    "section": "9.13 Lista 7 resolvida no SPSS",
    "text": "9.13 Lista 7 resolvida no SPSS"
  },
  {
    "objectID": "lista_7.html#referências",
    "href": "lista_7.html#referências",
    "title": "8  Lista 7 - Séries Temporais (ARIMA)",
    "section": "9.14 Referências",
    "text": "9.14 Referências\nhttps://facebook.github.io/prophet/docs/installation.html#r\nhttps://rpubs.com/mpleo/timeseries_prophet\nhttps://www.youtube.com/watch?v=ny3gRhfVsi4&t=10s\nhttps://www.youtube.com/watch?v=Txuo9JQjnKE ótima ref em PT-BR\nhttps://www.youtube.com/watch?v=RJzmHkGWCxs&list=PLEuzmtv9IuT_vg5oE0lQyZR-wgbVeGztt"
  },
  {
    "objectID": "lista_7.html#versões-dos-pacotes",
    "href": "lista_7.html#versões-dos-pacotes",
    "title": "8  Lista 7 - Séries Temporais (ARIMA)",
    "section": "9.15 Versões dos pacotes",
    "text": "9.15 Versões dos pacotes\n\nreport(sessionInfo())\n\nAnalyses were conducted using the R Statistical language (version 4.3.1; R Core\nTeam, 2023) on Windows 11 x64 (build 22621), using the packages effectsize\n(version 0.8.6; Ben-Shachar MS et al., 2020), Rcpp (version 1.0.11;\nEddelbuettel D et al., 2023), tm (version 0.7.11; Feinerer I, Hornik K, 2023),\nflexplot (version 0.20.5; Fife D, 2024), lubridate (version 1.9.3; Grolemund G,\nWickham H, 2011), rlang (version 1.1.1; Henry L, Wickham H, 2023), NLP (version\n0.2.1; Hornik K, 2020), forecast (version 8.21.1; Hyndman R et al., 2023),\nparameters (version 0.21.3; Lüdecke D et al., 2020), performance (version\n0.10.8; Lüdecke D et al., 2021), easystats (version 0.6.0; Lüdecke D et al.,\n2022), see (version 0.8.1; Lüdecke D et al., 2021), insight (version 0.19.6;\nLüdecke D et al., 2019), bayestestR (version 0.13.1; Makowski D et al., 2019),\nmodelbased (version 0.8.6; Makowski D et al., 2020), report (version 0.5.7;\nMakowski D et al., 2023), correlation (version 0.8.4; Makowski D et al., 2022),\ntibble (version 3.2.1; Müller K, Wickham H, 2023), datawizard (version 0.9.0;\nPatil I et al., 2022), foreign (version 0.8.85; R Core Team, 2023), prophet\n(version 1.0; Taylor S, Letham B, 2021), rempsyc (version 0.1.6; Thériault R,\n2023), tseries (version 0.10.55; Trapletti A, Hornik K, 2023), ggplot2 (version\n3.4.4; Wickham H, 2016), forcats (version 1.0.0; Wickham H, 2023), stringr\n(version 1.5.1; Wickham H, 2023), tidyverse (version 2.0.0; Wickham H et al.,\n2019), dplyr (version 1.1.3; Wickham H et al., 2023), purrr (version 1.0.2;\nWickham H, Henry L, 2023), readr (version 2.1.4; Wickham H et al., 2023), tidyr\n(version 1.3.0; Wickham H et al., 2023), zoo (version 1.8.12; Zeileis A,\nGrothendieck G, 2005), lmtest (version 0.9.40; Zeileis A, Hothorn T, 2002) and\nkableExtra (version 1.3.4; Zhu H, 2021).\n\nReferences\n----------\n  - Ben-Shachar MS, Lüdecke D, Makowski D (2020). \"effectsize: Estimation of\nEffect Size Indices and Standardized Parameters.\" _Journal of Open Source\nSoftware_, *5*(56), 2815. doi:10.21105/joss.02815\n&lt;https://doi.org/10.21105/joss.02815&gt;, &lt;https://doi.org/10.21105/joss.02815&gt;.\n  - Eddelbuettel D, Francois R, Allaire J, Ushey K, Kou Q, Russell N, Ucar I,\nBates D, Chambers J (2023). _Rcpp: Seamless R and C++ Integration_. R package\nversion 1.0.11, &lt;https://CRAN.R-project.org/package=Rcpp&gt;. Eddelbuettel D,\nFrançois R (2011). \"Rcpp: Seamless R and C++ Integration.\" _Journal of\nStatistical Software_, *40*(8), 1-18. doi:10.18637/jss.v040.i08\n&lt;https://doi.org/10.18637/jss.v040.i08&gt;. Eddelbuettel D (2013). _Seamless R and\nC++ Integration with Rcpp_. Springer, New York. doi:10.1007/978-1-4614-6868-4\n&lt;https://doi.org/10.1007/978-1-4614-6868-4&gt;, ISBN 978-1-4614-6867-7.\nEddelbuettel D, Balamuta J (2018). \"Extending R with C++: A Brief Introduction\nto Rcpp.\" _The American Statistician_, *72*(1), 28-36.\ndoi:10.1080/00031305.2017.1375990\n&lt;https://doi.org/10.1080/00031305.2017.1375990&gt;.\n  - Feinerer I, Hornik K (2023). _tm: Text Mining Package_. R package version\n0.7-11, &lt;https://CRAN.R-project.org/package=tm&gt;. Feinerer I, Hornik K, Meyer D\n(2008). \"Text Mining Infrastructure in R.\" _Journal of Statistical Software_,\n*25*(5), 1-54. doi:10.18637/jss.v025.i05\n&lt;https://doi.org/10.18637/jss.v025.i05&gt;.\n  - Fife D (2024). _flexplot: Graphically Based Data Analysis Using 'flexplot'_.\nR package version 0.20.5.\n  - Grolemund G, Wickham H (2011). \"Dates and Times Made Easy with lubridate.\"\n_Journal of Statistical Software_, *40*(3), 1-25.\n&lt;https://www.jstatsoft.org/v40/i03/&gt;.\n  - Henry L, Wickham H (2023). _rlang: Functions for Base Types and Core R and\n'Tidyverse' Features_. R package version 1.1.1,\n&lt;https://CRAN.R-project.org/package=rlang&gt;.\n  - Hornik K (2020). _NLP: Natural Language Processing Infrastructure_. R package\nversion 0.2-1, &lt;https://CRAN.R-project.org/package=NLP&gt;.\n  - Hyndman R, Athanasopoulos G, Bergmeir C, Caceres G, Chhay L, O'Hara-Wild M,\nPetropoulos F, Razbash S, Wang E, Yasmeen F (2023). _forecast: Forecasting\nfunctions for time series and linear models_. R package version 8.21.1,\n&lt;https://pkg.robjhyndman.com/forecast/&gt;. Hyndman RJ, Khandakar Y (2008).\n\"Automatic time series forecasting: the forecast package for R.\" _Journal of\nStatistical Software_, *26*(3), 1-22. doi:10.18637/jss.v027.i03\n&lt;https://doi.org/10.18637/jss.v027.i03&gt;.\n  - Lüdecke D, Ben-Shachar M, Patil I, Makowski D (2020). \"Extracting, Computing\nand Exploring the Parameters of Statistical Models using R.\" _Journal of Open\nSource Software_, *5*(53), 2445. doi:10.21105/joss.02445\n&lt;https://doi.org/10.21105/joss.02445&gt;.\n  - Lüdecke D, Ben-Shachar M, Patil I, Waggoner P, Makowski D (2021).\n\"performance: An R Package for Assessment, Comparison and Testing of\nStatistical Models.\" _Journal of Open Source Software_, *6*(60), 3139.\ndoi:10.21105/joss.03139 &lt;https://doi.org/10.21105/joss.03139&gt;.\n  - Lüdecke D, Ben-Shachar M, Patil I, Wiernik B, Makowski D (2022). \"easystats:\nFramework for Easy Statistical Modeling, Visualization, and Reporting.\" _CRAN_.\nR package, &lt;https://easystats.github.io/easystats/&gt;.\n  - Lüdecke D, Patil I, Ben-Shachar M, Wiernik B, Waggoner P, Makowski D (2021).\n\"see: An R Package for Visualizing Statistical Models.\" _Journal of Open Source\nSoftware_, *6*(64), 3393. doi:10.21105/joss.03393\n&lt;https://doi.org/10.21105/joss.03393&gt;.\n  - Lüdecke D, Waggoner P, Makowski D (2019). \"insight: A Unified Interface to\nAccess Information from Model Objects in R.\" _Journal of Open Source Software_,\n*4*(38), 1412. doi:10.21105/joss.01412 &lt;https://doi.org/10.21105/joss.01412&gt;.\n  - Makowski D, Ben-Shachar M, Lüdecke D (2019). \"bayestestR: Describing Effects\nand their Uncertainty, Existence and Significance within the Bayesian\nFramework.\" _Journal of Open Source Software_, *4*(40), 1541.\ndoi:10.21105/joss.01541 &lt;https://doi.org/10.21105/joss.01541&gt;,\n&lt;https://joss.theoj.org/papers/10.21105/joss.01541&gt;.\n  - Makowski D, Ben-Shachar M, Patil I, Lüdecke D (2020). \"Estimation of\nModel-Based Predictions, Contrasts and Means.\" _CRAN_.\n&lt;https://github.com/easystats/modelbased&gt;.\n  - Makowski D, Lüdecke D, Patil I, Thériault R, Ben-Shachar M, Wiernik B (2023).\n\"Automated Results Reporting as a Practical Tool to Improve Reproducibility and\nMethodological Best Practices Adoption.\" _CRAN_.\n&lt;https://easystats.github.io/report/&gt;.\n  - Makowski D, Wiernik B, Patil I, Lüdecke D, Ben-Shachar M (2022).\n\"correlation: Methods for Correlation Analysis.\" Version 0.8.3,\n&lt;https://CRAN.R-project.org/package=correlation&gt;. Makowski D, Ben-Shachar M,\nPatil I, Lüdecke D (2020). \"Methods and Algorithms for Correlation Analysis in\nR.\" _Journal of Open Source Software_, *5*(51), 2306. doi:10.21105/joss.02306\n&lt;https://doi.org/10.21105/joss.02306&gt;,\n&lt;https://joss.theoj.org/papers/10.21105/joss.02306&gt;.\n  - Müller K, Wickham H (2023). _tibble: Simple Data Frames_. R package version\n3.2.1, &lt;https://CRAN.R-project.org/package=tibble&gt;.\n  - Patil I, Makowski D, Ben-Shachar M, Wiernik B, Bacher E, Lüdecke D (2022).\n\"datawizard: An R Package for Easy Data Preparation and Statistical\nTransformations.\" _Journal of Open Source Software_, *7*(78), 4684.\ndoi:10.21105/joss.04684 &lt;https://doi.org/10.21105/joss.04684&gt;.\n  - R Core Team (2023). _foreign: Read Data Stored by 'Minitab', 'S', 'SAS',\n'SPSS', 'Stata', 'Systat', 'Weka', 'dBase', ..._. R package version 0.8-85,\n&lt;https://CRAN.R-project.org/package=foreign&gt;.\n  - R Core Team (2023). _R: A Language and Environment for Statistical\nComputing_. R Foundation for Statistical Computing, Vienna, Austria.\n&lt;https://www.R-project.org/&gt;.\n  - Taylor S, Letham B (2021). _prophet: Automatic Forecasting Procedure_. R\npackage version 1.0, &lt;https://CRAN.R-project.org/package=prophet&gt;.\n  - Thériault R (2023). \"rempsyc: Convenience functions for psychology.\" _Journal\nof Open Source Software_, *8*(87), 5466. doi:10.21105/joss.05466\n&lt;https://doi.org/10.21105/joss.05466&gt;, &lt;https://doi.org/10.21105/joss.05466&gt;.\n  - Trapletti A, Hornik K (2023). _tseries: Time Series Analysis and\nComputational Finance_. R package version 0.10-55,\n&lt;https://CRAN.R-project.org/package=tseries&gt;.\n  - Wickham H (2016). _ggplot2: Elegant Graphics for Data Analysis_.\nSpringer-Verlag New York. ISBN 978-3-319-24277-4,\n&lt;https://ggplot2.tidyverse.org&gt;.\n  - Wickham H (2023). _forcats: Tools for Working with Categorical Variables\n(Factors)_. R package version 1.0.0,\n&lt;https://CRAN.R-project.org/package=forcats&gt;.\n  - Wickham H (2023). _stringr: Simple, Consistent Wrappers for Common String\nOperations_. R package version 1.5.1,\n&lt;https://CRAN.R-project.org/package=stringr&gt;.\n  - Wickham H, Averick M, Bryan J, Chang W, McGowan LD, François R, Grolemund G,\nHayes A, Henry L, Hester J, Kuhn M, Pedersen TL, Miller E, Bache SM, Müller K,\nOoms J, Robinson D, Seidel DP, Spinu V, Takahashi K, Vaughan D, Wilke C, Woo K,\nYutani H (2019). \"Welcome to the tidyverse.\" _Journal of Open Source Software_,\n*4*(43), 1686. doi:10.21105/joss.01686 &lt;https://doi.org/10.21105/joss.01686&gt;.\n  - Wickham H, François R, Henry L, Müller K, Vaughan D (2023). _dplyr: A Grammar\nof Data Manipulation_. R package version 1.1.3,\n&lt;https://CRAN.R-project.org/package=dplyr&gt;.\n  - Wickham H, Henry L (2023). _purrr: Functional Programming Tools_. R package\nversion 1.0.2, &lt;https://CRAN.R-project.org/package=purrr&gt;.\n  - Wickham H, Hester J, Bryan J (2023). _readr: Read Rectangular Text Data_. R\npackage version 2.1.4, &lt;https://CRAN.R-project.org/package=readr&gt;.\n  - Wickham H, Vaughan D, Girlich M (2023). _tidyr: Tidy Messy Data_. R package\nversion 1.3.0, &lt;https://CRAN.R-project.org/package=tidyr&gt;.\n  - Zeileis A, Grothendieck G (2005). \"zoo: S3 Infrastructure for Regular and\nIrregular Time Series.\" _Journal of Statistical Software_, *14*(6), 1-27.\ndoi:10.18637/jss.v014.i06 &lt;https://doi.org/10.18637/jss.v014.i06&gt;.\n  - Zeileis A, Hothorn T (2002). \"Diagnostic Checking in Regression\nRelationships.\" _R News_, *2*(3), 7-10.\n&lt;https://CRAN.R-project.org/doc/Rnews/&gt;.\n  - Zhu H (2021). _kableExtra: Construct Complex Table with 'kable' and Pipe\nSyntax_. R package version 1.3.4,\n&lt;https://CRAN.R-project.org/package=kableExtra&gt;."
  },
  {
    "objectID": "SEM.html#referências",
    "href": "SEM.html#referências",
    "title": "SEM",
    "section": "Referências",
    "text": "Referências\nhttps://repositorio.ufba.br/bitstream/ri/17684/1/ebook_SEM_2012.pdf\nhttps://statplace.com.br/blog/modelagem-de-equacoes-estruturais/"
  },
  {
    "objectID": "lista_8.html#a-regressão-linear",
    "href": "lista_8.html#a-regressão-linear",
    "title": "9  Lista 8 - CFA e Path Analysis",
    "section": "9.1 a) Regressão linear",
    "text": "9.1 a) Regressão linear\n\n\n\n\n\n\nExercício\n\n\n\nVeja o banco de dados DADOSPATH.sav. Nele temos os dados de Idade, IMC, numero de treinos e sociabilidade (questionario) de um grupo de 94 pessoas. Faca um modelo de regressao linear tendo como variavel dependente o numero de Treinos e as demais variaveis como independentes.\n\n\n\noriginal = read.spss(\"DADOS PATH.sav\", to.data.frame=TRUE)\nmodelo_1 = lm(Treinos ~ Idade + IMC1 + Sociabilidade, data = original)\n\nModelo:\n\\[\nY \\sim \\beta_0 + \\beta_1*idade + \\beta_2*IMC1 + \\beta_3*Sociabilidade + \\epsilon\n\\]\n\nResultados\n\nkable(summary(modelo_1)$coef)\n\n\n\n\n\nEstimate\nStd. Error\nt value\nPr(&gt;|t|)\n\n\n\n\n(Intercept)\n78.0103771\n33.1315541\n2.3545644\n0.0207191\n\n\nIdade\n1.9071028\n0.5479748\n3.4802749\n0.0007745\n\n\nIMC1\n-2.8021799\n1.1809989\n-2.3727202\n0.0197865\n\n\nSociabilidade\n0.5177685\n0.5903261\n0.8770889\n0.3827736\n\n\n\n\n\n\n\nUm modelo linear (estimado usando Mínimos Quadrados Ordinários - OLS) foi utilizado para prever a variável Treinos com base nas variáveis Idade, IMC1 e Sociabilidade. O modelo explica uma proporção estatisticamente significativa e moderada da variância (R² = 0,14, F(3, 90) = 5,06, p = 0,003, R² ajustado = 0,12). Dentro desse modelo: • O efeito da Idade é estatisticamente significativo e positivo (beta = 1,91, IC 95% [0,82, 3,00], t(90) = 3,48, p &lt; 0,001; Beta padronizado = 0,35, IC 95% [0,15, 0,56]) • O efeito do IMC1 é estatisticamente significativo e negativo (beta = -2,80, IC 95% [-5,15, -0,46], t(90) = -2,37, p = 0,020; Beta padronizado = -0,24, IC 95% [-0,44, -0,04]) • O efeito da Sociabilidade é estatisticamente não significativo e positivo (beta = 0,52, IC 95% [-0,66, 1,69], t(90) = 0,88, p = 0,383; Beta padronizado = 0,09, IC 95% [-0,11, 0,28]) Parâmetros padronizados foram obtidos ajustando o modelo a uma versão padronizada do conjunto de dados. Intervalos de Confiança (ICs) de 95% e valores-p foram calculados usando uma aproximação da distribuição t de Wald."
  },
  {
    "objectID": "lista_8.html#b-path-analysis",
    "href": "lista_8.html#b-path-analysis",
    "title": "9  Lista 8 - CFA e Path Analysis",
    "section": "9.2 b) Path Analysis",
    "text": "9.2 b) Path Analysis\n\n\n\n\n\n\nExercício\n\n\n\nCom base no mesmo banco acima faça uma Path Analysis e monte um diagrama no AMOS R. Compare os resultados com os dados encontrados na regressão linear.\n\n\n\npath_1 = \"Treinos ~ Idade + IMC1 + Sociabilidade\"\n\n\npath_model_1 = sem(\n  model = path_1,\n  data = original,\n)\n\n\nTabela com os resultados\nComo sempre, podemos utilizar a função summary() para retornar um resumo com os resultados do modelo\n\nsummary(path_model_1) # posso colocar o parametro fit.measures = TRUE para obter os valores de aderência do modelo\n\nlavaan 0.6.16 ended normally after 1 iteration\n\n  Estimator                                         ML\n  Optimization method                           NLMINB\n  Number of model parameters                         4\n\n  Number of observations                            94\n\nModel Test User Model:\n                                                      \n  Test statistic                                 0.000\n  Degrees of freedom                                 0\n\nParameter Estimates:\n\n  Standard errors                             Standard\n  Information                                 Expected\n  Information saturated (h1) model          Structured\n\nRegressions:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n  Treinos ~                                           \n    Idade             1.907    0.536    3.557    0.000\n    IMC1             -2.802    1.156   -2.425    0.015\n    Sociabilidade     0.518    0.578    0.896    0.370\n\nVariances:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n   .Treinos        2050.999  299.169    6.856    0.000\n\n\nNo caso da path analisys recomendamos utilizar a função parameterEstimates() do pacote lavaan para ter uma tabela mais direta com os resultados dos estimadores.\n\nkable(parameterEstimates(path_model_1))\n\n\n\n\nlhs\nop\nrhs\nest\nse\nz\npvalue\nci.lower\nci.upper\n\n\n\n\nTreinos\n~\nIdade\n1.9071028\n0.5361890\n3.5567736\n0.0003754\n0.8561917\n2.9580139\n\n\nTreinos\n~\nIMC1\n-2.8021799\n1.1555981\n-2.4248741\n0.0153137\n-5.0671106\n-0.5372493\n\n\nTreinos\n~\nSociabilidade\n0.5177685\n0.5776294\n0.8963679\n0.3700563\n-0.6143644\n1.6499014\n\n\nTreinos\n~~\nTreinos\n2050.9987436\n299.1689143\n6.8556546\n0.0000000\n1464.6384463\n2637.3590409\n\n\nIdade\n~~\nIdade\n82.5840878\n0.0000000\nNA\nNA\n82.5840878\n82.5840878\n\n\nIdade\n~~\nIMC1\n10.7872961\n0.0000000\nNA\nNA\n10.7872961\n10.7872961\n\n\nIdade\n~~\nSociabilidade\n3.7635808\n0.0000000\nNA\nNA\n3.7635808\n3.7635808\n\n\nIMC1\n~~\nIMC1\n17.7567863\n0.0000000\nNA\nNA\n17.7567863\n17.7567863\n\n\nIMC1\n~~\nSociabilidade\n1.2498636\n0.0000000\nNA\nNA\n1.2498636\n1.2498636\n\n\nSociabilidade\n~~\nSociabilidade\n65.6008375\n0.0000000\nNA\nNA\n65.6008375\n65.6008375\n\n\n\n\n\n\n\nOs resultados foram os mesmos obtidos tanto pela path analysis quanto pela regressão linear simples.\n\n\nIndices de qualidade do modelo\n\nmodel_performance(path_model_1, metrics = c(\"Chi2\", \"Chi2_df\", \"NFI\", \"NNFI\", \"CFI\", \"RMSEA\", \"AIC\", \"BIC\"))\n\n# Indices of model performance\n\nChi2(0) |   NFI |  NNFI |   CFI | RMSEA |     AIC |      BIC\n------------------------------------------------------------\n0.000   | 1.000 | 1.000 | 1.000 | 0.000 | 991.612 | 1001.785\n\nAIC(path_model_1)\n\n[1] 991.6122\n\n\n\n\nDiagrama da path analysis\n\nP &lt;- semPaths(\n          object = path_model_1,\n          what = \"path\",\n          whatLabels = \"par\",\n          style = \"ram\",\n          layout = \"tree\",\n          rotation = 2,\n          sizeMan = 7,\n          sizeLat = 7,\n          color = \"lightgray\",\n          edge.label.cex = 1.2,\n          label.cex = 1.3\n)"
  },
  {
    "objectID": "lista_8.html#c-cfa",
    "href": "lista_8.html#c-cfa",
    "title": "9  Lista 8 - CFA e Path Analysis",
    "section": "9.3 c) CFA",
    "text": "9.3 c) CFA\n\n\n\n\n\n\nExercício\n\n\n\nVeja o banco de dados Fatorial escala.sav. Faça uma Análise fatorial confirmatória (CFA) gerando os seguintes fatores com base no questionário de apego a amigos (IAA).\n\n\nSegundo a teoria esperada, os fatores teriam o seguinte agrupamento: a. Confianca – Q13 Q14 Q15 b. Alienacao – Q1 Q2 Q3 Monte o diagrama e discuta a qualidade do modelo e suas limitações caso existam.\nEquação do Modelo 1:\ncfa_eq = \" Alienação =~ IAa1 + IAa2 + IAa3 Confiança =~ IAa13 + IAa14 + IAa15  \"\nAnálise Fatorial Confirmatória do modelo 1\ncfa_modelo = cfa(   model = cfa_eq,   data = dados_CFA,   std.lv = TRUE  )\n\ndados_CFA = read.spss(\"fatorial CFA.sav\", to.data.frame=TRUE)\n\n\ncfa_eq = \"\nAlienação =~ IAa1 + IAa2 + IAa3\nConfiança =~ IAa13 + IAa14 + IAa15\n\n\"\n\n\ncfa_modelo = cfa(\n  model = cfa_eq,\n  data = dados_CFA,\n  std.lv = TRUE #If TRUE, the metric of each latent variable is determined by fixing their (residual) variances to 1.0. If FALSE, the metric of each latent variable is determined by fixing the factor loading of the first indicator to 1.0.\n  \n)\n\n\nResultados do modelo sem covariâncias entre os resíduos (modelo 1)\n\nsummary(cfa_modelo) # posso colocar no summary o parametro fit.measures = TRUE\n\nlavaan 0.6.16 ended normally after 18 iterations\n\n  Estimator                                         ML\n  Optimization method                           NLMINB\n  Number of model parameters                        13\n\n                                                  Used       Total\n  Number of observations                           347         348\n\nModel Test User Model:\n                                                      \n  Test statistic                                39.166\n  Degrees of freedom                                 8\n  P-value (Chi-square)                           0.000\n\nParameter Estimates:\n\n  Standard errors                             Standard\n  Information                                 Expected\n  Information saturated (h1) model          Structured\n\nLatent Variables:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n  Alienação =~                                        \n    IAa1              0.578    0.069    8.408    0.000\n    IAa2              0.842    0.069   12.135    0.000\n    IAa3              0.423    0.051    8.278    0.000\n  Confiança =~                                        \n    IAa13             0.580    0.044   13.279    0.000\n    IAa14             0.660    0.052   12.652    0.000\n    IAa15             0.586    0.053   11.105    0.000\n\nCovariances:\n                  Estimate  Std.Err  z-value  P(&gt;|z|)\n  Alienação ~~                                       \n    Confiança        0.865    0.051   16.807    0.000\n\nVariances:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n   .IAa1              1.023    0.088   11.607    0.000\n   .IAa2              0.676    0.089    7.627    0.000\n   .IAa3              0.568    0.049   11.667    0.000\n   .IAa13             0.316    0.036    8.898    0.000\n   .IAa14             0.485    0.051    9.564    0.000\n   .IAa15             0.564    0.052   10.767    0.000\n    Alienação         1.000                           \n    Confiança         1.000                           \n\n\n\nkable(parameterEstimates(cfa_modelo))\n\n\n\n\nlhs\nop\nrhs\nest\nse\nz\npvalue\nci.lower\nci.upper\n\n\n\n\nAlienação\n=~\nIAa1\n0.5783085\n0.0687768\n8.408481\n0\n0.4435084\n0.7131086\n\n\nAlienação\n=~\nIAa2\n0.8419500\n0.0693835\n12.134735\n0\n0.7059609\n0.9779391\n\n\nAlienação\n=~\nIAa3\n0.4226729\n0.0510624\n8.277581\n0\n0.3225925\n0.5227533\n\n\nConfiança\n=~\nIAa13\n0.5796173\n0.0436497\n13.278840\n0\n0.4940655\n0.6651691\n\n\nConfiança\n=~\nIAa14\n0.6603480\n0.0521921\n12.652247\n0\n0.5580533\n0.7626427\n\n\nConfiança\n=~\nIAa15\n0.5856667\n0.0527386\n11.105077\n0\n0.4823008\n0.6890325\n\n\nIAa1\n~~\nIAa1\n1.0234312\n0.0881741\n11.606933\n0\n0.8506131\n1.1962493\n\n\nIAa2\n~~\nIAa2\n0.6763156\n0.0886784\n7.626611\n0\n0.5025092\n0.8501221\n\n\nIAa3\n~~\nIAa3\n0.5677370\n0.0486609\n11.667220\n0\n0.4723635\n0.6631105\n\n\nIAa13\n~~\nIAa13\n0.3160382\n0.0355192\n8.897671\n0\n0.2464219\n0.3856546\n\n\nIAa14\n~~\nIAa14\n0.4851673\n0.0507280\n9.564088\n0\n0.3857422\n0.5845925\n\n\nIAa15\n~~\nIAa15\n0.5636709\n0.0523500\n10.767362\n0\n0.4610669\n0.6662750\n\n\nAlienação\n~~\nAlienação\n1.0000000\n0.0000000\nNA\nNA\n1.0000000\n1.0000000\n\n\nConfiança\n~~\nConfiança\n1.0000000\n0.0000000\nNA\nNA\n1.0000000\n1.0000000\n\n\nAlienação\n~~\nConfiança\n0.8646695\n0.0514471\n16.806951\n0\n0.7638349\n0.9655040\n\n\n\n\n\n\n\nOs resultados da análise de equações estruturais indicam que o modelo ajustado apresenta um bom ajuste aos dados observados (χ² = 39,166, df = 8, p &lt; 0,001). O modelo envolve duas variáveis latentes, “Alienação” e “Confiança”, e suas variáveis observadas.\nOs coeficientes de carga (estimates) indicam que as perguntas associadas a “Alienação” (IAa1, IAa2, IAa3) e “Confiança” (IAa13, IAa14, IAa15) têm influências positivas significativas em suas respectivas variáveis latentes.\nAlém disso, a covariância entre “Alienação” e “Confiança” é estatisticamente significativa (estimate = 0,865, p &lt; 0,001), sugerindo uma relação entre essas duas dimensões.\nEsses resultados fornecem evidências de que o modelo proposto é estatisticamente significativo.\n\n\nÍndices de qualidade do modelo 1\n\nmodel_performance(cfa_modelo, metrics = c(\"Chi2\", \"Chi2_df\", \"NFI\", \"CFI\", \"RMSEA\", \"p_RMSEA\", \"AIC\", \"BIC\", \"NNFI\") )\n\n# Indices of model performance\n\nChi2(8) |   NFI |   CFI | RMSEA | p (RMSEA) |      AIC |      BIC |  NNFI\n-------------------------------------------------------------------------\n39.166  | 0.918 | 0.933 | 0.106 |     0.003 | 5402.476 | 5452.517 | 0.874\n\n\nOs resultados dos índices de qualidade indicam que o modelo apresenta uma adequada qualidade de aderência aos dados observados, conforme evidenciado pelos índices de ajuste (NFI, CFI) acima de 0.9. Apenas o NNFI (ou TFI) está abaixo de 0.9, indicando um bom ajuste relativo.\nNo entanto, o valor do RMSEA é alto (10%), indicando que o modelo pode ser aprimorado.\nOs valores de AIC e BIC serão utilizados para efeito de comparação com os modelos a seguir.\n\n\nDiagrama da CFA com o modelo 1\n\nplot_CFA &lt;- semPaths(\n          object = cfa_modelo,\n          what = \"path\",\n          whatLabels = \"par\",\n          style = \"ram\",\n          layout = \"tree\",\n          rotation = 2,\n          sizeMan = 7,\n          sizeLat = 7,\n          color = \"lightgray\",\n          edge.label.cex = 1.2,\n          label.cex = 1.3\n)\n\n\n\n\n\n\nVerificar os índices de modificações do modelo 1\nOs índices de modificação podem ser obtidos utilizando a função modindices(). Por padrão, os índices de modificação são impressos para cada parâmetro não livre (ou fixado como zero). Os índices de modificação são complementados pelos valores de mudança esperada nos parâmetros (EPC) (coluna epc). As últimas três colunas contêm os valores padronizados de EPC (sepc.lv: padronização apenas das variáveis latentes; sepc.all: padronização de todas as variáveis; sepc.nox: padronização de todas, exceto variáveis observadas exógenas).\n\nkable(modificationindices(cfa_modelo, sort = TRUE, minimum.value = 5))\n\n\n\n\n\nlhs\nop\nrhs\nmi\nepc\nsepc.lv\nsepc.all\nsepc.nox\n\n\n\n\n34\nIAa13\n~~\nIAa14\n18.245523\n0.1825252\n0.1825252\n0.4661302\n0.4661302\n\n\n18\nAlienação\n=~\nIAa15\n18.245517\n0.9569991\n0.9569991\n1.0050447\n1.0050447\n\n\n29\nIAa2\n~~\nIAa14\n17.160433\n-0.2043919\n-0.2043919\n-0.3568151\n-0.3568151\n\n\n30\nIAa2\n~~\nIAa15\n10.461405\n0.1539148\n0.1539148\n0.2492832\n0.2492832\n\n\n20\nConfiança\n=~\nIAa2\n8.403845\n-1.6415789\n-1.6415789\n-1.3947817\n-1.3947817\n\n\n23\nIAa1\n~~\nIAa3\n8.403843\n-0.1390871\n-0.1390871\n-0.1824669\n-0.1824669\n\n\n35\nIAa13\n~~\nIAa15\n5.006171\n-0.0840609\n-0.0840609\n-0.1991642\n-0.1991642\n\n\n17\nAlienação\n=~\nIAa14\n5.006165\n-0.5603084\n-0.5603084\n-0.5837728\n-0.5837728\n\n\n\n\n\n\n\n\n\nNovo modelo com a covariância dos resíduos (modelo 2)\n\ncfa_eq_2 = \"\nAlienação =~ IAa1 + IAa2 + IAa3\nConfiança =~ IAa13 + IAa14 + IAa15\n\n# Covariancia dos resíduos\nIAa1 ~~ IAa3\nIAa13 ~~ IAa14\nIAa13 ~~ IAa15\n\n\"\n\n\ncfa_modelo_2 = cfa(\n  model = cfa_eq_2,\n  data = dados_CFA,\n  std.lv = TRUE\n)\n\nEquação do Modelo 2:\ncfa_eq_2 = \" Alienação =~ IAa1 + IAa2 + IAa3 Confiança =~ IAa13 + IAa14 + IAa15  # Covariancia dos resíduos IAa1 ~~ IAa3  IAa13 ~~ IAa14 IAa13 ~~ IAa15  \"\nAnálise Fatorial Confirmatória do modelo 2\ncfa_modelo_2 = cfa(   model = cfa_eq_2,   data = dados_CFA,   std.lv = TRUE    )\n\n\nResultados modelo 2\n\nsummary(cfa_modelo_2) # posso colocar no summary o parametro fit.measures = TRUE\n\nlavaan 0.6.16 ended normally after 24 iterations\n\n  Estimator                                         ML\n  Optimization method                           NLMINB\n  Number of model parameters                        16\n\n                                                  Used       Total\n  Number of observations                           347         348\n\nModel Test User Model:\n                                                      \n  Test statistic                                14.194\n  Degrees of freedom                                 5\n  P-value (Chi-square)                           0.014\n\nParameter Estimates:\n\n  Standard errors                             Standard\n  Information                                 Expected\n  Information saturated (h1) model          Structured\n\nLatent Variables:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n  Alienação =~                                        \n    IAa1              0.625    0.069    9.009    0.000\n    IAa2              0.844    0.066   12.774    0.000\n    IAa3              0.440    0.052    8.484    0.000\n  Confiança =~                                        \n    IAa13             0.486    0.054    9.010    0.000\n    IAa14             0.558    0.057    9.744    0.000\n    IAa15             0.627    0.058   10.741    0.000\n\nCovariances:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n .IAa1 ~~                                             \n   .IAa3             -0.131    0.047   -2.812    0.005\n .IAa13 ~~                                            \n   .IAa14             0.156    0.042    3.700    0.000\n   .IAa15             0.005    0.037    0.123    0.902\n  Alienação ~~                                        \n    Confiança         0.945    0.063   15.041    0.000\n\nVariances:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n   .IAa1              0.968    0.088   11.049    0.000\n   .IAa2              0.674    0.081    8.299    0.000\n   .IAa3              0.553    0.049   11.303    0.000\n   .IAa13             0.416    0.048    8.717    0.000\n   .IAa14             0.609    0.059   10.323    0.000\n   .IAa15             0.514    0.060    8.497    0.000\n    Alienação         1.000                           \n    Confiança         1.000                           \n\n\n\nkable(parameterEstimates(cfa_modelo_2))\n\n\n\n\nlhs\nop\nrhs\nest\nse\nz\npvalue\nci.lower\nci.upper\n\n\n\n\nAlienação\n=~\nIAa1\n0.6246375\n0.0693348\n9.0090043\n0.0000000\n0.4887438\n0.7605313\n\n\nAlienação\n=~\nIAa2\n0.8436173\n0.0660435\n12.7736683\n0.0000000\n0.7141745\n0.9730601\n\n\nAlienação\n=~\nIAa3\n0.4398298\n0.0518412\n8.4841676\n0.0000000\n0.3382228\n0.5414367\n\n\nConfiança\n=~\nIAa13\n0.4855333\n0.0538885\n9.0099663\n0.0000000\n0.3799138\n0.5911527\n\n\nConfiança\n=~\nIAa14\n0.5583551\n0.0573047\n9.7436136\n0.0000000\n0.4460399\n0.6706703\n\n\nConfiança\n=~\nIAa15\n0.6267943\n0.0583571\n10.7406769\n0.0000000\n0.5124166\n0.7411721\n\n\nIAa1\n~~\nIAa3\n-0.1314725\n0.0467540\n-2.8120052\n0.0049234\n-0.2231086\n-0.0398363\n\n\nIAa13\n~~\nIAa14\n0.1558199\n0.0421126\n3.7000779\n0.0002155\n0.0732807\n0.2383591\n\n\nIAa13\n~~\nIAa15\n0.0045594\n0.0370060\n0.1232056\n0.9019443\n-0.0679712\n0.0770899\n\n\nIAa1\n~~\nIAa1\n0.9676998\n0.0875801\n11.0493149\n0.0000000\n0.7960460\n1.1393536\n\n\nIAa2\n~~\nIAa2\n0.6735053\n0.0811578\n8.2987178\n0.0000000\n0.5144390\n0.8325716\n\n\nIAa3\n~~\nIAa3\n0.5529392\n0.0489190\n11.3031626\n0.0000000\n0.4570597\n0.6488186\n\n\nIAa13\n~~\nIAa13\n0.4162519\n0.0477495\n8.7174157\n0.0000000\n0.3226647\n0.5098391\n\n\nIAa14\n~~\nIAa14\n0.6094664\n0.0590382\n10.3232593\n0.0000000\n0.4937537\n0.7251790\n\n\nIAa15\n~~\nIAa15\n0.5138053\n0.0604718\n8.4966149\n0.0000000\n0.3952828\n0.6323277\n\n\nAlienação\n~~\nAlienação\n1.0000000\n0.0000000\nNA\nNA\n1.0000000\n1.0000000\n\n\nConfiança\n~~\nConfiança\n1.0000000\n0.0000000\nNA\nNA\n1.0000000\n1.0000000\n\n\nAlienação\n~~\nConfiança\n0.9447949\n0.0628146\n15.0410074\n0.0000000\n0.8216805\n1.0679092\n\n\n\n\n\n\n\nOs resultados da análise indicam que o modelo apresenta um razoável ajuste aos dados observados, conforme evidenciado pelos índices de ajuste, embora o teste qui-quadrado seja estatisticamente significativo (χ² = 14.194, df = 5, p = 0.014), indicando diferenças entre o modelo e os dados.\nAs cargas fatoriais para os indicadores associados às variáveis latentes “Alienação” e “Confiança” são todas estatisticamente significativas (p &lt; 0.001), indicando que esses indicadores têm uma relação com suas respectivas variáveis latentes.\n\n\nÍndices de qualidade do modelo 2\n\nmodel_performance(cfa_modelo_2, metrics = c(\"Chi2\", \"Chi2_df\", \"NFI\", \"CFI\", \"RMSEA\", \"p_RMSEA\", \"AIC\", \"BIC\", \"NNFI\"))\n\n# Indices of model performance\n\nChi2(5) |   NFI |   CFI | RMSEA | p (RMSEA) |      AIC |      BIC |  NNFI\n-------------------------------------------------------------------------\n14.194  | 0.970 | 0.980 | 0.073 |     0.165 | 5383.504 | 5445.093 | 0.940\n\n\nOs resultados dos índices de qualidade indicam que o modelo apresenta uma adequada qualidade de aderência aos dados observados, conforme evidenciado pelos índices de ajuste (NFI, CFI e NNFI) acima de 0.9.\nNo entanto, o valor do RMSEA é moderado (7%), indicando que o modelo pode ser aprimorado.\nOs valores de AIC e BIC serão utilizados para efeito de comparação com os modelos a seguir.\n\n\nDiagrama do modelo 2\n\nplot_CFA &lt;- semPaths(\n          object = cfa_modelo_2,\n          what = \"path\",\n          whatLabels = \"par\",\n          style = \"ram\",\n          layout = \"tree\",\n          rotation = 2,\n          sizeMan = 7,\n          sizeLat = 7,\n          color = \"lightgray\",\n          edge.label.cex = 1.2,\n          label.cex = 1.3\n)\n\n\n\n\n\n\nComparação entre os modelos\n\ncompare_performance(cfa_modelo, cfa_modelo_2, \n                    metrics = c(\"NFI\", \"CFI\", \"RMSEA\", \"p_RMSEA\", \"AIC\", \"BIC\", \"NNFI\"),\n                    rank = TRUE, verbose = F)\n\n# Comparison of Model Performance Indices\n\nName         |  Model |   NFI |   CFI | RMSEA | p (RMSEA) |  NNFI | AIC weights | BIC weights | Performance-Score\n-----------------------------------------------------------------------------------------------------------------\ncfa_modelo_2 | lavaan | 0.970 | 0.980 | 0.073 |     0.165 | 0.940 |       1.000 |       0.976 |            85.71%\ncfa_modelo   | lavaan | 0.918 | 0.933 | 0.106 |     0.003 | 0.874 |    7.59e-05 |       0.024 |            14.29%\n\n\nO modelo_2 demonstra superioridade em relação ao modelo_1 com base nos critérios de ajuste avaliados."
  },
  {
    "objectID": "lista_8.html#complementar-modelo-com-apenas-um-fator-latente-modelo-3",
    "href": "lista_8.html#complementar-modelo-com-apenas-um-fator-latente-modelo-3",
    "title": "9  Lista 8 - CFA e Path Analysis",
    "section": "9.4 Complementar: Modelo com apenas um fator latente (modelo 3)",
    "text": "9.4 Complementar: Modelo com apenas um fator latente (modelo 3)\n\ncfa_eq_3 = \"\nF1 =~ IAa1 + IAa2 + IAa3 + IAa13 + IAa14 + IAa15\n\"\n\n\ncfa_modelo_3 = cfa(\n  model = cfa_eq_3,\n  data = dados_CFA,\n  std.lv = TRUE\n)\n\nEquação do modelo 3:\ncfa_eq_3 = \" F1 =~ IAa1 + IAa2 + IAa3 + IAa13 + IAa14 + IAa15 \"\nAnálise Fatorial Confirmatória do modelo 2\ncfa_modelo_3 = cfa(   model = cfa_eq_3,   data = dados_CFA,   std.lv = TRUE    )\n\nResultados do modelo 3\n\nkable(parameterEstimates(cfa_modelo_3))\n\n\n\n\nlhs\nop\nrhs\nest\nse\nz\npvalue\nci.lower\nci.upper\n\n\n\n\nF1\n=~\nIAa1\n0.5580340\n0.0664300\n8.400335\n0\n0.4278336\n0.6882343\n\n\nF1\n=~\nIAa2\n0.7651182\n0.0637750\n11.997154\n0\n0.6401216\n0.8901149\n\n\nF1\n=~\nIAa3\n0.4044799\n0.0493864\n8.190103\n0\n0.3076843\n0.5012755\n\n\nF1\n=~\nIAa13\n0.5564023\n0.0432259\n12.871965\n0\n0.4716811\n0.6411235\n\n\nF1\n=~\nIAa14\n0.6400430\n0.0517363\n12.371268\n0\n0.5386419\n0.7414442\n\n\nF1\n=~\nIAa15\n0.5959511\n0.0519930\n11.462144\n0\n0.4940467\n0.6978555\n\n\nIAa1\n~~\nIAa1\n1.0464704\n0.0865635\n12.089050\n0\n0.8768091\n1.2161317\n\n\nIAa2\n~~\nIAa2\n0.7997900\n0.0764096\n10.467135\n0\n0.6500299\n0.9495502\n\n\nIAa3\n~~\nIAa3\n0.5827853\n0.0479619\n12.151008\n0\n0.4887817\n0.6767889\n\n\nIAa13\n~~\nIAa13\n0.3424110\n0.0348598\n9.822517\n0\n0.2740870\n0.4107349\n\n\nIAa14\n~~\nIAa14\n0.5115718\n0.0501136\n10.208248\n0\n0.4133510\n0.6097926\n\n\nIAa15\n~~\nIAa15\n0.5515190\n0.0510740\n10.798424\n0\n0.4514157\n0.6516222\n\n\nF1\n~~\nF1\n1.0000000\n0.0000000\nNA\nNA\n1.0000000\n1.0000000\n\n\n\n\n\n\n\nO modelo de uma única variável latente “F1” apresenta um ajuste geral adequado aos dados, conforme indicado pelo teste qui-quadrado significativo (χ² = 45.034, df = 9, p = 0.000).\nAs cargas fatoriais dos indicadores para “F1” são todas estatisticamente significativas (p &lt; 0.001), indicando que essas variáveis observadas têm uma relação com a variável latente “F1”.\n\n\nÍndices de qualidade do modelo 3\n\nmodel_performance(cfa_modelo_3, metrics = c(\"Chi2\", \"Chi2_df\", \"NFI\", \"CFI\", \"RMSEA\", \"p_RMSEA\", \"AIC\", \"BIC\", \"NNFI\") )\n\n# Indices of model performance\n\nChi2(9) |   NFI |   CFI | RMSEA | p (RMSEA) |      AIC |      BIC |  NNFI\n-------------------------------------------------------------------------\n45.034  | 0.906 | 0.922 | 0.107 |     0.001 | 5406.344 | 5452.536 | 0.870\n\n\n\n\nDiagrama do modelo 3\n\nplot_CFA &lt;- semPaths(\n          object = cfa_modelo_3,\n          what = \"path\",\n          whatLabels = \"par\",\n          style = \"ram\",\n          layout = \"tree\",\n          rotation = 2,\n          sizeMan = 7,\n          sizeLat = 7,\n          color = \"lightgray\",\n          edge.label.cex = 1.2,\n          label.cex = 1.3\n)\n\n\n\n\n\n\nÍndices de modificação para o modelo\n\nkable(modificationindices(cfa_modelo_3, standardized = FALSE, minimum.value = 5))\n\n\n\n\n\nlhs\nop\nrhs\nmi\nepc\n\n\n\n\n16\nIAa1\n~~\nIAa13\n6.419170\n-0.1034145\n\n\n19\nIAa2\n~~\nIAa3\n5.260435\n0.1017547\n\n\n21\nIAa2\n~~\nIAa14\n19.900038\n-0.2224777\n\n\n22\nIAa2\n~~\nIAa15\n6.284104\n0.1223301\n\n\n26\nIAa13\n~~\nIAa14\n24.013115\n0.1712177"
  },
  {
    "objectID": "lista_8.html#modelo-4-com-covariância-entre-os-resíduos",
    "href": "lista_8.html#modelo-4-com-covariância-entre-os-resíduos",
    "title": "9  Lista 8 - CFA e Path Analysis",
    "section": "9.5 Modelo 4 com covariância entre os resíduos",
    "text": "9.5 Modelo 4 com covariância entre os resíduos\n\ncfa_eq_4 = \"\nF1 =~ IAa1 + IAa2 + IAa3 + IAa13 + IAa14 + IAa15\n\n#Covariância dos resíduos\nIAa2    ~~  IAa14\nIAa13   ~~  IAa14\n\"\n\nAnálise Fatorial Confirmatória do modelo 4\n\ncfa_modelo_4 = cfa(\n  model = cfa_eq_4,\n  data = dados_CFA,\n  std.lv = TRUE\n)\n\n\nResultados do modelo 4\n\nkable(parameterEstimates(cfa_modelo_4))\n\n\n\n\nlhs\nop\nrhs\nest\nse\nz\npvalue\nci.lower\nci.upper\n\n\n\n\nF1\n=~\nIAa1\n0.5755782\n0.0658579\n8.739696\n0.0000000\n0.4464990\n0.7046573\n\n\nF1\n=~\nIAa2\n0.8812882\n0.0659778\n13.357336\n0.0000000\n0.7519740\n1.0106024\n\n\nF1\n=~\nIAa3\n0.4106200\n0.0490163\n8.377216\n0.0000000\n0.3145499\n0.5066902\n\n\nF1\n=~\nIAa13\n0.4773285\n0.0461558\n10.341675\n0.0000000\n0.3868648\n0.5677923\n\n\nF1\n=~\nIAa14\n0.6235655\n0.0604044\n10.323181\n0.0000000\n0.5051751\n0.7419560\n\n\nF1\n=~\nIAa15\n0.5905868\n0.0525289\n11.243084\n0.0000000\n0.4876320\n0.6935415\n\n\nIAa2\n~~\nIAa14\n-0.1604716\n0.0490176\n-3.273757\n0.0010613\n-0.2565442\n-0.0643989\n\n\nIAa13\n~~\nIAa14\n0.1249518\n0.0402391\n3.105235\n0.0019013\n0.0460846\n0.2038189\n\n\nIAa1\n~~\nIAa1\n1.0265817\n0.0852570\n12.041031\n0.0000000\n0.8594811\n1.1936823\n\n\nIAa2\n~~\nIAa2\n0.6085266\n0.0820552\n7.416062\n0.0000000\n0.4477013\n0.7693519\n\n\nIAa3\n~~\nIAa3\n0.5777805\n0.0475147\n12.160028\n0.0000000\n0.4846534\n0.6709077\n\n\nIAa13\n~~\nIAa13\n0.4241519\n0.0395633\n10.720852\n0.0000000\n0.3466093\n0.5016945\n\n\nIAa14\n~~\nIAa14\n0.5298461\n0.0642606\n8.245273\n0.0000000\n0.4038976\n0.6557945\n\n\nIAa15\n~~\nIAa15\n0.5578837\n0.0519546\n10.737912\n0.0000000\n0.4560546\n0.6597128\n\n\nF1\n~~\nF1\n1.0000000\n0.0000000\nNA\nNA\n1.0000000\n1.0000000\n\n\n\n\n\n\n\nOs resultados do modelo sugerem que o ajuste do modelo aos dados é razoável, conforme indicado pelo teste qui-quadrado (χ² = 12.216, df = 7, p = 0.094). O modelo envolve uma única variável latente “F1,” e por seis variáveis observadas (IAa1, IAa2, IAa3, IAa13, IAa14, IAa15). As cargas fatoriais associadas a cada indicador são todas estatisticamente significativas (p &lt; 0.001), indicando uma relação entre esses indicadores e a variável latente “F1”. As variâncias dos indicadores também são significativas, sugerindo que cada indicador contribui para a variabilidade total da variável latente “F1”.\nAlém disso, há duas covariâncias estimadas entre os indicadores: uma entre IAa2 e IAa14, e outra entre IAa13 e IAa14. Essas covariâncias indicam associações adicionais entre os indicadores além daquelas explicadas pelas relações com a variável latente “F1”.\n\n\nÍndices de qualidade do modelo 4\n\nmodel_performance(cfa_modelo_4, metrics = c(\"Chi2\", \"Chi2_df\", \"NFI\", \"CFI\", \"RMSEA\", \"p_RMSEA\", \"AIC\", \"BIC\", \"NNFI\"))\n\n# Indices of model performance\n\nChi2(7) |   NFI |   CFI | RMSEA | p (RMSEA) |      AIC |      BIC |  NNFI\n-------------------------------------------------------------------------\n12.216  | 0.974 | 0.989 | 0.046 |     0.498 | 5377.526 | 5431.416 | 0.976\n\n\nO modelo apresenta índices NFI (0.974), CFI (0.989) e NNFI (0.976) próximos de 1, indicando um bom ajuste. O RMSEA (0.046) é baixo, sugerindo uma adequada aproximação do modelo aos dados.\n\n\nDiagrama do modelo 4\n\nplot_CFA &lt;- semPaths(\n          object = cfa_modelo_4,\n          what = \"path\",\n          whatLabels = \"par\",\n          style = \"ram\",\n          layout = \"tree\",\n          rotation = 2,\n          sizeMan = 7,\n          sizeLat = 7,\n          color = \"lightgray\",\n          edge.label.cex = 1.2,\n          label.cex = 1.3\n)\n\n\n\n\n\n\nComparação entre os modelos\n\ncompare_performance(cfa_modelo, cfa_modelo_2, cfa_modelo_3, cfa_modelo_4,\n                    metrics = c(\"NFI\", \"CFI\", \"RMSEA\", \"p_RMSEA\", \"AIC\", \"BIC\", \"NNFI\"),\n                    rank = TRUE, verbose = F)\n\n# Comparison of Model Performance Indices\n\nName         |  Model |   NFI |   CFI | RMSEA | p (RMSEA) |  NNFI | AIC weights | BIC weights | Performance-Score\n-----------------------------------------------------------------------------------------------------------------\ncfa_modelo_4 | lavaan | 0.974 | 0.989 | 0.046 |     0.498 | 0.976 |       0.952 |       0.999 |            85.71%\ncfa_modelo_2 | lavaan | 0.970 | 0.980 | 0.073 |     0.165 | 0.940 |       0.048 |       0.001 |            47.00%\ncfa_modelo   | lavaan | 0.918 | 0.933 | 0.106 |     0.003 | 0.874 |    3.64e-06 |    2.62e-05 |            19.27%\ncfa_modelo_3 | lavaan | 0.906 | 0.922 | 0.107 |     0.001 | 0.870 |    5.26e-07 |    2.59e-05 |            14.29%\n\n\nO modelo_4 demonstra superioridade em relação aos demais modelos com base nos critérios de ajuste avaliados.\n\n# Links de referência\n\n# https://rdrr.io/cran/performance/man/model_performance.lavaan.html\n# https://methodenlehre.github.io/SGSCLM-R-course/cfa-and-sem-with-lavaan.html#structural-equation-modelling-sem"
  },
  {
    "objectID": "lista_8.html#lista-8-resolvida-no-spss",
    "href": "lista_8.html#lista-8-resolvida-no-spss",
    "title": "9  Lista 8 - CFA e Path Analysis",
    "section": "9.6 Lista 8 resolvida no SPSS",
    "text": "9.6 Lista 8 resolvida no SPSS"
  },
  {
    "objectID": "lista_8.html#extras",
    "href": "lista_8.html#extras",
    "title": "9  Lista 8 - CFA e Path Analysis",
    "section": "9.7 Extras!",
    "text": "9.7 Extras!\n\nMais gráficos\n\nsemPaths(cfa_modelo, \"std\", weighted = FALSE, nCharNodes = 7, shapeMan = \"rectangle\",\n         sizeMan = 8, sizeMan2 = 5)"
  },
  {
    "objectID": "lista_8.html#referências",
    "href": "lista_8.html#referências",
    "title": "9  Lista 8 - CFA e Path Analysis",
    "section": "9.8 Referências",
    "text": "9.8 Referências\nhttps://www.jstatsoft.org/article/view/v048i02\nhttps://lavaan.ugent.be/tutorial/inspect.html"
  },
  {
    "objectID": "lista_8.html#versões-dos-pacotes",
    "href": "lista_8.html#versões-dos-pacotes",
    "title": "9  Lista 8 - CFA e Path Analysis",
    "section": "9.9 Versões dos pacotes",
    "text": "9.9 Versões dos pacotes\n\nreport(sessionInfo())\n\nAnalyses were conducted using the R Statistical language (version 4.3.1; R Core\nTeam, 2023) on Windows 11 x64 (build 22621), using the packages effectsize\n(version 0.8.6; Ben-Shachar MS et al., 2020), semPlot (version 1.1.6; Epskamp\nS, 2022), lubridate (version 1.9.3; Grolemund G, Wickham H, 2011), parameters\n(version 0.21.3; Lüdecke D et al., 2020), performance (version 0.10.8; Lüdecke\nD et al., 2021), easystats (version 0.6.0; Lüdecke D et al., 2022), see\n(version 0.8.1; Lüdecke D et al., 2021), insight (version 0.19.6; Lüdecke D et\nal., 2019), bayestestR (version 0.13.1; Makowski D et al., 2019), modelbased\n(version 0.8.6; Makowski D et al., 2020), report (version 0.5.7; Makowski D et\nal., 2023), correlation (version 0.8.4; Makowski D et al., 2022), tibble\n(version 3.2.1; Müller K, Wickham H, 2023), datawizard (version 0.9.0; Patil I\net al., 2022), foreign (version 0.8.85; R Core Team, 2023), lavaan (version\n0.6.16; Rosseel Y, 2012), ggplot2 (version 3.4.4; Wickham H, 2016), forcats\n(version 1.0.0; Wickham H, 2023), stringr (version 1.5.1; Wickham H, 2023),\ntidyverse (version 2.0.0; Wickham H et al., 2019), dplyr (version 1.1.3;\nWickham H et al., 2023), purrr (version 1.0.2; Wickham H, Henry L, 2023), readr\n(version 2.1.4; Wickham H et al., 2023), tidyr (version 1.3.0; Wickham H et\nal., 2023) and kableExtra (version 1.3.4; Zhu H, 2021).\n\nReferences\n----------\n  - Ben-Shachar MS, Lüdecke D, Makowski D (2020). \"effectsize: Estimation of\nEffect Size Indices and Standardized Parameters.\" _Journal of Open Source\nSoftware_, *5*(56), 2815. doi:10.21105/joss.02815\n&lt;https://doi.org/10.21105/joss.02815&gt;, &lt;https://doi.org/10.21105/joss.02815&gt;.\n  - Epskamp S (2022). _semPlot: Path Diagrams and Visual Analysis of Various SEM\nPackages' Output_. R package version 1.1.6,\n&lt;https://CRAN.R-project.org/package=semPlot&gt;.\n  - Grolemund G, Wickham H (2011). \"Dates and Times Made Easy with lubridate.\"\n_Journal of Statistical Software_, *40*(3), 1-25.\n&lt;https://www.jstatsoft.org/v40/i03/&gt;.\n  - Lüdecke D, Ben-Shachar M, Patil I, Makowski D (2020). \"Extracting, Computing\nand Exploring the Parameters of Statistical Models using R.\" _Journal of Open\nSource Software_, *5*(53), 2445. doi:10.21105/joss.02445\n&lt;https://doi.org/10.21105/joss.02445&gt;.\n  - Lüdecke D, Ben-Shachar M, Patil I, Waggoner P, Makowski D (2021).\n\"performance: An R Package for Assessment, Comparison and Testing of\nStatistical Models.\" _Journal of Open Source Software_, *6*(60), 3139.\ndoi:10.21105/joss.03139 &lt;https://doi.org/10.21105/joss.03139&gt;.\n  - Lüdecke D, Ben-Shachar M, Patil I, Wiernik B, Makowski D (2022). \"easystats:\nFramework for Easy Statistical Modeling, Visualization, and Reporting.\" _CRAN_.\nR package, &lt;https://easystats.github.io/easystats/&gt;.\n  - Lüdecke D, Patil I, Ben-Shachar M, Wiernik B, Waggoner P, Makowski D (2021).\n\"see: An R Package for Visualizing Statistical Models.\" _Journal of Open Source\nSoftware_, *6*(64), 3393. doi:10.21105/joss.03393\n&lt;https://doi.org/10.21105/joss.03393&gt;.\n  - Lüdecke D, Waggoner P, Makowski D (2019). \"insight: A Unified Interface to\nAccess Information from Model Objects in R.\" _Journal of Open Source Software_,\n*4*(38), 1412. doi:10.21105/joss.01412 &lt;https://doi.org/10.21105/joss.01412&gt;.\n  - Makowski D, Ben-Shachar M, Lüdecke D (2019). \"bayestestR: Describing Effects\nand their Uncertainty, Existence and Significance within the Bayesian\nFramework.\" _Journal of Open Source Software_, *4*(40), 1541.\ndoi:10.21105/joss.01541 &lt;https://doi.org/10.21105/joss.01541&gt;,\n&lt;https://joss.theoj.org/papers/10.21105/joss.01541&gt;.\n  - Makowski D, Ben-Shachar M, Patil I, Lüdecke D (2020). \"Estimation of\nModel-Based Predictions, Contrasts and Means.\" _CRAN_.\n&lt;https://github.com/easystats/modelbased&gt;.\n  - Makowski D, Lüdecke D, Patil I, Thériault R, Ben-Shachar M, Wiernik B (2023).\n\"Automated Results Reporting as a Practical Tool to Improve Reproducibility and\nMethodological Best Practices Adoption.\" _CRAN_.\n&lt;https://easystats.github.io/report/&gt;.\n  - Makowski D, Wiernik B, Patil I, Lüdecke D, Ben-Shachar M (2022).\n\"correlation: Methods for Correlation Analysis.\" Version 0.8.3,\n&lt;https://CRAN.R-project.org/package=correlation&gt;. Makowski D, Ben-Shachar M,\nPatil I, Lüdecke D (2020). \"Methods and Algorithms for Correlation Analysis in\nR.\" _Journal of Open Source Software_, *5*(51), 2306. doi:10.21105/joss.02306\n&lt;https://doi.org/10.21105/joss.02306&gt;,\n&lt;https://joss.theoj.org/papers/10.21105/joss.02306&gt;.\n  - Müller K, Wickham H (2023). _tibble: Simple Data Frames_. R package version\n3.2.1, &lt;https://CRAN.R-project.org/package=tibble&gt;.\n  - Patil I, Makowski D, Ben-Shachar M, Wiernik B, Bacher E, Lüdecke D (2022).\n\"datawizard: An R Package for Easy Data Preparation and Statistical\nTransformations.\" _Journal of Open Source Software_, *7*(78), 4684.\ndoi:10.21105/joss.04684 &lt;https://doi.org/10.21105/joss.04684&gt;.\n  - R Core Team (2023). _foreign: Read Data Stored by 'Minitab', 'S', 'SAS',\n'SPSS', 'Stata', 'Systat', 'Weka', 'dBase', ..._. R package version 0.8-85,\n&lt;https://CRAN.R-project.org/package=foreign&gt;.\n  - R Core Team (2023). _R: A Language and Environment for Statistical\nComputing_. R Foundation for Statistical Computing, Vienna, Austria.\n&lt;https://www.R-project.org/&gt;.\n  - Rosseel Y (2012). \"lavaan: An R Package for Structural Equation Modeling.\"\n_Journal of Statistical Software_, *48*(2), 1-36. doi:10.18637/jss.v048.i02\n&lt;https://doi.org/10.18637/jss.v048.i02&gt;.\n  - Wickham H (2016). _ggplot2: Elegant Graphics for Data Analysis_.\nSpringer-Verlag New York. ISBN 978-3-319-24277-4,\n&lt;https://ggplot2.tidyverse.org&gt;.\n  - Wickham H (2023). _forcats: Tools for Working with Categorical Variables\n(Factors)_. R package version 1.0.0,\n&lt;https://CRAN.R-project.org/package=forcats&gt;.\n  - Wickham H (2023). _stringr: Simple, Consistent Wrappers for Common String\nOperations_. R package version 1.5.1,\n&lt;https://CRAN.R-project.org/package=stringr&gt;.\n  - Wickham H, Averick M, Bryan J, Chang W, McGowan LD, François R, Grolemund G,\nHayes A, Henry L, Hester J, Kuhn M, Pedersen TL, Miller E, Bache SM, Müller K,\nOoms J, Robinson D, Seidel DP, Spinu V, Takahashi K, Vaughan D, Wilke C, Woo K,\nYutani H (2019). \"Welcome to the tidyverse.\" _Journal of Open Source Software_,\n*4*(43), 1686. doi:10.21105/joss.01686 &lt;https://doi.org/10.21105/joss.01686&gt;.\n  - Wickham H, François R, Henry L, Müller K, Vaughan D (2023). _dplyr: A Grammar\nof Data Manipulation_. R package version 1.1.3,\n&lt;https://CRAN.R-project.org/package=dplyr&gt;.\n  - Wickham H, Henry L (2023). _purrr: Functional Programming Tools_. R package\nversion 1.0.2, &lt;https://CRAN.R-project.org/package=purrr&gt;.\n  - Wickham H, Hester J, Bryan J (2023). _readr: Read Rectangular Text Data_. R\npackage version 2.1.4, &lt;https://CRAN.R-project.org/package=readr&gt;.\n  - Wickham H, Vaughan D, Girlich M (2023). _tidyr: Tidy Messy Data_. R package\nversion 1.3.0, &lt;https://CRAN.R-project.org/package=tidyr&gt;.\n  - Zhu H (2021). _kableExtra: Construct Complex Table with 'kable' and Pipe\nSyntax_. R package version 1.3.4,\n&lt;https://CRAN.R-project.org/package=kableExtra&gt;."
  },
  {
    "objectID": "lista_8_1.html#a-modelo-causal-teórico",
    "href": "lista_8_1.html#a-modelo-causal-teórico",
    "title": "10  Lista 8.1 - Moderação e Mediação",
    "section": "10.1 a) Modelo causal teórico",
    "text": "10.1 a) Modelo causal teórico\n\n\n\n\n\n\nExercício\n\n\n\nVerifique esse modelo causal teórico e veja se ele faz sentido, utilizando um modelo SEM com mediação. Avalie os efeitos diretos e indiretos e decida se esse modelo teórico faz sentido, utilizando o AMOS e o Process.\n\n\nResolução do exercício foi baseada no vídeo “Simple Mediation using lavaan package of R” https://www.youtube.com/watch?v=nfQOCy9xMnk\n\noriginal = read.spss(\"DADOS PATH.sav\", to.data.frame=TRUE)\nglimpse(original)\n\nRows: 94\nColumns: 4\n$ Idade         &lt;dbl&gt; 57, 41, 29, 26, 33, 37, 26, 44, 31, 36, 30, 55, 43, 27, …\n$ IMC1          &lt;dbl&gt; 28.46122, 32.62609, 26.99050, 19.03602, 28.76650, 24.686…\n$ Treinos       &lt;dbl&gt; 108, 144, 48, 102, 123, 63, 39, 105, 6, 48, 144, 144, 11…\n$ Sociabilidade &lt;dbl&gt; 14, 34, 17, 20, 26, 19, 15, 32, 27, 19, 28, 9, 30, 29, 1…\n\n\n\nmodelo_1 = \"Treinos ~ c_*Sociabilidade + b*IMC1 \n            IMC1 ~ a*Sociabilidade\n            Indireto := a*b\n            Total_direto_C := a*b + c_\"\n\n\nfit_1 = sem(modelo_1, original, se = \"bootstrap\", bootstrap = 500)\n\n\n#summary(fit_1) # parâmetros adicionais summary(fit_1, fit.measures = TRUE, standardized = TRUE, rsquare = TRUE) \n\nkable(parameterEstimates(fit_1))\n\n\n\n\nlhs\nop\nrhs\nlabel\nest\nse\nz\npvalue\nci.lower\nci.upper\n\n\n\n\nTreinos\n~\nSociabilidade\nc_\n0.6052243\n0.6619768\n0.9142682\n0.3605759\n-0.6524603\n1.8245324\n\n\nTreinos\n~\nIMC1\nb\n-1.6497656\n1.0185007\n-1.6197982\n0.1052756\n-3.6551562\n0.4350822\n\n\nIMC1\n~\nSociabilidade\na\n0.0190526\n0.0507549\n0.3753835\n0.7073753\n-0.0861290\n0.1130998\n\n\nTreinos\n~~\nTreinos\n\n2327.0247317\n187.7869286\n12.3918355\n0.0000000\n1884.6418875\n2629.3007296\n\n\nIMC1\n~~\nIMC1\n\n17.7329732\n3.0046312\n5.9018802\n0.0000000\n12.1538364\n23.9097897\n\n\nSociabilidade\n~~\nSociabilidade\n\n65.6008375\n0.0000000\nNA\nNA\n65.6008375\n65.6008375\n\n\nIndireto\n:=\na*b\nIndireto\n-0.0314322\n0.0996909\n-0.3152970\n0.7525362\n-0.2192393\n0.2283743\n\n\nTotal_direto_C\n:=\na*b+c_\nTotal_direto_C\n0.5737921\n0.6689293\n0.8577768\n0.3910157\n-0.7354611\n1.7852540\n\n\n\n\n\n\n\n\nResultados\n\nRegressões:\n\n\nO coeficiente estimado para a relação entre Sociabilidae e Treinos é 0.605, mas não é estatisticamente significativo (p = 0.360).\nO coeficiente estimado para a relação entre IMC e Treinos é -1.650, indicando uma relação negativa. No entanto, esse coeficiente também não é estatisticamente significativo (p = 0.100).\nO coeficiente estimado para a relação entre Sociabilidae e IMC é 0.019 e não é estatisticamente significativo (p = 0.693).\n\n\nParâmetros Definidos:\n\n\nO efeito indireto é estimado como -0.031, mas não é estatisticamente significativo (p = 0.717). Isso sugere que a variável IMC não medeia significativamente a relação entre Sociabilidae e Treinos.\nO efeito direto da Sociabilidade no Treino é estimado como 0.574 e também não é estatisticamente significativo (p = 0.386).\n\nCom base nos resultados, podemos concluir que o modelo teórico não se sustenta, pois não há evidência estatística significativa para sugerir relações entre as variáveis Sociabilidae , IMC e Treinos."
  },
  {
    "objectID": "lista_8_1.html#b-mediação-vs-regressões-lineares",
    "href": "lista_8_1.html#b-mediação-vs-regressões-lineares",
    "title": "10  Lista 8.1 - Moderação e Mediação",
    "section": "10.2 b) Mediação vs Regressões lineares",
    "text": "10.2 b) Mediação vs Regressões lineares\n\n\n\n\n\n\nExercício\n\n\n\nCompare os dados encontrados com aqueles realizados por um conjunto de regressões lineares (OLS). Fazer esta análise de mediação por regressão linear e utilizando o AMOS+Process é a mesma coisa? Coloque também o diagrama gerado aqui.\n\n\n\nValor de “c”\n\nsoc_treinos = lm(Treinos ~ Sociabilidade, data = original) #valor de c\nkable(summary(soc_treinos)$coef)\n\n\n\n\n\nEstimate\nStd. Error\nt value\nPr(&gt;|t|)\n\n\n\n\n(Intercept)\n69.4395522\n14.1638541\n4.9025888\n0.0000041\n\n\nSociabilidade\n0.5737921\n0.6273496\n0.9146289\n0.3627775\n\n\n\n\n\n\n\n\n\nValor de a\n\nsoc_imc = lm(IMC1 ~ Sociabilidade, data = original) \nkable(summary(soc_imc)$coef)\n\n\n\n\n\nEstimate\nStd. Error\nt value\nPr(&gt;|t|)\n\n\n\n\n(Intercept)\n25.3971491\n1.2238100\n20.7525264\n0.0000000\n\n\nSociabilidade\n0.0190526\n0.0542054\n0.3514884\n0.7260257\n\n\n\n\n\n\n\n\n\nvalor de b e de c’\n\nsoc_E_imc_treinos = lm(Treinos ~ IMC1 + Sociabilidade, data = original) \nkable(summary(soc_E_imc_treinos)$coef)\n\n\n\n\n\nEstimate\nStd. Error\nt value\nPr(&gt;|t|)\n\n\n\n\n(Intercept)\n111.3388945\n33.5981763\n3.3138374\n0.0013220\n\n\nIMC1\n-1.6497656\n1.2008507\n-1.3738307\n0.1728690\n\n\nSociabilidade\n0.6052243\n0.6247647\n0.9687235\n0.3352508\n\n\n\n\n\n\n\nOs resultados são diferentes. As mediações apenas por regressão linear não apresentam o resultado do efeito indireto, mostrado no resultado do exercício anterior\n\n\nDiagrama do modelo\n\ndiagrama_1 &lt;- semPaths(\n          object = fit_1,\n          what = \"path\",\n          whatLabels = \"par\",\n          style = \"ram\",\n          layout = \"tree\",\n          rotation = 2,\n          sizeMan = 7,\n          sizeLat = 7,\n          color = \"lightgray\",\n          edge.label.cex = 1.2,\n          label.cex = 1.3\n)"
  },
  {
    "objectID": "lista_8_1.html#modelo-2-opcional-1",
    "href": "lista_8_1.html#modelo-2-opcional-1",
    "title": "10  Lista 8.1 - Moderação e Mediação",
    "section": "10.3 Modelo 2 (Opcional 1)",
    "text": "10.3 Modelo 2 (Opcional 1)\nRefaça o modelo tendo a variável Idade como mediador.\n\nmodelo_2 = \"Treinos ~ c_*Sociabilidade + b*Idade \n            Idade ~ a*Sociabilidade\n            Indireto := a*b\n            Total_direto_C := a*b + c_\"\n\n\nfit_2 = sem(modelo_2, original, se = \"bootstrap\", bootstrap = 500)\n\nkable(parameterEstimates(fit_2)) # parâmetros adicionais summary(fit_1, fit.measures = TRUE, standardized = TRUE, rsquare = TRUE) \n\n\n\n\nlhs\nop\nrhs\nlabel\nest\nse\nz\npvalue\nci.lower\nci.upper\n\n\n\n\nTreinos\n~\nSociabilidade\nc_\n0.4852942\n0.6196786\n0.7831385\n0.4335458\n-0.7090243\n1.6900127\n\n\nTreinos\n~\nIdade\nb\n1.5425565\n0.4588149\n3.3620452\n0.0007737\n0.6913514\n2.4044144\n\n\nIdade\n~\nSociabilidade\na\n0.0573709\n0.1100893\n0.5211310\n0.6022755\n-0.1575502\n0.2725941\n\n\nTreinos\n~~\nTreinos\n\n2179.2955768\n194.4639552\n11.2066813\n0.0000000\n1707.6722717\n2479.7855236\n\n\nIdade\n~~\nIdade\n\n82.3681677\n10.5597227\n7.8002207\n0.0000000\n61.5549212\n102.4772562\n\n\nSociabilidade\n~~\nSociabilidade\n\n65.6008375\n0.0000000\nNA\nNA\n65.6008375\n65.6008375\n\n\nIndireto\n:=\na*b\nIndireto\n0.0884979\n0.1735841\n0.5098273\n0.6101725\n-0.2660349\n0.4446866\n\n\nTotal_direto_C\n:=\na*b+c_\nTotal_direto_C\n0.5737921\n0.6808613\n0.8427445\n0.3993714\n-0.7934420\n1.9182149\n\n\n\n\n\n\n\n\nResultados\n\nRegressões:\n\nA relação estimada entre Sociabilidade e Treinos é 0.485, mas não é estatisticamente significativa (p = 0.384).\nA relação estimada entre Idade e Treinos é 1.543, indicando uma relação positiva e significativa (p = 0.001).\nA relação estimada entre Sociabldd e Idade é 0.057 e não é estatisticamente significativa (p = 0.592).\n\nParâmetros Definidos:\n\nO efeito Indireto é estimado como 0.088, mas não é estatisticamente significativo (p = 0.605). Isso sugere que a variável Idade não medeia significativamente a relação entre Sociabilidade e Treinos.\nO efeito total direto da Sociabilidae nos Treinos é estimado como 0.574 e não é estatisticamente significativo (p = 0.345).\n\n\nOs resultados sugerem que a variável Idade está significativamente relacionada à variável Treinos, enquanto a variável Sociabilidade não tem uma relação significativa com Treinos. O efeito indireto através de Idade não é estatisticamente significativo, e o efeito total direto também não é significativo.\n\n\nDiagrama do modelo 2\n\ndiagrama_2 &lt;- semPaths(\n          object = fit_2,\n          what = \"path\",\n          whatLabels = \"par\",\n          style = \"ram\",\n          layout = \"tree\",\n          rotation = 2,\n          sizeMan = 7,\n          sizeLat = 7,\n          color = \"lightgray\",\n          edge.label.cex = 1.2,\n          label.cex = 1.3\n)\n\n\n\n\n\nmediation_model_2 = lm(Idade ~ Sociabilidade, data = original)\nkable(summary(mediation_model_2)$coef)\n\n\n\n\n\nEstimate\nStd. Error\nt value\nPr(&gt;|t|)\n\n\n\n\n(Intercept)\n32.8228531\n2.6375635\n12.4443843\n0.0000000\n\n\nSociabilidade\n0.0573709\n0.1168237\n0.4910896\n0.6245325\n\n\n\n\n\n\n# library(flexplot)\n# visualize(mediation_model_2) análise gráfica do modelo\n\n\nfull_model_2 = lm(Treinos ~ Idade + Sociabilidade, data = original)\nkable(summary(full_model_2)$coef)\n\n\n\n\n\nEstimate\nStd. Error\nt value\nPr(&gt;|t|)\n\n\n\n\n(Intercept)\n18.8084463\n22.3454098\n0.8417141\n0.4021546\n\n\nIdade\n1.5425565\n0.5392097\n2.8607731\n0.0052418\n\n\nSociabilidade\n0.4852942\n0.6049941\n0.8021469\n0.4245578\n\n\n\n\n\n\n#visualize(full_model_2) análise gráfica do modelo\n\n\nresults_2 = mediate(mediation_model_2, full_model_2,\n                  treat = \"Sociabilidade\",\n                  mediator = \"Idade\",\n                  boot = TRUE,\n                  sims = 500)\n\nsummary(results_2)\n\n\nCausal Mediation Analysis \n\nNonparametric Bootstrap Confidence Intervals with the Percentile Method\n\n               Estimate 95% CI Lower 95% CI Upper p-value\nACME             0.0885      -0.2126         0.45    0.52\nADE              0.4853      -0.6804         1.70    0.37\nTotal Effect     0.5738      -0.6401         1.88    0.33\nProp. Mediated   0.1542      -1.7984         1.59    0.50\n\nSample Size Used: 94 \n\n\nSimulations: 500 \n\n\n\nmediate_plot(Treinos ~ Idade  + Sociabilidade  , data = original)"
  },
  {
    "objectID": "lista_8_1.html#modelo-3-opcional-2",
    "href": "lista_8_1.html#modelo-3-opcional-2",
    "title": "10  Lista 8.1 - Moderação e Mediação",
    "section": "10.4 Modelo 3 (Opcional 2)",
    "text": "10.4 Modelo 3 (Opcional 2)\nTestando outros modelos, foi possível observar que o efeito do IMC sobre o treinamento é mediado pela Idade\n\nmodelo_3 = \"Treinos ~ c_*IMC1 + b*Idade \n            Idade ~ a*IMC1\n            Indireto := a*b\n            Total_direto_C := a*b + c_\"\n\n\nfit_3 = sem(modelo_3, original, se = \"bootstrap\", bootstrap = 500) #demora um tempo para executar\n\n\nkable(parameterEstimates(fit_3)) # parâmetros adicionais summary(fit_1, fit.measures = TRUE, standardized = TRUE, rsquare = TRUE)\n\n\n\n\nlhs\nop\nrhs\nlabel\nest\nse\nz\npvalue\nci.lower\nci.upper\n\n\n\n\nTreinos\n~\nIMC1\nc_\n-2.7781642\n1.0067476\n-2.759544\n0.0057882\n-4.6800358\n-0.6198768\n\n\nTreinos\n~\nIdade\nb\n1.9275620\n0.4583106\n4.205798\n0.0000260\n0.9813260\n2.7588243\n\n\nIdade\n~\nIMC1\na\n0.6075027\n0.2252141\n2.697446\n0.0069874\n0.2357407\n1.0753598\n\n\nTreinos\n~~\nTreinos\n\n2068.5298836\n190.9705838\n10.831668\n0.0000000\n1660.9183246\n2429.8198497\n\n\nIdade\n~~\nIdade\n\n76.0307760\n9.8646493\n7.707398\n0.0000000\n55.5284839\n95.0898386\n\n\nIMC1\n~~\nIMC1\n\n17.7567863\n0.0000000\nNA\nNA\n17.7567863\n17.7567863\n\n\nIndireto\n:=\na*b\nIndireto\n1.1709992\n0.5155848\n2.271206\n0.0231345\n0.3149790\n2.3125077\n\n\nTotal_direto_C\n:=\na*b+c_\nTotal_direto_C\n-1.6071651\n1.0825367\n-1.484629\n0.1376422\n-3.6571736\n0.6752811\n\n\n\n\n\n\n\n\nResultados\n\nRegressões:\n\nA relação estimada entre IMC1 (Índice de Massa Corporal) e Treinos é -2.778, indicando uma relação negativa e significativa (p = 0.006).\nA relação estimada entre Idade e Treinos é 1.928, indicando uma relação positiva e significativa (p = 0.000).\nA relação estimada entre IMC e Idade é 0.608 e é estatisticamente significativa (p = 0.005).\n\nParâmetros Definidos:\n\nO efeito Indireto é estimado como 1.171 e é estatisticamente significativo (p = 0.030). Isso sugere que a variável Idade medeia significativamente a relação entre IMC e Treinos.\nO efeito total direto de IMC nos Treinos é estimado como -1.607, mas não é estatisticamente significativo (p = 0.114).\n\n\nOs resultados indicam que a variável IMC está significativamente relacionada negativamente à variável Treinos. A variável Idade atua como mediadora nessa relação. O efeito indireto é estimado como 1.171 (p = 0.030), indicando que a inclusão de Idade no modelo altera a relação entre IMC1 e Treinos, tornando-a mais negativa do que a relação direta."
  },
  {
    "objectID": "lista_8_1.html#diagrama-do-modelo-3",
    "href": "lista_8_1.html#diagrama-do-modelo-3",
    "title": "10  Lista 8.1 - Moderação e Mediação",
    "section": "10.5 Diagrama do modelo 3",
    "text": "10.5 Diagrama do modelo 3\n\ndiagrama_3 &lt;- semPaths(\n          object = fit_3,\n          what = \"path\",\n          whatLabels = \"par\",\n          style = \"ram\",\n          layout = \"tree\",\n          rotation = 2,\n          sizeMan = 7,\n          sizeLat = 7,\n          color = \"lightgray\",\n          edge.label.cex = 1.2,\n          label.cex = 1.3\n)\n\n\n\n\n\nmediation_model_3 = lm(Idade ~ IMC1, data = original)\nsummary(mediation_model_3)$coef\n\n              Estimate Std. Error  t value    Pr(&gt;|t|)\n(Intercept) 18.3591515   5.639405 3.255512 0.001584908\nIMC1         0.6075027   0.215734 2.815980 0.005949584\n\nvisualize(mediation_model_3) \n\n\n\n\n\nfull_model_3 = lm(Treinos ~ Idade + IMC1, data = original)\nsummary(full_model_3)$coef\n\n             Estimate Std. Error   t value     Pr(&gt;|t|)\n(Intercept) 87.606237 31.2333809  2.804891 0.0061538896\nIdade        1.927562  0.5467836  3.525274 0.0006645242\nIMC1        -2.778164  1.1791838 -2.356006 0.0206193649\n\nvisualize(full_model_3)\n\n\n\n\n\nresults_3 = mediate(mediation_model_3, full_model_3,\n                  treat = \"IMC1\",\n                  mediator = \"Idade\",\n                  boot = TRUE,\n                  sims = 500)\n\nsummary(results_3)\n\n\nCausal Mediation Analysis \n\nNonparametric Bootstrap Confidence Intervals with the Percentile Method\n\n               Estimate 95% CI Lower 95% CI Upper p-value    \nACME              1.171        0.339         2.43  &lt;2e-16 ***\nADE              -2.778       -4.585        -0.62   0.024 *  \nTotal Effect     -1.607       -3.441         0.57   0.156    \nProp. Mediated   -0.729      -11.591         7.21   0.156    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nSample Size Used: 94 \n\n\nSimulations: 500 \n\n\n\nmediate_plot(Treinos ~ Idade  + IMC1  , data = original)"
  },
  {
    "objectID": "lista_8_1.html#lista-8.1-resolvida-no-spss",
    "href": "lista_8_1.html#lista-8.1-resolvida-no-spss",
    "title": "10  Lista 8.1 - Moderação e Mediação",
    "section": "10.6 Lista 8.1 resolvida no SPSS",
    "text": "10.6 Lista 8.1 resolvida no SPSS"
  },
  {
    "objectID": "lista_8_1.html#extras",
    "href": "lista_8_1.html#extras",
    "title": "10  Lista 8.1 - Moderação e Mediação",
    "section": "10.7 Extras!",
    "text": "10.7 Extras!\nOutro tipo de resolução baseada no vídeo do Dustin Fife (How to do a mediation analysis in R…with visuals!)\n\n# Mediação com visualização\nlibrary(mediation)\nlibrary(flexplot)\n\n\nmediation_model = lm(IMC1 ~ Sociabilidade, data = original)\nsummary(mediation_model)\n\n\nCall:\nlm(formula = IMC1 ~ Sociabilidade, data = original)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-7.3645 -2.8931 -0.4598  2.7881 14.5354 \n\nCoefficients:\n              Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)   25.39715    1.22381  20.753   &lt;2e-16 ***\nSociabilidade  0.01905    0.05421   0.351    0.726    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 4.257 on 92 degrees of freedom\nMultiple R-squared:  0.001341,  Adjusted R-squared:  -0.009514 \nF-statistic: 0.1235 on 1 and 92 DF,  p-value: 0.726\n\n\n\nvisualize(mediation_model, plot = \"model\")\n\n\n\n\n\nfull_model = lm(Treinos ~ IMC1 + Sociabilidade, data = original)\nsummary(full_model)\n\n\nCall:\nlm(formula = Treinos ~ IMC1 + Sociabilidade, data = original)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-85.683 -42.165   2.807  47.623  69.596 \n\nCoefficients:\n              Estimate Std. Error t value Pr(&gt;|t|)   \n(Intercept)   111.3389    33.5982   3.314  0.00132 **\nIMC1           -1.6498     1.2009  -1.374  0.17287   \nSociabilidade   0.6052     0.6248   0.969  0.33525   \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 49.03 on 91 degrees of freedom\nMultiple R-squared:  0.02915,   Adjusted R-squared:  0.00781 \nF-statistic: 1.366 on 2 and 91 DF,  p-value: 0.2603\n\n\n\nvisualize(full_model)\n\n\n\n\n\nresults = mediate(mediation_model, full_model,\n                  treat = \"Sociabilidade\",\n                  mediator = \"IMC1\",\n                  boot = TRUE,\n                  sims = 500)\n\n\nsummary(results)\n\n\nCausal Mediation Analysis \n\nNonparametric Bootstrap Confidence Intervals with the Percentile Method\n\n               Estimate 95% CI Lower 95% CI Upper p-value\nACME            -0.0314      -0.1976         0.17    0.78\nADE              0.6052      -0.6669         1.95    0.29\nTotal Effect     0.5738      -0.6201         1.89    0.30\nProp. Mediated  -0.0548      -1.3478         1.26    0.87\n\nSample Size Used: 94 \n\n\nSimulations: 500 \n\n\n\nmediate_plot(Treinos ~ IMC1 +  Sociabilidade, data = original) # Ordem em que aparece as variáveis é muito importante. A última variável será sempre a variável DEPENDENTE (X). Todas as outras que vierem antes dela, serão tratadas como MEDIADORAS (no caso IMC1)"
  },
  {
    "objectID": "lista_8_1.html#referências",
    "href": "lista_8_1.html#referências",
    "title": "10  Lista 8.1 - Moderação e Mediação",
    "section": "10.8 Referências",
    "text": "10.8 Referências\nhttps://www.youtube.com/watch?v=_4Fu8SZID2k"
  },
  {
    "objectID": "lista_8_1.html#versões-dos-pacotes",
    "href": "lista_8_1.html#versões-dos-pacotes",
    "title": "10  Lista 8.1 - Moderação e Mediação",
    "section": "10.9 Versões dos pacotes",
    "text": "10.9 Versões dos pacotes\n\nreport(sessionInfo())\n\nAnalyses were conducted using the R Statistical language (version 4.3.1; R Core\nTeam, 2023) on Windows 11 x64 (build 22621), using the packages Matrix (version\n1.6.0; Bates D et al., 2023), effectsize (version 0.8.6; Ben-Shachar MS et al.,\n2020), semPlot (version 1.1.6; Epskamp S, 2022), flexplot (version 0.20.5; Fife\nD, 2024), mvtnorm (version 1.2.3; Genz A, Bretz F, 2009), lubridate (version\n1.9.3; Grolemund G, Wickham H, 2011), semTools (version 0.5.6; Jorgensen TD et\nal., 2022), parameters (version 0.21.3; Lüdecke D et al., 2020), performance\n(version 0.10.8; Lüdecke D et al., 2021), easystats (version 0.6.0; Lüdecke D\net al., 2022), see (version 0.8.1; Lüdecke D et al., 2021), insight (version\n0.19.6; Lüdecke D et al., 2019), bayestestR (version 0.13.1; Makowski D et al.,\n2019), modelbased (version 0.8.6; Makowski D et al., 2020), report (version\n0.5.7; Makowski D et al., 2023), correlation (version 0.8.4; Makowski D et al.,\n2022), tibble (version 3.2.1; Müller K, Wickham H, 2023), datawizard (version\n0.9.0; Patil I et al., 2022), foreign (version 0.8.85; R Core Team, 2023),\nlavaan (version 0.6.16; Rosseel Y, 2012), mediation (version 4.5.0; Tingley D\net al., 2014), MASS (version 7.3.60; Venables WN, Ripley BD, 2002), ggplot2\n(version 3.4.4; Wickham H, 2016), forcats (version 1.0.0; Wickham H, 2023),\nstringr (version 1.5.1; Wickham H, 2023), tidyverse (version 2.0.0; Wickham H\net al., 2019), dplyr (version 1.1.3; Wickham H et al., 2023), purrr (version\n1.0.2; Wickham H, Henry L, 2023), readr (version 2.1.4; Wickham H et al.,\n2023), tidyr (version 1.3.0; Wickham H et al., 2023), sandwich (version 3.1.0;\nZeileis A et al., 2020) and kableExtra (version 1.3.4; Zhu H, 2021).\n\nReferences\n----------\n  - Bates D, Maechler M, Jagan M (2023). _Matrix: Sparse and Dense Matrix Classes\nand Methods_. R package version 1.6-0,\n&lt;https://CRAN.R-project.org/package=Matrix&gt;.\n  - Ben-Shachar MS, Lüdecke D, Makowski D (2020). \"effectsize: Estimation of\nEffect Size Indices and Standardized Parameters.\" _Journal of Open Source\nSoftware_, *5*(56), 2815. doi:10.21105/joss.02815\n&lt;https://doi.org/10.21105/joss.02815&gt;, &lt;https://doi.org/10.21105/joss.02815&gt;.\n  - Epskamp S (2022). _semPlot: Path Diagrams and Visual Analysis of Various SEM\nPackages' Output_. R package version 1.1.6,\n&lt;https://CRAN.R-project.org/package=semPlot&gt;.\n  - Fife D (2024). _flexplot: Graphically Based Data Analysis Using 'flexplot'_.\nR package version 0.20.5.\n  - Genz A, Bretz F (2009). _Computation of Multivariate Normal and t\nProbabilities_, series Lecture Notes in Statistics. Springer-Verlag,\nHeidelberg. ISBN 978-3-642-01688-2.\n  - Grolemund G, Wickham H (2011). \"Dates and Times Made Easy with lubridate.\"\n_Journal of Statistical Software_, *40*(3), 1-25.\n&lt;https://www.jstatsoft.org/v40/i03/&gt;.\n  - Jorgensen TD, Pornprasertmanit S, Schoemann AM, Rosseel Y (2022).\n_\\texttt{semTools}: Useful tools for structural equation modeling_. R package\nversion 0.5-6, &lt;https://CRAN.R-project.org/package=semTools&gt;.\n  - Lüdecke D, Ben-Shachar M, Patil I, Makowski D (2020). \"Extracting, Computing\nand Exploring the Parameters of Statistical Models using R.\" _Journal of Open\nSource Software_, *5*(53), 2445. doi:10.21105/joss.02445\n&lt;https://doi.org/10.21105/joss.02445&gt;.\n  - Lüdecke D, Ben-Shachar M, Patil I, Waggoner P, Makowski D (2021).\n\"performance: An R Package for Assessment, Comparison and Testing of\nStatistical Models.\" _Journal of Open Source Software_, *6*(60), 3139.\ndoi:10.21105/joss.03139 &lt;https://doi.org/10.21105/joss.03139&gt;.\n  - Lüdecke D, Ben-Shachar M, Patil I, Wiernik B, Makowski D (2022). \"easystats:\nFramework for Easy Statistical Modeling, Visualization, and Reporting.\" _CRAN_.\nR package, &lt;https://easystats.github.io/easystats/&gt;.\n  - Lüdecke D, Patil I, Ben-Shachar M, Wiernik B, Waggoner P, Makowski D (2021).\n\"see: An R Package for Visualizing Statistical Models.\" _Journal of Open Source\nSoftware_, *6*(64), 3393. doi:10.21105/joss.03393\n&lt;https://doi.org/10.21105/joss.03393&gt;.\n  - Lüdecke D, Waggoner P, Makowski D (2019). \"insight: A Unified Interface to\nAccess Information from Model Objects in R.\" _Journal of Open Source Software_,\n*4*(38), 1412. doi:10.21105/joss.01412 &lt;https://doi.org/10.21105/joss.01412&gt;.\n  - Makowski D, Ben-Shachar M, Lüdecke D (2019). \"bayestestR: Describing Effects\nand their Uncertainty, Existence and Significance within the Bayesian\nFramework.\" _Journal of Open Source Software_, *4*(40), 1541.\ndoi:10.21105/joss.01541 &lt;https://doi.org/10.21105/joss.01541&gt;,\n&lt;https://joss.theoj.org/papers/10.21105/joss.01541&gt;.\n  - Makowski D, Ben-Shachar M, Patil I, Lüdecke D (2020). \"Estimation of\nModel-Based Predictions, Contrasts and Means.\" _CRAN_.\n&lt;https://github.com/easystats/modelbased&gt;.\n  - Makowski D, Lüdecke D, Patil I, Thériault R, Ben-Shachar M, Wiernik B (2023).\n\"Automated Results Reporting as a Practical Tool to Improve Reproducibility and\nMethodological Best Practices Adoption.\" _CRAN_.\n&lt;https://easystats.github.io/report/&gt;.\n  - Makowski D, Wiernik B, Patil I, Lüdecke D, Ben-Shachar M (2022).\n\"correlation: Methods for Correlation Analysis.\" Version 0.8.3,\n&lt;https://CRAN.R-project.org/package=correlation&gt;. Makowski D, Ben-Shachar M,\nPatil I, Lüdecke D (2020). \"Methods and Algorithms for Correlation Analysis in\nR.\" _Journal of Open Source Software_, *5*(51), 2306. doi:10.21105/joss.02306\n&lt;https://doi.org/10.21105/joss.02306&gt;,\n&lt;https://joss.theoj.org/papers/10.21105/joss.02306&gt;.\n  - Müller K, Wickham H (2023). _tibble: Simple Data Frames_. R package version\n3.2.1, &lt;https://CRAN.R-project.org/package=tibble&gt;.\n  - Patil I, Makowski D, Ben-Shachar M, Wiernik B, Bacher E, Lüdecke D (2022).\n\"datawizard: An R Package for Easy Data Preparation and Statistical\nTransformations.\" _Journal of Open Source Software_, *7*(78), 4684.\ndoi:10.21105/joss.04684 &lt;https://doi.org/10.21105/joss.04684&gt;.\n  - R Core Team (2023). _foreign: Read Data Stored by 'Minitab', 'S', 'SAS',\n'SPSS', 'Stata', 'Systat', 'Weka', 'dBase', ..._. R package version 0.8-85,\n&lt;https://CRAN.R-project.org/package=foreign&gt;.\n  - R Core Team (2023). _R: A Language and Environment for Statistical\nComputing_. R Foundation for Statistical Computing, Vienna, Austria.\n&lt;https://www.R-project.org/&gt;.\n  - Rosseel Y (2012). \"lavaan: An R Package for Structural Equation Modeling.\"\n_Journal of Statistical Software_, *48*(2), 1-36. doi:10.18637/jss.v048.i02\n&lt;https://doi.org/10.18637/jss.v048.i02&gt;.\n  - Tingley D, Yamamoto T, Hirose K, Keele L, Imai K (2014). \"mediation: R\nPackage for Causal Mediation Analysis.\" _Journal of Statistical Software_,\n*59*(5), 1-38. &lt;http://www.jstatsoft.org/v59/i05/&gt;. Imai K, Keele L, Yamamoto T\n(2010). \"Identification, Inference, and Sensitivity Analysis for Causal\nMediation Effects.\" _Statistical Science_, *25*(1), 51-71.\n&lt;http://imai.princeton.edu/research/mediation.html&gt;. Imai K, Keele L, Tingley D\n(2010). \"A General Approach to Causal Mediation Analysis.\" _Psychological\nMethods_, *15*(4), 309-334.\n&lt;http://imai.princeton.edu/research/BaronKenny.html&gt;. Imai K, Keele L, Tingley\nD, Yamamoto T (2011). \"Unpacking the Black Box of Causality: Learning about\nCausal Mechanisms from Experimental and Observational Studies.\" _American\nPolitical Science Review_, *105*(4), 765-789.\n&lt;http://imai.princeton.edu/research/mediationP.html&gt;. Imai K, Yamamoto T\n(2013). \"Identification and Sensitivity Analysis for Multiple Causal\nMechanisms: Revisiting Evidence from Framing Experiments.\" _Political\nAnalysis_, *21*(2), 141-171. &lt;http://imai.princeton.edu/research/medsens.html&gt;.\nImai K, Keele L, Tingley D, Yamamoto T (2010). \"Causal Mediation Analysis Using\nR.\" In Vinod HD (ed.), _Advances in Social Science Research Using R_.\nSpringer-Verlag, New York.\n  - Venables WN, Ripley BD (2002). _Modern Applied Statistics with S_, Fourth\nedition. Springer, New York. ISBN 0-387-95457-0,\n&lt;https://www.stats.ox.ac.uk/pub/MASS4/&gt;.\n  - Wickham H (2016). _ggplot2: Elegant Graphics for Data Analysis_.\nSpringer-Verlag New York. ISBN 978-3-319-24277-4,\n&lt;https://ggplot2.tidyverse.org&gt;.\n  - Wickham H (2023). _forcats: Tools for Working with Categorical Variables\n(Factors)_. R package version 1.0.0,\n&lt;https://CRAN.R-project.org/package=forcats&gt;.\n  - Wickham H (2023). _stringr: Simple, Consistent Wrappers for Common String\nOperations_. R package version 1.5.1,\n&lt;https://CRAN.R-project.org/package=stringr&gt;.\n  - Wickham H, Averick M, Bryan J, Chang W, McGowan LD, François R, Grolemund G,\nHayes A, Henry L, Hester J, Kuhn M, Pedersen TL, Miller E, Bache SM, Müller K,\nOoms J, Robinson D, Seidel DP, Spinu V, Takahashi K, Vaughan D, Wilke C, Woo K,\nYutani H (2019). \"Welcome to the tidyverse.\" _Journal of Open Source Software_,\n*4*(43), 1686. doi:10.21105/joss.01686 &lt;https://doi.org/10.21105/joss.01686&gt;.\n  - Wickham H, François R, Henry L, Müller K, Vaughan D (2023). _dplyr: A Grammar\nof Data Manipulation_. R package version 1.1.3,\n&lt;https://CRAN.R-project.org/package=dplyr&gt;.\n  - Wickham H, Henry L (2023). _purrr: Functional Programming Tools_. R package\nversion 1.0.2, &lt;https://CRAN.R-project.org/package=purrr&gt;.\n  - Wickham H, Hester J, Bryan J (2023). _readr: Read Rectangular Text Data_. R\npackage version 2.1.4, &lt;https://CRAN.R-project.org/package=readr&gt;.\n  - Wickham H, Vaughan D, Girlich M (2023). _tidyr: Tidy Messy Data_. R package\nversion 1.3.0, &lt;https://CRAN.R-project.org/package=tidyr&gt;.\n  - Zeileis A, Köll S, Graham N (2020). \"Various Versatile Variances: An\nObject-Oriented Implementation of Clustered Covariances in R.\" _Journal of\nStatistical Software_, *95*(1), 1-36. doi:10.18637/jss.v095.i01\n&lt;https://doi.org/10.18637/jss.v095.i01&gt;. Zeileis A (2004). \"Econometric\nComputing with HC and HAC Covariance Matrix Estimators.\" _Journal of\nStatistical Software_, *11*(10), 1-17. doi:10.18637/jss.v011.i10\n&lt;https://doi.org/10.18637/jss.v011.i10&gt;. Zeileis A (2006). \"Object-Oriented\nComputation of Sandwich Estimators.\" _Journal of Statistical Software_,\n*16*(9), 1-16. doi:10.18637/jss.v016.i09\n&lt;https://doi.org/10.18637/jss.v016.i09&gt;.\n  - Zhu H (2021). _kableExtra: Construct Complex Table with 'kable' and Pipe\nSyntax_. R package version 1.3.4,\n&lt;https://CRAN.R-project.org/package=kableExtra&gt;."
  }
]