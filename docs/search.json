[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Técnicas e Métodos de Pesquisa no R",
    "section": "",
    "text": "Bem-vindo",
    "crumbs": [
      "Bem-vindo"
    ]
  },
  {
    "objectID": "index.html#sobre-as-aulas",
    "href": "index.html#sobre-as-aulas",
    "title": "Técnicas e Métodos de Pesquisa no R",
    "section": "Sobre as aulas",
    "text": "Sobre as aulas\nAs aulas são gravadas e disponibilizadas gratuitamente por meio de lives no canal Cientística & Podcast Naruhodo do YouTube. Destacando aqui o agradecimento mais do que especial para a Maria Lucia Oliveira De Souza Formigoni, por tornar possível a disciplina.",
    "crumbs": [
      "Introdução"
    ]
  },
  {
    "objectID": "index.html#sobre-o-tutorial",
    "href": "index.html#sobre-o-tutorial",
    "title": "Técnicas e Métodos de Pesquisa no R",
    "section": "Sobre o tutorial",
    "text": "Sobre o tutorial\nEste tutorial tem como objetivo oferecer uma introdução prática à análise estatística de dados no R, utilizando diversos bancos de dados para cada tipo de anáise. O público-alvo abrange estudantes de Estatística Aplicada a Psicobiologia II, pós-graduandos e pesquisadores que buscam aprimorar suas habilidades em análise de dados. É recomendado ter conhecimento básico em estatística, particularmente Estatística Aplicada a Psicobiologia I, e alguma familiaridade com o ambiente R para acompanhar este tutorial. Abordaremos as seguintes análises:\n\nTransformação de dados para análises\nModelos lineares:\n\nModelo linear geral (GLM ) de medidas repetidas\nGeneralized Estimated Equations (GEE)\nModelos mistos e hierárquicos (GMM)\nGeneralized linear models (GzLM)\n\n\n\n\nAnálise de sobrevida\n\nKaplan-Meier\nRegressão de Cox\nCox Tempo dependente\n\n\n\n\nSéries temporais (ARIMA)\nModelagem de Equação Estrutural (SEM)\n\nPath analysis\nConfrmatory Factor Analysis (CFA)\nModeração e mediação\n\n\nAo fim de cada capítulos, nas seções intituladas “Extras”, vamos mostrar dicas sobre pacotes que podem ser úteis para suas análises, mas que não estão disponíveis no SPSS ou no Jamovi.\n\n\n\n\n\n\nImportante!\n\n\n\nO material apresentado aqui é complementar às aulas teóricas e práticas. É imprescindível que você assista às aulas antes de resolver os exercícios no R.",
    "crumbs": [
      "Introdução"
    ]
  },
  {
    "objectID": "index.html#r-e-rstudio",
    "href": "index.html#r-e-rstudio",
    "title": "Técnicas e Métodos de Pesquisa no R",
    "section": "R e Rstudio",
    "text": "R e Rstudio\nEmbora as aulas práticas tenham sido gravadas utilizando o SPSS, o intuito do tutorial é replicar as análises no R, que é gratuito! Portanto você precisa baixar o R e o Rstudio.\nDownload do R\nDownload do Rstudio",
    "crumbs": [
      "Introdução"
    ]
  },
  {
    "objectID": "index.html#aulas-práticas-gravadas",
    "href": "index.html#aulas-práticas-gravadas",
    "title": "Técnicas e Métodos de Pesquisa no R",
    "section": "Aulas práticas gravadas",
    "text": "Aulas práticas gravadas\nOs vídeos das aulas práticas no SPSS foram anexados ao fim de cada capítulo para que você possa ter uma referência do tipo de análise realizada. Em alguns casos você notarão que os resultados não serão idênticos no SPSS e no R. Isso ocorre devido aos diferentes algorítimos de estimação de coeficientes utilizados nos programas. O importante é você sempre reportar como a análise foi feita, quais programas e sempre que possível, disponibilizar o código ou o passo-a-passo utilizado para realizar a análise.",
    "crumbs": [
      "Introdução"
    ]
  },
  {
    "objectID": "index.html#boas-práticas-no-rstudio",
    "href": "index.html#boas-práticas-no-rstudio",
    "title": "Técnicas e Métodos de Pesquisa no R",
    "section": "Boas práticas no Rstudio",
    "text": "Boas práticas no Rstudio\nCriar um projeto separado para cada tipo de análise no R é uma prática recomendada porque mantém o ambiente organizado, evita conflitos entre projetos, facilita a colaboração e torna a reprodução e compartilhamento de trabalho mais eficientes.\n\nCriando o projeto e alocando os arquivos\nPara criar um novo projeto no R, siga estes passos simples:\n\nAbra o RStudio.\nVá até a guia “File” (Arquivo) e selecione “New Project” (Novo Projeto).\nEscolha um diretório para o seu projeto, onde todas as pastas e arquivos relacionados a ele serão armazenados. Isso ajudará na organização.\nClique em “Create Project” (Criar Projeto).\n\nFeito isso você terá um novo projeto configurado. Qualquer arquivo que você deseje usar para o tutorial deve ser colocado dentro da pasta desse projeto. Isso garantirá que todos os caminhos e referências aos arquivos sejam relativos ao diretório do projeto, facilitando a portabilidade e compartilhamento do tutorial.\nCom esses passos, você terá um ambiente de projeto limpo e organizado para trabalhar com seus arquivos e conduzir seu tutorial no R.",
    "crumbs": [
      "Introdução"
    ]
  },
  {
    "objectID": "index.html#instalando-e-carregando-os-pacotes",
    "href": "index.html#instalando-e-carregando-os-pacotes",
    "title": "Técnicas e Métodos de Pesquisa no R",
    "section": "Instalando e carregando os pacotes",
    "text": "Instalando e carregando os pacotes\nNo início de cada capítulo, você encontrará uma lista completa dos pacotes necessários para reproduzir as análises correspondentes.\nPara instalar um pacote, basta executar o comando install.packages(\"nome_do_pacote\") uma única vez.\nPor exemplo: install.packages(\"effects\"). Este comando instalará o pacote “effects”, que contém funções para calcular os estimadores de modelos lineares. É importante colocar o nome do pacote entre aspas (” “)\nApós a instalação do pacote, será necessário carregá-lo sempre que desejar utilizar alguma função associada a ele. Para isso basta executar o comando library(nome_do_pacote). Note que aqui não há a necessidade de colocar o nome do pacote entre aspas.\nExemplo: library(effects).\nPronto! Agora você está familiarizado com o processo de instalação e carregamento dos pacotes que serão utilizados ao longo deste tutorial. Pode-se fazer uma analogia com uma biblioteca: adquirir os livros seria como instalar os pacotes (install.packages), e retirar um livro da prateleira seria como carregar o pacote (library) quando necessário.",
    "crumbs": [
      "Introdução"
    ]
  },
  {
    "objectID": "index.html#referências",
    "href": "index.html#referências",
    "title": "Técnicas e Métodos de Pesquisa no R",
    "section": "Referências",
    "text": "Referências\n\nhttps://r4ds.hadley.nz/",
    "crumbs": [
      "Introdução"
    ]
  },
  {
    "objectID": "survival.html#pressupostos-da-cox-regression",
    "href": "survival.html#pressupostos-da-cox-regression",
    "title": "SURVIVAL",
    "section": "",
    "text": "Proporcionalidade dos Riscos:\n\nO pressuposto fundamental é que os riscos relativos entre dois grupos são constantes ao longo do tempo. Em outras palavras, a razão instantânea de riscos (hazard ratio) entre grupos não muda com o tempo. Este é o pressuposto de proporcionalidade dos riscos.\n\nIndependência Censura:\n\nA censura dos dados deve ser independente da probabilidade de falha. Isso significa que a probabilidade de um evento censurado (ocorrido após o fim do acompanhamento) deve ser a mesma para todos os grupos.\n\nLinearidade no Logaritmo dos Riscos:\n\nA relação entre as variáveis independentes e o logaritmo do risco deve ser linear. Isso é crucial para a interpretação dos coeficientes como log-riscos instantâneos.\n\nAuscência de Colinearidade:\n\nAs variáveis independentes no modelo não devem estar altamente correlacionadas (colinearidade). A colinearidade pode levar a estimativas imprecisas dos coeficientes.\n\nAusência de Efeito de Interferência:\n\nNão deve haver efeito de interferência entre indivíduos, o que significa que o status de um indivíduo não deve influenciar diretamente o tempo de falha de outro indivíduo.\n\nAdequação do Modelo:\n\nO modelo escolhido deve ser apropriado para os dados. Avaliações de adequação, como testes de resíduos, podem ser úteis para verificar a qualidade do ajuste do modelo aos dados.\n\n\n\n\nProporcionalidade dos riscos\nTemos duas formas de avaliar a proporcionalidade dos riscos\n\n1) Análise do gráfico da Kaplan-Meier\nAo analisar o gráfico de Kaplan-Meier para diferentes grupos, é crucial observar se as curvas de sobrevivência são aproximadamente paralelas ou se cruzam entre si. Se as curvas são paralelas, isso sugere proporcionalidade dos riscos, indicando que as diferenças nas taxas de falha entre os grupos são constantes ao longo do tempo. No entanto, se as curvas se cruzam, isso indica uma possível violação da proporcionalidade dos riscos.\nCruzamentos nas curvas podem indicar mudanças na relação de risco entre os grupos ao longo do tempo. Essa mudança pode ser devido a diferentes dinâmicas de risco em períodos distintos do estudo. Se as curvas se cruzarem, a aplicação da Regressão de Cox não deve ser feita para não gerar interpretações erradas!\n\nfit2_km\n\n\n\n\n\n\n\n\nPodemos observar que em nosso exemplo as linhas de sobrevida não cruzam, portanto podemos assumir que os riscos são proporcionais pela análise gráfica.\n\n\n2) Resíduos de Schoenfeld\nA segunda forma para se avaliar a suposição de proporcionalidade dos riscos na Regressão de Cox vamos utilizar o teste de Schoenfeld, que verifica se há uma relação sistemática entre os resíduos de Schoenfeld e o tempo, o que indicaria uma violação dessa suposição.\nA ideia central é que, se os resíduos de Schoenfeld não apresentarem uma relação significativa com o tempo, isso sugere que a proporcionalidade dos riscos é razoável. Logo, a hipótese nula é que não há relação entre os resíduos e o tempo, o que indicaria proporcionalidade dos riscos. O teste estatístico avalia se é razoável rejeitar essa hipótese nula.\n\n\n\n\n\n\nImportante!\n\n\n\nVamos torcer para o valor de p ser MAIOR que 0.05!\n\n\nUtilizando a função cox.zph() do pacote survival temos o seguinte código:\n\ntest &lt;- survival::cox.zph(cox_res)\ntest\n\n       chisq df    p\ntx      0.58  1 0.45\nGLOBAL  0.58  1 0.45\n\n\nOk! Temos riscos proporcionais!\nOutra forma de verificar a proporcionalidade dos riscos é com o gráfico dos resíduos de Schoenfeld.\n\n# Plot the Schoenfeld residuals over time for each covariate\nsurvminer::ggcoxzph(test, point.size = 0.1)[1]\n\n$`1`\n\n\n\n\n\n\n\n\n\nSe os resíduos mostrarem um padrão claro ao longo do tempo, isso pode indicar uma violação da suposição de riscos proporcionais.\nAlgumas dicas para ajudar na interpretação:\n\nSem Padrão (Resíduos Constantes): Se os resíduos aparecerem aleatoriamente espalhados em torno de zero, sem nenhuma tendência ou padrão claro, isso sugere que a suposição de riscos proporcionais é razoável.\nTendência Linear: Uma tendência linear (aumentando ou diminuindo) nos resíduos ao longo do tempo pode sugerir uma violação da suposição de riscos proporcionais. Por exemplo, se os resíduos forem consistentemente positivos ou negativos ao longo do tempo, isso indica um efeito dependente do tempo.\nPadrão Não Linear: Se os resíduos exibirem um padrão não linear ou formatos específicos (por exemplo, formato de U, formato de V), isso pode indicar desvios dos riscos proporcionais.\nParalelismo: Paralelismo significa que a propagação e distribuição dos resíduos são relativamente constantes ao longo do tempo. Se os resíduos aumentarem ou diminuirem ao longo do tempo, isso pode sugerir uma violação da suposição.\n\nRetomaremos a discussão sobre os pressupostos ao desenvolvermos nosso primeiro modelo e também o que fazer quando o pressuposto da proporcionalidade dos riscos é violado.",
    "crumbs": [
      "SURVIVAL"
    ]
  },
  {
    "objectID": "lista_6.html#carregando-pacotes",
    "href": "lista_6.html#carregando-pacotes",
    "title": "6  Lista 6 - Kaplan-Meier e Cox Regression",
    "section": "6.1 Carregando pacotes",
    "text": "6.1 Carregando pacotes\n\nlibrary(tidyverse)\nlibrary(flexplot)\nlibrary(foreign)\nlibrary(dplyr)\nlibrary(tm)\nlibrary(ggplot2)\nlibrary(forcats)\nlibrary(rempsyc)\nlibrary(easystats)\nlibrary(kableExtra)\nlibrary(gtsummary)\n\n#Específicos para survival\nlibrary(survival)\nlibrary(ggsurvfit)\nlibrary(survminer)\nlibrary(broom)\nlibrary(survMisc)\nlibrary(PHInfiniteEstimates)\nlibrary(coin)\nlibrary(condSURV)"
  },
  {
    "objectID": "lista_6.html#limpando-o-ambiente",
    "href": "lista_6.html#limpando-o-ambiente",
    "title": "6  Lista 6 - Kaplan-Meier e Cox Regression",
    "section": "6.2 Limpando o ambiente",
    "text": "6.2 Limpando o ambiente\nQuando executamos diversos comandos no R muitas vezes acabamos deixando o ambiente meio “sujo”. Cheio de variáveis que não estamos mais utilizando, ou pacotes que estão carregados e não serão utilizados no momento.\nEm longas sessões utilizando o R é sempre bom dar uma limpada no ambiente entre um projeto e outro. Para isso podemos executar o código abaixo:\n\n# Limpa o ambiente\nrm(list = ls(all.names = TRUE)) # will clear all objects including hidden objects\ngc() # free up memory and report the memory usage\n\n          used  (Mb) gc trigger  (Mb) max used  (Mb)\nNcells 3170881 169.4    4805995 256.7  4805995 256.7\nVcells 5390829  41.2   10154066  77.5  8395055  64.1\n\noptions(max.print = .Machine$integer.max, scipen = 999, stringsAsFactors = F, dplyr.summarise.inform = F) # avoid truncated output in R console and scientific notation\n\n# Set seed\nset.seed(42)"
  },
  {
    "objectID": "lista_6.html#definindo-um-tema-para-os-gráficos",
    "href": "lista_6.html#definindo-um-tema-para-os-gráficos",
    "title": "6  Lista 6 - Kaplan-Meier e Cox Regression",
    "section": "6.3 Definindo um tema para os gráficos",
    "text": "6.3 Definindo um tema para os gráficos\nPreenhcer todos os parâmetros da função ggplot() é uma tarefa morosa e repetitiva. Podemos criar um tema para todos os nossos gráficos e assim manter a consistência nas figuras e não precisar ficar escrevendo toda hora aquele parâmetro para mudar a espessura da linha do eixo X…\nUma vez definido o tema, podemos apenas chamá-lo dentro da função ggplot para repetir o padrão. Vamos armazenar todas as informações da padronização em uma variável com o código a seguir:\n\nmeu_tema &lt;- theme(plot.title = element_text(size = rel(2)),\n                  panel.grid.major.y = element_line(colour = 'gray'),\n                  panel.grid.minor.y = element_line(colour = 'gray'),\n                  panel.grid.major.x = element_blank(),\n                  panel.grid.minor.x = element_blank(),\n                  plot.background = element_rect(fill = NULL, colour = 'white'),\n                  panel.background = element_rect(fill = 'white'),\n                  # Axis stuff\n                  axis.line = element_line(colour = 'black', linewidth = 1),\n                  axis.text = element_text(colour = \"black\", face = 'bold'),\n                  axis.text.x = element_text(size = rel(1)),\n                  axis.text.y = element_text(size = rel(1)),\n                  axis.title = element_text(size = rel(1.2)),\n                  axis.ticks = element_line(colour = 'black', linewidth = 1.2),\n                  # Legend stuff\n                  legend.position = \"bottom\",\n                  legend.margin = margin(6, 6, 6, 6),\n                  legend.title = element_text(face = 'bold'),\n                  legend.background = element_blank(),\n                  legend.box.background = element_rect(colour = \"black\"))\n\nVamos utilizar o tema em nossos gráficos mais adiante!"
  },
  {
    "objectID": "lista_6.html#sec-carrega_dados",
    "href": "lista_6.html#sec-carrega_dados",
    "title": "6  Lista 6 - Kaplan-Meier e Cox Regression",
    "section": "6.4 Carregando os dados e modificando o tipo de variável",
    "text": "6.4 Carregando os dados e modificando o tipo de variável\nComo de costume, vamos carregar os dados e ver os tipos das variáveis que temos no banco de dados.\n\noriginal = read.spss(\"teste Cox tempo dep Tx.sav\", to.data.frame=TRUE)\nglimpse(original)\n\nRows: 124\nColumns: 5\n$ id    &lt;chr&gt; \"13758618I                     \", \"13750502G                    …\n$ t_seg &lt;dbl&gt; 99, 98, 97, 97, 97, 96, 92, 90, 89, 87, 83, 83, 82, 82, 80, 77, …\n$ t_tx  &lt;dbl&gt; 22, 81, NA, 25, 93, 5, 1, 30, 88, 28, 30, 13, 49, NA, NA, 10, NA…\n$ tx    &lt;fct&gt; sim, sim, não, sim, sim, sim, sim, sim, sim, sim, sim, sim, sim,…\n$ obito &lt;fct&gt; não, não, não, não, não, não, não, não, sim, não, não, não, não,…\n\n\n\n\n\n\n\n\nCuidado!\n\n\n\nA variável do evento (óbito em nosso exemplo) PRECISA ser recodificada para uma variável numérica binária, ou seja, 1 e 0 caso queira realizar a análise de sobrevida.\n\n\nNa seção Section 6.16, exploraremos as distinções entre conduzir as análises com os fatores “sim” e “não” versus os números 1 e 0.\nInicialmente, ajustaremos a variável para aceitar os valores 1 e 0, representando a ocorrência do evento e a censura, respectivamente. Para isso, empregaremos o operador pipe %&gt;% para duplicar a base de dados original e efetuar a modificação no mesmo script. O operador pipe é útil para executar várias operações em uma única sequência de código.\n\ndb &lt;- original %&gt;%\n  mutate(\n    obito = as.integer(obito == \"sim\") # para transformar sim e não em 1 e 0, respectivamente\n  )\n\nglimpse(db)\n\nRows: 124\nColumns: 5\n$ id    &lt;chr&gt; \"13758618I                     \", \"13750502G                    …\n$ t_seg &lt;dbl&gt; 99, 98, 97, 97, 97, 96, 92, 90, 89, 87, 83, 83, 82, 82, 80, 77, …\n$ t_tx  &lt;dbl&gt; 22, 81, NA, 25, 93, 5, 1, 30, 88, 28, 30, 13, 49, NA, NA, 10, NA…\n$ tx    &lt;fct&gt; sim, sim, não, sim, sim, sim, sim, sim, sim, sim, sim, sim, sim,…\n$ obito &lt;int&gt; 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n\n\nPronto, agora temos que óbito assumiu os valores de números 1 e 0.\nOutra análise exploratória importante a fazer nos dados é observar se há dados faltantes (NA) e onde eles estão, caso estejam presentes. Se uma variável tiver muitos NAs, vamos precisar de cautela para inserir a variável na análise.\n\n# Verificando NAs\ndata.frame(\n  nas_t_seg = sum(is.na(db$t_seg)),\n  nas_t_seg = sum(is.na(db$t_tx)),\n  nas_tx = sum(is.na(db$tx)),\n  nas_obito = sum(is.na(db$obito))\n)\n\n  nas_t_seg nas_t_seg.1 nas_tx nas_obito\n1         0          64      0         0\n\n\n\nkable(report(db))\n\n\n\n\n\nVariable\nLevel\nn_Obs\npercentage_Obs\npercentage_Missing\nMean\nSD\nMedian\nMAD\nMin\nMax\nSkewness\nKurtosis\nn_Entries\nn_Missing\n\n\n\n\n3\nid\nNA\n124\n\n0.00\n\n\n\n\n\n\n\n\n124.00\n0\n\n\n5\nt_seg\nNA\n124\n\n0.00\n45.22\n24.08\n42.00\n19.27\n0.00\n99.00\n0.38\n-0.19\n\n\n\n\n6\nt_tx\nNA\n124\n\n51.61\n19.90\n20.05\n\n16.31\n1.00\n93.00\n1.99\n4.70\n\n\n\n\n1\ntx\nsim\n60\n48.39\n\n\n\n\n\n\n\n\n\n\n\n\n\n2\ntx\nnão\n64\n51.61\n\n\n\n\n\n\n\n\n\n\n\n\n\n4\nobito\nNA\n124\n\n0.00\n0.27\n0.45\n0.00\n0.00\n0.00\n1.00\n1.02\n-0.97\n\n\n\n\n\n\n\n\n\nO número de NAs na variável t_tx é alto (51.61%) pelo simples motivo de que pessoas que não fizeram transplante não possuem a marca do tempo que fizeram o transplante. Em todo caso podemos verificar se existem indivíduos que fizeram o transplante mas não possuem a marca do tempo em que fizeram o transplante.\n\ndb %&gt;%\n  filter(tx == \"sim\" & is.na(t_tx))\n\n[1] id    t_seg t_tx  tx    obito\n&lt;0 linhas&gt; (ou row.names de comprimento 0)\n\n\nO código acima filtra os dados de pessoas que fizeram o transplante (tx sim) e que tenham NA na coluna t_tx. Como o resultado volta com zero elementos, podemos concluir que todas as pessoas que fizeram o transplante, possuem a marca do horário em que o transplante foi feito.\nNa tabela acima podemos perceber também que a porcentagem de pessoas que não fizeram o transplante (51.61) é a mesma porcentagem de dados faltantes (missing) da variável t_tx (51.61)\nPor fim, podemos ver quantas pessoas morreram pela causa de morte do desfecho durante o período de observação.\n\nkable(table(db$obito))\n\n\n\n\nVar1\nFreq\n\n\n\n\n0\n90\n\n\n1\n34\n\n\n\n\n\n\n\nLembrando que 1 é o evento, que no nosso exemplo é ocorrência do óbito\nVamos agora às análises."
  },
  {
    "objectID": "lista_6.html#criando-a-estrutura-de-dados",
    "href": "lista_6.html#criando-a-estrutura-de-dados",
    "title": "6  Lista 6 - Kaplan-Meier e Cox Regression",
    "section": "6.5 Criando a estrutura de dados",
    "text": "6.5 Criando a estrutura de dados\nIniciamos especificando para a função Surv() as colunas referentes ao tempo observado e aos eventos de interesse, que, neste caso, são os óbitos.\n\nsurv_obj &lt;- Surv(time = db$t_seg, event = db$obito)"
  },
  {
    "objectID": "lista_6.html#a-tábua-de-vida",
    "href": "lista_6.html#a-tábua-de-vida",
    "title": "6  Lista 6 - Kaplan-Meier e Cox Regression",
    "section": "6.6 a) Tábua de vida",
    "text": "6.6 a) Tábua de vida\n\n\n\n\n\n\nExercício\n\n\n\nFaça duas tábuas de vida em função da variável óbito comparando grupos que fizeram ou não transplante: Ambas com período 0 até 99 meses. A primeira dividida em períodos de 20 meses e a segunda com períodos de 1 mês. Faça um parágrafo descrevendo as diferenças nos gráficos.\n\n\nAgora vamos criar a tabela de vida. Por enquanto, não faremos a separação dos dados por grupos.\n\nfit1 &lt;- survfit(surv_obj ~ 1, data = db)\n\nA função summary() também pode ser utilizada para verificar os resultados dos modelos de sobrevida.\n\nsummary(fit1)\n\nCall: survfit(formula = surv_obj ~ 1, data = db)\n\n time n.risk n.event survival std.err lower 95% CI upper 95% CI\n    0    124       2    0.984  0.0113        0.962        1.000\n    3    121       2    0.968  0.0159        0.937        0.999\n    4    119       2    0.951  0.0194        0.914        0.990\n    6    117       1    0.943  0.0208        0.903        0.985\n    8    116       2    0.927  0.0234        0.882        0.974\n   11    114       1    0.919  0.0246        0.872        0.968\n   13    113       1    0.911  0.0257        0.862        0.962\n   16    110       1    0.902  0.0268        0.851        0.956\n   19    108       1    0.894  0.0278        0.841        0.950\n   24    106       2    0.877  0.0297        0.821        0.937\n   25    104       1    0.869  0.0306        0.811        0.931\n   26    103       1    0.860  0.0314        0.801        0.924\n   27    102       1    0.852  0.0323        0.791        0.917\n   29    101       1    0.843  0.0330        0.781        0.911\n   34     89       3    0.815  0.0358        0.748        0.888\n   36     82       1    0.805  0.0367        0.736        0.880\n   38     70       1    0.794  0.0379        0.723        0.871\n   40     68       1    0.782  0.0391        0.709        0.862\n   41     65       2    0.758  0.0414        0.681        0.844\n   44     59       1    0.745  0.0427        0.666        0.834\n   45     55       1    0.731  0.0440        0.650        0.823\n   46     53       1    0.718  0.0453        0.634        0.812\n   49     47       1    0.702  0.0468        0.616        0.800\n   58     32       1    0.680  0.0502        0.589        0.786\n   66     24       1    0.652  0.0556        0.552        0.771\n   89      9       1    0.580  0.0843        0.436        0.771\n\n\nE a função função tidy_survfit() nos oferece uma tabela bem mais completa.\n\ntidy_survfit(fit1)\n\n# A tibble: 63 × 14\n    time n.risk n.event n.censor cum.event cum.censor estimate std.error\n   &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;      &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;\n 1     0    124       2        1         2          1    0.984    0.0115\n 2     3    121       2        0         4          1    0.968    0.0165\n 3     4    119       2        0         6          1    0.951    0.0204\n 4     6    117       1        0         7          1    0.943    0.0221\n 5     8    116       2        0         9          1    0.927    0.0253\n 6    11    114       1        0        10          1    0.919    0.0268\n 7    13    113       1        0        11          1    0.911    0.0282\n 8    14    112       0        1        11          2    0.911    0.0282\n 9    15    111       0        1        11          3    0.911    0.0282\n10    16    110       1        0        12          3    0.902    0.0297\n# ℹ 53 more rows\n# ℹ 6 more variables: conf.high &lt;dbl&gt;, conf.low &lt;dbl&gt;, estimate_type &lt;chr&gt;,\n#   estimate_type_label &lt;chr&gt;, monotonicity_type &lt;chr&gt;, conf.level &lt;dbl&gt;"
  },
  {
    "objectID": "lista_6.html#b-kaplan-meier",
    "href": "lista_6.html#b-kaplan-meier",
    "title": "6  Lista 6 - Kaplan-Meier e Cox Regression",
    "section": "6.7 b) Kaplan-Meier",
    "text": "6.7 b) Kaplan-Meier\n\n\n\n\n\n\nExercício\n\n\n\nFaça uma curva de Kaplan-meyer comparando os grupos que fizeram vs não fizeram transplante em relação ao óbito. Analise o gráfico e as saídas do teste.\n\n\nPara produzir um gráfico Kaplan-Meier simples podemos utilizar a função plot().\n\nplot(fit1)\n\n\n\n\nMeio pobrezinho e sem cor ne?\nPodemos melhorar utilizando a função ggsurvfit(), do pacote com o mesmo nome.\n\nfit1_km = ggsurvfit(fit1, linewidth = 1) +\n  labs(x = 'Dias', y = 'Overall survival') +\n  add_confidence_interval() +\n  add_risktable() +\n  scale_ggsurvfit() \n\nfit1_km\n\n\n\n\nAté aqui estamos vendo o gráfico da sobrevida sem separar por grupos. A seguir vamos comparar entre os grupos que receberam ou não o transplante de rins."
  },
  {
    "objectID": "lista_6.html#separando-por-transplante-e-nos-tempos-0-20-40-60-80",
    "href": "lista_6.html#separando-por-transplante-e-nos-tempos-0-20-40-60-80",
    "title": "6  Lista 6 - Kaplan-Meier e Cox Regression",
    "section": "6.8 Separando por transplante e nos tempos 0, 20, 40, 60, 80",
    "text": "6.8 Separando por transplante e nos tempos 0, 20, 40, 60, 80\nQueremos comparar a sobrevida entre quem fez e não fez o transplante. Para isso podemos especificar no modelo que o transplante (tx) será uma das variáveis independentes.\n\nfit2 = survfit(surv_obj ~ tx, # basta colocar tx como uma variável preditora no modelo\n               data = db) \n\n\nsummary(fit2)\n\nCall: survfit(formula = surv_obj ~ tx, data = db)\n\n                tx=sim \n time n.risk n.event survival std.err lower 95% CI upper 95% CI\n    3     59       1    0.983  0.0168        0.951        1.000\n    4     58       1    0.966  0.0236        0.921        1.000\n   24     57       1    0.949  0.0286        0.895        1.000\n   26     56       1    0.932  0.0327        0.870        0.999\n   29     55       1    0.915  0.0363        0.847        0.989\n   38     44       1    0.894  0.0410        0.818        0.978\n   41     41       1    0.873  0.0454        0.788        0.966\n   45     37       1    0.849  0.0499        0.757        0.953\n   49     32       1    0.823  0.0550        0.722        0.938\n   66     19       1    0.779  0.0670        0.658        0.922\n   89      8       1    0.682  0.1083        0.499        0.931\n\n                tx=não \n time n.risk n.event survival std.err lower 95% CI upper 95% CI\n    0     64       2    0.969  0.0217        0.927        1.000\n    3     62       1    0.953  0.0264        0.903        1.000\n    4     61       1    0.938  0.0303        0.880        0.999\n    6     60       1    0.922  0.0335        0.858        0.990\n    8     59       2    0.891  0.0390        0.817        0.970\n   11     57       1    0.875  0.0413        0.798        0.960\n   13     56       1    0.859  0.0435        0.778        0.949\n   16     53       1    0.843  0.0456        0.758        0.937\n   19     51       1    0.827  0.0476        0.738        0.925\n   24     49       1    0.810  0.0495        0.718        0.913\n   25     48       1    0.793  0.0513        0.699        0.900\n   27     47       1    0.776  0.0529        0.679        0.887\n   34     38       3    0.715  0.0594        0.607        0.841\n   36     35       1    0.694  0.0611        0.584        0.825\n   40     26       1    0.668  0.0643        0.553        0.806\n   41     24       1    0.640  0.0674        0.520        0.786\n   44     21       1    0.609  0.0707        0.485        0.765\n   46     18       1    0.575  0.0745        0.447        0.742\n   58     11       1    0.523  0.0841        0.382        0.717\n\n\nA função summary() aceita um parâmetro com intervalos específicos para aparecer nos resultados. Vamos utilizar a função seq() para criar uma sequência de números que vai do 0 ao 100 com intervalos de 20 em 20.\n\n# Cria o intervalo de tempo\n\ntempos_específicos &lt;- seq(0, 100, by = 20) # sequencia de 0 a 100 em intervalos de 20.\n\nAplicando o intervalo na função temos o seguinte script:\n\nsummary(fit2, times = tempos_específicos)\n\nCall: survfit(formula = surv_obj ~ tx, data = db)\n\n                tx=sim \n time n.risk n.event survival std.err lower 95% CI upper 95% CI\n    0     60       0    1.000  0.0000        1.000        1.000\n   20     57       2    0.966  0.0236        0.921        1.000\n   40     42       4    0.894  0.0410        0.818        0.978\n   60     21       3    0.823  0.0550        0.722        0.938\n   80     12       1    0.779  0.0670        0.658        0.922\n\n                tx=não \n time n.risk n.event survival std.err lower 95% CI upper 95% CI\n    0     64       2    0.969  0.0217        0.927        1.000\n   20     50       9    0.827  0.0476        0.738        0.925\n   40     26       8    0.668  0.0643        0.553        0.806\n   60      7       4    0.523  0.0841        0.382        0.717\n   80      3       0    0.523  0.0841        0.382        0.717\n\n\nPodemos nos perguntar também qual é a probabilidade de sobreviver após um certo tempo. Para obter a resposta basta ajustar o parâmetro times da função summary() para o tempo desejado.\n\nsummary(fit2, times = 75)\n\nCall: survfit(formula = surv_obj ~ tx, data = db)\n\n                tx=sim \n        time       n.risk      n.event     survival      std.err lower 95% CI \n      75.000       14.000       10.000        0.779        0.067        0.658 \nupper 95% CI \n       0.922 \n\n                tx=não \n        time       n.risk      n.event     survival      std.err lower 95% CI \n     75.0000       4.0000      23.0000       0.5232       0.0841       0.3818 \nupper 95% CI \n      0.7169 \n\n\nNa análise do tempo de sobrevivência neste modelo, observamos o seguinte:\nPara o grupo que realizou o transplante (tx=sim):\n\nAos 75 meses, havia 14 indivíduos em risco.\n10 eventos ocorreram até esse momento.\nA taxa de sobrevivência foi de 0.779, com um desvio padrão de 0.067.\nO intervalo de confiança de 95% para a taxa de sobrevivência variou de 0.658 a 0.922.\n\nPara o grupo que não realizou o transplante (tx=não):\n\nAos 75 meses, havia 4 indivíduos em risco.\n23 eventos ocorreram até esse momento.\nA taxa de sobrevivência foi de 0.5232, com um desvio padrão de 0.0841.\nO intervalo de confiança de 95% para a taxa de sobrevivência variou de 0.3818 a 0.7169.\n\nPodemos ainda calcular quantas vezes a probabilidade de sobrevivência é maior no grupo que realizou o transplante em comparação com o grupo que não o fez.\n\nsummary(fit2, times = 75)$surv[1] / summary(fit2, times = 75)$surv[2]\n\n[1] 1.489431\n\n\nO resultado revela que a probabilidade de sobrevivência no grupo que fez o transplante é aproximadamente 1.5 vezes maior do que no grupo que não o realizou.\n\nKaplan-Meir do novo modelo\nVamos salvar o plot padrão do segundo modelo para adicionar mais alguns parâmetros e incrementar a visualização dos resultados.\n\nfit2_km = ggsurvfit(fit2, linewidth = 1) +\n  labs(x = 'Tempo (meses)', y = '% Probabilidade de sobrevivência') +\n  add_confidence_interval() +\n  #add_risktable() + \n  scale_ggsurvfit() \n\nfit2_km\n\n\n\n\nCom o plot salvo, podemos adicionar mais elementos aos poucos, como as linhas tracejadas para enfatizar diferenças.\n\nfit2_km +\n  geom_vline(xintercept = 75, \n             linetype = 'dashed', \n             colour = 'red', \n             size = 1) + # adiciona a linha vermelha vertical \n  geom_hline(yintercept = summary(fit2, times = 75)$surv, \n             linetype = 'dashed', \n             colour = 'red', size = 1) # adiciona as linhas vermelhas horizontais.\n\n\n\n\n\n\nPorcentagem fixa, tempos diferentes\nA função ggsurvfit oferece vários parâmetros interessantes. Um deles, bastante útil, permite traçar uma linha para comparar o tempo em que a probabilidade de sobrevivência X ocorre entre grupos diferentes.\nEm quanto tempo será que a probabilidade de sobrevida chega a 75% nos dois grupos? Vamos utilizar o parâmetro add_quantile() para ter uma estimativa gráfica.\n\nfit2 %&gt;% \n  ggsurvfit(linewidth = 1) +\n  labs(x = 'Tempo (meses)', y = '% Probabilidade de sobrevivência') +\n  add_confidence_interval() +\n  #  add_risktable() +\n  add_quantile(y_value = 0.75, color = \"gray50\", linewidth = 0.75) +\n  scale_ggsurvfit()\n\n\n\n\nAo examinarmos a imagem, observamos que o grupo que não passou pelo transplante atinge uma probabilidade de sobrevida de 75% em aproximadamente 35 meses. Por outro lado, no grupo que se submeteu ao transplante, essa mesma probabilidade só ocorre por volta do 90º mês, sendo ainda maior antes desse período.\n\n\nEscolhendo um intervalo de tempo\nCaso você queira apresentar apenas um período específico de tempo em sua análise, podemos fazer isso utilizando o parâmetro coord_cartesian().\n\nggsurvfit(fit2, linewidth = 1) +\n  labs(x = 'Tempo (meses)', y = '% Probabilidade de sobrevivência') +\n  add_confidence_interval() +\n  # add_risktable() +\n  scale_ggsurvfit() + \n  coord_cartesian(xlim = c(0, 60)) # coloque os números que\n\n\n\n\nPersonalize os limites do intervalo de tempo em sua análise ajustando os valores “0” e “60”, de acordo com suas necessidades específicas."
  },
  {
    "objectID": "lista_6.html#comparando-as-curvas",
    "href": "lista_6.html#comparando-as-curvas",
    "title": "6  Lista 6 - Kaplan-Meier e Cox Regression",
    "section": "6.9 Comparando as curvas",
    "text": "6.9 Comparando as curvas\n\nLog-rank: utilizar para comparar o primeiro terço do gráfico\nGehan: utilizar para comparar o meio do gráfico\nTarone: utilizar para comparar o final do gráfico\nPeto-Peto: parecido com o Log-rank, utilizar para comparar o primeiro terço do gráfico\n\nPacote mais indicado para utilizar é o coin.\n\nTipos de testes possíveis\n“logrank”, “Gehan-Breslow”, “Tarone-Ware”, “Peto-Peto”, “Prentice”, “Prentice-Marek”, “Andersen-Borgan-Gill-Keiding”, “Fleming-Harrington”, “Gaugler-Kim-Liao”, “Self”\n\nLog-rank\n\ncoin::logrank_test(surv_obj ~ tx, data = db, type = \"logrank\" ) # padrão é o log-rank\n\n\n    Asymptotic Two-Sample Logrank Test\n\ndata:  surv_obj by tx (sim, não)\nZ = 2.9275, p-value = 0.003417\nalternative hypothesis: true theta is not equal to 1\n\n\n\n\nGehan-Breslow\n\ncoin::logrank_test(surv_obj ~ tx ,data = db, type = \"Gehan-Breslow\")\n\n\n    Asymptotic Two-Sample Gehan-Breslow Test\n\ndata:  surv_obj by tx (sim, não)\nZ = 3.0103, p-value = 0.00261\nalternative hypothesis: true theta is not equal to 1\n\n\n\n\nTarone-Ware\n\ncoin::logrank_test(surv_obj ~ tx ,data = db, type = \"Tarone-Ware\")\n\n\n    Asymptotic Two-Sample Tarone-Ware Test\n\ndata:  surv_obj by tx (sim, não)\nZ = 3.0338, p-value = 0.002415\nalternative hypothesis: true theta is not equal to 1\n\n\n\n\nPeto-Peto\n\ncoin::logrank_test(surv_obj ~ tx ,data = db, type = \"Peto-Peto\")\n\n\n    Asymptotic Two-Sample Peto-Peto Test\n\ndata:  surv_obj by tx (sim, não)\nZ = 2.9857, p-value = 0.002829\nalternative hypothesis: true theta is not equal to 1\n\n\nEm todos os testes a hipótese alternativa sugere que o verdadeiro parâmetro theta não é igual a 1, indicando assim que há diferenças significativas nas curvas de sobrevida entre os dois grupos analisados. Em termos práticos, isso sugere que a probabilidade de sobrevivência varia de maneira estatisticamente significativa entre os grupos que fizeram ou não o transplante."
  },
  {
    "objectID": "lista_6.html#c-cox-regression",
    "href": "lista_6.html#c-cox-regression",
    "title": "6  Lista 6 - Kaplan-Meier e Cox Regression",
    "section": "6.10 c) Cox Regression",
    "text": "6.10 c) Cox Regression\n\n\n\n\n\n\nExercício\n\n\n\nReproduza a análise do item b) com uma Cox Regression. Descreva os resultados\n\n\nCompare com base no resultado da Cox, qual seria a diferença na sobrevida (HR) entre uma pessoa que fez e outra que não fez transplante com 50 meses de observação\nA Regressão de Cox é uma técnica estatística utilizada para analisar a relação entre variáveis explicativas e o tempo até um evento ocorrer, como a morte. Ao contrário de modelos de regressão linear, a Regressão de Cox lida com dados de sobrevida, levando em consideração o tempo até o evento ou a censura. O código apresentado realiza uma Regressão de Cox com a função coxph().\n\n# Cox regression ======================================================\n# Fit the model\ncox_res &lt;- coxph(Surv(time = db$t_seg, event = db$obito) ~ tx, data = db)\n\nO código acima ajusta o modelo de Regressão de Cox. A variável dependente é definida como o tempo (t_seg) até o evento (obito) ocorrer, e a variável independente é tx.\nNotem que dentro da função coxph(), repetimos o código para gerar a tabela de vida.Durante a criação da estrutura dos dados, armazenamos a tabela de vida em uma variável chamada surv_obj. Podemos reutilizá-la na Regressão de Cox, evitando a necessidade de reescrever o código.\nVamos fazer isso!\n\ncox_res_2 = coxph(surv_obj ~ tx, data = db)\n\nBem mais limpo, não? E como vamos escrever mais alguns modelos, é uma boa prática salvar o padrão que se repete em uma variável.\n\nResultados dos modelos\nSabe qual função vamos utilizar para verificar o resultado? Sim, a summary().\nPrimeiro vamos verificar se as duas formas que escrevemos os modelos geram os mesmos resultados.\n\nsummary(cox_res)\n\nCall:\ncoxph(formula = Surv(time = db$t_seg, event = db$obito) ~ tx, \n    data = db)\n\n  n= 124, number of events= 34 \n\n        coef exp(coef) se(coef)     z Pr(&gt;|z|)   \ntxnão 1.0787    2.9409   0.3753 2.874  0.00405 **\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n      exp(coef) exp(-coef) lower .95 upper .95\ntxnão     2.941       0.34     1.409     6.136\n\nConcordance= 0.638  (se = 0.04 )\nLikelihood ratio test= 8.99  on 1 df,   p=0.003\nWald test            = 8.26  on 1 df,   p=0.004\nScore (logrank) test = 9.01  on 1 df,   p=0.003\n\n\n\n\nsummary(cox_res_2)\n\nCall:\ncoxph(formula = surv_obj ~ tx, data = db)\n\n  n= 124, number of events= 34 \n\n        coef exp(coef) se(coef)     z Pr(&gt;|z|)   \ntxnão 1.0787    2.9409   0.3753 2.874  0.00405 **\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n      exp(coef) exp(-coef) lower .95 upper .95\ntxnão     2.941       0.34     1.409     6.136\n\nConcordance= 0.638  (se = 0.04 )\nLikelihood ratio test= 8.99  on 1 df,   p=0.003\nWald test            = 8.26  on 1 df,   p=0.004\nScore (logrank) test = 9.01  on 1 df,   p=0.003\n\n\n\nBoa! Os resultados são idênticos, então podemos manter o padrão de escrevr o modelo utilizando a tábua de vida salva em uma variável.\nEmbora o resultado da função summary() para modelos de Regressão de Cox possa não ser visualmente atraente, ele oferece informações detalhadas sobre como o modelo se ajusta aos dados. Vamos analisar cada componente separadamente:\n\nSumário do Modelo:\n\nCall: Indica a chamada da função utilizada para ajustar o modelo.\nn= 124, number of events= 34: Informa o número total de observações (n) e o número de eventos ocorridos (number of events).\n\nCoeficientes:\n\ncoef: O coeficiente estimado para a variável tx.\nexp(coef): A interpretação deste valor é que, para pessoas do grupo que não fizeram o transplante (txnão), o risco de o evento (morte) ocorrer aumenta em 2.941 vezes.\nse(coef): O erro padrão do coeficiente.\n\nTeste de Hipótese para Coeficientes:\n\nz: O valor z do teste de Wald, indicando quão longe o coeficiente está da média em termos de erros padrão.\nPr(&gt;|z|): O p-valor associado ao teste de Wald. No exemplo, 0.00405 sugere que o efeito da variável tx é estatisticamente significativo.\nSignificância codes: ** indica significância a 0.01.\n\nIntervalo de Confiança para Exp(Coef):\n\nexp(coef) exp(-coef) lower .95 upper .95: O intervalo de confiança de 95% para o efeito da variável tx.\n\nMedidas de Desempenho do Modelo:\n\nConcordance= 0.638: A concordância é uma medida de quão bem o modelo prevê a ordem de eventos.\nLikelihood ratio test= 8.99, p=0.003: O teste de razão de verossimilhança avalia se o modelo é significativamente melhor do que um modelo nulo. O p-valor sugere que o modelo é estatisticamente significativo.\nWald test= 8.26, p=0.004: O teste de Wald também avalia a significância global do modelo.\nScore (logrank) test= 9.01, p=0.003: O teste de log-rank compara as curvas de sobrevivência entre os grupos.\n\n\nE claro que temos formas melhores de visualizar e mostrar os dados mais importantes. Vamos utilizar a função tbl_regression() do pacote gtsummary, que pega um objeto de modelo de regressão e retorna uma tabela formatada pronta para publicação.\n\ntbl_regression(cox_res, exponentiate = TRUE)\n\n\n\n\n\n  \n    \n    \n      Characteristic\n      HR1\n      95% CI1\n      p-value\n    \n  \n  \n    tx\n\n\n\n        sim\n—\n—\n\n        não\n2.94\n1.41, 6.14\n0.004\n  \n  \n  \n    \n      1 HR = Hazard Ratio, CI = Confidence Interval\n    \n  \n\n\n\n\nPra fazer isso aí no word demoraria uns 30 minutos hein? E ficaria feia ainda. Com uma linha de código fizemos miséria!\n\n\nPlots do modelo e do resultado\nTendo ajustado um modelo de Cox aos dados, é possível visualizar a proporção de sobrevivência prevista em qualquer momento para um determinado grupo de risco.\nNeste caso, construímos um novo banco de dados com duas linhas, uma para cada valor de tx.\n\ntx_df &lt;- with(db,\n              data.frame(tx = c(\"sim\", \"não\")\n              )\n)\nkable(tx_df)\n\n\n\n\ntx\n\n\n\n\nsim\n\n\nnão\n\n\n\n\n\n\n\nAgora podemos utilizar o nosso modelo para prever os valores de sobrevida e criar um gráfico da Regressão de Cox.\n\ncox_graph &lt;- survfit(cox_res, newdata = tx_df)\n\nggsurvplot(cox_graph, conf.int = TRUE, legend.labs=c(\"tx=sim\", \"tx=não\"),\n           ggtheme = theme_minimal(),\n           data = db)\n\n\n\n\n\n\n\n\n\n\nCuidado!\n\n\n\nO gráfico do modelo da Regressão de Cox é diferente do gráfico da Kaplan-Meir! O cálculo da regressão distorce os valores e encaixa o modelo aos dados. Observe a diferença!\n\n\n\n# Gráfico da Kaplan-Meir\nfit2_km\n\n\n\n\nNão podemos deixar e fora o gráfico do modelo. Com pouca tinta (e pouco código) vamos mostrar tudo o que a função summary() nos proporcionou. Para isso vamos utilizar a função ggforest() do pacote survminer.\n\nggforest(cox_res, data = db)\n\n\n\n\nSe não escorreu uma lágrima aí do outro lado da tela agora, eu desisto. E olha que utilizamos apenas uma variável independente no modelo!"
  },
  {
    "objectID": "lista_6.html#hazard-ratio-e-risco-relativo-confirmar-o-conteúdo",
    "href": "lista_6.html#hazard-ratio-e-risco-relativo-confirmar-o-conteúdo",
    "title": "6  Lista 6 - Kaplan-Meier e Cox Regression",
    "section": "6.11 Hazard ratio e risco relativo (CONFIRMAR O CONTEÚDO)",
    "text": "6.11 Hazard ratio e risco relativo (CONFIRMAR O CONTEÚDO)\nVocês repararam que tanto na tabela quanto no gráfico com os resultados no modelo aparece o resultado como “Hazard Ratio”… pois bem, isso está errado!\n\n\n\n\n\n\nAtenção!\n\n\n\nO risco relativo compara a probabilidade cumulativa de um evento ocorrer entre dois grupos ao longo de um período específico, enquanto o hazard ratio avalia a razão instantânea de riscos proporcionais entre os grupos, considerando a variação no risco ao longo do tempo. Enquanto o risco relativo se concentra em eventos cumulativos, o hazard ratio destaca as diferenças nas taxas instantâneas de falha, sendo especialmente útil em análises de sobrevida e estudos onde a dinâmica temporal do risco é crucial."
  },
  {
    "objectID": "lista_6.html#d-hazard-ratio",
    "href": "lista_6.html#d-hazard-ratio",
    "title": "6  Lista 6 - Kaplan-Meier e Cox Regression",
    "section": "6.12 d) Hazard Ratio",
    "text": "6.12 d) Hazard Ratio\n\n\n\n\n\n\nExercício\n\n\n\nCompare com base no resultado da Cox, qual seria a diferença na sobrevida (HR) entre uma pessoa que fez e outra que não fez transplante com 50 meses de observação\n\n\nPara de fato calcular o Hazard Ratio precisamos utilizar nosso modelo para prever a sobrevida em um tempo específico de nosso interesse.\nVamos começar salvando nosso modelo em uma variável\n\n# Ajuste do modelo de regressão de Cox\ncox_res &lt;- coxph(Surv(time = t_seg, event = obito) ~ tx, data = db)\n\nAgora vamos criar um conjunto de dados com informações simuladas sobre tempo de seguimento, ocorrência de evento (óbito), e uma variável indicadora de tratamento. Como queremos comparar o tempo de sobrevida entre quem fez ou não o transplante, a única variável que terá valores diferentes será a tx.\n\npred_dat &lt;- data.frame(t_seg = c(41,41),\n                       obito = c(0,0), \n                       tx = c(\"sim\",\"não\")\n                       )\nkable(pred_dat)\n\n\n\n\nt_seg\nobito\ntx\n\n\n\n\n41\n0\nsim\n\n\n41\n0\nnão\n\n\n\n\n\n\n\nA seguir vamos utiliza a função predict() para fazer previsões com base em nosso modelo previamente ajustado (cox_res).\n\npreds &lt;- predict(cox_res, newdata = pred_dat, type = \"survival\", se.fit = TRUE)\n\nSalvamos o resultado da função em uma variável para poder adicionar os resultados das predições em nosso dataframe criado anteriormente (pred_dat). Queremos os resultados da média e do Intervalo de Confiança. Para isso executamos o código a seguir:\n\npred_dat$prob &lt;- preds$fit\npred_dat$lcl &lt;- preds$fit - 1.96*preds$se.fit\npred_dat$ucl &lt;- preds$fit + 1.96*preds$se.fit\nkable(pred_dat)\n\n\n\n\nt_seg\nobito\ntx\nprob\nlcl\nucl\n\n\n\n\n41\n0\nsim\n0.8630231\n0.7805057\n0.9455404\n\n\n41\n0\nnão\n0.6484075\n0.5224067\n0.7744083\n\n\n\n\n\n\n\nPor fim, podemos finalmente verificar o Hazard Ratio no tempo de 41 meses, dividindo a probabilidade de sobrevida do grupo que fez o transplante pela probabilidade de sobrevida do grupo que não fez o transplante.\n\nHR_41 = pred_dat$prob[1] / pred_dat$prob[2] # Diferença na sobrevida (HR) no tempo 41 meses \nHR_41\n\n[1] 1.330989\n\n\n\nTemos que no tempo de 41 meses a probabilidade de sobrevida de quem não fez o transplante é 1.33 menor do que quem fez o transplante.\nCaso tenha interesse em mais pontos, podemos criar vários tempos de interesse em um único dataframe e repetir o código.\n\nmulti_pred_dat &lt;- data.frame(t_seg = c(41,41, 50, 50, 80, 80),\n                       obito = c(0,0,0,0,0,0), \n                       tx = c(\"sim\",\"não\",\"sim\",\"não\",\"sim\",\"não\")\n                       )\n\npreds &lt;- predict(cox_res, newdata = multi_pred_dat, type = \"survival\", se.fit = TRUE)\n\nmulti_pred_dat$prob &lt;- preds$fit\nmulti_pred_dat$lcl &lt;- preds$fit - 1.96*preds$se.fit\nmulti_pred_dat$ucl &lt;- preds$fit + 1.96*preds$se.fit\n\nHR_41 = multi_pred_dat$prob[1] / multi_pred_dat$prob[2] # 41 \nHR_50 = multi_pred_dat$prob[3] / multi_pred_dat$prob[4] # 50 \nHR_80 = multi_pred_dat$prob[5] / multi_pred_dat$prob[6] # 80 \n\ntabela_HR = data.frame(Tempo = c(41, 50, 80),\n                       HR_Não = c(HR_41, HR_50, HR_80))\nkable(tabela_HR)\n\n\n\n\nTempo\nHR_Não\n\n\n\n\n41\n1.330989\n\n\n50\n1.454309\n\n\n80\n1.597592"
  },
  {
    "objectID": "lista_6.html#verificando-os-pressupostos-da-cox-regression",
    "href": "lista_6.html#verificando-os-pressupostos-da-cox-regression",
    "title": "6  Lista 6 - Kaplan-Meier e Cox Regression",
    "section": "6.13 Verificando os pressupostos da Cox regression",
    "text": "6.13 Verificando os pressupostos da Cox regression\nA Regressão de Cox é uma técnica robusta, mas, como qualquer método estatístico, possui alguns pressupostos importantes. Os principais pressupostos da Regressão de Cox são:\n\nProporcionalidade dos Riscos:\n\nO pressuposto fundamental é que os riscos relativos entre dois grupos são constantes ao longo do tempo. Em outras palavras, a razão instantânea de riscos (hazard ratio) entre grupos não muda com o tempo. Este é o pressuposto de proporcionalidade dos riscos.\n\nIndependência Censura:\n\nA censura dos dados deve ser independente da probabilidade de falha. Isso significa que a probabilidade de um evento censurado (ocorrido após o fim do acompanhamento) deve ser a mesma para todos os grupos.\n\nLinearidade no Logaritmo dos Riscos:\n\nA relação entre as variáveis independentes e o logaritmo do risco deve ser linear. Isso é crucial para a interpretação dos coeficientes como log-riscos instantâneos.\n\nAuscência de Colinearidade:\n\nAs variáveis independentes no modelo não devem estar altamente correlacionadas (colinearidade). A colinearidade pode levar a estimativas imprecisas dos coeficientes.\n\nAusência de Efeito de Interferência:\n\nNão deve haver efeito de interferência entre indivíduos, o que significa que o status de um indivíduo não deve influenciar diretamente o tempo de falha de outro indivíduo.\n\nAdequação do Modelo:\n\nO modelo escolhido deve ser apropriado para os dados. Avaliações de adequação, como testes de resíduos, podem ser úteis para verificar a qualidade do ajuste do modelo aos dados.\n\n\nOs pressupostos de 2 a 6 são inerentes ao desenho do experimento e do acompanhamento durante as observações. O único que vamos abordar aqui no tutorial é o de proporcionalidade dos riscos.\n\nProporcionalidade dos riscos\nTemos duas formas de avaliar a proporcionalidade dos riscos\n\n1) Análise do gráfico da Kaplan-Meier\nAo analisar o gráfico de Kaplan-Meier para diferentes grupos, é crucial observar se as curvas de sobrevivência são aproximadamente paralelas ou se cruzam entre si. Se as curvas são paralelas, isso sugere proporcionalidade dos riscos, indicando que as diferenças nas taxas de falha entre os grupos são constantes ao longo do tempo. No entanto, se as curvas se cruzam, isso indica uma possível violação da proporcionalidade dos riscos.\nCruzamentos nas curvas podem indicar mudanças na relação de risco entre os grupos ao longo do tempo. Essa mudança pode ser devido a diferentes dinâmicas de risco em períodos distintos do estudo. Se as curvas se cruzarem, a aplicação da Regressão de Cox não deve ser feita para não gerar interpretações erradas!\n\nfit2_km\n\n\n\n\nPodemos observar que em nosso exemplo as linhas de sobrevida não cruzam, portanto podemos assumir que os riscos são proporcionais pela análise gráfica.\n\n\n2) Resíduos de Schoenfeld\nA segunda forma para se avaliar a suposição de proporcionalidade dos riscos na Regressão de Cox vamos utilizar o teste de Schoenfeld, que verifica se há uma relação sistemática entre os resíduos de Schoenfeld e o tempo, o que indicaria uma violação dessa suposição.\nA ideia central é que, se os resíduos de Schoenfeld não apresentarem uma relação significativa com o tempo, isso sugere que a proporcionalidade dos riscos é razoável. Logo, a hipótese nula é que não há relação entre os resíduos e o tempo, o que indicaria proporcionalidade dos riscos. O teste estatístico avalia se é razoável rejeitar essa hipótese nula.\n\n\n\n\n\n\nImportante!\n\n\n\nVamos torcer para o valor de p ser MAIOR que 0.05!\n\n\nUtilizando a função cox.zph() do pacote survival temos o seguinte código:\n\ntest &lt;- survival::cox.zph(cox_res)\ntest\n\n       chisq df    p\ntx      0.58  1 0.45\nGLOBAL  0.58  1 0.45\n\n\nOk! Temos riscos proporcionais!\nOutra forma de verificar a proporcionalidade dos riscos é com o gráfico dos resíduos de Schoenfeld.\n\n# Plot the Schoenfeld residuals over time for each covariate\nsurvminer::ggcoxzph(test, point.size = 0.1)[1]\n\n$`1`\n\n\n\n\n\nSe os resíduos mostrarem um padrão claro ao longo do tempo, isso pode indicar uma violação da suposição de riscos proporcionais.\nAlgumas dicas para ajudar na interpretação:\n\nSem Padrão (Resíduos Constantes): Se os resíduos aparecerem aleatoriamente espalhados em torno de zero, sem nenhuma tendência ou padrão claro, isso sugere que a suposição de riscos proporcionais é razoável.\nTendência Linear: Uma tendência linear (aumentando ou diminuindo) nos resíduos ao longo do tempo pode sugerir uma violação da suposição de riscos proporcionais. Por exemplo, se os resíduos forem consistentemente positivos ou negativos ao longo do tempo, isso indica um efeito dependente do tempo.\nPadrão Não Linear: Se os resíduos exibirem um padrão não linear ou formatos específicos (por exemplo, formato de U, formato de V), isso pode indicar desvios dos riscos proporcionais.\nParalelismo: Paralelismo significa que a propagação e distribuição dos resíduos são relativamente constantes ao longo do tempo. Se os resíduos aumentarem ou diminuirem ao longo do tempo, isso pode sugerir uma violação da suposição."
  },
  {
    "objectID": "lista_6.html#conlcusões",
    "href": "lista_6.html#conlcusões",
    "title": "6  Lista 6 - Kaplan-Meier e Cox Regression",
    "section": "6.14 Conlcusões",
    "text": "6.14 Conlcusões\nMuito bacana a análise de sobrevida e a Regressão de Cox! Na seção Extras! vamos ver mais algumas formas de plotar os gráficos e avaliar a proporcionalidade dos riscos caso a Variável Independente seja contínua!\nPróximo capitulo: Cox tempo-dependente!"
  },
  {
    "objectID": "lista_6.html#lista-6-resolvida-no-spss",
    "href": "lista_6.html#lista-6-resolvida-no-spss",
    "title": "6  Lista 6 - Kaplan-Meier e Cox Regression",
    "section": "6.15 Lista 6 resolvida no SPSS",
    "text": "6.15 Lista 6 resolvida no SPSS"
  },
  {
    "objectID": "lista_6.html#sec-extrasVI",
    "href": "lista_6.html#sec-extrasVI",
    "title": "6  Lista 6 - Kaplan-Meier e Cox Regression",
    "section": "6.16 Extras!",
    "text": "6.16 Extras!\n\nEvento como fator ou como número\nComo mencionado na seção Section 6.4, o tipo da variável do evento (morte) afeta os resultados tanto da Kaplan-Meir quanto na Regressão de Cox.\nVamos criar alguns modelos utilizando o banco de dados original (variável óbito é um fator) e também o db (variável óbito é binária, 1 e 0).\nVamos começar observando a diferença do tipo da variável nos bancos utilizando a função glimpse():\n\nglimpse(original$obito)\n\n Factor w/ 2 levels \"não\",\"sim\": 1 1 1 1 1 1 1 1 2 1 ...\n\n\n\nglimpse(db$obito)\n\n int [1:124] 0 0 0 0 0 0 0 0 1 0 ...\n\n\nE tem mais! Temos que lembrar que quando deixamos as variáveis como fatores elas sempre possuem um nível de referência. Já verificamos isso em outros exercícios utilizando a função levels().\n\nlevels(original$obito)\n\n[1] \"não\" \"sim\"\n\n\nVeja só! A referência para a variável óbito é o “não”. Para fins didáditcos vamos criar três modelos:\nÓbito como variável binária (banco db) Óbito como fator com nível de referência “não” (banco original) Óbito como fator com nível de referência “sim” (banco original_sim)\n\noriginal_sim = original\noriginal_sim$obito = relevel(original_sim$obito, ref = \"sim\")\n\nAgora vamos repetir todo o procedimento já demonstrado no início das análises, utilizando os três bancos de dados.\n\nsurv_db &lt;- Surv(time = db$t_seg, event = db$obito)\nsurv_oiriginal_não &lt;- Surv(time = original$t_seg, event = original$obito)\nsurv_oiriginal_sim &lt;- Surv(time = original_sim$t_seg, event = original_sim$obito)\n\n\nfit_db &lt;- survfit(surv_db ~ 1, data = db)\nfit_original_não &lt;- survfit(surv_oiriginal_não ~ 1, data = original)\nfit_original_sim &lt;- survfit(surv_oiriginal_sim ~ 1, data = original_sim)\n\n\nplot(fit_db)\n\n\n\nplot(fit_original_não)\n\n\n\nplot(fit_original_sim)\n\n\n\n\n\nggsurvfit(fit_db, linewidth = 1) +\n  ggtitle(\"Binário\") +\n  labs(x = 'Dias', y = 'Overall survival') +\n  add_confidence_interval() +\n    add_risktable() +\n  scale_ggsurvfit() \n\n\n\nggcuminc(fit_original_não, linewidth = 1, type = \"survival\" ) +\n  ggtitle(\"Fator - Lelvel = Não\") +\n  labs(x = 'Dias', y = 'Overall survival') +\n  add_confidence_interval() +\n  add_risktable() +\n  scale_ggsurvfit() \n\nPlotting outcome \"sim\".\n\n\nWarning in ggplot2::geom_step(ggplot2::aes(x = .data$time, y = .data$estimate),\n: Ignoring unknown parameters: `type`\n\n\n\n\nggcuminc(fit_original_sim, linewidth = 1) +\n  ggtitle(\"Fator - Lelvel = Sim\") +\n  labs(x = 'Dias', y = 'Overall survival') +\n  add_confidence_interval() +\n  add_risktable() +\n  scale_ggsurvfit() \n\nPlotting outcome \"não\".\n\n\n\n\n\nComo podemos observar, quando utilizamos a variável de evento como um fator, acabamos analisando o risco cumulativo e não a sobrevida.\n\n\nMais gráficos!\nCom o ggplot2\n\nkm_plot = survfit2(surv_obj ~ tx, data = db) %&gt;%\n  tidy_survfit() %&gt;%\n  ggplot(aes(x = time, y = estimate,\n             min = conf.low, ymax = conf.low,\n             color = strata, fill = strata)) +\n  geom_step()\n\nkm_plot\n\n\n\n\nCom a função ggsurvplot() do pacote survminer.\n\nggsurvplot(fit2, data = db,\n           size = 1,\n           palette = c('#E7B800', '#2e9fdf'),\n           censor.shape = '|', censor.size = 4,\n           conf.int = TRUE,\n           pval = TRUE,\n           risk.table = TRUE,\n           risk.table.col = 'strata',\n           legend.labs = list('0' = 'Transplante = sim', '1' = 'Transplante = não'),\n           risk.table.height = 0.25,\n           ggtheme = theme_bw())\n\n\n\n\nGráficos de proporcionalidade com outras funções\n\nggcoxdiagnostics(cox_res, type = \"dfbeta\", linear.predictions = FALSE)\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\nE um específico para variáveis contínuas.\n\n# Não é importante para variáveis categóricas, mas fica o código para eventual consulta.\nggcoxdiagnostics(cox_res, type = \"deviance\", linear.predictions = FALSE)\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\nPacots alternativos para comparar curvas\n\ngehan.wilcoxon.test(surv_obj ~ tx ,data=db)\n\n\n    Gehan-Wilcoxon\n\ndata:  \n= 9.1531, p-value = 0.002483\nalternative hypothesis: two-sided\n\n\nsurvdiff Com rho = 0 este é o teste log-rank ou Mantel-Haenszel, e com rho = 1 é equivalente à modificação Peto & Peto do teste Gehan-Wilcoxon.\n\nsurvdiff(surv_obj ~ tx, data=db, rho = 2)\n\nCall:\nsurvdiff(formula = surv_obj ~ tx, data = db, rho = 2)\n\n        N Observed Expected (O-E)^2/E (O-E)^2/V\ntx=sim 60      7.4     14.0      3.12      9.19\ntx=não 64     17.9     11.3      3.89      9.19\n\n Chisq= 9.2  on 1 degrees of freedom, p= 0.002 \n\n\n\n\nTabela completa do modelo 2\n\nlife_table2 = survfit2(Surv(time = t_seg, event = obito) ~ tx, data = db) %&gt;%\n  tidy_survfit() \n\nkable(life_table2)\n\n\n\n\ntime\nn.risk\nn.event\nn.censor\ncum.event\ncum.censor\nestimate\nstd.error\nconf.high\nconf.low\nstrata\nestimate_type\nestimate_type_label\nmonotonicity_type\nstrata_label\nconf.level\n\n\n\n\n0\n60\n0\n1\n0\n1\n1.0000000\n0.0000000\n1.0000000\n1.0000000\nsim\nsurvival\nSurvival Probability\ndecreasing\ntx\n0.95\n\n\n3\n59\n1\n0\n1\n1\n0.9830508\n0.0170946\n1.0000000\n0.9506595\nsim\nsurvival\nSurvival Probability\ndecreasing\ntx\n0.95\n\n\n4\n58\n1\n0\n2\n1\n0.9661017\n0.0243866\n1.0000000\n0.9210112\nsim\nsurvival\nSurvival Probability\ndecreasing\ntx\n0.95\n\n\n24\n57\n1\n0\n3\n1\n0.9491525\n0.0301329\n1.0000000\n0.8947194\nsim\nsurvival\nSurvival Probability\ndecreasing\ntx\n0.95\n\n\n26\n56\n1\n0\n4\n1\n0.9322034\n0.0351093\n0.9986097\n0.8702130\nsim\nsurvival\nSurvival Probability\ndecreasing\ntx\n0.95\n\n\n29\n55\n1\n0\n5\n1\n0.9152542\n0.0396152\n0.9891503\n0.8468787\nsim\nsurvival\nSurvival Probability\ndecreasing\ntx\n0.95\n\n\n32\n54\n0\n3\n5\n4\n0.9152542\n0.0396152\n0.9891503\n0.8468787\nsim\nsurvival\nSurvival Probability\ndecreasing\ntx\n0.95\n\n\n34\n51\n0\n1\n5\n5\n0.9152542\n0.0396152\n0.9891503\n0.8468787\nsim\nsurvival\nSurvival Probability\ndecreasing\ntx\n0.95\n\n\n35\n50\n0\n3\n5\n8\n0.9152542\n0.0396152\n0.9891503\n0.8468787\nsim\nsurvival\nSurvival Probability\ndecreasing\ntx\n0.95\n\n\n36\n47\n0\n1\n5\n9\n0.9152542\n0.0396152\n0.9891503\n0.8468787\nsim\nsurvival\nSurvival Probability\ndecreasing\ntx\n0.95\n\n\n37\n46\n0\n2\n5\n11\n0.9152542\n0.0396152\n0.9891503\n0.8468787\nsim\nsurvival\nSurvival Probability\ndecreasing\ntx\n0.95\n\n\n38\n44\n1\n0\n6\n11\n0.8944530\n0.0458029\n0.9784644\n0.8176548\nsim\nsurvival\nSurvival Probability\ndecreasing\ntx\n0.95\n\n\n39\n43\n0\n1\n6\n12\n0.8944530\n0.0458029\n0.9784644\n0.8176548\nsim\nsurvival\nSurvival Probability\ndecreasing\ntx\n0.95\n\n\n40\n42\n0\n1\n6\n13\n0.8944530\n0.0458029\n0.9784644\n0.8176548\nsim\nsurvival\nSurvival Probability\ndecreasing\ntx\n0.95\n\n\n41\n41\n1\n0\n7\n13\n0.8726371\n0.0520352\n0.9663315\n0.7880272\nsim\nsurvival\nSurvival Probability\ndecreasing\ntx\n0.95\n\n\n42\n40\n0\n2\n7\n15\n0.8726371\n0.0520352\n0.9663315\n0.7880272\nsim\nsurvival\nSurvival Probability\ndecreasing\ntx\n0.95\n\n\n44\n38\n0\n1\n7\n16\n0.8726371\n0.0520352\n0.9663315\n0.7880272\nsim\nsurvival\nSurvival Probability\ndecreasing\ntx\n0.95\n\n\n45\n37\n1\n1\n8\n17\n0.8490523\n0.0588083\n0.9527789\n0.7566181\nsim\nsurvival\nSurvival Probability\ndecreasing\ntx\n0.95\n\n\n46\n35\n0\n1\n8\n18\n0.8490523\n0.0588083\n0.9527789\n0.7566181\nsim\nsurvival\nSurvival Probability\ndecreasing\ntx\n0.95\n\n\n48\n34\n0\n2\n8\n20\n0.8490523\n0.0588083\n0.9527789\n0.7566181\nsim\nsurvival\nSurvival Probability\ndecreasing\ntx\n0.95\n\n\n49\n32\n1\n2\n9\n22\n0.8225194\n0.0668317\n0.9376341\n0.7215375\nsim\nsurvival\nSurvival Probability\ndecreasing\ntx\n0.95\n\n\n51\n29\n0\n1\n9\n23\n0.8225194\n0.0668317\n0.9376341\n0.7215375\nsim\nsurvival\nSurvival Probability\ndecreasing\ntx\n0.95\n\n\n52\n28\n0\n1\n9\n24\n0.8225194\n0.0668317\n0.9376341\n0.7215375\nsim\nsurvival\nSurvival Probability\ndecreasing\ntx\n0.95\n\n\n54\n27\n0\n1\n9\n25\n0.8225194\n0.0668317\n0.9376341\n0.7215375\nsim\nsurvival\nSurvival Probability\ndecreasing\ntx\n0.95\n\n\n55\n26\n0\n4\n9\n29\n0.8225194\n0.0668317\n0.9376341\n0.7215375\nsim\nsurvival\nSurvival Probability\ndecreasing\ntx\n0.95\n\n\n57\n22\n0\n1\n9\n30\n0.8225194\n0.0668317\n0.9376341\n0.7215375\nsim\nsurvival\nSurvival Probability\ndecreasing\ntx\n0.95\n\n\n65\n21\n0\n2\n9\n32\n0.8225194\n0.0668317\n0.9376341\n0.7215375\nsim\nsurvival\nSurvival Probability\ndecreasing\ntx\n0.95\n\n\n66\n19\n1\n1\n10\n33\n0.7792289\n0.0859678\n0.9222336\n0.6583990\nsim\nsurvival\nSurvival Probability\ndecreasing\ntx\n0.95\n\n\n67\n17\n0\n1\n10\n34\n0.7792289\n0.0859678\n0.9222336\n0.6583990\nsim\nsurvival\nSurvival Probability\ndecreasing\ntx\n0.95\n\n\n73\n16\n0\n1\n10\n35\n0.7792289\n0.0859678\n0.9222336\n0.6583990\nsim\nsurvival\nSurvival Probability\ndecreasing\ntx\n0.95\n\n\n74\n15\n0\n1\n10\n36\n0.7792289\n0.0859678\n0.9222336\n0.6583990\nsim\nsurvival\nSurvival Probability\ndecreasing\ntx\n0.95\n\n\n75\n14\n0\n1\n10\n37\n0.7792289\n0.0859678\n0.9222336\n0.6583990\nsim\nsurvival\nSurvival Probability\ndecreasing\ntx\n0.95\n\n\n77\n13\n0\n1\n10\n38\n0.7792289\n0.0859678\n0.9222336\n0.6583990\nsim\nsurvival\nSurvival Probability\ndecreasing\ntx\n0.95\n\n\n82\n12\n0\n1\n10\n39\n0.7792289\n0.0859678\n0.9222336\n0.6583990\nsim\nsurvival\nSurvival Probability\ndecreasing\ntx\n0.95\n\n\n83\n11\n0\n2\n10\n41\n0.7792289\n0.0859678\n0.9222336\n0.6583990\nsim\nsurvival\nSurvival Probability\ndecreasing\ntx\n0.95\n\n\n87\n9\n0\n1\n10\n42\n0.7792289\n0.0859678\n0.9222336\n0.6583990\nsim\nsurvival\nSurvival Probability\ndecreasing\ntx\n0.95\n\n\n89\n8\n1\n0\n11\n42\n0.6818253\n0.1588949\n0.9309465\n0.4993689\nsim\nsurvival\nSurvival Probability\ndecreasing\ntx\n0.95\n\n\n90\n7\n0\n1\n11\n43\n0.6818253\n0.1588949\n0.9309465\n0.4993689\nsim\nsurvival\nSurvival Probability\ndecreasing\ntx\n0.95\n\n\n92\n6\n0\n1\n11\n44\n0.6818253\n0.1588949\n0.9309465\n0.4993689\nsim\nsurvival\nSurvival Probability\ndecreasing\ntx\n0.95\n\n\n96\n5\n0\n1\n11\n45\n0.6818253\n0.1588949\n0.9309465\n0.4993689\nsim\nsurvival\nSurvival Probability\ndecreasing\ntx\n0.95\n\n\n97\n4\n0\n2\n11\n47\n0.6818253\n0.1588949\n0.9309465\n0.4993689\nsim\nsurvival\nSurvival Probability\ndecreasing\ntx\n0.95\n\n\n98\n2\n0\n1\n11\n48\n0.6818253\n0.1588949\n0.9309465\n0.4993689\nsim\nsurvival\nSurvival Probability\ndecreasing\ntx\n0.95\n\n\n99\n1\n0\n1\n11\n49\n0.6818253\n0.1588949\n0.9309465\n0.4993689\nsim\nsurvival\nSurvival Probability\ndecreasing\ntx\n0.95\n\n\n0\n64\n2\n0\n2\n0\n0.9687500\n0.0224507\n1.0000000\n0.9270468\nnão\nsurvival\nSurvival Probability\ndecreasing\ntx\n0.95\n\n\n3\n62\n1\n0\n3\n0\n0.9531250\n0.0277208\n1.0000000\n0.9027217\nnão\nsurvival\nSurvival Probability\ndecreasing\ntx\n0.95\n\n\n4\n61\n1\n0\n4\n0\n0.9375000\n0.0322749\n0.9987199\n0.8800328\nnão\nsurvival\nSurvival Probability\ndecreasing\ntx\n0.95\n\n\n6\n60\n1\n0\n5\n0\n0.9218750\n0.0363889\n0.9900254\n0.8584159\nnão\nsurvival\nSurvival Probability\ndecreasing\ntx\n0.95\n\n\n8\n59\n2\n0\n7\n0\n0.8906250\n0.0438048\n0.9704688\n0.8173502\nnão\nsurvival\nSurvival Probability\ndecreasing\ntx\n0.95\n\n\n11\n57\n1\n0\n8\n0\n0.8750000\n0.0472456\n0.9598946\n0.7976136\nnão\nsurvival\nSurvival Probability\ndecreasing\ntx\n0.95\n\n\n13\n56\n1\n0\n9\n0\n0.8593750\n0.0505650\n0.9489071\n0.7782905\nnão\nsurvival\nSurvival Probability\ndecreasing\ntx\n0.95\n\n\n14\n55\n0\n1\n9\n1\n0.8593750\n0.0505650\n0.9489071\n0.7782905\nnão\nsurvival\nSurvival Probability\ndecreasing\ntx\n0.95\n\n\n15\n54\n0\n1\n9\n2\n0.8593750\n0.0505650\n0.9489071\n0.7782905\nnão\nsurvival\nSurvival Probability\ndecreasing\ntx\n0.95\n\n\n16\n53\n1\n0\n10\n2\n0.8431604\n0.0540339\n0.9373546\n0.7584316\nnão\nsurvival\nSurvival Probability\ndecreasing\ntx\n0.95\n\n\n18\n52\n0\n1\n10\n3\n0.8431604\n0.0540339\n0.9373546\n0.7584316\nnão\nsurvival\nSurvival Probability\ndecreasing\ntx\n0.95\n\n\n19\n51\n1\n0\n11\n3\n0.8266278\n0.0575484\n0.9253272\n0.7384562\nnão\nsurvival\nSurvival Probability\ndecreasing\ntx\n0.95\n\n\n22\n50\n0\n1\n11\n4\n0.8266278\n0.0575484\n0.9253272\n0.7384562\nnão\nsurvival\nSurvival Probability\ndecreasing\ntx\n0.95\n\n\n24\n49\n1\n0\n12\n4\n0.8097579\n0.0611309\n0.9128300\n0.7183241\nnão\nsurvival\nSurvival Probability\ndecreasing\ntx\n0.95\n\n\n25\n48\n1\n0\n13\n4\n0.7928879\n0.0646549\n0.9000075\n0.6985178\nnão\nsurvival\nSurvival Probability\ndecreasing\ntx\n0.95\n\n\n27\n47\n1\n0\n14\n4\n0.7760180\n0.0681380\n0.8868924\n0.6790044\nnão\nsurvival\nSurvival Probability\ndecreasing\ntx\n0.95\n\n\n29\n46\n0\n1\n14\n5\n0.7760180\n0.0681380\n0.8868924\n0.6790044\nnão\nsurvival\nSurvival Probability\ndecreasing\ntx\n0.95\n\n\n30\n45\n0\n4\n14\n9\n0.7760180\n0.0681380\n0.8868924\n0.6790044\nnão\nsurvival\nSurvival Probability\ndecreasing\ntx\n0.95\n\n\n31\n41\n0\n1\n14\n10\n0.7760180\n0.0681380\n0.8868924\n0.6790044\nnão\nsurvival\nSurvival Probability\ndecreasing\ntx\n0.95\n\n\n32\n40\n0\n2\n14\n12\n0.7760180\n0.0681380\n0.8868924\n0.6790044\nnão\nsurvival\nSurvival Probability\ndecreasing\ntx\n0.95\n\n\n34\n38\n3\n0\n17\n12\n0.7147534\n0.0830568\n0.8411128\n0.6073768\nnão\nsurvival\nSurvival Probability\ndecreasing\ntx\n0.95\n\n\n36\n35\n1\n5\n18\n17\n0.6943319\n0.0879702\n0.8249877\n0.5843684\nnão\nsurvival\nSurvival Probability\ndecreasing\ntx\n0.95\n\n\n37\n29\n0\n3\n18\n20\n0.6943319\n0.0879702\n0.8249877\n0.5843684\nnão\nsurvival\nSurvival Probability\ndecreasing\ntx\n0.95\n\n\n40\n26\n1\n1\n19\n21\n0.6676268\n0.0963183\n0.8063435\n0.5527738\nnão\nsurvival\nSurvival Probability\ndecreasing\ntx\n0.95\n\n\n41\n24\n1\n0\n20\n21\n0.6398090\n0.1053035\n0.7864748\n0.5204942\nnão\nsurvival\nSurvival Probability\ndecreasing\ntx\n0.95\n\n\n42\n23\n0\n2\n20\n23\n0.6398090\n0.1053035\n0.7864748\n0.5204942\nnão\nsurvival\nSurvival Probability\ndecreasing\ntx\n0.95\n\n\n44\n21\n1\n2\n21\n25\n0.6093419\n0.1160593\n0.7649815\n0.4853680\nnão\nsurvival\nSurvival Probability\ndecreasing\ntx\n0.95\n\n\n46\n18\n1\n2\n22\n27\n0.5754896\n0.1293744\n0.7415854\n0.4465949\nnão\nsurvival\nSurvival Probability\ndecreasing\ntx\n0.95\n\n\n50\n15\n0\n1\n22\n28\n0.5754896\n0.1293744\n0.7415854\n0.4465949\nnão\nsurvival\nSurvival Probability\ndecreasing\ntx\n0.95\n\n\n51\n14\n0\n1\n22\n29\n0.5754896\n0.1293744\n0.7415854\n0.4465949\nnão\nsurvival\nSurvival Probability\ndecreasing\ntx\n0.95\n\n\n54\n13\n0\n1\n22\n30\n0.5754896\n0.1293744\n0.7415854\n0.4465949\nnão\nsurvival\nSurvival Probability\ndecreasing\ntx\n0.95\n\n\n56\n12\n0\n1\n22\n31\n0.5754896\n0.1293744\n0.7415854\n0.4465949\nnão\nsurvival\nSurvival Probability\ndecreasing\ntx\n0.95\n\n\n58\n11\n1\n3\n23\n34\n0.5231723\n0.1607130\n0.7168758\n0.3818086\nnão\nsurvival\nSurvival Probability\ndecreasing\ntx\n0.95\n\n\n60\n7\n0\n1\n23\n35\n0.5231723\n0.1607130\n0.7168758\n0.3818086\nnão\nsurvival\nSurvival Probability\ndecreasing\ntx\n0.95\n\n\n65\n6\n0\n1\n23\n36\n0.5231723\n0.1607130\n0.7168758\n0.3818086\nnão\nsurvival\nSurvival Probability\ndecreasing\ntx\n0.95\n\n\n71\n5\n0\n1\n23\n37\n0.5231723\n0.1607130\n0.7168758\n0.3818086\nnão\nsurvival\nSurvival Probability\ndecreasing\ntx\n0.95\n\n\n77\n4\n0\n1\n23\n38\n0.5231723\n0.1607130\n0.7168758\n0.3818086\nnão\nsurvival\nSurvival Probability\ndecreasing\ntx\n0.95\n\n\n80\n3\n0\n1\n23\n39\n0.5231723\n0.1607130\n0.7168758\n0.3818086\nnão\nsurvival\nSurvival Probability\ndecreasing\ntx\n0.95\n\n\n82\n2\n0\n1\n23\n40\n0.5231723\n0.1607130\n0.7168758\n0.3818086\nnão\nsurvival\nSurvival Probability\ndecreasing\ntx\n0.95\n\n\n97\n1\n0\n1\n23\n41\n0.5231723\n0.1607130\n0.7168758\n0.3818086\nnão\nsurvival\nSurvival Probability\ndecreasing\ntx\n0.95\n\n\n\n\n\n\nsummary(life_table2)\n\n      time           n.risk        n.event          n.censor    \n Min.   : 0.00   Min.   : 1.0   Min.   :0.0000   Min.   :0.000  \n 1st Qu.:28.00   1st Qu.:13.5   1st Qu.:0.0000   1st Qu.:0.000  \n Median :42.00   Median :34.0   Median :0.0000   Median :1.000  \n Mean   :46.25   Mean   :31.9   Mean   :0.4096   Mean   :1.084  \n 3rd Qu.:65.50   3rd Qu.:50.0   3rd Qu.:1.0000   3rd Qu.:1.000  \n Max.   :99.00   Max.   :64.0   Max.   :3.0000   Max.   :5.000  \n   cum.event       cum.censor       estimate        std.error      \n Min.   : 0.00   Min.   : 0.00   Min.   :0.5232   Min.   :0.00000  \n 1st Qu.: 7.00   1st Qu.: 4.00   1st Qu.:0.6818   1st Qu.:0.05056  \n Median :10.00   Median :20.00   Median :0.7929   Median :0.06683  \n Mean   :11.48   Mean   :20.04   Mean   :0.7757   Mean   :0.08234  \n 3rd Qu.:14.00   3rd Qu.:34.50   3rd Qu.:0.8726   3rd Qu.:0.11068  \n Max.   :23.00   Max.   :49.00   Max.   :1.0000   Max.   :0.16071  \n   conf.high         conf.low      strata   estimate_type     \n Min.   :0.7169   Min.   :0.3818   sim:43   Length:83         \n 1st Qu.:0.8869   1st Qu.:0.5099   não:40   Class :character  \n Median :0.9309   Median :0.6985            Mode  :character  \n Mean   :0.9015   Mean   :0.6716                              \n 3rd Qu.:0.9663   3rd Qu.:0.7880                              \n Max.   :1.0000   Max.   :1.0000                              \n estimate_type_label monotonicity_type  strata_label         conf.level  \n Length:83           Length:83          Length:83          Min.   :0.95  \n Class :character    Class :character   Class :character   1st Qu.:0.95  \n Mode  :character    Mode  :character   Mode  :character   Median :0.95  \n                                                           Mean   :0.95  \n                                                           3rd Qu.:0.95  \n                                                           Max.   :0.95  \n\nsummary(life_table2, times = tempos_específicos)\n\n      time           n.risk        n.event          n.censor    \n Min.   : 0.00   Min.   : 1.0   Min.   :0.0000   Min.   :0.000  \n 1st Qu.:28.00   1st Qu.:13.5   1st Qu.:0.0000   1st Qu.:0.000  \n Median :42.00   Median :34.0   Median :0.0000   Median :1.000  \n Mean   :46.25   Mean   :31.9   Mean   :0.4096   Mean   :1.084  \n 3rd Qu.:65.50   3rd Qu.:50.0   3rd Qu.:1.0000   3rd Qu.:1.000  \n Max.   :99.00   Max.   :64.0   Max.   :3.0000   Max.   :5.000  \n   cum.event       cum.censor       estimate        std.error      \n Min.   : 0.00   Min.   : 0.00   Min.   :0.5232   Min.   :0.00000  \n 1st Qu.: 7.00   1st Qu.: 4.00   1st Qu.:0.6818   1st Qu.:0.05056  \n Median :10.00   Median :20.00   Median :0.7929   Median :0.06683  \n Mean   :11.48   Mean   :20.04   Mean   :0.7757   Mean   :0.08234  \n 3rd Qu.:14.00   3rd Qu.:34.50   3rd Qu.:0.8726   3rd Qu.:0.11068  \n Max.   :23.00   Max.   :49.00   Max.   :1.0000   Max.   :0.16071  \n   conf.high         conf.low      strata   estimate_type     \n Min.   :0.7169   Min.   :0.3818   sim:43   Length:83         \n 1st Qu.:0.8869   1st Qu.:0.5099   não:40   Class :character  \n Median :0.9309   Median :0.6985            Mode  :character  \n Mean   :0.9015   Mean   :0.6716                              \n 3rd Qu.:0.9663   3rd Qu.:0.7880                              \n Max.   :1.0000   Max.   :1.0000                              \n estimate_type_label monotonicity_type  strata_label         conf.level  \n Length:83           Length:83          Length:83          Min.   :0.95  \n Class :character    Class :character   Class :character   1st Qu.:0.95  \n Mode  :character    Mode  :character   Mode  :character   Median :0.95  \n                                                           Mean   :0.95  \n                                                           3rd Qu.:0.95  \n                                                           Max.   :0.95  \n\nhead(life_table2)\n\n# A tibble: 6 × 16\n   time n.risk n.event n.censor cum.event cum.censor estimate std.error\n  &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;      &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;\n1     0     60       0        1         0          1    1        0     \n2     3     59       1        0         1          1    0.983    0.0171\n3     4     58       1        0         2          1    0.966    0.0244\n4    24     57       1        0         3          1    0.949    0.0301\n5    26     56       1        0         4          1    0.932    0.0351\n6    29     55       1        0         5          1    0.915    0.0396\n# ℹ 8 more variables: conf.high &lt;dbl&gt;, conf.low &lt;dbl&gt;, strata &lt;fct&gt;,\n#   estimate_type &lt;chr&gt;, estimate_type_label &lt;chr&gt;, monotonicity_type &lt;chr&gt;,\n#   strata_label &lt;chr&gt;, conf.level &lt;dbl&gt;\n\n\n\n\nCódigo não usado\n\n# Create the new data  \nnew_df &lt;- with(db,\n               data.frame(tx = c(\"sim\", \"não\")\n               )\n)\nglimpse(new_df)\n\nRows: 2\nColumns: 1\n$ tx &lt;chr&gt; \"sim\", \"não\"\n\nnew_df$tx = as.factor(new_df$tx)\n\n\n# Survival curves with new data\n#%%%%%%%%%%%%%%%%%%%%%%%%%%%\nfit_cox &lt;- survfit(cox_res, newdata = new_df)\n\n\nggsurvplot(fit_cox, data = db,\n           size = 1,\n           palette = c('#E7B800', '#2e9fdf'),\n           censor.shape = '|', censor.size = 4,\n           conf.int = TRUE,\n           pval = TRUE,\n          # risk.table = TRUE,\n         #  risk.table.col = 'strata',\n           legend.labs = list('0' = 'Transplante = sim', '1' = 'Transplante = não'),\n           risk.table.height = 0.25,\n           ggtheme = theme_bw())\n\nWarning in .pvalue(fit, data = data, method = method, pval = pval, pval.coord = pval.coord, : There are no survival curves to be compared. \n This is a null model.\n\n\n\n\n\n\n\nPara salvar os valores de sobrevida\n\nsurv_fit_cox = survfit(cox_res)\n\n# Extrai os tempos de sobrevida e as estimativas de sobrevida\nsurv_df_cox &lt;- data.frame(time = surv_fit_cox$time, surv = surv_fit_cox$surv)\nsurv_df_cox\n\n   time      surv\n1     0 0.9919270\n2     3 0.9837071\n3     4 0.9754200\n4     6 0.9712508\n5     8 0.9628064\n6    11 0.9585298\n7    13 0.9542158\n8    14 0.9542158\n9    15 0.9542158\n10   16 0.9497436\n11   18 0.9497436\n12   19 0.9451662\n13   22 0.9451662\n14   24 0.9357670\n15   25 0.9310329\n16   26 0.9262516\n17   27 0.9214703\n18   29 0.9166403\n19   30 0.9166403\n20   31 0.9166403\n21   32 0.9166403\n22   34 0.8995899\n23   35 0.8995899\n24   36 0.8936099\n25   37 0.8936099\n26   38 0.8862225\n27   39 0.8862225\n28   40 0.8787730\n29   41 0.8630231\n30   42 0.8630231\n31   44 0.8544152\n32   45 0.8449676\n33   46 0.8354131\n34   48 0.8354131\n35   49 0.8245091\n36   50 0.8245091\n37   51 0.8245091\n38   52 0.8245091\n39   54 0.8245091\n40   55 0.8245091\n41   56 0.8245091\n42   57 0.8245091\n43   58 0.8091983\n44   60 0.8091983\n45   65 0.8091983\n46   66 0.7855423\n47   67 0.7855423\n48   71 0.7855423\n49   73 0.7855423\n50   74 0.7855423\n51   75 0.7855423\n52   77 0.7855423\n53   80 0.7855423\n54   82 0.7855423\n55   83 0.7855423\n56   87 0.7855423\n57   89 0.7169271\n58   90 0.7169271\n59   92 0.7169271\n60   96 0.7169271\n61   97 0.7169271\n62   98 0.7169271\n63   99 0.7169271"
  },
  {
    "objectID": "lista_6.html#referências",
    "href": "lista_6.html#referências",
    "title": "6  Lista 6 - Kaplan-Meier e Cox Regression",
    "section": "6.17 Referências",
    "text": "6.17 Referências\nhttps://bookdown.org/mpfoley1973/survival/semiparametric.html#fitting-the-model-1\nhttps://biostatsquid.com/easy-survival-analysis-r-tutorial/\nhttps://www.youtube.com/watch?v=XrvCCFQRCZE\nhttps://www.youtube.com/watch?v=vX3l36ptrTU&list=PLqzoL9-eJTNDdnKvep_YHIwk2AMqHhuJ0\nhttp://www.sthda.com/english/wiki/cox-proportional-hazards-model"
  },
  {
    "objectID": "lista_6.html#versões-dos-pacotes",
    "href": "lista_6.html#versões-dos-pacotes",
    "title": "6  Lista 6 - Kaplan-Meier e Cox Regression",
    "section": "6.18 Versões dos pacotes",
    "text": "6.18 Versões dos pacotes\n\nreport(sessionInfo())\n\nAnalyses were conducted using the R Statistical language (version 4.3.1; R Core\nTeam, 2023) on Windows 11 x64 (build 22621), using the packages effectsize\n(version 0.8.6; Ben-Shachar MS et al., 2020), lpSolve (version 5.6.19;\nBerkelaar M, others, 2023), survMisc (version 0.5.6; Dardis C, 2022), tm\n(version 0.7.11; Feinerer I, Hornik K, 2023), flexplot (version 0.20.5; Fife D,\n2024), lubridate (version 1.9.3; Grolemund G, Wickham H, 2011), coxphf (version\n1.13.4; Heinze G et al., 2023), NLP (version 0.2.1; Hornik K, 2020), coin\n(version 1.4.3; Hothorn T et al., 2006), ggpubr (version 0.6.0; Kassambara A,\n2023), survminer (version 0.4.9; Kassambara A et al., 2021),\nPHInfiniteEstimates (version 2.9.5; Kolassa JE, Zhang J, 2023), parameters\n(version 0.21.3; Lüdecke D et al., 2020), performance (version 0.10.8; Lüdecke\nD et al., 2021), easystats (version 0.6.0; Lüdecke D et al., 2022), see\n(version 0.8.1; Lüdecke D et al., 2021), insight (version 0.19.6; Lüdecke D et\nal., 2019), bayestestR (version 0.13.1; Makowski D et al., 2019), modelbased\n(version 0.8.6; Makowski D et al., 2020), report (version 0.5.7; Makowski D et\nal., 2023), correlation (version 0.8.4; Makowski D et al., 2022), condSURV\n(version 2.0.4; Meira-Machado L, Sestelo M, 2023), tibble (version 3.2.1;\nMüller K, Wickham H, 2023), datawizard (version 0.9.0; Patil I et al., 2022),\nforeign (version 0.8.85; R Core Team, 2023), nph (version 2.1; Ristl R et al.,\n2021), broom (version 1.0.5; Robinson D et al., 2023), ggsurvfit (version\n1.0.0; Sjoberg D et al., 2023), gtsummary (version 1.7.2; Sjoberg D et al.,\n2021), rempsyc (version 0.1.6; Thériault R, 2023), survival (version 3.5.7;\nTherneau T, 2023), ggplot2 (version 3.4.4; Wickham H, 2016), forcats (version\n1.0.0; Wickham H, 2023), stringr (version 1.5.1; Wickham H, 2023), tidyverse\n(version 2.0.0; Wickham H et al., 2019), dplyr (version 1.1.3; Wickham H et\nal., 2023), purrr (version 1.0.2; Wickham H, Henry L, 2023), readr (version\n2.1.4; Wickham H et al., 2023), tidyr (version 1.3.0; Wickham H et al., 2023)\nand kableExtra (version 1.3.4; Zhu H, 2021).\n\nReferences\n----------\n  - Ben-Shachar MS, Lüdecke D, Makowski D (2020). \"effectsize: Estimation of\nEffect Size Indices and Standardized Parameters.\" _Journal of Open Source\nSoftware_, *5*(56), 2815. doi:10.21105/joss.02815\n&lt;https://doi.org/10.21105/joss.02815&gt;, &lt;https://doi.org/10.21105/joss.02815&gt;.\n  - Berkelaar M, others (2023). _lpSolve: Interface to 'Lp_solve' v. 5.5 to Solve\nLinear/Integer Programs_. R package version 5.6.19,\n&lt;https://CRAN.R-project.org/package=lpSolve&gt;.\n  - Dardis C (2022). _survMisc: Miscellaneous Functions for Survival Data_. R\npackage version 0.5.6, &lt;https://CRAN.R-project.org/package=survMisc&gt;.\n  - Feinerer I, Hornik K (2023). _tm: Text Mining Package_. R package version\n0.7-11, &lt;https://CRAN.R-project.org/package=tm&gt;. Feinerer I, Hornik K, Meyer D\n(2008). \"Text Mining Infrastructure in R.\" _Journal of Statistical Software_,\n*25*(5), 1-54. doi:10.18637/jss.v025.i05\n&lt;https://doi.org/10.18637/jss.v025.i05&gt;.\n  - Fife D (2024). _flexplot: Graphically Based Data Analysis Using 'flexplot'_.\nR package version 0.20.5.\n  - Grolemund G, Wickham H (2011). \"Dates and Times Made Easy with lubridate.\"\n_Journal of Statistical Software_, *40*(3), 1-25.\n&lt;https://www.jstatsoft.org/v40/i03/&gt;.\n  - Heinze G, Ploner M, Jiricka L, Steiner G (2023). _coxphf: Cox Regression with\nFirth's Penalized Likelihood_. R package version 1.13.4,\n&lt;https://CRAN.R-project.org/package=coxphf&gt;.\n  - Hornik K (2020). _NLP: Natural Language Processing Infrastructure_. R package\nversion 0.2-1, &lt;https://CRAN.R-project.org/package=NLP&gt;.\n  - Hothorn T, Hornik K, van de Wiel MA, Zeileis A (2006). \"A Lego system for\nconditional inference.\" _The American Statistician_, *60*(3), 257-263.\ndoi:10.1198/000313006X118430 &lt;https://doi.org/10.1198/000313006X118430&gt;.\nHothorn T, Hornik K, van de Wiel MA, Zeileis A (2008). \"Implementing a class of\npermutation tests: The coin package.\" _Journal of Statistical Software_,\n*28*(8), 1-23. doi:10.18637/jss.v028.i08\n&lt;https://doi.org/10.18637/jss.v028.i08&gt;.\n  - Kassambara A (2023). _ggpubr: 'ggplot2' Based Publication Ready Plots_. R\npackage version 0.6.0, &lt;https://CRAN.R-project.org/package=ggpubr&gt;.\n  - Kassambara A, Kosinski M, Biecek P (2021). _survminer: Drawing Survival\nCurves using 'ggplot2'_. R package version 0.4.9,\n&lt;https://CRAN.R-project.org/package=survminer&gt;.\n  - Kolassa JE, Zhang J (2023). _PHInfiniteEstimates: Tools for Inference in the\nPresence of a Monotone Likelihood_. R package version 2.9.5,\n&lt;https://CRAN.R-project.org/package=PHInfiniteEstimates&gt;.\n  - Lüdecke D, Ben-Shachar M, Patil I, Makowski D (2020). \"Extracting, Computing\nand Exploring the Parameters of Statistical Models using R.\" _Journal of Open\nSource Software_, *5*(53), 2445. doi:10.21105/joss.02445\n&lt;https://doi.org/10.21105/joss.02445&gt;.\n  - Lüdecke D, Ben-Shachar M, Patil I, Waggoner P, Makowski D (2021).\n\"performance: An R Package for Assessment, Comparison and Testing of\nStatistical Models.\" _Journal of Open Source Software_, *6*(60), 3139.\ndoi:10.21105/joss.03139 &lt;https://doi.org/10.21105/joss.03139&gt;.\n  - Lüdecke D, Ben-Shachar M, Patil I, Wiernik B, Makowski D (2022). \"easystats:\nFramework for Easy Statistical Modeling, Visualization, and Reporting.\" _CRAN_.\nR package, &lt;https://easystats.github.io/easystats/&gt;.\n  - Lüdecke D, Patil I, Ben-Shachar M, Wiernik B, Waggoner P, Makowski D (2021).\n\"see: An R Package for Visualizing Statistical Models.\" _Journal of Open Source\nSoftware_, *6*(64), 3393. doi:10.21105/joss.03393\n&lt;https://doi.org/10.21105/joss.03393&gt;.\n  - Lüdecke D, Waggoner P, Makowski D (2019). \"insight: A Unified Interface to\nAccess Information from Model Objects in R.\" _Journal of Open Source Software_,\n*4*(38), 1412. doi:10.21105/joss.01412 &lt;https://doi.org/10.21105/joss.01412&gt;.\n  - Makowski D, Ben-Shachar M, Lüdecke D (2019). \"bayestestR: Describing Effects\nand their Uncertainty, Existence and Significance within the Bayesian\nFramework.\" _Journal of Open Source Software_, *4*(40), 1541.\ndoi:10.21105/joss.01541 &lt;https://doi.org/10.21105/joss.01541&gt;,\n&lt;https://joss.theoj.org/papers/10.21105/joss.01541&gt;.\n  - Makowski D, Ben-Shachar M, Patil I, Lüdecke D (2020). \"Estimation of\nModel-Based Predictions, Contrasts and Means.\" _CRAN_.\n&lt;https://github.com/easystats/modelbased&gt;.\n  - Makowski D, Lüdecke D, Patil I, Thériault R, Ben-Shachar M, Wiernik B (2023).\n\"Automated Results Reporting as a Practical Tool to Improve Reproducibility and\nMethodological Best Practices Adoption.\" _CRAN_.\n&lt;https://easystats.github.io/report/&gt;.\n  - Makowski D, Wiernik B, Patil I, Lüdecke D, Ben-Shachar M (2022).\n\"correlation: Methods for Correlation Analysis.\" Version 0.8.3,\n&lt;https://CRAN.R-project.org/package=correlation&gt;. Makowski D, Ben-Shachar M,\nPatil I, Lüdecke D (2020). \"Methods and Algorithms for Correlation Analysis in\nR.\" _Journal of Open Source Software_, *5*(51), 2306. doi:10.21105/joss.02306\n&lt;https://doi.org/10.21105/joss.02306&gt;,\n&lt;https://joss.theoj.org/papers/10.21105/joss.02306&gt;.\n  - Meira-Machado L, Sestelo M (2023). _condSURV: Estimation of the Conditional\nSurvival Function for Ordered Multivariate Failure Time Data_. R package\nversion 2.0.4, &lt;https://CRAN.R-project.org/package=condSURV&gt;.\n  - Müller K, Wickham H (2023). _tibble: Simple Data Frames_. R package version\n3.2.1, &lt;https://CRAN.R-project.org/package=tibble&gt;.\n  - Patil I, Makowski D, Ben-Shachar M, Wiernik B, Bacher E, Lüdecke D (2022).\n\"datawizard: An R Package for Easy Data Preparation and Statistical\nTransformations.\" _Journal of Open Source Software_, *7*(78), 4684.\ndoi:10.21105/joss.04684 &lt;https://doi.org/10.21105/joss.04684&gt;.\n  - R Core Team (2023). _foreign: Read Data Stored by 'Minitab', 'S', 'SAS',\n'SPSS', 'Stata', 'Systat', 'Weka', 'dBase', ..._. R package version 0.8-85,\n&lt;https://CRAN.R-project.org/package=foreign&gt;.\n  - R Core Team (2023). _R: A Language and Environment for Statistical\nComputing_. R Foundation for Statistical Computing, Vienna, Austria.\n&lt;https://www.R-project.org/&gt;.\n  - Ristl R, Ballarini N, Götte H, Schüler A, Posch M, König F (2021). \"Delayed\ntreatment effects, treatment switching and heterogeneous patient populations:\nHow to design and analyze RCTs in oncology.\" _Pharmaceutical statistics_,\n*20*(1), 129-145.\n  - Robinson D, Hayes A, Couch S (2023). _broom: Convert Statistical Objects into\nTidy Tibbles_. R package version 1.0.5,\n&lt;https://CRAN.R-project.org/package=broom&gt;.\n  - Sjoberg D, Baillie M, Fruechtenicht C, Haesendonckx S, Treis T (2023).\n_ggsurvfit: Flexible Time-to-Event Figures_. R package version 1.0.0,\n&lt;https://CRAN.R-project.org/package=ggsurvfit&gt;.\n  - Sjoberg D, Whiting K, Curry M, Lavery J, Larmarange J (2021). \"Reproducible\nSummary Tables with the gtsummary Package.\" _The R Journal_, *13*, 570-580.\ndoi:10.32614/RJ-2021-053 &lt;https://doi.org/10.32614/RJ-2021-053&gt;,\n&lt;https://doi.org/10.32614/RJ-2021-053&gt;.\n  - Thériault R (2023). \"rempsyc: Convenience functions for psychology.\" _Journal\nof Open Source Software_, *8*(87), 5466. doi:10.21105/joss.05466\n&lt;https://doi.org/10.21105/joss.05466&gt;, &lt;https://doi.org/10.21105/joss.05466&gt;.\n  - Therneau T (2023). _A Package for Survival Analysis in R_. R package version\n3.5-7, &lt;https://CRAN.R-project.org/package=survival&gt;. Terry M. Therneau,\nPatricia M. Grambsch (2000). _Modeling Survival Data: Extending the Cox Model_.\nSpringer, New York. ISBN 0-387-98784-3.\n  - Wickham H (2016). _ggplot2: Elegant Graphics for Data Analysis_.\nSpringer-Verlag New York. ISBN 978-3-319-24277-4,\n&lt;https://ggplot2.tidyverse.org&gt;.\n  - Wickham H (2023). _forcats: Tools for Working with Categorical Variables\n(Factors)_. R package version 1.0.0,\n&lt;https://CRAN.R-project.org/package=forcats&gt;.\n  - Wickham H (2023). _stringr: Simple, Consistent Wrappers for Common String\nOperations_. R package version 1.5.1,\n&lt;https://CRAN.R-project.org/package=stringr&gt;.\n  - Wickham H, Averick M, Bryan J, Chang W, McGowan LD, François R, Grolemund G,\nHayes A, Henry L, Hester J, Kuhn M, Pedersen TL, Miller E, Bache SM, Müller K,\nOoms J, Robinson D, Seidel DP, Spinu V, Takahashi K, Vaughan D, Wilke C, Woo K,\nYutani H (2019). \"Welcome to the tidyverse.\" _Journal of Open Source Software_,\n*4*(43), 1686. doi:10.21105/joss.01686 &lt;https://doi.org/10.21105/joss.01686&gt;.\n  - Wickham H, François R, Henry L, Müller K, Vaughan D (2023). _dplyr: A Grammar\nof Data Manipulation_. R package version 1.1.3,\n&lt;https://CRAN.R-project.org/package=dplyr&gt;.\n  - Wickham H, Henry L (2023). _purrr: Functional Programming Tools_. R package\nversion 1.0.2, &lt;https://CRAN.R-project.org/package=purrr&gt;.\n  - Wickham H, Hester J, Bryan J (2023). _readr: Read Rectangular Text Data_. R\npackage version 2.1.4, &lt;https://CRAN.R-project.org/package=readr&gt;.\n  - Wickham H, Vaughan D, Girlich M (2023). _tidyr: Tidy Messy Data_. R package\nversion 1.3.0, &lt;https://CRAN.R-project.org/package=tidyr&gt;.\n  - Zhu H (2021). _kableExtra: Construct Complex Table with 'kable' and Pipe\nSyntax_. R package version 1.3.4,\n&lt;https://CRAN.R-project.org/package=kableExtra&gt;."
  },
  {
    "objectID": "lista_6_1.html#carregando-pacotes",
    "href": "lista_6_1.html#carregando-pacotes",
    "title": "7  Lista 6.1 - Cox tempo dependente",
    "section": "7.1 Carregando pacotes",
    "text": "7.1 Carregando pacotes\n\nlibrary(tidyverse)\nlibrary(flexplot)\nlibrary(foreign)\nlibrary(dplyr)\nlibrary(tm)\nlibrary(ggplot2)\nlibrary(forcats)\nlibrary(rempsyc)\nlibrary(easystats)\nlibrary(kableExtra)\nlibrary(gtsummary)\n\n#Específicos para survival\nlibrary(survival)\nlibrary(ggsurvfit)\nlibrary(survminer)\nlibrary(broom)\nlibrary(survMisc)\nlibrary(PHInfiniteEstimates)\nlibrary(coin)\nlibrary(condSURV)"
  },
  {
    "objectID": "lista_6_1.html#carregando-os-dados-e-modificando-o-tipo-de-variável",
    "href": "lista_6_1.html#carregando-os-dados-e-modificando-o-tipo-de-variável",
    "title": "7  Lista 6.1 - Cox tempo dependente",
    "section": "7.2 Carregando os dados e modificando o tipo de variável",
    "text": "7.2 Carregando os dados e modificando o tipo de variável\nMantendo as boas práticas das análises, logo após carregar os dados em uma variável, vamos verificar os tipos de variávels que temos em nosso banco.\n\noriginal = read.spss(\"Cox tempo dependente 2_1.sav\", to.data.frame=TRUE)\nglimpse(original)\n\nRows: 628\nColumns: 7\n$ ID            &lt;dbl&gt; 112, 91, 113, 150, 22, 139, 104, 590, 189, 171, 338, 492…\n$ age           &lt;dbl&gt; 35, 33, 35, 31, 33, 43, 25, 35, 29, 27, 35, 23, 24, 23, …\n$ race          &lt;fct&gt; branco, branco, branco, branco, branco, branco, branco, …\n$ treat         &lt;dbl&gt; 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1,…\n$ Tempo_dialise &lt;dbl&gt; 51, 67, 88, 156, 12, 139, 90, 25, 187, 34, 29, 78, 63, 8…\n$ time          &lt;dbl&gt; 1172, 762, 734, 720, 659, 658, 655, 654, 634, 630, 621, …\n$ morte         &lt;fct&gt; Não, Não, Não, Não, Não, Não, Não, Não, Não, Não, Não, N…\n\n\nNovamente podemos observar que o evento de interesse (morte) está como um fator. Vamos modificar como já fizemos a lista 6 e também já vamos ajustar a variável “treat” para que ela seja um fator e não um número.\n\ndb &lt;- original %&gt;%\n  mutate(\n    morte = as.integer(morte == \"Sim\"), # para transformar sim e não em 1 e 0, respectivamente\n    treat = as.factor(treat)\n  )\nglimpse(db)\n\nRows: 628\nColumns: 7\n$ ID            &lt;dbl&gt; 112, 91, 113, 150, 22, 139, 104, 590, 189, 171, 338, 492…\n$ age           &lt;dbl&gt; 35, 33, 35, 31, 33, 43, 25, 35, 29, 27, 35, 23, 24, 23, …\n$ race          &lt;fct&gt; branco, branco, branco, branco, branco, branco, branco, …\n$ treat         &lt;fct&gt; 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1,…\n$ Tempo_dialise &lt;dbl&gt; 51, 67, 88, 156, 12, 139, 90, 25, 187, 34, 29, 78, 63, 8…\n$ time          &lt;dbl&gt; 1172, 762, 734, 720, 659, 658, 655, 654, 634, 630, 621, …\n$ morte         &lt;int&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n\n\nFeito! Vamos também verificar se há presença de dados faltantes e em quais variáveis.\n\n# Verificando NAs\nresumo_nas &lt;- db %&gt;%\n  summarise(\n    nas_age = sum(is.na(age)),\n    nas_race = sum(is.na(race)),\n    nas_treat = sum(is.na(treat)),\n    nas_t_dialise = sum(is.na(Tempo_dialise)),\n    nas_time = sum(is.na(time)),\n    nas_morte = sum(is.na(morte)),\n  )\nkable(resumo_nas)\n\n\n\n\nnas_age\nnas_race\nnas_treat\nnas_t_dialise\nnas_time\nnas_morte\n\n\n\n\n5\n6\n0\n0\n0\n0\n\n\n\n\n\n\n\nAté chegar na Cox tempo dependente, vamos repetir basicamente o que já fizemos no Capítulo 6"
  },
  {
    "objectID": "lista_6_1.html#criando-a-estrutura-de-dados",
    "href": "lista_6_1.html#criando-a-estrutura-de-dados",
    "title": "7  Lista 6.1 - Cox tempo dependente",
    "section": "7.3 Criando a estrutura de dados",
    "text": "7.3 Criando a estrutura de dados\n\n# Create a survival object\nsurv_obj &lt;- Surv(time = db$time, event = db$morte)\n\n\nTábua de vida\n\n# Create survival curve\nfit1 &lt;- survfit(surv_obj ~ treat, data = db)\nkable(head(tidy(fit1)))\n\n\n\n\ntime\nn.risk\nn.event\nn.censor\nestimate\nstd.error\nconf.high\nconf.low\nstrata\n\n\n\n\n3\n320\n2\n0\n0.993750\n0.0044333\n1.0000000\n0.9851526\ntreat=0\n\n\n4\n318\n2\n0\n0.987500\n0.0062894\n0.9997483\n0.9754017\ntreat=0\n\n\n5\n316\n1\n0\n0.984375\n0.0070430\n0.9980575\n0.9708801\ntreat=0\n\n\n6\n315\n2\n0\n0.978125\n0.0083599\n0.9942837\n0.9622289\ntreat=0\n\n\n7\n313\n2\n0\n0.971875\n0.0095097\n0.9901593\n0.9539283\ntreat=0\n\n\n8\n311\n1\n0\n0.968750\n0.0100402\n0.9880024\n0.9498728\ntreat=0\n\n\n\n\n\n\n\n\n\nGráfico Kaplan-Meir\n\nkm_plot = survfit2(surv_obj ~ treat, data = db) %&gt;%\n  tidy_survfit() %&gt;%\n  ggplot(aes(x = time, y = estimate,\n             min = conf.low, ymax = conf.low,\n             color = strata, fill = strata)) +\n  geom_step()\nkm_plot\n\n\n\n\nPodemos ajustar as configurações do eixo X para exibir uma escala temporal com intervalos de 50 unidades.\n\n# km_plot2 = fit1 %&gt;%\n#   tidy_survfit() %&gt;%\n#   ggplot(aes(x = time, y = estimate,\n#              min = conf.low, ymax = conf.low,\n#              color = strata, fill = strata)) +\n#   geom_step()\n\nkm_plot2 = fit1 %&gt;%\n  tidy_survfit() %&gt;%\n  ggplot(aes(x = time, y = estimate,\n             min = conf.low, ymax = conf.low,\n             color = strata, fill = strata)) +\n  geom_step() +\n  scale_x_continuous(breaks = seq(0, max(fit1$time), by = 50))\n\n\nkm_plot2\n\n\n\n\n\n\nTabela com Sobrevida em tempos espcíficos.\n\ntbl_survfit_ex3 &lt;-\n  list(\n    survfit(surv_obj ~ 1, db),\n    survfit(surv_obj ~ treat, db)\n  ) %&gt;%\n  tbl_survfit(times = c(100, 600))\ntbl_survfit_ex3\n\n\n\n\n\n  \n    \n    \n      Characteristic\n      Time 100\n      Time 600\n    \n  \n  \n    Overall\n66% (63%, 70%)\n19% (16%, 22%)\n    treat\n\n\n        0\n61% (56%, 66%)\n16% (13%, 21%)\n        1\n72% (67%, 77%)\n21% (17%, 26%)\n  \n  \n  \n\n\n\n\n\n\nLog-rank\n\ncoin::logrank_test(surv_obj ~ treat, data = db, type = \"logrank\" ) # padrão é o log-rank\n\n\n    Asymptotic Two-Sample Logrank Test\n\ndata:  surv_obj by treat (0, 1)\nZ = -2.5984, p-value = 0.009365\nalternative hypothesis: true theta is not equal to 1\n\n\n\n\nGehan-Breslow\n\ncoin::logrank_test(surv_obj ~ treat ,data = db, type = \"Gehan-Breslow\")\n\n\n    Asymptotic Two-Sample Gehan-Breslow Test\n\ndata:  surv_obj by treat (0, 1)\nZ = -3.0713, p-value = 0.002132\nalternative hypothesis: true theta is not equal to 1\n\n\n\n\nTarone-Ware\n\ncoin::logrank_test(surv_obj ~ treat ,data = db, type = \"Tarone-Ware\")\n\n\n    Asymptotic Two-Sample Tarone-Ware Test\n\ndata:  surv_obj by treat (0, 1)\nZ = -2.9622, p-value = 0.003055\nalternative hypothesis: true theta is not equal to 1\n\n\n\n\nPeto-Peto\n\ncoin::logrank_test(surv_obj ~ treat ,data = db, type = \"Peto-Peto\")\n\n\n    Asymptotic Two-Sample Peto-Peto Test\n\ndata:  surv_obj by treat (0, 1)\nZ = -3.0608, p-value = 0.002207\nalternative hypothesis: true theta is not equal to 1"
  },
  {
    "objectID": "lista_6_1.html#cox-regression",
    "href": "lista_6_1.html#cox-regression",
    "title": "7  Lista 6.1 - Cox tempo dependente",
    "section": "7.4 Cox regression",
    "text": "7.4 Cox regression\n\n# Cox regression ======================================================\n# Fit the model\n\ncox_res &lt;- coxph(Surv(time = db$time, event = db$morte) ~ treat, data = db)\n### Para testar todas as variáveis\n#cox_res &lt;- coxph(Surv(time = db$time, event = db$morte2) ~ treat + age + Tempo_dialise, data = db)\n\ntbl_regression(cox_res, exponentiate = TRUE)\n\n\n\n\n\n  \n    \n    \n      Characteristic\n      HR1\n      95% CI1\n      p-value\n    \n  \n  \n    treat\n\n\n\n        0\n—\n—\n\n        1\n0.79\n0.67, 0.94\n0.009\n  \n  \n  \n    \n      1 HR = Hazard Ratio, CI = Confidence Interval\n    \n  \n\n\n\n\n\nVerificando os pressupostos da Cox regression\nRelembrando a análise dos riscos proporcionais com base nos resíduos de Schoenfeld:\n\np-val &lt; 0,05: há evidências contra a pressuposto de riscos proporcionais, os HRs não são constantes ao longo do tempo\nchisq: quanto maior o valor, mais forte a violação dos pressupostos"
  },
  {
    "objectID": "lista_6_1.html#plot-dos-resíduos-de-schoenfeld",
    "href": "lista_6_1.html#plot-dos-resíduos-de-schoenfeld",
    "title": "7  Lista 6.1 - Cox tempo dependente",
    "section": "7.5 Plot dos resíduos de Schoenfeld",
    "text": "7.5 Plot dos resíduos de Schoenfeld\n\n# Plot the Schoenfeld residuals over time for each covariate\nsurvminer::ggcoxzph(cox.zph(cox_res), point.size = 0.1)\n\n\n\n\nSe os resíduos mostrarem um padrão claro ao longo do tempo, isso pode indicar uma violação da suposição de riscos proporcionais.\nAlgumas dicas para ajudar na interpretação:\n\nSem Padrão (Resíduos Constantes): Se os resíduos aparecerem aleatoriamente espalhados em torno de zero, sem nenhuma tendência ou padrão claro, isso sugere que a suposição de riscos proporcionais é razoável.\nTendência Linear: Uma tendência linear (aumentando ou diminuindo) nos resíduos ao longo do tempo pode sugerir uma violação da suposição de riscos proporcionais. Por exemplo, se os resíduos forem consistentemente positivos ou negativos ao longo do tempo, isso indica um efeito dependente do tempo.\nPadrão Não Linear: Se os resíduos exibirem um padrão não linear ou formatos específicos (por exemplo, formato de U, formato de V), isso pode indicar desvios dos riscos proporcionais.\nParalelismo: Paralelismo significa que a propagação e distribuição dos resíduos são relativamente constantes ao longo do tempo. Se os resíduos aumentarem ou diminuirem ao longo do tempo, isso pode sugerir uma violação da suposição.\n\n\nggcoxdiagnostics(cox_res, type = \"dfbeta\", linear.predictions = FALSE)\n\nWarning: `gather_()` was deprecated in tidyr 1.2.0.\nℹ Please use `gather()` instead.\nℹ The deprecated feature was likely used in the survminer package.\n  Please report the issue at &lt;https://github.com/kassambara/survminer/issues&gt;.\n\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n# Não é importante para variáveis categóricas, mas fica o código para eventual consulta.\nggcoxdiagnostics(cox_res, type = \"deviance\", linear.predictions = FALSE)\n\n`geom_smooth()` using formula = 'y ~ x'"
  },
  {
    "objectID": "lista_6_1.html#plots-do-modelo",
    "href": "lista_6_1.html#plots-do-modelo",
    "title": "7  Lista 6.1 - Cox tempo dependente",
    "section": "7.6 Plots do modelo",
    "text": "7.6 Plots do modelo\n\nForest plot\n\n# Forest plots ================================================================\n# Visualise your Cox model results\nggforest(cox_res, data = db)\n\n\n\n\n\n\nGráfico de sobrevida\nAssim como fizemos no exercício anterior, precisamos criar um novo banco de dados para visualizar o gráfico da Regressão de Cox:\n\n# Precisa ser feito apenas com uma variável\ncox_res2 &lt;- coxph(Surv(time = db$time, event = db$morte) ~ treat, data = db)\n\n# Criando o novo banco de dados\nnew_df &lt;- with(db,\n               data.frame(treat = c(\"0\", \"1\"))\n)\n\nE precisamos transformar a variável treat em um fator.\n\nnew_df$treat = as.factor(new_df$treat)\nkable(new_df)\n\n\n\n\ntreat\n\n\n\n\n0\n\n\n1\n\n\n\n\n\n\n\nCriando os dados com base no modelo e plotando o gráfico.\n\nfit_cox &lt;- survfit(cox_res2, newdata = new_df)\n\nJ = ggsurvplot(fit_cox, conf.int = TRUE, legend.labs=c(\"tx=sim\", \"tx=não\"),\n           ggtheme = theme_minimal(),\n           data = db)\n\nJ$plot = J$plot +\n  scale_x_continuous(breaks = seq(0, 900, 20))\n\nScale for x is already present.\nAdding another scale for x, which will replace the existing scale.\n\nJ\n\n\n\n\nReparem na distorção do gráfico em relação à Kaplan-Meir\n\nkm_plot"
  },
  {
    "objectID": "lista_6_1.html#cox-tempo-dependente",
    "href": "lista_6_1.html#cox-tempo-dependente",
    "title": "7  Lista 6.1 - Cox tempo dependente",
    "section": "7.7 Cox tempo-dependente",
    "text": "7.7 Cox tempo-dependente\nJá vimos que os riscos não são proporcionais neste caso. Porém, nem tudo está perdido. Podemos finalmente agora falar da Cox Tempo-dependente.\nO primeiro passo é identificar um possível fator que esteja afetando a proporcionalidade dos riscos no estudo. Pela literatura tempos que o tempo em diálise afeta os riscos entre pessoas que fizeram ou não o transplante de rim. Daí a importância de entender bem o fenômeno que estamos estudando. Como bons pesquisadores, também coletamos o tempo em diálise e esses dados estão no banco de dados\n\nglimpse(db$Tempo_dialise)\n\n num [1:628] 51 67 88 156 12 139 90 25 187 34 ...\n\n\nA variável é numérica e contínua, logo ela já está formatada para continuarmos com a análise.\nNão existe regras escritas na pedra para contornar o problema de não proporcionalidade. Vamos mostrar uma abordagem aqui. Não deixe de ver as referências para outros casos.\n\nCovariáveis tempo dependente\nNo R, há diversas formas de indicar uma variável como tempo-dependente. A escolha do método dependerá da natureza da variável independente e da sua relação teórica com o evento em estudo. A função coxph() oferece a opção de utilizar o argumento tt(), o qual especifica qual variável independente será considerada uma covariável tempo-dependente e como o coeficiente associado a ela deve ser modificado ao longo do tempo.\nO modelo deve seguir a seguinte estrutura\ncoxph(Surv(time, event) ~ covariavel1 + covariavel2 + tt(covariavel2), data, tt=function(x,t,…) x*t)\nPodemos substituir o Surv(time, event) pela variável que salvamos com o objeto survival, surv_obj.\nA função tt (function(x,t,…)___) pode assumir alguns modelos. A seguir trazemos três exemplos mais utilizados em diversas análises:\n\nx*t permitirá que o coeficiente mude linearmente com o tempo\nx*log(t) permite que o coeficiente mude com o log do tempo\nx*(t&gt;tempo) permite que o coeficiente assuma 2 valores diferentes, um valor quando t&lt;=tempo e outro valor t&gt;tempo\n\nVamos gerar vários modelos e avaliá-los comparando os índices de ajuste e os resultados obtidos.\n\n\nSem variável tempo dependente\n\ndialise &lt;- coxph(surv_obj ~ treat + Tempo_dialise, \n                          data=db) # corte no 660\n\nsummary(dialise)\n\nCall:\ncoxph(formula = surv_obj ~ treat + Tempo_dialise, data = db)\n\n  n= 628, number of events= 508 \n\n                    coef  exp(coef)   se(coef)       z            Pr(&gt;|z|)    \ntreat1         0.0618983  1.0638541  0.0899990   0.688               0.492    \nTempo_dialise -0.0084493  0.9915863  0.0007709 -10.960 &lt;0.0000000000000002 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n              exp(coef) exp(-coef) lower .95 upper .95\ntreat1           1.0639      0.940    0.8918    1.2691\nTempo_dialise    0.9916      1.008    0.9901    0.9931\n\nConcordance= 0.75  (se = 0.012 )\nLikelihood ratio test= 151.4  on 2 df,   p=&lt;0.0000000000000002\nWald test            = 121.2  on 2 df,   p=&lt;0.0000000000000002\nScore (logrank) test = 120.6  on 2 df,   p=&lt;0.0000000000000002\n\n\n\n\nMudança linear\n\ndialise_linear &lt;- coxph(surv_obj ~ treat + Tempo_dialise + tt(Tempo_dialise),\n                        data=db,\n                          tt=function(x,t,...) x*t) \nsummary(dialise_linear)\n\nCall:\ncoxph(formula = surv_obj ~ treat + Tempo_dialise + tt(Tempo_dialise), \n    data = db, tt = function(x, t, ...) x * t)\n\n  n= 628, number of events= 508 \n\n                          coef    exp(coef)     se(coef)       z\ntreat1            -0.016001236  0.984126103  0.091676088  -0.175\nTempo_dialise     -0.023777102  0.976503346  0.001506128 -15.787\ntt(Tempo_dialise)  0.000070699  1.000070701  0.000005184  13.637\n                             Pr(&gt;|z|)    \ntreat1                          0.861    \nTempo_dialise     &lt;0.0000000000000002 ***\ntt(Tempo_dialise) &lt;0.0000000000000002 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n                  exp(coef) exp(-coef) lower .95 upper .95\ntreat1               0.9841     1.0161    0.8223    1.1778\nTempo_dialise        0.9765     1.0241    0.9736    0.9794\ntt(Tempo_dialise)    1.0001     0.9999    1.0001    1.0001\n\nConcordance= 0.761  (se = 0.009 )\nLikelihood ratio test= 337.6  on 3 df,   p=&lt;0.0000000000000002\nWald test            = 249.3  on 3 df,   p=&lt;0.0000000000000002\nScore (logrank) test = 229.1  on 3 df,   p=&lt;0.0000000000000002\n\n\n\n\nModelo log\n\ndialise_log &lt;- coxph(surv_obj ~ treat + Tempo_dialise + tt(Tempo_dialise),\n                          data=db,\n                          tt=function(x,t,...) x*log(t)) \n\nsummary(dialise_log)\n\nCall:\ncoxph(formula = surv_obj ~ treat + Tempo_dialise + tt(Tempo_dialise), \n    data = db, tt = function(x, t, ...) x * log(t))\n\n  n= 628, number of events= 508 \n\n                       coef exp(coef)  se(coef)      z            Pr(&gt;|z|)    \ntreat1            -0.071106  0.931363  0.092369  -0.77               0.441    \nTempo_dialise     -0.097417  0.907178  0.005942 -16.40 &lt;0.0000000000000002 ***\ntt(Tempo_dialise)  0.017178  1.017326  0.001087  15.80 &lt;0.0000000000000002 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n                  exp(coef) exp(-coef) lower .95 upper .95\ntreat1               0.9314      1.074    0.7771    1.1162\nTempo_dialise        0.9072      1.102    0.8967    0.9178\ntt(Tempo_dialise)    1.0173      0.983    1.0152    1.0195\n\nConcordance= 0.759  (se = 0.01 )\nLikelihood ratio test= 461.5  on 3 df,   p=&lt;0.0000000000000002\nWald test            = 284.6  on 3 df,   p=&lt;0.0000000000000002\nScore (logrank) test = 223.9  on 3 df,   p=&lt;0.0000000000000002\n\n\n\n\nModelo temporal\n\ndialise_tempo_650 &lt;- coxph(surv_obj ~ treat + Tempo_dialise + tt(Tempo_dialise),\n                          data=db,\n                          tt=function(x,t,...) x*(t&gt;650))\n\nsummary(dialise_tempo_650)\n\nCall:\ncoxph(formula = surv_obj ~ treat + Tempo_dialise + tt(Tempo_dialise), \n    data = db, tt = function(x, t, ...) x * (t &gt; 650))\n\n  n= 628, number of events= 508 \n\n                        coef  exp(coef)   se(coef)       z            Pr(&gt;|z|)\ntreat1             0.0617615  1.0637086  0.0900051   0.686               0.493\nTempo_dialise     -0.0084524  0.9915832  0.0007713 -10.958 &lt;0.0000000000000002\ntt(Tempo_dialise)  0.0028519  1.0028560  0.0221016   0.129               0.897\n                     \ntreat1               \nTempo_dialise     ***\ntt(Tempo_dialise)    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n                  exp(coef) exp(-coef) lower .95 upper .95\ntreat1               1.0637     0.9401    0.8917    1.2689\nTempo_dialise        0.9916     1.0085    0.9901    0.9931\ntt(Tempo_dialise)    1.0029     0.9972    0.9603    1.0473\n\nConcordance= 0.75  (se = 0.01 )\nLikelihood ratio test= 151.5  on 3 df,   p=&lt;0.0000000000000002\nWald test            = 121.2  on 3 df,   p=&lt;0.0000000000000002\nScore (logrank) test = 120.6  on 3 df,   p=&lt;0.0000000000000002\n\n\n\n\nÍndices de aderência (AIC e BIC)\nPodemos comparar os modelos computando os valores de AIC e BIC\n\ncombined_df &lt;- data.frame(\n  Model = c(\"dialise\", \"dialise_linear\", \"dialise_log\", \"dialise_tempo_650\"),\n  AIC = c(AIC(dialise), AIC(dialise_linear), AIC(dialise_log), AIC(dialise_tempo_650)),\n  BIC = c(BIC(dialise), BIC(dialise_linear), BIC(dialise_log), BIC(dialise_tempo_650))\n)\n\nkable(combined_df)\n\n\n\n\nModel\nAIC\nBIC\n\n\n\n\ndialise\n5771.688\n5780.149\n\n\ndialise_linear\n5587.564\n5600.256\n\n\ndialise_log\n5463.651\n5476.343\n\n\ndialise_tempo_650\n5773.672\n5786.363\n\n\n\n\n\n\n\nPor esse critério, temos que o melhor modelo é o log em seguida o linear.\n\n\nResíduos de Schoenfeld\nAgora vamos analisar mais uma vez os resíduos de Schoenfeld, mas agora variando pelo “Tempo em Diálise”.\n\ncox_res_T_Cov &lt;- coxph(Surv(time = db$time, event = db$morte) ~ treat + Tempo_dialise, data = db)  \nggcoxzph(cox.zph(cox_res_T_Cov), var =\"Tempo_dialise\") \n\n\n\n\nPodemos observar que o Beta do tempo em diálise tem um aumento linear conforme maior o tempo. O resultado pode indicar que o efeito do tempo sobre a o tempo em diálise pode ser linear.\n\n\nInterpretando os resultados.\nA interpretação dos coeficientes da Cox Tempo-dependente é diferente das outras regressõs.\nVamos interpretar o valor do modelo com mudança linear.\n\nsummary(dialise_linear)\n\nCall:\ncoxph(formula = surv_obj ~ treat + Tempo_dialise + tt(Tempo_dialise), \n    data = db, tt = function(x, t, ...) x * t)\n\n  n= 628, number of events= 508 \n\n                          coef    exp(coef)     se(coef)       z\ntreat1            -0.016001236  0.984126103  0.091676088  -0.175\nTempo_dialise     -0.023777102  0.976503346  0.001506128 -15.787\ntt(Tempo_dialise)  0.000070699  1.000070701  0.000005184  13.637\n                             Pr(&gt;|z|)    \ntreat1                          0.861    \nTempo_dialise     &lt;0.0000000000000002 ***\ntt(Tempo_dialise) &lt;0.0000000000000002 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n                  exp(coef) exp(-coef) lower .95 upper .95\ntreat1               0.9841     1.0161    0.8223    1.1778\nTempo_dialise        0.9765     1.0241    0.9736    0.9794\ntt(Tempo_dialise)    1.0001     0.9999    1.0001    1.0001\n\nConcordance= 0.761  (se = 0.009 )\nLikelihood ratio test= 337.6  on 3 df,   p=&lt;0.0000000000000002\nWald test            = 249.3  on 3 df,   p=&lt;0.0000000000000002\nScore (logrank) test = 229.1  on 3 df,   p=&lt;0.0000000000000002\n\n\nO coeficiente Tempo_dialise = -0.023, deve ser interpretado como o efeito do tempo de diálise no tempo zero. Já o coeficiente tt(Tempo_dialise) = deve ser interpretado como o a mudança do efeito do tempo em diálise a cada unidade de tempo a mais.\n\n\nObservações SPSS e R\nNa aula prática o modelo não é feito com o Tempo em Diálise fora da variável tempo dependente. Já na aula teórica do curso II de 2023, o modelo é escrito como foi feito aqui no R, levando em conta o Tempo em Diálise como uma variável tempo dependente e também como covariável no modelo."
  },
  {
    "objectID": "lista_6_1.html#covariando-para-idade-e-raça",
    "href": "lista_6_1.html#covariando-para-idade-e-raça",
    "title": "7  Lista 6.1 - Cox tempo dependente",
    "section": "7.8 Covariando para idade e raça",
    "text": "7.8 Covariando para idade e raça\nO conjunto de dados ainda possui duas variáveis que não foram incluídas no modelo: idade e raça. Conforme o procedimento padrão, vamos examinar a natureza dessas variáveis. Começando com a idade.\n\nglimpse(db)\n\nRows: 628\nColumns: 7\n$ ID            &lt;dbl&gt; 112, 91, 113, 150, 22, 139, 104, 590, 189, 171, 338, 492…\n$ age           &lt;dbl&gt; 35, 33, 35, 31, 33, 43, 25, 35, 29, 27, 35, 23, 24, 23, …\n$ race          &lt;fct&gt; branco, branco, branco, branco, branco, branco, branco, …\n$ treat         &lt;fct&gt; 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1,…\n$ Tempo_dialise &lt;dbl&gt; 51, 67, 88, 156, 12, 139, 90, 25, 187, 34, 29, 78, 63, 8…\n$ time          &lt;dbl&gt; 1172, 762, 734, 720, 659, 658, 655, 654, 634, 630, 621, …\n$ morte         &lt;int&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n\n\nÓtimo, idade já está como uma variável numérica e contínua e raça está como um fator. Por fim, vamos verificar qual o nível de referência da variável “race”.\n\nlevels(db$race)\n\n[1] \"branco\"      \"negro/pardo\"\n\n\nO nível “branco” está como referência, logo, os resultados do modelo mostrarão os valores dos coeficientes do nível “negro/pardo” em relação ao nível “branco”.\nVamos ao modelo completo.\n\nModelo completo Cox tempo dependente\n\ncox_full_model &lt;- coxph(surv_obj ~ age + race + treat + Tempo_dialise + tt(Tempo_dialise),\n                        data=db,\n                          tt=function(x,t,...) x*t) \nsummary(cox_full_model)\n\nCall:\ncoxph(formula = surv_obj ~ age + race + treat + Tempo_dialise + \n    tt(Tempo_dialise), data = db, tt = function(x, t, ...) x * \n    t)\n\n  n= 617, number of events= 500 \n   (11 observations deleted due to missingness)\n\n                          coef    exp(coef)     se(coef)       z\nage               -0.005531327  0.994483942  0.007272881  -0.761\nracenegro/pardo   -0.342009991  0.710341107  0.108147939  -3.162\ntreat1             0.042207387  1.043110784  0.093368582   0.452\nTempo_dialise     -0.023671737  0.976606241  0.001511519 -15.661\ntt(Tempo_dialise)  0.000068807  1.000068809  0.000005196  13.242\n                              Pr(&gt;|z|)    \nage                            0.44693    \nracenegro/pardo                0.00156 ** \ntreat1                         0.65123    \nTempo_dialise     &lt; 0.0000000000000002 ***\ntt(Tempo_dialise) &lt; 0.0000000000000002 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n                  exp(coef) exp(-coef) lower .95 upper .95\nage                  0.9945     1.0055    0.9804    1.0088\nracenegro/pardo      0.7103     1.4078    0.5747    0.8781\ntreat1               1.0431     0.9587    0.8687    1.2526\nTempo_dialise        0.9766     1.0240    0.9737    0.9795\ntt(Tempo_dialise)    1.0001     0.9999    1.0001    1.0001\n\nConcordance= 0.765  (se = 0.009 )\nLikelihood ratio test= 343.2  on 5 df,   p=&lt;0.0000000000000002\nWald test            = 259.4  on 5 df,   p=&lt;0.0000000000000002\nScore (logrank) test = 243.3  on 5 df,   p=&lt;0.0000000000000002\n\n\nAgora temos que a raça tem um efeito significativo no modelo. Seguindo o vídeo da aula prática, podemos segmentar o banco de dados para as duas raças que temos no banco de dados.\n\n\nSegmentando o banco de dados por raça\n\ndb_branco = db %&gt;%\n  filter(race == \"branco\")\n\ndb_pardo_negro = db %&gt;% \n  filter(race == \"negro/pardo\")\n\n\n\nKM por raça = Branco\n\n# Criando um novo objeto Surv\nsurv_obj_branco &lt;- Surv(time = db_branco$time, event = db_branco$morte)\n\nfit_br = survfit(surv_obj_branco ~ treat, data = db_branco)\nggsurvfit(fit_br)\n\n\n\nggsurvfit(fit_br, linewidth = 1) +\n  labs(x = 'Dias', y = 'Overall survival') +\n  add_confidence_interval() +\n # add_risktable() +\n  scale_ggsurvfit() + \n  biostatsquid_theme #+  coord_cartesian(xlim = c(0, 8))\n\n\n\n\n\n\nModelo completo para brancos\n\n# Escrevendo o modelo\n\ncox_full_model_branco &lt;- coxph(surv_obj_branco ~ age + treat + Tempo_dialise + tt(Tempo_dialise),\n                        data=db_branco,\n                          tt=function(x,t,...) x*t) \n\nsummary(cox_full_model_branco)\n\nCall:\ncoxph(formula = surv_obj_branco ~ age + treat + Tempo_dialise + \n    tt(Tempo_dialise), data = db_branco, tt = function(x, t, \n    ...) x * t)\n\n  n= 464, number of events= 385 \n   (3 observations deleted due to missingness)\n\n                          coef    exp(coef)     se(coef)      z\nage               -0.000811624  0.999188705  0.008137628  -0.10\ntreat1             0.028995294  1.029419750  0.107276897   0.27\nTempo_dialise     -0.024166842  0.976122838  0.001707544 -14.15\ntt(Tempo_dialise)  0.000070240  1.000070242  0.000005841  12.03\n                             Pr(&gt;|z|)    \nage                             0.921    \ntreat1                          0.787    \nTempo_dialise     &lt;0.0000000000000002 ***\ntt(Tempo_dialise) &lt;0.0000000000000002 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n                  exp(coef) exp(-coef) lower .95 upper .95\nage                  0.9992     1.0008    0.9834    1.0153\ntreat1               1.0294     0.9714    0.8342    1.2703\nTempo_dialise        0.9761     1.0245    0.9729    0.9794\ntt(Tempo_dialise)    1.0001     0.9999    1.0001    1.0001\n\nConcordance= 0.78  (se = 0.01 )\nLikelihood ratio test= 286.5  on 4 df,   p=&lt;0.0000000000000002\nWald test            = 201.8  on 4 df,   p=&lt;0.0000000000000002\nScore (logrank) test = 185.6  on 4 df,   p=&lt;0.0000000000000002\n\n\n\n\nKM por raça = negro/pardo\n\n# Criando um novo objeto Surv\n\nsurv_obj_pardo_negro&lt;- Surv(time = db_pardo_negro$time, event = db_pardo_negro$morte)\n\nfit_pn = survfit(surv_obj_pardo_negro ~ treat, data = db_pardo_negro)\n\nggsurvfit(fit_pn, linewidth = 1) +\n  labs(x = 'Dias', y = 'Overall survival') +\n  add_confidence_interval() +\n # add_risktable() +\n  scale_ggsurvfit() + \n  biostatsquid_theme #+  coord_cartesian(xlim = c(0, 8))\n\n\n\n\n\n\nModelo completo para pardo/negro\n\n# Escrevendo o modelo\n\ncox_full_model_pardo_negro &lt;- coxph(surv_obj_pardo_negro ~ age + treat + Tempo_dialise + tt(Tempo_dialise),\n                        data=db_pardo_negro,\n                          tt=function(x,t,...) x*t) \n\nsummary(cox_full_model_pardo_negro)\n\nCall:\ncoxph(formula = surv_obj_pardo_negro ~ age + treat + Tempo_dialise + \n    tt(Tempo_dialise), data = db_pardo_negro, tt = function(x, \n    t, ...) x * t)\n\n  n= 153, number of events= 115 \n   (2 observations deleted due to missingness)\n\n                         coef   exp(coef)    se(coef)      z      Pr(&gt;|z|)    \nage               -0.02336224  0.97690855  0.01673857 -1.396         0.163    \ntreat1             0.07806397  1.08119182  0.19431411  0.402         0.688    \nTempo_dialise     -0.02367178  0.97660620  0.00397339 -5.958 0.00000000256 ***\ntt(Tempo_dialise)  0.00007639  1.00007639  0.00001784  4.282 0.00001853157 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n                  exp(coef) exp(-coef) lower .95 upper .95\nage                  0.9769     1.0236    0.9454    1.0095\ntreat1               1.0812     0.9249    0.7388    1.5824\nTempo_dialise        0.9766     1.0240    0.9690    0.9842\ntt(Tempo_dialise)    1.0001     0.9999    1.0000    1.0001\n\nConcordance= 0.696  (se = 0.025 )\nLikelihood ratio test= 48.53  on 4 df,   p=0.0000000007\nWald test            = 39.77  on 4 df,   p=0.00000005\nScore (logrank) test = 42.56  on 4 df,   p=0.00000001"
  },
  {
    "objectID": "lista_6_1.html#lista-6.1-resolvida-no-spss",
    "href": "lista_6_1.html#lista-6.1-resolvida-no-spss",
    "title": "7  Lista 6.1 - Cox tempo dependente",
    "section": "7.9 Lista 6.1 resolvida no SPSS",
    "text": "7.9 Lista 6.1 resolvida no SPSS"
  },
  {
    "objectID": "lista_6_1.html#extras",
    "href": "lista_6_1.html#extras",
    "title": "7  Lista 6.1 - Cox tempo dependente",
    "section": "7.10 Extras",
    "text": "7.10 Extras\n\nMais gráficos\nE utilizar nosso tema para personalizar e padronizar.\n\nfit2_km &lt;- ggsurvfit(fit1, linewidth = 1) +\n  labs(x = 'Dias', y = 'Porcentagem de sobrevida') +\n  add_confidence_interval() +\n # add_risktable() +\n  scale_ggsurvfit() + \n  biostatsquid_theme #+  coord_cartesian(xlim = c(0, 8))\n\nfit2_km\n\n\n\n\nCuidado com o p-value do gráfico a seguir, ele se refere apenas ao Log-rank\n\nggsurvplot(fit1, data = db,\n           size = 1,\n           palette = c('#E7B800', '#2e9fdf'),\n           censor.shape = '|', censor.size = 4,\n           conf.int = TRUE,\n           pval = TRUE, # CUIDADO, apenas log-rank\n          # risk.table = TRUE,\n         #  risk.table.col = 'strata',\n           legend.labs = list('0' = 'Transplante = sim', '1' = 'Transplante = não'),\n           risk.table.height = 0.25,\n           ggtheme = theme_bw())\n\n\n\n\n\n\nCox tempo dependente log\n\ncox_full_model_2 &lt;- coxph(surv_obj ~ age + race + treat + Tempo_dialise + tt(Tempo_dialise),\n                        data=db,\n                          tt=function(x,t,...) x*log(t)) \nsummary(cox_full_model_2)\n\nCall:\ncoxph(formula = surv_obj ~ age + race + treat + Tempo_dialise + \n    tt(Tempo_dialise), data = db, tt = function(x, t, ...) x * \n    log(t))\n\n  n= 617, number of events= 500 \n   (11 observations deleted due to missingness)\n\n                       coef exp(coef)  se(coef)       z             Pr(&gt;|z|)\nage               -0.005656  0.994360  0.007318  -0.773              0.43960\nracenegro/pardo   -0.296846  0.743159  0.108704  -2.731              0.00632\ntreat1            -0.007682  0.992348  0.094183  -0.082              0.93499\nTempo_dialise     -0.096272  0.908217  0.005996 -16.056 &lt; 0.0000000000000002\ntt(Tempo_dialise)  0.016885  1.017028  0.001098  15.383 &lt; 0.0000000000000002\n                     \nage                  \nracenegro/pardo   ** \ntreat1               \nTempo_dialise     ***\ntt(Tempo_dialise) ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n                  exp(coef) exp(-coef) lower .95 upper .95\nage                  0.9944     1.0057    0.9802    1.0087\nracenegro/pardo      0.7432     1.3456    0.6006    0.9196\ntreat1               0.9923     1.0077    0.8251    1.1935\nTempo_dialise        0.9082     1.1011    0.8976    0.9190\ntt(Tempo_dialise)    1.0170     0.9833    1.0148    1.0192\n\nConcordance= 0.764  (se = 0.009 )\nLikelihood ratio test= 459.7  on 5 df,   p=&lt;0.0000000000000002\nWald test            = 290.9  on 5 df,   p=&lt;0.0000000000000002\nScore (logrank) test = 237.8  on 5 df,   p=&lt;0.0000000000000002\n\nAIC(cox_full_model_2)\n\n[1] 5356.724"
  },
  {
    "objectID": "lista_6_1.html#referencias",
    "href": "lista_6_1.html#referencias",
    "title": "7  Lista 6.1 - Cox tempo dependente",
    "section": "7.11 Referencias",
    "text": "7.11 Referencias\nhttps://stats.oarc.ucla.edu/wp-content/uploads/2022/05/survival_r.html#(48)\nhttps://www.youtube.com/watch?v=Y_83HXuHMdc\nhttps://youtu.be/Y_83HXuHMdc?t=9151"
  },
  {
    "objectID": "lista_6_1.html#códigos-não-utilizados",
    "href": "lista_6_1.html#códigos-não-utilizados",
    "title": "7  Lista 6.1 - Cox tempo dependente",
    "section": "7.12 Códigos não utilizados",
    "text": "7.12 Códigos não utilizados\n\n# Ajustando o banco de dados\n\ndb3 = db\n\n\n# db3$time = pmax(0.5, db3$time - 0) caso eu tenha zeros no tempo de morte\n# db3$time660 = as.integer(db3$time660)\n# head(db3)\n\n# db3$time660 = as.integer(db3$time660)\n\ndb3 &lt;- tmerge(\n  data1 = db3,\n  data2 = db3,\n  id = ID,\n # death = event(T1, delta1), caso tenha dois eventos de morte independentes. Duas doenças diferentes, por exemplo\n  death = event(time, morte),\n  T_Cov = tdc(Tempo_dialise) # indicando a covariavel tempo-dependente\n)\n\nhead(db3)\n\n   ID age   race treat Tempo_dialise time morte tstart tstop death T_Cov\n1 112  35 branco     1            51 1172     0      0    51     0     0\n2 112  35 branco     1            51 1172     0     51  1172     0     1\n3  91  33 branco     0            67  762     0      0    67     0     0\n4  91  33 branco     0            67  762     0     67   762     0     1\n5 113  35 branco     0            88  734     0      0    88     0     0\n6 113  35 branco     0            88  734     0     88   734     0     1\n\n\n\n# Duvida para Altay - colocar o evento como morte2 ou death\ncox_model_T_Cov &lt;- coxph(Surv(time = tstart, time2 = tstop, event = morte) ~ treat + T_Cov, data = db3)\n\nsummary(cox_model_T_Cov)\n\nCall:\ncoxph(formula = Surv(time = tstart, time2 = tstop, event = morte) ~ \n    treat + T_Cov, data = db3)\n\n  n= 1174, number of events= 934 \n\n           coef exp(coef) se(coef)      z Pr(&gt;|z|)   \ntreat1 -0.17205   0.84194  0.06668 -2.580  0.00987 **\nT_Cov   0.03829   1.03903  0.08493  0.451  0.65210   \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n       exp(coef) exp(-coef) lower .95 upper .95\ntreat1    0.8419     1.1877    0.7388    0.9595\nT_Cov     1.0390     0.9624    0.8797    1.2272\n\nConcordance= 0.539  (se = 0.01 )\nLikelihood ratio test= 7.53  on 2 df,   p=0.02\nWald test            = 7.53  on 2 df,   p=0.02\nScore (logrank) test = 7.54  on 2 df,   p=0.02\n\ndb3 %&gt;% \n  coxph(Surv(time = tstart, time2 = tstop, event = death) ~ treat + age + race + T_Cov, data = .) %&gt;% \n  gtsummary::tbl_regression(exp = TRUE)\n\n\n\n\n\n  \n    \n    \n      Characteristic\n      HR1\n      95% CI1\n      p-value\n    \n  \n  \n    treat\n\n\n\n        0\n—\n—\n\n        1\n1.05\n0.88, 1.25\n0.6\n    age\n1.00\n0.98, 1.01\n0.5\n    race\n\n\n\n        branco\n—\n—\n\n        negro/pardo\n0.68\n0.55, 0.84\n&lt;0.001\n    T_Cov\n13.6\n10.1, 18.4\n&lt;0.001\n  \n  \n  \n    \n      1 HR = Hazard Ratio, CI = Confidence Interval\n    \n  \n\n\n\n\n\nTempo em diálise como covariante tempo-dependente\n\n# Ajustando o banco de dados\n\ndb2 = db\n\n\n#db2$time = pmax(0.5, db2$time - 0)\n\n\ndb2 &lt;- tmerge(\n  data1 = db,\n  data2 = db,\n  id = ID,\n # death = event(T1, delta1), caso tenha dois eventos de morte independentes. Duas doenças diferentes, por exemplo\n  death = event(time, morte),\n  T_Tempo_dialise = tdc(Tempo_dialise) # indicando a covariavel tempo-dependente\n)\nhead(db2)\n\n   ID age   race treat Tempo_dialise time morte tstart tstop death\n1 112  35 branco     1            51 1172     0      0    51     0\n2 112  35 branco     1            51 1172     0     51  1172     0\n3  91  33 branco     0            67  762     0      0    67     0\n4  91  33 branco     0            67  762     0     67   762     0\n5 113  35 branco     0            88  734     0      0    88     0\n6 113  35 branco     0            88  734     0     88   734     0\n  T_Tempo_dialise\n1               0\n2               1\n3               0\n4               1\n5               0\n6               1\n\n\n\ncox_model_time_dependent &lt;- coxph(Surv(time = tstart, time2 = tstop, event = death) ~ T_Tempo_dialise + treat, data = db2)\n\nsummary(cox_model_time_dependent)\n\nCall:\ncoxph(formula = Surv(time = tstart, time2 = tstop, event = death) ~ \n    T_Tempo_dialise + treat, data = db2)\n\n  n= 1174, number of events= 508 \n\n                     coef exp(coef)  se(coef)      z            Pr(&gt;|z|)    \nT_Tempo_dialise  2.585761 13.273384  0.150925 17.133 &lt;0.0000000000000002 ***\ntreat1          -0.003201  0.996804  0.089471 -0.036               0.971    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n                exp(coef) exp(-coef) lower .95 upper .95\nT_Tempo_dialise   13.2734    0.07534    9.8745    17.842\ntreat1             0.9968    1.00321    0.8365     1.188\n\nConcordance= 0.699  (se = 0.014 )\nLikelihood ratio test= 382.7  on 2 df,   p=&lt;0.0000000000000002\nWald test            = 294.6  on 2 df,   p=&lt;0.0000000000000002\nScore (logrank) test = 354.7  on 2 df,   p=&lt;0.0000000000000002\n\ndb2 %&gt;% \n  coxph(Surv(time = tstart, time2 = tstop, event = death) ~ T_Tempo_dialise * treat, data = .) %&gt;% \n  gtsummary::tbl_regression(exp = TRUE)\n\n\n\n\n\n  \n    \n    \n      Characteristic\n      HR1\n      95% CI1\n      p-value\n    \n  \n  \n    T_Tempo_dialise\n9.78\n6.78, 14.1\n&lt;0.001\n    treat\n\n\n\n        0\n—\n—\n\n        1\n0.59\n0.38, 0.92\n0.020\n    T_Tempo_dialise * treat\n\n\n\n        T_Tempo_dialise * 1\n1.86\n1.15, 3.02\n0.012\n  \n  \n  \n    \n      1 HR = Hazard Ratio, CI = Confidence Interval"
  },
  {
    "objectID": "lista_6_1.html#versões-dos-pacotes",
    "href": "lista_6_1.html#versões-dos-pacotes",
    "title": "7  Lista 6.1 - Cox tempo dependente",
    "section": "7.13 Versões dos pacotes",
    "text": "7.13 Versões dos pacotes\n\nreport(sessionInfo())\n\nAnalyses were conducted using the R Statistical language (version 4.3.1; R Core\nTeam, 2023) on Windows 11 x64 (build 22621), using the packages effectsize\n(version 0.8.6; Ben-Shachar MS et al., 2020), lpSolve (version 5.6.19;\nBerkelaar M, others, 2023), survMisc (version 0.5.6; Dardis C, 2022), tm\n(version 0.7.11; Feinerer I, Hornik K, 2023), flexplot (version 0.20.5; Fife D,\n2024), lubridate (version 1.9.3; Grolemund G, Wickham H, 2011), coxphf (version\n1.13.4; Heinze G et al., 2023), NLP (version 0.2.1; Hornik K, 2020), coin\n(version 1.4.3; Hothorn T et al., 2006), ggpubr (version 0.6.0; Kassambara A,\n2023), survminer (version 0.4.9; Kassambara A et al., 2021),\nPHInfiniteEstimates (version 2.9.5; Kolassa JE, Zhang J, 2023), parameters\n(version 0.21.3; Lüdecke D et al., 2020), performance (version 0.10.8; Lüdecke\nD et al., 2021), easystats (version 0.6.0; Lüdecke D et al., 2022), see\n(version 0.8.1; Lüdecke D et al., 2021), insight (version 0.19.6; Lüdecke D et\nal., 2019), bayestestR (version 0.13.1; Makowski D et al., 2019), modelbased\n(version 0.8.6; Makowski D et al., 2020), report (version 0.5.7; Makowski D et\nal., 2023), correlation (version 0.8.4; Makowski D et al., 2022), condSURV\n(version 2.0.4; Meira-Machado L, Sestelo M, 2023), tibble (version 3.2.1;\nMüller K, Wickham H, 2023), datawizard (version 0.9.0; Patil I et al., 2022),\nforeign (version 0.8.85; R Core Team, 2023), nph (version 2.1; Ristl R et al.,\n2021), broom (version 1.0.5; Robinson D et al., 2023), ggsurvfit (version\n1.0.0; Sjoberg D et al., 2023), gtsummary (version 1.7.2; Sjoberg D et al.,\n2021), rempsyc (version 0.1.6; Thériault R, 2023), survival (version 3.5.7;\nTherneau T, 2023), ggplot2 (version 3.4.4; Wickham H, 2016), forcats (version\n1.0.0; Wickham H, 2023), stringr (version 1.5.1; Wickham H, 2023), tidyverse\n(version 2.0.0; Wickham H et al., 2019), dplyr (version 1.1.3; Wickham H et\nal., 2023), purrr (version 1.0.2; Wickham H, Henry L, 2023), readr (version\n2.1.4; Wickham H et al., 2023), tidyr (version 1.3.0; Wickham H et al., 2023)\nand kableExtra (version 1.3.4; Zhu H, 2021).\n\nReferences\n----------\n  - Ben-Shachar MS, Lüdecke D, Makowski D (2020). \"effectsize: Estimation of\nEffect Size Indices and Standardized Parameters.\" _Journal of Open Source\nSoftware_, *5*(56), 2815. doi:10.21105/joss.02815\n&lt;https://doi.org/10.21105/joss.02815&gt;, &lt;https://doi.org/10.21105/joss.02815&gt;.\n  - Berkelaar M, others (2023). _lpSolve: Interface to 'Lp_solve' v. 5.5 to Solve\nLinear/Integer Programs_. R package version 5.6.19,\n&lt;https://CRAN.R-project.org/package=lpSolve&gt;.\n  - Dardis C (2022). _survMisc: Miscellaneous Functions for Survival Data_. R\npackage version 0.5.6, &lt;https://CRAN.R-project.org/package=survMisc&gt;.\n  - Feinerer I, Hornik K (2023). _tm: Text Mining Package_. R package version\n0.7-11, &lt;https://CRAN.R-project.org/package=tm&gt;. Feinerer I, Hornik K, Meyer D\n(2008). \"Text Mining Infrastructure in R.\" _Journal of Statistical Software_,\n*25*(5), 1-54. doi:10.18637/jss.v025.i05\n&lt;https://doi.org/10.18637/jss.v025.i05&gt;.\n  - Fife D (2024). _flexplot: Graphically Based Data Analysis Using 'flexplot'_.\nR package version 0.20.5.\n  - Grolemund G, Wickham H (2011). \"Dates and Times Made Easy with lubridate.\"\n_Journal of Statistical Software_, *40*(3), 1-25.\n&lt;https://www.jstatsoft.org/v40/i03/&gt;.\n  - Heinze G, Ploner M, Jiricka L, Steiner G (2023). _coxphf: Cox Regression with\nFirth's Penalized Likelihood_. R package version 1.13.4,\n&lt;https://CRAN.R-project.org/package=coxphf&gt;.\n  - Hornik K (2020). _NLP: Natural Language Processing Infrastructure_. R package\nversion 0.2-1, &lt;https://CRAN.R-project.org/package=NLP&gt;.\n  - Hothorn T, Hornik K, van de Wiel MA, Zeileis A (2006). \"A Lego system for\nconditional inference.\" _The American Statistician_, *60*(3), 257-263.\ndoi:10.1198/000313006X118430 &lt;https://doi.org/10.1198/000313006X118430&gt;.\nHothorn T, Hornik K, van de Wiel MA, Zeileis A (2008). \"Implementing a class of\npermutation tests: The coin package.\" _Journal of Statistical Software_,\n*28*(8), 1-23. doi:10.18637/jss.v028.i08\n&lt;https://doi.org/10.18637/jss.v028.i08&gt;.\n  - Kassambara A (2023). _ggpubr: 'ggplot2' Based Publication Ready Plots_. R\npackage version 0.6.0, &lt;https://CRAN.R-project.org/package=ggpubr&gt;.\n  - Kassambara A, Kosinski M, Biecek P (2021). _survminer: Drawing Survival\nCurves using 'ggplot2'_. R package version 0.4.9,\n&lt;https://CRAN.R-project.org/package=survminer&gt;.\n  - Kolassa JE, Zhang J (2023). _PHInfiniteEstimates: Tools for Inference in the\nPresence of a Monotone Likelihood_. R package version 2.9.5,\n&lt;https://CRAN.R-project.org/package=PHInfiniteEstimates&gt;.\n  - Lüdecke D, Ben-Shachar M, Patil I, Makowski D (2020). \"Extracting, Computing\nand Exploring the Parameters of Statistical Models using R.\" _Journal of Open\nSource Software_, *5*(53), 2445. doi:10.21105/joss.02445\n&lt;https://doi.org/10.21105/joss.02445&gt;.\n  - Lüdecke D, Ben-Shachar M, Patil I, Waggoner P, Makowski D (2021).\n\"performance: An R Package for Assessment, Comparison and Testing of\nStatistical Models.\" _Journal of Open Source Software_, *6*(60), 3139.\ndoi:10.21105/joss.03139 &lt;https://doi.org/10.21105/joss.03139&gt;.\n  - Lüdecke D, Ben-Shachar M, Patil I, Wiernik B, Makowski D (2022). \"easystats:\nFramework for Easy Statistical Modeling, Visualization, and Reporting.\" _CRAN_.\nR package, &lt;https://easystats.github.io/easystats/&gt;.\n  - Lüdecke D, Patil I, Ben-Shachar M, Wiernik B, Waggoner P, Makowski D (2021).\n\"see: An R Package for Visualizing Statistical Models.\" _Journal of Open Source\nSoftware_, *6*(64), 3393. doi:10.21105/joss.03393\n&lt;https://doi.org/10.21105/joss.03393&gt;.\n  - Lüdecke D, Waggoner P, Makowski D (2019). \"insight: A Unified Interface to\nAccess Information from Model Objects in R.\" _Journal of Open Source Software_,\n*4*(38), 1412. doi:10.21105/joss.01412 &lt;https://doi.org/10.21105/joss.01412&gt;.\n  - Makowski D, Ben-Shachar M, Lüdecke D (2019). \"bayestestR: Describing Effects\nand their Uncertainty, Existence and Significance within the Bayesian\nFramework.\" _Journal of Open Source Software_, *4*(40), 1541.\ndoi:10.21105/joss.01541 &lt;https://doi.org/10.21105/joss.01541&gt;,\n&lt;https://joss.theoj.org/papers/10.21105/joss.01541&gt;.\n  - Makowski D, Ben-Shachar M, Patil I, Lüdecke D (2020). \"Estimation of\nModel-Based Predictions, Contrasts and Means.\" _CRAN_.\n&lt;https://github.com/easystats/modelbased&gt;.\n  - Makowski D, Lüdecke D, Patil I, Thériault R, Ben-Shachar M, Wiernik B (2023).\n\"Automated Results Reporting as a Practical Tool to Improve Reproducibility and\nMethodological Best Practices Adoption.\" _CRAN_.\n&lt;https://easystats.github.io/report/&gt;.\n  - Makowski D, Wiernik B, Patil I, Lüdecke D, Ben-Shachar M (2022).\n\"correlation: Methods for Correlation Analysis.\" Version 0.8.3,\n&lt;https://CRAN.R-project.org/package=correlation&gt;. Makowski D, Ben-Shachar M,\nPatil I, Lüdecke D (2020). \"Methods and Algorithms for Correlation Analysis in\nR.\" _Journal of Open Source Software_, *5*(51), 2306. doi:10.21105/joss.02306\n&lt;https://doi.org/10.21105/joss.02306&gt;,\n&lt;https://joss.theoj.org/papers/10.21105/joss.02306&gt;.\n  - Meira-Machado L, Sestelo M (2023). _condSURV: Estimation of the Conditional\nSurvival Function for Ordered Multivariate Failure Time Data_. R package\nversion 2.0.4, &lt;https://CRAN.R-project.org/package=condSURV&gt;.\n  - Müller K, Wickham H (2023). _tibble: Simple Data Frames_. R package version\n3.2.1, &lt;https://CRAN.R-project.org/package=tibble&gt;.\n  - Patil I, Makowski D, Ben-Shachar M, Wiernik B, Bacher E, Lüdecke D (2022).\n\"datawizard: An R Package for Easy Data Preparation and Statistical\nTransformations.\" _Journal of Open Source Software_, *7*(78), 4684.\ndoi:10.21105/joss.04684 &lt;https://doi.org/10.21105/joss.04684&gt;.\n  - R Core Team (2023). _foreign: Read Data Stored by 'Minitab', 'S', 'SAS',\n'SPSS', 'Stata', 'Systat', 'Weka', 'dBase', ..._. R package version 0.8-85,\n&lt;https://CRAN.R-project.org/package=foreign&gt;.\n  - R Core Team (2023). _R: A Language and Environment for Statistical\nComputing_. R Foundation for Statistical Computing, Vienna, Austria.\n&lt;https://www.R-project.org/&gt;.\n  - Ristl R, Ballarini N, Götte H, Schüler A, Posch M, König F (2021). \"Delayed\ntreatment effects, treatment switching and heterogeneous patient populations:\nHow to design and analyze RCTs in oncology.\" _Pharmaceutical statistics_,\n*20*(1), 129-145.\n  - Robinson D, Hayes A, Couch S (2023). _broom: Convert Statistical Objects into\nTidy Tibbles_. R package version 1.0.5,\n&lt;https://CRAN.R-project.org/package=broom&gt;.\n  - Sjoberg D, Baillie M, Fruechtenicht C, Haesendonckx S, Treis T (2023).\n_ggsurvfit: Flexible Time-to-Event Figures_. R package version 1.0.0,\n&lt;https://CRAN.R-project.org/package=ggsurvfit&gt;.\n  - Sjoberg D, Whiting K, Curry M, Lavery J, Larmarange J (2021). \"Reproducible\nSummary Tables with the gtsummary Package.\" _The R Journal_, *13*, 570-580.\ndoi:10.32614/RJ-2021-053 &lt;https://doi.org/10.32614/RJ-2021-053&gt;,\n&lt;https://doi.org/10.32614/RJ-2021-053&gt;.\n  - Thériault R (2023). \"rempsyc: Convenience functions for psychology.\" _Journal\nof Open Source Software_, *8*(87), 5466. doi:10.21105/joss.05466\n&lt;https://doi.org/10.21105/joss.05466&gt;, &lt;https://doi.org/10.21105/joss.05466&gt;.\n  - Therneau T (2023). _A Package for Survival Analysis in R_. R package version\n3.5-7, &lt;https://CRAN.R-project.org/package=survival&gt;. Terry M. Therneau,\nPatricia M. Grambsch (2000). _Modeling Survival Data: Extending the Cox Model_.\nSpringer, New York. ISBN 0-387-98784-3.\n  - Wickham H (2016). _ggplot2: Elegant Graphics for Data Analysis_.\nSpringer-Verlag New York. ISBN 978-3-319-24277-4,\n&lt;https://ggplot2.tidyverse.org&gt;.\n  - Wickham H (2023). _forcats: Tools for Working with Categorical Variables\n(Factors)_. R package version 1.0.0,\n&lt;https://CRAN.R-project.org/package=forcats&gt;.\n  - Wickham H (2023). _stringr: Simple, Consistent Wrappers for Common String\nOperations_. R package version 1.5.1,\n&lt;https://CRAN.R-project.org/package=stringr&gt;.\n  - Wickham H, Averick M, Bryan J, Chang W, McGowan LD, François R, Grolemund G,\nHayes A, Henry L, Hester J, Kuhn M, Pedersen TL, Miller E, Bache SM, Müller K,\nOoms J, Robinson D, Seidel DP, Spinu V, Takahashi K, Vaughan D, Wilke C, Woo K,\nYutani H (2019). \"Welcome to the tidyverse.\" _Journal of Open Source Software_,\n*4*(43), 1686. doi:10.21105/joss.01686 &lt;https://doi.org/10.21105/joss.01686&gt;.\n  - Wickham H, François R, Henry L, Müller K, Vaughan D (2023). _dplyr: A Grammar\nof Data Manipulation_. R package version 1.1.3,\n&lt;https://CRAN.R-project.org/package=dplyr&gt;.\n  - Wickham H, Henry L (2023). _purrr: Functional Programming Tools_. R package\nversion 1.0.2, &lt;https://CRAN.R-project.org/package=purrr&gt;.\n  - Wickham H, Hester J, Bryan J (2023). _readr: Read Rectangular Text Data_. R\npackage version 2.1.4, &lt;https://CRAN.R-project.org/package=readr&gt;.\n  - Wickham H, Vaughan D, Girlich M (2023). _tidyr: Tidy Messy Data_. R package\nversion 1.3.0, &lt;https://CRAN.R-project.org/package=tidyr&gt;.\n  - Zhu H (2021). _kableExtra: Construct Complex Table with 'kable' and Pipe\nSyntax_. R package version 1.3.4,\n&lt;https://CRAN.R-project.org/package=kableExtra&gt;."
  },
  {
    "objectID": "ARIMA.html#fundamentos-do-arima",
    "href": "ARIMA.html#fundamentos-do-arima",
    "title": "ARIMA",
    "section": "Fundamentos do ARIMA:",
    "text": "Fundamentos do ARIMA:\nAutoRegressivo (AR): Refere-se à relação entre uma observação atual e suas observações passadas. O termo “AutoRegressivo” destaca a dependência linear de uma observação em relação a suas antecessoras.\nIntegrated (I): Indica o número de diferenciações necessárias para tornar a série temporal estacionária, ou seja, para remover tendências e padrões sistemáticos. A estacionarização é crucial para garantir a estabilidade do modelo.\nMédia Móvel (MA): Considera os erros residuais das observações anteriores para prever a próxima. O componente “Média Móvel” reflete a média dos erros anteriores, incorporando informações sobre o comportamento recente da série.\nNúmero de observações: O número ideal de observações repetidas para uma única unidade de análise é de pelo menos 40, sendo preferível alcançar 50 observações. Não é necessário ter um grande número de pessoas ou unidades de análise; até mesmo com N = 1, você pode obter várias observações do mesmo indivíduo, tornando o ARIMA uma ferramenta eficaz de análise."
  },
  {
    "objectID": "ARIMA.html#condições-e-pressupostos",
    "href": "ARIMA.html#condições-e-pressupostos",
    "title": "ARIMA",
    "section": "Condições e Pressupostos:",
    "text": "Condições e Pressupostos:\nEstacionariedade: O ARIMA assume que a série temporal seja estacionária, o que significa que a média, a variância e a estrutura de autocorrelação não devem variar significativamente ao longo do tempo. Se a série não for estacionária, é necessário aplicar diferenciação até atingir a estacionariedade.\nIdentificação de Ordem: A escolha adequada dos parâmetros p, d, e q (ordens AR, I, e MA) é crucial. Isso geralmente é feito por meio de análise visual, funções de autocorrelação (ACF) e autocorrelação parcial (PACF), bem como métodos estatísticos como o critério de informação de Akaike (AIC).\nRuído Branco: Os resíduos do modelo ARIMA devem se comportar como um “ruído branco”, ou seja, serem independentes, terem média zero e variância constante. Isso garante que não haja padrões significativos nos erros residuais não capturados pelo modelo.\nAlém dos componentes fundamentais, o ARIMA pode ser estendido para lidar com sazonalidade através do SARIMA (Seasonal ARIMA), que incorpora parâmetros adicionais para modelar padrões recorrentes em determinados intervalos de tempo.\nA adequada compreensão dos fundamentos, condições e pressupostos é essencial para explorar todo o potencial desse método e fazer previsões precisas em uma variedade de contextos.",
    "crumbs": [
      "ARIMA"
    ]
  },
  {
    "objectID": "ARIMA.html#passo-a-passo-da-arima",
    "href": "ARIMA.html#passo-a-passo-da-arima",
    "title": "ARIMA",
    "section": "Passo a Passo da ARIMA",
    "text": "Passo a Passo da ARIMA\n\nColeta e Exploração de Dados:\n\nInicie coletando dados temporais relevantes para sua análise.\nExplore graficamente a série temporal para identificar padrões, sazonalidades e tendências.\n\nEstacionarização da Série:\n\nDiferencie a série temporal para torná-la estacionária.\nUtilize gráficos, como sequence charts, para visualizar mudanças ao longo do tempo.\n\nIdentificação dos Parâmetros (p, d, q):\n\nAnalise as funções de autocorrelação (ACF) e autocorrelação parcial (PACF) para determinar os valores ideais de p (ordem AR) e q (ordem MA).\nEstabeleça a ordem de diferenciação d necessária para atingir a estacionariedade.\n\nDivisão dos Dados:\n\nSepare os dados em conjuntos de treinamento e teste para avaliar o desempenho do modelo posteriormente.\n\nAjuste do Modelo ARIMA:\n\nUtilize os parâmetros (p, d, q) identificados para ajustar o modelo ARIMA aos dados de treinamento.\nAjuste também os parâmetros sazonais, se aplicável (SARIMA).\n\nValidação do Modelo:\n\nAvalie a qualidade do modelo usando critérios de informação como AIC (Akaike Information Criterion) e BIC (Bayesian Information Criterion) para modelos com os mesmos valores de p, d, e q.\nCalcule o erro médio quadrático (RMSE) para comparar modelos com diferentes configurações de p, d, e q.\n\nPrevisões e Avaliação:\n\nFaça previsões utilizando o modelo ARIMA ajustado nos dados de teste.\nAvalie a precisão das previsões comparando-as com os valores reais.\n\nAjustes Finais e Refinamentos:\n\nSe necessário, ajuste os parâmetros do modelo com base na análise da qualidade das previsões.\nConsidere iterar nos passos anteriores para melhorar a performance do modelo.\n\nInterpretação e Comunicação dos Resultados:\n\nComunique os resultados do modelo de forma clara, destacando as tendências identificadas e a capacidade de previsão.\n\n\nNa lista prática de exercícios vamos analisar dois bancos de dados, um apenas para verificar se o modelo é estacionário ou não e outro para de fato criar modelos ARIMA.\nPara mais informações sobre os parâmetros p, d, q, consulte as referências",
    "crumbs": [
      "ARIMA"
    ]
  },
  {
    "objectID": "ARIMA.html#referências",
    "href": "ARIMA.html#referências",
    "title": "ARIMA",
    "section": "Referências",
    "text": "Referências\nhttps://people.duke.edu/~rnau/411arim.htm",
    "crumbs": [
      "ARIMA"
    ]
  },
  {
    "objectID": "lista_7.html",
    "href": "lista_7.html",
    "title": "8  Lista 7 - Séries Temporais (ARIMA)",
    "section": "",
    "text": "9 Cigarro"
  },
  {
    "objectID": "lista_7.html#pacotes",
    "href": "lista_7.html#pacotes",
    "title": "8  Lista 7 - Séries Temporais (ARIMA)",
    "section": "8.1 Pacotes",
    "text": "8.1 Pacotes\n\nlibrary(tidyverse)\nlibrary(flexplot)\nlibrary(foreign)\nlibrary(dplyr)\nlibrary(tm)\nlibrary(ggplot2)\nlibrary(forcats)\nlibrary(rempsyc)\nlibrary(easystats)\nlibrary(kableExtra)\n\n#Específicos para series temporais\nlibrary(prophet)\nlibrary(forecast)\nlibrary(tseries)"
  },
  {
    "objectID": "lista_7.html#limpando-o-ambiente",
    "href": "lista_7.html#limpando-o-ambiente",
    "title": "8  Lista 7 - Séries Temporais (ARIMA)",
    "section": "8.2 Limpando o ambiente",
    "text": "8.2 Limpando o ambiente"
  },
  {
    "objectID": "lista_7.html#carregando-os-dados-e-modificando-o-tipo-de-variável",
    "href": "lista_7.html#carregando-os-dados-e-modificando-o-tipo-de-variável",
    "title": "8  Lista 7 - Séries Temporais (ARIMA)",
    "section": "9.1 Carregando os dados e modificando o tipo de variável",
    "text": "9.1 Carregando os dados e modificando o tipo de variável\n\noriginal = read.spss(\"CigarrosROD_1.sav\", to.data.frame=TRUE)\nglimpse(original)\n\nRows: 20\nColumns: 2\n$ Dia         &lt;dbl&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17,…\n$ cigarrosROD &lt;dbl&gt; 6, 10, 4, 13, 4, 11, 4, 6, 4, 15, 5, 14, 5, 21, 10, 31, 13…\n\ndb = original"
  },
  {
    "objectID": "lista_7.html#verificando-se-os-dados-são-estacionários",
    "href": "lista_7.html#verificando-se-os-dados-são-estacionários",
    "title": "8  Lista 7 - Séries Temporais (ARIMA)",
    "section": "9.2 Verificando se os dados são estacionários",
    "text": "9.2 Verificando se os dados são estacionários\nIniciaremos nossa primeira análise para verificar a estacionaridade dos dados por meio de uma abordagem gráfica. Este gráfico simples exibirá o número de cigarros consumidos ao longo do tempo, apresentando uma linha média que atravessa toda a linha temporal. A ideia é observar se os números de cigarros oscilam próximos à média, proporcionando uma visualização intuitiva da estacionariedade dos dados.\n\n# Plot estilizado\n# media_cigarros &lt;- mean(db$cigarrosROD)\n# \n# # Cria o gráfico com ggplot\n# ggplot(data = data.frame(cigarrosROD = db$cigarrosROD), aes(x = seq_along(cigarrosROD), y = cigarrosROD)) +\n#   geom_line(color = \"black\", size = 1) +\n#   geom_point(color = \"black\", size = 3) +\n#   geom_hline(yintercept = media_cigarros, linetype = \"dashed\", color = \"blue\", size = 1) +  # Adiciona a linha média\n#   labs(x = \"Dias\", y = \"Cigarros por dia\") +\n#   scale_x_continuous(breaks = seq_along(db$cigarrosROD), labels = seq_along(db$cigarrosROD)) +\n#   theme_minimal() +\n#   theme(panel.grid = element_blank(),\n#         axis.ticks = element_line())  # Adiciona ticks nos eixos x e y\n\n\nPlot simples\n\nmedia_cigarros &lt;- mean(db$cigarrosROD)\n\n# plot mais simples\nplot.ts(db$cigarrosROD)\nabline(h = media_cigarros, col = \"blue\", lty = 2, lwd = 2)\naxis(1, at = db$Dia, labels = db$Dia)\n\n\n\n\nClaramente os dados desviam bastante da média, logo essa não é uma série estacionária.\n\n\nAdf teste\nPodemos também utilizar o Augmented Dickey-Fuller (ADF) Test para avaliar a estacionaridade em séries temporais. A função para realizar o teste é a adf.test().\nInterpretação do Resultado:\n\nSe a estatística do teste for menor que o valor crítico (p &lt; 0.05), rejeitamos a hipótese nula e concluímos que a série é estacionária.\nSe a estatística do teste for maior que o valor crítico (p &gt; 0.05), falhamos em rejeitar a hipótese nula, sugerindo que a série é não estacionária.\n\n\n# Adf teste\nadf.test(db$cigarrosROD)\n\n\n    Augmented Dickey-Fuller Test\n\ndata:  db$cigarrosROD\nDickey-Fuller = -0.38979, Lag order = 2, p-value = 0.9797\nalternative hypothesis: stationary\n\n\nCorroborando a análise visual, falhamos em rejeitar a hipótese nula, logo podemos assumir que a série temporal em questão não é estacionária. Em seguida vamos ver como podemos ajustar os dados.\n\n\nAutocorrelação\nA função acf() (AutoCorrelation Function) no R é utilizada para calcular e visualizar os coeficientes de autocorrelação em uma série temporal. A autocorrelação mede a correlação entre uma observação e suas observações anteriores em diferentes defasagens (lags de tempo).\n\n# Calcula as autocorrelações e cria o gráfico\n\nautocorrelacoes = acf(db$cigarrosROD, plot = FALSE)\n\nautoplot(autocorrelacoes)\n\n\n\n\n\nggtsdisplay(db$cigarrosROD)\n\n\n\n\nOs valores de lag que tiveram um AFC além do intervalo de confiança (linha tracejada), são candidatos para utilizarmos em nosso modelo ARIMA. Portanto lag 2 e 4 são candidatos. Além disso podemos basear nossa decisão também o teste de Ljung-Box.\n\n\nTeste Ljung-Box\nO Teste Ljung-Box avalia para cada lag se a séria é estacionária ou não. Podemos testar individualmente para cada lag.\n\n# Teste Ljung-Box com lag 2\nBox.test(autocorrelacoes$acf , lag = 3, type = \"Ljung-Box\")\n\n\n    Box-Ljung test\n\ndata:  autocorrelacoes$acf\nX-squared = 8.5179, df = 3, p-value = 0.03644\n\nlag(db$cigarrosROD,1)\n\n [1] NA  6 10  4 13  4 11  4  6  4 15  5 14  5 21 10 31 13 39 16\n\n\nUma outra forma é criar um dataframe com todos os valores de lags calculados na autocorrelação.\n\n# Obtém o número máximo de lags disponíveis\nmax_lags &lt;- length(autocorrelacoes$acf) - 1\n\n# Inicialize os vetores para armazenar os resultados\nlags &lt;- numeric(max_lags)\np_values &lt;- numeric(max_lags)\n\n# Itere sobre os lags\nfor (lag in 1:max_lags) {\n  # Execute o teste de Ljung-Box para o lag atual\n  resultado_teste &lt;- Box.test(autocorrelacoes$acf, lag = lag, type = \"Ljung-Box\")\n  \n  # Armazene os resultados\n  lags[lag] &lt;- lag\n  p_values[lag] &lt;- resultado_teste$p.value\n}\n\n# Crie um dataframe com os resultados\nresultados_df &lt;- data.frame(Lag = lags, P_Value = p_values)\nkable(resultados_df)\n\n\n\n\nLag\nP_Value\n\n\n\n\n1\n0.9409683\n\n\n2\n0.0166341\n\n\n3\n0.0364377\n\n\n4\n0.0200419\n\n\n5\n0.0236724\n\n\n6\n0.0359384\n\n\n7\n0.0197526\n\n\n8\n0.0337181\n\n\n9\n0.0101406\n\n\n10\n0.0150763\n\n\n11\n0.0030557\n\n\n12\n0.0038952\n\n\n13\n0.0006256\n\n\n\n\n\n\n\nOu ainda\n\ntsdiag(auto.arima(db$cigarrosROD))"
  },
  {
    "objectID": "lista_7.html#transformação-variabilidade-e-estacionária",
    "href": "lista_7.html#transformação-variabilidade-e-estacionária",
    "title": "8  Lista 7 - Séries Temporais (ARIMA)",
    "section": "9.3 Transformação variabilidade e estacionária",
    "text": "9.3 Transformação variabilidade e estacionária\nPrimeiro vamos modificar a série para que tenha variabilidade constante\n\nlambda = BoxCox.lambda(db$cigarrosROD)\nlambda\n\n[1] -0.1713367\n\nvar_const = BoxCox(db$cigarrosROD, lambda = lambda)\n\nggtsdisplay(var_const)\n\n\n\n\nE agora podemos ajustar a serie para que ela fique estacionária.\n\nndiffs(var_const)\n\n[1] 1\n\n\n\nestacio = diff(var_const, 1)\nggtsdisplay(estacio)\n\n\n\n\nDe acordo com os resultados, qualquer lag, a não ser o lag 1, poderá ser utilizado para transformar os dados.\nPara decidir devemos levar em conta tanto a análise gráfica da autocorrelação quanto o teste de Ljung-Box.\nLogo os lags 2 e 4 são bons candidatos. Por parcimônia e sem nenhum critério teórico, vamos optar pelo lag menor, ou seja, lag 2."
  },
  {
    "objectID": "lista_7.html#transformando-os-dados-para-estacionários",
    "href": "lista_7.html#transformando-os-dados-para-estacionários",
    "title": "8  Lista 7 - Séries Temporais (ARIMA)",
    "section": "9.4 Transformando os dados para estacionários",
    "text": "9.4 Transformando os dados para estacionários\nPara modificar nossa série temporal utilizando lag 2 vamos utilizar a função diff().\n\n# Log\nlag_2 = diff(db$cigarrosROD, differences = 2) # posso colocar o log da diferença também caso os valores fiquem muito pequenos.\n\n\nPlot\n\nmedia_lag_2 = mean(lag_2)\nplot.ts(lag_2)\nabline(h = media_lag_2, col = \"blue\", lty = 2, lwd = 2)\naxis(1, at = db$Dia, labels = db$Dia)\n\n\n\n\nPronto! Agora os valores estão ocilando em torno da média. Apenas para confirmar que agora temos uma série temporal estacionária, podemos rodar novamente o adf.test.\n\nadf.test(lag_2) # testar com outros valores de K(lag) para verificar o p-value\n\n\n    Augmented Dickey-Fuller Test\n\ndata:  lag_2\nDickey-Fuller = -4.3237, Lag order = 2, p-value = 0.01196\nalternative hypothesis: stationary\n\n\nEsse banco de dados era apenas para transformar os dados não estacionários para estacionários. Vamos agora carregar outro banco de dados e criar o modelo ARIMA."
  },
  {
    "objectID": "lista_7.html#dados-séries-temporais",
    "href": "lista_7.html#dados-séries-temporais",
    "title": "8  Lista 7 - Séries Temporais (ARIMA)",
    "section": "9.5 Dados séries temporais",
    "text": "9.5 Dados séries temporais\n\noriginal_ts = read.spss(\"dados series temporais.sav\", to.data.frame=TRUE)\n\nre-encoding from CP1252\n\ndb_ts = original_ts\n\nglimpse(db_ts)\n\nRows: 120\nColumns: 11\n$ date         &lt;dbl&gt; 12818995200, 12821673600, 12824092800, 12826771200, 12829…\n$ men          &lt;dbl&gt; 11357.92, 10605.95, 16998.57, 6563.75, 6607.69, 9839.00, …\n$ women        &lt;dbl&gt; 16578.93, 18236.13, 43393.55, 30908.49, 28701.58, 29647.5…\n$ horas        &lt;dbl&gt; 7978, 8290, 8029, 7752, 8685, 7847, 7881, 8121, 7811, 870…\n$ divida       &lt;dbl&gt; 73, 88, 65, 85, 74, 87, 79, 72, 83, 111, 74, 105, 66, 59,…\n$ idade        &lt;dbl&gt; 34, 29, 24, 20, 17, 30, 28, 27, 35, 25, 30, 45, 35, 20, 2…\n$ propaganda   &lt;dbl&gt; 22294.48, 27426.47, 27978.66, 28949.65, 22642.27, 27210.6…\n$ escolaridade &lt;dbl&gt; 20, 20, 26, 22, 21, 23, 22, 20, 15, 20, 16, 29, 22, 28, 2…\n$ YEAR_        &lt;dbl&gt; 1989, 1989, 1989, 1989, 1989, 1989, 1989, 1989, 1989, 198…\n$ MONTH_       &lt;dbl&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 1, 2, 3, 4, 5, 6, …\n$ DATE_        &lt;chr&gt; \"JAN 1989\", \"FEB 1989\", \"MAR 1989\", \"APR 1989\", \"MAY 1989…\n\n\n\nPlot simples\n\nmedia_sal_men &lt;- mean(db_ts$men)\ndb_season = ts(db_ts$men,\n               frequency = 12,\n               start = c(1989, 1))\n\nts.plot(db_season)\nabline(h = media_sal_men, col = \"blue\", lty = 2, lwd = 2)\n\n\n\n\n\nseasonplot(db_season,\n           col = rainbow(12),\n           year.labels = TRUE,\n           type = \"o\",\n           pch = 16)\n\n\n\n\n\nggtsdisplay(db_season)\n\n\n\n\nSemelhante ao ARIMA (0,0,0)\n\n\nAdf teste\n\n# Adf teste\nadf.test(db_ts$men, k =1) #já está no formato estacionário\n\nWarning in adf.test(db_ts$men, k = 1): p-value smaller than printed p-value\n\n\n\n    Augmented Dickey-Fuller Test\n\ndata:  db_ts$men\nDickey-Fuller = -6.1931, Lag order = 1, p-value = 0.01\nalternative hypothesis: stationary\n\n\n\n\nLjung-Box\nDescrever\n\n# Teste Ljung-Box com lag 2\nBox.test(db_ts$men , lag = 1, type = \"Ljung-Box\")\n\n\n    Box-Ljung test\n\ndata:  db_ts$men\nX-squared = 19.742, df = 1, p-value = 0.000008865"
  },
  {
    "objectID": "lista_7.html#modelo-arima-100",
    "href": "lista_7.html#modelo-arima-100",
    "title": "8  Lista 7 - Séries Temporais (ARIMA)",
    "section": "9.6 Modelo ARIMA (1,0,0)",
    "text": "9.6 Modelo ARIMA (1,0,0)\n\nmodelo_sal_men = Arima(db_ts$men, order = c(1,0,0))\n\n\nPlot 1 do modelo (1,0,0)\n\n# Supondo que você tenha as séries temporais 'modelo_sal_men$fitted' e 'db_ts$men'\n\n# Cria o gráfico\nplot(modelo_sal_men$x, type = \"l\", col = \"red\", lty = 1, lwd = 2, xlab = \"Tempo\", ylab = \"Salário\")\nlines(modelo_sal_men$fitted, col = \"blue\", lty = 1, lwd = 2)\n\n# Adiciona uma legenda\nlegend(\"topright\", legend = c(\"Real\", \"Modelo\"), col = c(\"red\", \"blue\"), lty = c(1, 1), lwd = 2)\n\n# Adiciona um título ao gráfico\ntitle(main = \"Valores e Reais e do Modelo ARIMA de Salário para Homens\")"
  },
  {
    "objectID": "lista_7.html#modelo-arima-010",
    "href": "lista_7.html#modelo-arima-010",
    "title": "8  Lista 7 - Séries Temporais (ARIMA)",
    "section": "9.7 Modelo ARIMA (0,1,0)",
    "text": "9.7 Modelo ARIMA (0,1,0)\n\nmodelo2_sal_men = Arima(db_ts$men, order = c(0,1,0))\n\n\nPlot 1 do modelo (0,1,0)\n\n# Supondo que você tenha as séries temporais 'modelo2_sal_men$fitted' e 'db_ts$men'\n\n# Cria o gráfico\nplot(modelo2_sal_men$x, type = \"l\", col = \"red\", lty = 1, lwd = 2, xlab = \"Tempo\", ylab = \"Salário\")\nlines(modelo2_sal_men$fitted, col = \"blue\", lty = 1, lwd = 2)\n\n# Adiciona uma legenda\nlegend(\"topright\", legend = c(\"Real\", \"Modelo\"), col = c(\"red\", \"blue\"), lty = c(1, 1), lwd = 2)\n\n# Adiciona um título ao gráfico\ntitle(main = \"Valores e Reais e do Modelo ARIMA de Salário para Homens\")"
  },
  {
    "objectID": "lista_7.html#modelo-autoarima",
    "href": "lista_7.html#modelo-autoarima",
    "title": "8  Lista 7 - Séries Temporais (ARIMA)",
    "section": "9.8 Modelo autoARIMA",
    "text": "9.8 Modelo autoARIMA\nAssim como o SPSS o R também tem uma função que determina automaticamente os parâmetros p, d, q. Vamos verificar qual modelo a função auto.arima()sugere.\n\n# Para verificar qual o modelo sugerido pela função auto.arima\nauto.arima(db_ts$men, trace = TRUE)\n\n\n ARIMA(2,1,2) with drift         : Inf\n ARIMA(0,1,0) with drift         : 2434.823\n ARIMA(1,1,0) with drift         : 2412.096\n ARIMA(0,1,1) with drift         : Inf\n ARIMA(0,1,0)                    : 2432.897\n ARIMA(2,1,0) with drift         : 2411.86\n ARIMA(3,1,0) with drift         : 2408.495\n ARIMA(4,1,0) with drift         : 2407.461\n ARIMA(5,1,0) with drift         : 2408.674\n ARIMA(4,1,1) with drift         : Inf\n ARIMA(3,1,1) with drift         : Inf\n ARIMA(5,1,1) with drift         : Inf\n ARIMA(4,1,0)                    : 2405.816\n ARIMA(3,1,0)                    : 2406.731\n ARIMA(5,1,0)                    : 2407.075\n ARIMA(4,1,1)                    : 2394.525\n ARIMA(3,1,1)                    : 2392.515\n ARIMA(2,1,1)                    : 2392.416\n ARIMA(1,1,1)                    : 2391.073\n ARIMA(0,1,1)                    : 2393.07\n ARIMA(1,1,0)                    : 2410.255\n ARIMA(1,1,2)                    : 2392.894\n ARIMA(0,1,2)                    : 2391.92\n ARIMA(2,1,0)                    : 2410.02\n ARIMA(2,1,2)                    : Inf\n ARIMA(1,1,1) with drift         : Inf\n\n Best model: ARIMA(1,1,1)                    \n\n\nSeries: db_ts$men \nARIMA(1,1,1) \n\nCoefficients:\n         ar1      ma1\n      0.2036  -0.9139\ns.e.  0.1002   0.0347\n\nsigma^2 = 29737029:  log likelihood = -1192.43\nAIC=2390.86   AICc=2391.07   BIC=2399.2\n\n\nA função sugeriu o modelo 1, 1, 1. Vamos verificar os resultados.\n\nmodelo_auto_sal_men = Arima(db_ts$men, order = c(1,1,1))\n\n\nPlot 1 do modelo (1,1,1)\n\n# Supondo que você tenha as séries temporais 'modelo_atuo_sal_men$fitted' e 'db_ts$men'\n\n# Cria o gráfico\nplot(modelo_auto_sal_men$x, type = \"l\", col = \"red\", lty = 1, lwd = 2, xlab = \"Tempo\", ylab = \"Salário\")\nlines(modelo_auto_sal_men$fitted, col = \"blue\", lty = 1, lwd = 2)\n\n# Adiciona uma legenda\nlegend(\"topright\", legend = c(\"Real\", \"Modelo\"), col = c(\"red\", \"blue\"), lty = c(1, 1), lwd = 2)\n\n# Adiciona um título ao gráfico\ntitle(main = \"Valores e Reais e do Modelo ARIMA de Salário para Homens\")"
  },
  {
    "objectID": "lista_7.html#homens---modelo-com-variáveis-independentes",
    "href": "lista_7.html#homens---modelo-com-variáveis-independentes",
    "title": "8  Lista 7 - Séries Temporais (ARIMA)",
    "section": "9.9 Homens - Modelo com variáveis independentes",
    "text": "9.9 Homens - Modelo com variáveis independentes\n\n\n\n\n\n\nAtenção!\n\n\n\nAinda falta modificar os índices p, d, q das variáveis indepentendes como foi feito no SPSS.\n\n\n\nAuto arima\n\n# Defina as variáveis independentes originais\nnomes_variaveis &lt;- c(\"horas\", \"divida\", \"idade\", \"propaganda\", \"escolaridade\")\n\n# Crie a matriz de covariáveis\ncovars &lt;- as.matrix(db_ts[, nomes_variaveis, drop = FALSE])\n\n\n\n# Atribua os nomes diretamente à matriz de covariáveis\ncolnames(covars) &lt;- nomes_variaveis\n\n\n# \n# covars &lt;- cbind(\n#   db_ts$horas,\n#   db_ts$divida,\n#   db_ts$idade,\n#   db_ts$propaganda,\n#   db_ts$escolaridade\n# )\n\nauto.arima(db_ts$men, xreg = covars)\n\nSeries: db_ts$men \nRegression with ARIMA(1,0,0) errors \n\nCoefficients:\n         ar1   intercept   horas   divida     idade  propaganda  escolaridade\n      0.1968  -23753.966  2.0271  34.5286  342.9908      0.2046      -30.3841\ns.e.  0.1000    2752.767  0.2204  20.1900   43.9319      0.0733       41.3101\n\nsigma^2 = 8316739:  log likelihood = -1122.71\nAIC=2261.43   AICc=2262.72   BIC=2283.73\n\n\nModelo sugerido é o c(1,0,0)\n\n# Ajuste o modelo ARIMA com covariáveis\nmodelo_completo = Arima(\n  db_ts$men,\n  order = c(1, 0, 0),\n  xreg = covars, \n)\n\n\n# Defina as variáveis independentes originais\nnomes_variaveis &lt;- c(\"horas\", \"divida\", \"idade\", \"propaganda\", \"escolaridade\")\n\n# Inicialize uma lista para armazenar os modelos ajustados para cada VI\nmodelos_vi &lt;- list()\n\n# Loop através das variáveis independentes\nfor (variavel in nomes_variaveis) {\n  \n  # Selecione a VI específica\n  variavel_ts &lt;- db_ts[, variavel, drop = FALSE]\n  \n  # Ajuste as ordens p, d, q para a VI específica\n  ordens_vi &lt;- c(1, 0, 0)  # p, d, q\n  \n  # Ajuste o modelo ARIMA para a VI específica\n  modelo_vi &lt;- Arima(\n    variavel_ts,\n    order = ordens_vi,\n    include.mean = TRUE,\n    transform.pars = TRUE,\n    fixed = NULL,\n    include.drift = FALSE,\n    method = \"ML\",  # Mude conforme necessário\n    optim.control = list(trace = FALSE, REPORT = 1),\n    kappa = 1\n  )\n  \n  # Adicione o modelo ao vetor de modelos\n  modelos_vi[[variavel]] &lt;- modelo_vi\n}\n\n# Agora, você tem modelos ajustados para cada VI na lista modelos_vi\n\n# Combine os modelos ARIMA para as VI em uma única matriz\ncovars &lt;- cbind(\n  modelos_vi$horas$fitted, \n  modelos_vi$divida$fitted, \n  modelos_vi$idade$fitted, \n  modelos_vi$propaganda$fitted, \n  modelos_vi$escolaridade$fitted\n)\n\n# Ajuste o modelo ARIMA principal com as covariáveis\nmodelo_completo &lt;- Arima(\n  db_ts$men,\n  order = c(1, 0, 0),\n  xreg = covars,\n  seasonal = list(order = c(0, 0, 0)),  # Adapte conforme necessário\n  include.mean = TRUE,\n  transform.pars = TRUE,\n  fixed = NULL,\n  include.drift = FALSE,\n  method = \"ML\",  # Mude conforme necessário\n  optim.control = list(trace = FALSE, REPORT = 1),\n  kappa = 1\n)\n\n\n\nPlot do modelo com VIs\n\n# Criar um dataframe com as séries temporais\ndf_full &lt;- data.frame(\n  Tempo = seq_along(modelo_completo$fitted),\n  Ajustado = modelo_completo$fitted,\n  Real = modelo_completo$x\n)\n\n# Criar o gráfico com ggplot2\nggplot(df_full, aes(x = Tempo)) +\n  geom_line(aes(y = Ajustado, color = \"Ajustado\"), size = 1) +\n  geom_line(aes(y = Real, color = \"Real\"), size = 1) +\n  labs(x = \"Tempo\", y = \"Salário\", title = \"Valores Ajustados e Reais de Salário para Homens ao Longo do Tempo\") +\n  scale_color_manual(values = c(\"Ajustado\" = \"blue\", \"Real\" = \"red\"), guide = \"legend\") +\n  theme_minimal()\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead.\n\n\nDon't know how to automatically pick scale for object of type &lt;ts&gt;. Defaulting\nto continuous.\n\n\n\n\n\n\n\nAIC, BIC e RMSE\n\nperformance(modelo_completo)\n\n# Indices of model performance\n\nAIC      |     AICc |      BIC | R2.modelos_vi$horas$fitted | R2.modelos_vi$divida$fitted | R2.modelos_vi$idade$fitted | R2.modelos_vi$propaganda$fitted | R2.modelos_vi$escolaridade$fitted |     RMSE |    Sigma\n------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n2421.052 | 6925.052 | 2443.352 |                      0.397 |                       0.213 |                      0.722 |                       5.366e-04 |                             0.656 | 5442.460 | 5633.481\n\n\n\n\nResultados\n\n# Visualize o resumo do modelo\nsummary(modelo_completo)\n\nSeries: db_ts$men \nRegression with ARIMA(1,0,0) errors \n\nCoefficients:\n          ar1  intercept  modelos_vi$horas$fitted  modelos_vi$divida$fitted\n      -0.1727   34621.57                   0.7594                 -607.0271\ns.e.   0.1639   40027.85                   1.3741                  316.5860\n      modelos_vi$idade$fitted  modelos_vi$propaganda$fitted\n                     371.3498                        0.1770\ns.e.                 127.6716                        1.0677\n      modelos_vi$escolaridade$fitted\n                            135.8938\ns.e.                         81.0383\n\nsigma^2 = 31455262:  log likelihood = -1202.53\nAIC=2421.05   AICc=2422.35   BIC=2443.35\n\nTraining set error measures:\n                   ME    RMSE      MAE       MPE     MAPE     MASE        ACF1\nTraining set -5.05266 5442.46 3863.789 -11.92625 27.46778 0.826093 0.002906111\n\n# db_ts$horas,       xreg1    \n# db_ts$divida  ,    xreg2\n# db_ts$idade,       xreg3\n# db_ts$propaganda,  xreg4    \n# db_ts$escolaridade xreg5\n\n\nCoeficientes e valores de p\n\nlibrary(lmtest) # pacote para calcular os estimates e valores de p\n\nWarning: package 'lmtest' was built under R version 4.3.2\n\n\nCarregando pacotes exigidos: zoo\n\n\n\nAttaching package: 'zoo'\n\n\nThe following objects are masked from 'package:base':\n\n    as.Date, as.Date.numeric\n\n# Use a função coeftest para obter coeficientes e p-valores\ntest_coef &lt;- coeftest(modelo_completo)\n\n# Acesse os coeficientes estimados e os p-valores\ncoeficientes &lt;- round(test_coef[, \"Estimate\"], 3)\np_valores &lt;- round(test_coef[, \"Pr(&gt;|z|)\"], 3)\n\n# Crie uma nova coluna com asteriscos para valores de p significativos\ntest_coef$Significativo &lt;- ifelse(p_valores &lt; 0.05, \"*\", \"\")\n\nWarning in test_coef$Significativo &lt;- ifelse(p_valores &lt; 0.05, \"*\", \"\"):\nRealizando coerção de LHD para uma lista\n\n# Exiba os resultados\nresultados &lt;- data.frame(Coeficientes = coeficientes, p_valores = paste0(format(p_valores, digits = 3), test_coef$Significativo))\nprint(resultados)\n\n                               Coeficientes p_valores\nar1                                  -0.173     0.292\nintercept                         34621.566     0.387\nmodelos_vi$horas$fitted               0.759     0.581\nmodelos_vi$divida$fitted           -607.027     0.055\nmodelos_vi$idade$fitted             371.350    0.004*\nmodelos_vi$propaganda$fitted          0.177     0.868\nmodelos_vi$escolaridade$fitted      135.894     0.094\n\n\n\n\n\nMulheres - Modelo com variáveis independentes para\n\nVerificar qual o melhor modelo utilizando as VIs no auto.arima\n\n# Supondo que você tenha um dataframe 'db_ts' com as variáveis mencionadas\n\n# Defina as variáveis independentes originais\nnomes_variaveis &lt;- c(\"horas\", \"divida\", \"idade\", \"propaganda\", \"escolaridade\")\n\n# Crie a matriz de covariáveis\ncovars &lt;- as.matrix(db_ts[, nomes_variaveis, drop = FALSE])\n\n# Atribua os nomes diretamente à matriz de covariáveis\ncolnames(covars) &lt;- nomes_variaveis\n\n\n# \n# covars &lt;- cbind(\n#   db_ts$horas,\n#   db_ts$divida,\n#   db_ts$idade,\n#   db_ts$propaganda,\n#   db_ts$escolaridade\n# )\n\nauto.arima(db_ts$women, xreg = covars)\n\nSeries: db_ts$women \nRegression with ARIMA(0,0,1) errors \n\nCoefficients:\n         ma1   intercept   horas   divida     idade  propaganda  escolaridade\n      0.3351  -37941.151  2.6828  90.5433    1.6294      0.9805      445.6786\ns.e.  0.1096    6458.967  0.5145  52.4388  110.2176      0.1693      102.0171\n\nsigma^2 = 49641429:  log likelihood = -1229.95\nAIC=2475.89   AICc=2477.19   BIC=2498.19\n\n\nModelo sugerido é o c(0,0,1)\n\n# Ajuste o modelo ARIMA com covariáveis\nmodelo_completo_women = Arima(\n  db_ts$women,\n  order = c(0, 0, 1),\n  xreg = covars\n)\n\n\n\n# Visualize o resumo do modelo\nsummary(modelo_completo_women)\n\nSeries: db_ts$women \nRegression with ARIMA(0,0,1) errors \n\nCoefficients:\n         ma1   intercept   horas   divida     idade  propaganda  escolaridade\n      0.3351  -37941.151  2.6828  90.5433    1.6294      0.9805      445.6786\ns.e.  0.1096    6458.967  0.5145  52.4388  110.2176      0.1693      102.0171\n\nsigma^2 = 49641429:  log likelihood = -1229.95\nAIC=2475.89   AICc=2477.19   BIC=2498.19\n\nTraining set error measures:\n                     ME     RMSE  MAE       MPE    MAPE      MASE        ACF1\nTraining set -0.1962005 6837.081 4889 -3.414187 14.6811 0.5114592 -0.01923702\n\n\n\n# db_ts$horas,       xreg1    \n# db_ts$divida  ,    xreg2\n# db_ts$idade,       xreg3\n# db_ts$propaganda,  xreg4    \n# db_ts$escolaridade xreg5\n\ncheckresiduals(modelo_completo_women)\n\n\n\n\n\n    Ljung-Box test\n\ndata:  Residuals from Regression with ARIMA(0,0,1) errors\nQ* = 10.048, df = 9, p-value = 0.3466\n\nModel df: 1.   Total lags used: 10\n\n\n\n\nPlot do modelo com VIs\n\n# Criar um dataframe com as séries temporais\ndf_full_women &lt;- data.frame(\n  Tempo = seq_along(modelo_completo_women$fitted),\n  Ajustado = modelo_completo_women$fitted,\n  Real = modelo_completo_women$x\n)\n\n# Criar o gráfico com ggplot2\nggplot(df_full_women, aes(x = Tempo)) +\n  geom_line(aes(y = Ajustado, color = \"Ajustado\"), size = 1) +\n  geom_line(aes(y = Real, color = \"Real\"), size = 1) +\n  labs(x = \"Tempo\", y = \"Salário\", title = \"Valores Ajustados e Reais de Salário para Mulheres ao Longo do Tempo\") +\n  scale_color_manual(values = c(\"Ajustado\" = \"red\", \"Real\" = \"blue\"), guide = \"legend\") +\n  theme_minimal()\n\nDon't know how to automatically pick scale for object of type &lt;ts&gt;. Defaulting\nto continuous.\n\n\n\n\n\n\n\nCoeficientes e valores de p\n\nlibrary(lmtest) # pacote para calcular os estimates e valores de p\n\n\n# Use a função coeftest para obter coeficientes e p-valores\ntest_coef_women &lt;- coeftest(modelo_completo_women)\n\n# Acesse os coeficientes estimados e os p-valores\ncoeficientes_women &lt;- round(test_coef_women[, \"Estimate\"], 3)\np_valores_women &lt;- round(test_coef_women[, \"Pr(&gt;|z|)\"], 3)\n\n# Crie uma nova coluna com asteriscos para valores de p significativos\ntest_coef_women$Significativo &lt;- ifelse(p_valores_women &lt; 0.05, \"*\", \"\")\n\nWarning in test_coef_women$Significativo &lt;- ifelse(p_valores_women &lt; 0.05, :\nRealizando coerção de LHD para uma lista\n\n# Exiba os resultados\nresultados_women &lt;- data.frame(Coeficientes = coeficientes_women, Pvalores = paste0(format(p_valores_women, digits = 3), test_coef_women$Significativo))\nprint(resultados_women)\n\n             Coeficientes Pvalores\nma1                 0.335   0.002*\nintercept      -37941.151   0.000*\nhoras               2.683   0.000*\ndivida             90.543    0.084\nidade               1.629    0.988\npropaganda          0.981   0.000*\nescolaridade      445.679   0.000*"
  },
  {
    "objectID": "lista_7.html#forecast-previsões",
    "href": "lista_7.html#forecast-previsões",
    "title": "8  Lista 7 - Séries Temporais (ARIMA)",
    "section": "9.10 Forecast (previsões)",
    "text": "9.10 Forecast (previsões)\n\nMulheres - 50 anos\n\nwomen_salary_ts = ts(db_ts$women,\n               frequency = 12,\n               start = c(1989, 1))\n\n\nfit_arima_women = auto.arima(women_salary_ts)\n\nfcast_women = forecast(fit_arima_women, h=50)\nautoplot(fcast_women)\n\n\n\n\n\n\nHomens - 50 anos\n\nmen_salary_ts = ts(db_ts$men,\n               frequency = 12,\n               start = c(1989, 1))\n\n\nfit_arima_men = auto.arima(men_salary_ts)\n\nfcast_men = forecast(fit_arima_men, h=50)\nautoplot(fcast_men)"
  },
  {
    "objectID": "lista_7.html#extras",
    "href": "lista_7.html#extras",
    "title": "8  Lista 7 - Séries Temporais (ARIMA)",
    "section": "9.11 Extras",
    "text": "9.11 Extras\n\nMais gráficos\n\nPlot 2 do modelo (1,0,0)\n\nmodelo_sal_men = Arima(db_ts$men, order = c(1,0,0))\n\n# Criar um dataframe com as séries temporais\ndf_100 &lt;- data.frame(\n  Tempo = seq_along(modelo_sal_men$fitted),\n  Ajustado = modelo_sal_men$fitted,\n  Real = modelo_sal_men$x\n)\n\n# Criar o gráfico com ggplot2\nggplot(df_100, aes(x = Tempo)) +\n  geom_line(aes(y = Ajustado, color = \"Ajustado\"), size = 1) +\n  geom_line(aes(y = Real, color = \"Real\"), size = 1) +\n  labs(x = \"Tempo\", y = \"Salário\", title = \"Valores Ajustados e Reais de Salário para Homens ao Longo do Tempo\") +\n  scale_color_manual(values = c(\"Ajustado\" = \"red\", \"Real\" = \"blue\"), guide = \"legend\") +\n  theme_minimal()\n\nDon't know how to automatically pick scale for object of type &lt;ts&gt;. Defaulting\nto continuous.\n\n\n\n\n\n\n\nPlot 2 do modelo (0,1,0)\n\n# Criar um dataframe com as séries temporais\ndf_010 &lt;- data.frame(\n  Tempo = seq_along(modelo2_sal_men$fitted),\n  Ajustado = modelo2_sal_men$fitted,\n  Real = modelo2_sal_men$x\n)\n\n# Criar o gráfico com ggplot2\nggplot(df_010, aes(x = Tempo)) +\n  geom_line(aes(y = Ajustado, color = \"Ajustado\"), size = 1) +\n  geom_line(aes(y = Real, color = \"Real\"), size = 1) +\n  labs(x = \"Tempo\", y = \"Salário\", title = \"Valores Ajustados e Reais de Salário para Homens ao Longo do Tempo\") +\n  scale_color_manual(values = c(\"Ajustado\" = \"red\", \"Real\" = \"blue\"), guide = \"legend\") +\n  theme_minimal()\n\nDon't know how to automatically pick scale for object of type &lt;ts&gt;. Defaulting\nto continuous.\n\n\n\n\n\n\n\nPlot 2 do modelo (1,1,1)\n\nmodelo_atuo_sal_men = Arima(db_ts$men, order = c(1,1,1))\n\n# Criar um dataframe com as séries temporais\ndf_111 &lt;- data.frame(\n  Tempo = seq_along(modelo_atuo_sal_men$fitted),\n  Ajustado = modelo_atuo_sal_men$fitted,\n  Real = modelo_atuo_sal_men$x\n)\n\n# Criar o gráfico com ggplot2\nggplot(df_111, aes(x = Tempo)) +\n  geom_line(aes(y = Ajustado, color = \"Ajustado\"), size = 1) +\n  geom_line(aes(y = Real, color = \"Real\"), size = 1) +\n  labs(x = \"Tempo\", y = \"Salário\", title = \"Valores Ajustados e Reais de Salário para Homens ao Longo do Tempo\") +\n  scale_color_manual(values = c(\"Ajustado\" = \"red\", \"Real\" = \"blue\"), guide = \"legend\") +\n  theme_minimal()\n\nDon't know how to automatically pick scale for object of type &lt;ts&gt;. Defaulting\nto continuous."
  },
  {
    "objectID": "lista_7.html#verificando-resíduos",
    "href": "lista_7.html#verificando-resíduos",
    "title": "8  Lista 7 - Séries Temporais (ARIMA)",
    "section": "9.12 Verificando resíduos",
    "text": "9.12 Verificando resíduos\n\ncheckresiduals(modelo_auto_sal_men)\n\n\n\n\n\n    Ljung-Box test\n\ndata:  Residuals from ARIMA(1,1,1)\nQ* = 10.891, df = 8, p-value = 0.208\n\nModel df: 2.   Total lags used: 10\n\nsummary(modelo_auto_sal_men)\n\nSeries: db_ts$men \nARIMA(1,1,1) \n\nCoefficients:\n         ar1      ma1\n      0.2036  -0.9139\ns.e.  0.1002   0.0347\n\nsigma^2 = 29737029:  log likelihood = -1192.43\nAIC=2390.86   AICc=2391.07   BIC=2399.2\n\nTraining set error measures:\n                   ME     RMSE      MAE       MPE     MAPE      MASE\nTraining set 915.6723 5384.571 3662.003 -5.571742 25.15003 0.7829504\n                    ACF1\nTraining set -0.04692903"
  },
  {
    "objectID": "lista_7.html#lista-7-resolvida-no-spss",
    "href": "lista_7.html#lista-7-resolvida-no-spss",
    "title": "8  Lista 7 - Séries Temporais (ARIMA)",
    "section": "9.13 Lista 7 resolvida no SPSS",
    "text": "9.13 Lista 7 resolvida no SPSS"
  },
  {
    "objectID": "lista_7.html#referências",
    "href": "lista_7.html#referências",
    "title": "8  Lista 7 - Séries Temporais (ARIMA)",
    "section": "9.14 Referências",
    "text": "9.14 Referências\nhttps://facebook.github.io/prophet/docs/installation.html#r\nhttps://rpubs.com/mpleo/timeseries_prophet\nhttps://www.youtube.com/watch?v=ny3gRhfVsi4&t=10s\nhttps://www.youtube.com/watch?v=Txuo9JQjnKE ótima ref em PT-BR\nhttps://www.youtube.com/watch?v=RJzmHkGWCxs&list=PLEuzmtv9IuT_vg5oE0lQyZR-wgbVeGztt"
  },
  {
    "objectID": "lista_7.html#versões-dos-pacotes",
    "href": "lista_7.html#versões-dos-pacotes",
    "title": "8  Lista 7 - Séries Temporais (ARIMA)",
    "section": "9.15 Versões dos pacotes",
    "text": "9.15 Versões dos pacotes\n\nreport(sessionInfo())\n\nAnalyses were conducted using the R Statistical language (version 4.3.1; R Core\nTeam, 2023) on Windows 11 x64 (build 22621), using the packages effectsize\n(version 0.8.6; Ben-Shachar MS et al., 2020), Rcpp (version 1.0.11;\nEddelbuettel D et al., 2023), tm (version 0.7.11; Feinerer I, Hornik K, 2023),\nflexplot (version 0.20.5; Fife D, 2024), lubridate (version 1.9.3; Grolemund G,\nWickham H, 2011), rlang (version 1.1.1; Henry L, Wickham H, 2023), NLP (version\n0.2.1; Hornik K, 2020), forecast (version 8.21.1; Hyndman R et al., 2023),\nparameters (version 0.21.3; Lüdecke D et al., 2020), performance (version\n0.10.8; Lüdecke D et al., 2021), easystats (version 0.6.0; Lüdecke D et al.,\n2022), see (version 0.8.1; Lüdecke D et al., 2021), insight (version 0.19.6;\nLüdecke D et al., 2019), bayestestR (version 0.13.1; Makowski D et al., 2019),\nmodelbased (version 0.8.6; Makowski D et al., 2020), report (version 0.5.7;\nMakowski D et al., 2023), correlation (version 0.8.4; Makowski D et al., 2022),\ntibble (version 3.2.1; Müller K, Wickham H, 2023), datawizard (version 0.9.0;\nPatil I et al., 2022), foreign (version 0.8.85; R Core Team, 2023), prophet\n(version 1.0; Taylor S, Letham B, 2021), rempsyc (version 0.1.6; Thériault R,\n2023), tseries (version 0.10.55; Trapletti A, Hornik K, 2023), ggplot2 (version\n3.4.4; Wickham H, 2016), forcats (version 1.0.0; Wickham H, 2023), stringr\n(version 1.5.1; Wickham H, 2023), tidyverse (version 2.0.0; Wickham H et al.,\n2019), dplyr (version 1.1.3; Wickham H et al., 2023), purrr (version 1.0.2;\nWickham H, Henry L, 2023), readr (version 2.1.4; Wickham H et al., 2023), tidyr\n(version 1.3.0; Wickham H et al., 2023), zoo (version 1.8.12; Zeileis A,\nGrothendieck G, 2005), lmtest (version 0.9.40; Zeileis A, Hothorn T, 2002) and\nkableExtra (version 1.3.4; Zhu H, 2021).\n\nReferences\n----------\n  - Ben-Shachar MS, Lüdecke D, Makowski D (2020). \"effectsize: Estimation of\nEffect Size Indices and Standardized Parameters.\" _Journal of Open Source\nSoftware_, *5*(56), 2815. doi:10.21105/joss.02815\n&lt;https://doi.org/10.21105/joss.02815&gt;, &lt;https://doi.org/10.21105/joss.02815&gt;.\n  - Eddelbuettel D, Francois R, Allaire J, Ushey K, Kou Q, Russell N, Ucar I,\nBates D, Chambers J (2023). _Rcpp: Seamless R and C++ Integration_. R package\nversion 1.0.11, &lt;https://CRAN.R-project.org/package=Rcpp&gt;. Eddelbuettel D,\nFrançois R (2011). \"Rcpp: Seamless R and C++ Integration.\" _Journal of\nStatistical Software_, *40*(8), 1-18. doi:10.18637/jss.v040.i08\n&lt;https://doi.org/10.18637/jss.v040.i08&gt;. Eddelbuettel D (2013). _Seamless R and\nC++ Integration with Rcpp_. Springer, New York. doi:10.1007/978-1-4614-6868-4\n&lt;https://doi.org/10.1007/978-1-4614-6868-4&gt;, ISBN 978-1-4614-6867-7.\nEddelbuettel D, Balamuta J (2018). \"Extending R with C++: A Brief Introduction\nto Rcpp.\" _The American Statistician_, *72*(1), 28-36.\ndoi:10.1080/00031305.2017.1375990\n&lt;https://doi.org/10.1080/00031305.2017.1375990&gt;.\n  - Feinerer I, Hornik K (2023). _tm: Text Mining Package_. R package version\n0.7-11, &lt;https://CRAN.R-project.org/package=tm&gt;. Feinerer I, Hornik K, Meyer D\n(2008). \"Text Mining Infrastructure in R.\" _Journal of Statistical Software_,\n*25*(5), 1-54. doi:10.18637/jss.v025.i05\n&lt;https://doi.org/10.18637/jss.v025.i05&gt;.\n  - Fife D (2024). _flexplot: Graphically Based Data Analysis Using 'flexplot'_.\nR package version 0.20.5.\n  - Grolemund G, Wickham H (2011). \"Dates and Times Made Easy with lubridate.\"\n_Journal of Statistical Software_, *40*(3), 1-25.\n&lt;https://www.jstatsoft.org/v40/i03/&gt;.\n  - Henry L, Wickham H (2023). _rlang: Functions for Base Types and Core R and\n'Tidyverse' Features_. R package version 1.1.1,\n&lt;https://CRAN.R-project.org/package=rlang&gt;.\n  - Hornik K (2020). _NLP: Natural Language Processing Infrastructure_. R package\nversion 0.2-1, &lt;https://CRAN.R-project.org/package=NLP&gt;.\n  - Hyndman R, Athanasopoulos G, Bergmeir C, Caceres G, Chhay L, O'Hara-Wild M,\nPetropoulos F, Razbash S, Wang E, Yasmeen F (2023). _forecast: Forecasting\nfunctions for time series and linear models_. R package version 8.21.1,\n&lt;https://pkg.robjhyndman.com/forecast/&gt;. Hyndman RJ, Khandakar Y (2008).\n\"Automatic time series forecasting: the forecast package for R.\" _Journal of\nStatistical Software_, *26*(3), 1-22. doi:10.18637/jss.v027.i03\n&lt;https://doi.org/10.18637/jss.v027.i03&gt;.\n  - Lüdecke D, Ben-Shachar M, Patil I, Makowski D (2020). \"Extracting, Computing\nand Exploring the Parameters of Statistical Models using R.\" _Journal of Open\nSource Software_, *5*(53), 2445. doi:10.21105/joss.02445\n&lt;https://doi.org/10.21105/joss.02445&gt;.\n  - Lüdecke D, Ben-Shachar M, Patil I, Waggoner P, Makowski D (2021).\n\"performance: An R Package for Assessment, Comparison and Testing of\nStatistical Models.\" _Journal of Open Source Software_, *6*(60), 3139.\ndoi:10.21105/joss.03139 &lt;https://doi.org/10.21105/joss.03139&gt;.\n  - Lüdecke D, Ben-Shachar M, Patil I, Wiernik B, Makowski D (2022). \"easystats:\nFramework for Easy Statistical Modeling, Visualization, and Reporting.\" _CRAN_.\nR package, &lt;https://easystats.github.io/easystats/&gt;.\n  - Lüdecke D, Patil I, Ben-Shachar M, Wiernik B, Waggoner P, Makowski D (2021).\n\"see: An R Package for Visualizing Statistical Models.\" _Journal of Open Source\nSoftware_, *6*(64), 3393. doi:10.21105/joss.03393\n&lt;https://doi.org/10.21105/joss.03393&gt;.\n  - Lüdecke D, Waggoner P, Makowski D (2019). \"insight: A Unified Interface to\nAccess Information from Model Objects in R.\" _Journal of Open Source Software_,\n*4*(38), 1412. doi:10.21105/joss.01412 &lt;https://doi.org/10.21105/joss.01412&gt;.\n  - Makowski D, Ben-Shachar M, Lüdecke D (2019). \"bayestestR: Describing Effects\nand their Uncertainty, Existence and Significance within the Bayesian\nFramework.\" _Journal of Open Source Software_, *4*(40), 1541.\ndoi:10.21105/joss.01541 &lt;https://doi.org/10.21105/joss.01541&gt;,\n&lt;https://joss.theoj.org/papers/10.21105/joss.01541&gt;.\n  - Makowski D, Ben-Shachar M, Patil I, Lüdecke D (2020). \"Estimation of\nModel-Based Predictions, Contrasts and Means.\" _CRAN_.\n&lt;https://github.com/easystats/modelbased&gt;.\n  - Makowski D, Lüdecke D, Patil I, Thériault R, Ben-Shachar M, Wiernik B (2023).\n\"Automated Results Reporting as a Practical Tool to Improve Reproducibility and\nMethodological Best Practices Adoption.\" _CRAN_.\n&lt;https://easystats.github.io/report/&gt;.\n  - Makowski D, Wiernik B, Patil I, Lüdecke D, Ben-Shachar M (2022).\n\"correlation: Methods for Correlation Analysis.\" Version 0.8.3,\n&lt;https://CRAN.R-project.org/package=correlation&gt;. Makowski D, Ben-Shachar M,\nPatil I, Lüdecke D (2020). \"Methods and Algorithms for Correlation Analysis in\nR.\" _Journal of Open Source Software_, *5*(51), 2306. doi:10.21105/joss.02306\n&lt;https://doi.org/10.21105/joss.02306&gt;,\n&lt;https://joss.theoj.org/papers/10.21105/joss.02306&gt;.\n  - Müller K, Wickham H (2023). _tibble: Simple Data Frames_. R package version\n3.2.1, &lt;https://CRAN.R-project.org/package=tibble&gt;.\n  - Patil I, Makowski D, Ben-Shachar M, Wiernik B, Bacher E, Lüdecke D (2022).\n\"datawizard: An R Package for Easy Data Preparation and Statistical\nTransformations.\" _Journal of Open Source Software_, *7*(78), 4684.\ndoi:10.21105/joss.04684 &lt;https://doi.org/10.21105/joss.04684&gt;.\n  - R Core Team (2023). _foreign: Read Data Stored by 'Minitab', 'S', 'SAS',\n'SPSS', 'Stata', 'Systat', 'Weka', 'dBase', ..._. R package version 0.8-85,\n&lt;https://CRAN.R-project.org/package=foreign&gt;.\n  - R Core Team (2023). _R: A Language and Environment for Statistical\nComputing_. R Foundation for Statistical Computing, Vienna, Austria.\n&lt;https://www.R-project.org/&gt;.\n  - Taylor S, Letham B (2021). _prophet: Automatic Forecasting Procedure_. R\npackage version 1.0, &lt;https://CRAN.R-project.org/package=prophet&gt;.\n  - Thériault R (2023). \"rempsyc: Convenience functions for psychology.\" _Journal\nof Open Source Software_, *8*(87), 5466. doi:10.21105/joss.05466\n&lt;https://doi.org/10.21105/joss.05466&gt;, &lt;https://doi.org/10.21105/joss.05466&gt;.\n  - Trapletti A, Hornik K (2023). _tseries: Time Series Analysis and\nComputational Finance_. R package version 0.10-55,\n&lt;https://CRAN.R-project.org/package=tseries&gt;.\n  - Wickham H (2016). _ggplot2: Elegant Graphics for Data Analysis_.\nSpringer-Verlag New York. ISBN 978-3-319-24277-4,\n&lt;https://ggplot2.tidyverse.org&gt;.\n  - Wickham H (2023). _forcats: Tools for Working with Categorical Variables\n(Factors)_. R package version 1.0.0,\n&lt;https://CRAN.R-project.org/package=forcats&gt;.\n  - Wickham H (2023). _stringr: Simple, Consistent Wrappers for Common String\nOperations_. R package version 1.5.1,\n&lt;https://CRAN.R-project.org/package=stringr&gt;.\n  - Wickham H, Averick M, Bryan J, Chang W, McGowan LD, François R, Grolemund G,\nHayes A, Henry L, Hester J, Kuhn M, Pedersen TL, Miller E, Bache SM, Müller K,\nOoms J, Robinson D, Seidel DP, Spinu V, Takahashi K, Vaughan D, Wilke C, Woo K,\nYutani H (2019). \"Welcome to the tidyverse.\" _Journal of Open Source Software_,\n*4*(43), 1686. doi:10.21105/joss.01686 &lt;https://doi.org/10.21105/joss.01686&gt;.\n  - Wickham H, François R, Henry L, Müller K, Vaughan D (2023). _dplyr: A Grammar\nof Data Manipulation_. R package version 1.1.3,\n&lt;https://CRAN.R-project.org/package=dplyr&gt;.\n  - Wickham H, Henry L (2023). _purrr: Functional Programming Tools_. R package\nversion 1.0.2, &lt;https://CRAN.R-project.org/package=purrr&gt;.\n  - Wickham H, Hester J, Bryan J (2023). _readr: Read Rectangular Text Data_. R\npackage version 2.1.4, &lt;https://CRAN.R-project.org/package=readr&gt;.\n  - Wickham H, Vaughan D, Girlich M (2023). _tidyr: Tidy Messy Data_. R package\nversion 1.3.0, &lt;https://CRAN.R-project.org/package=tidyr&gt;.\n  - Zeileis A, Grothendieck G (2005). \"zoo: S3 Infrastructure for Regular and\nIrregular Time Series.\" _Journal of Statistical Software_, *14*(6), 1-27.\ndoi:10.18637/jss.v014.i06 &lt;https://doi.org/10.18637/jss.v014.i06&gt;.\n  - Zeileis A, Hothorn T (2002). \"Diagnostic Checking in Regression\nRelationships.\" _R News_, *2*(3), 7-10.\n&lt;https://CRAN.R-project.org/doc/Rnews/&gt;.\n  - Zhu H (2021). _kableExtra: Construct Complex Table with 'kable' and Pipe\nSyntax_. R package version 1.3.4,\n&lt;https://CRAN.R-project.org/package=kableExtra&gt;."
  },
  {
    "objectID": "SEM.html#referências",
    "href": "SEM.html#referências",
    "title": "SEM",
    "section": "Referências",
    "text": "Referências\nhttps://repositorio.ufba.br/bitstream/ri/17684/1/ebook_SEM_2012.pdf\nhttps://statplace.com.br/blog/modelagem-de-equacoes-estruturais/",
    "crumbs": [
      "SEM"
    ]
  },
  {
    "objectID": "lista_8.html#a-regressão-linear",
    "href": "lista_8.html#a-regressão-linear",
    "title": "9  Lista 8 - CFA e Path Analysis",
    "section": "9.1 a) Regressão linear",
    "text": "9.1 a) Regressão linear\n\n\n\n\n\n\nExercício\n\n\n\nVeja o banco de dados DADOSPATH.sav. Nele temos os dados de Idade, IMC, numero de treinos e sociabilidade (questionario) de um grupo de 94 pessoas. Faca um modelo de regressao linear tendo como variavel dependente o numero de Treinos e as demais variaveis como independentes.\n\n\n\noriginal = read.spss(\"DADOS PATH.sav\", to.data.frame=TRUE)\nmodelo_1 = lm(Treinos ~ Idade + IMC1 + Sociabilidade, data = original)\n\nModelo:\n\\[\nY \\sim \\beta_0 + \\beta_1*idade + \\beta_2*IMC1 + \\beta_3*Sociabilidade + \\epsilon\n\\]\n\nResultados\n\nkable(summary(modelo_1)$coef)\n\n\n\n\n\nEstimate\nStd. Error\nt value\nPr(&gt;|t|)\n\n\n\n\n(Intercept)\n78.0103771\n33.1315541\n2.3545644\n0.0207191\n\n\nIdade\n1.9071028\n0.5479748\n3.4802749\n0.0007745\n\n\nIMC1\n-2.8021799\n1.1809989\n-2.3727202\n0.0197865\n\n\nSociabilidade\n0.5177685\n0.5903261\n0.8770889\n0.3827736\n\n\n\n\n\n\n\nUm modelo linear (estimado usando Mínimos Quadrados Ordinários - OLS) foi utilizado para prever a variável Treinos com base nas variáveis Idade, IMC1 e Sociabilidade. O modelo explica uma proporção estatisticamente significativa e moderada da variância (R² = 0,14, F(3, 90) = 5,06, p = 0,003, R² ajustado = 0,12). Dentro desse modelo: • O efeito da Idade é estatisticamente significativo e positivo (beta = 1,91, IC 95% [0,82, 3,00], t(90) = 3,48, p &lt; 0,001; Beta padronizado = 0,35, IC 95% [0,15, 0,56]) • O efeito do IMC1 é estatisticamente significativo e negativo (beta = -2,80, IC 95% [-5,15, -0,46], t(90) = -2,37, p = 0,020; Beta padronizado = -0,24, IC 95% [-0,44, -0,04]) • O efeito da Sociabilidade é estatisticamente não significativo e positivo (beta = 0,52, IC 95% [-0,66, 1,69], t(90) = 0,88, p = 0,383; Beta padronizado = 0,09, IC 95% [-0,11, 0,28]) Parâmetros padronizados foram obtidos ajustando o modelo a uma versão padronizada do conjunto de dados. Intervalos de Confiança (ICs) de 95% e valores-p foram calculados usando uma aproximação da distribuição t de Wald."
  },
  {
    "objectID": "lista_8.html#b-path-analysis",
    "href": "lista_8.html#b-path-analysis",
    "title": "9  Lista 8 - CFA e Path Analysis",
    "section": "9.2 b) Path Analysis",
    "text": "9.2 b) Path Analysis\n\n\n\n\n\n\nExercício\n\n\n\nCom base no mesmo banco acima faça uma Path Analysis e monte um diagrama no AMOS R. Compare os resultados com os dados encontrados na regressão linear.\n\n\n\npath_1 = \"Treinos ~ Idade + IMC1 + Sociabilidade\"\n\n\npath_model_1 = sem(\n  model = path_1,\n  data = original,\n)\n\n\nTabela com os resultados\nComo sempre, podemos utilizar a função summary() para retornar um resumo com os resultados do modelo\n\nsummary(path_model_1) # posso colocar o parametro fit.measures = TRUE para obter os valores de aderência do modelo\n\nlavaan 0.6.16 ended normally after 1 iteration\n\n  Estimator                                         ML\n  Optimization method                           NLMINB\n  Number of model parameters                         4\n\n  Number of observations                            94\n\nModel Test User Model:\n                                                      \n  Test statistic                                 0.000\n  Degrees of freedom                                 0\n\nParameter Estimates:\n\n  Standard errors                             Standard\n  Information                                 Expected\n  Information saturated (h1) model          Structured\n\nRegressions:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n  Treinos ~                                           \n    Idade             1.907    0.536    3.557    0.000\n    IMC1             -2.802    1.156   -2.425    0.015\n    Sociabilidade     0.518    0.578    0.896    0.370\n\nVariances:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n   .Treinos        2050.999  299.169    6.856    0.000\n\n\nNo caso da path analisys recomendamos utilizar a função parameterEstimates() do pacote lavaan para ter uma tabela mais direta com os resultados dos estimadores.\n\nkable(parameterEstimates(path_model_1))\n\n\n\n\nlhs\nop\nrhs\nest\nse\nz\npvalue\nci.lower\nci.upper\n\n\n\n\nTreinos\n~\nIdade\n1.9071028\n0.5361890\n3.5567736\n0.0003754\n0.8561917\n2.9580139\n\n\nTreinos\n~\nIMC1\n-2.8021799\n1.1555981\n-2.4248741\n0.0153137\n-5.0671106\n-0.5372493\n\n\nTreinos\n~\nSociabilidade\n0.5177685\n0.5776294\n0.8963679\n0.3700563\n-0.6143644\n1.6499014\n\n\nTreinos\n~~\nTreinos\n2050.9987436\n299.1689143\n6.8556546\n0.0000000\n1464.6384463\n2637.3590409\n\n\nIdade\n~~\nIdade\n82.5840878\n0.0000000\nNA\nNA\n82.5840878\n82.5840878\n\n\nIdade\n~~\nIMC1\n10.7872961\n0.0000000\nNA\nNA\n10.7872961\n10.7872961\n\n\nIdade\n~~\nSociabilidade\n3.7635808\n0.0000000\nNA\nNA\n3.7635808\n3.7635808\n\n\nIMC1\n~~\nIMC1\n17.7567863\n0.0000000\nNA\nNA\n17.7567863\n17.7567863\n\n\nIMC1\n~~\nSociabilidade\n1.2498636\n0.0000000\nNA\nNA\n1.2498636\n1.2498636\n\n\nSociabilidade\n~~\nSociabilidade\n65.6008375\n0.0000000\nNA\nNA\n65.6008375\n65.6008375\n\n\n\n\n\n\n\nOs resultados foram os mesmos obtidos tanto pela path analysis quanto pela regressão linear simples.\n\n\nIndices de qualidade do modelo\n\nmodel_performance(path_model_1, metrics = c(\"Chi2\", \"Chi2_df\", \"NFI\", \"NNFI\", \"CFI\", \"RMSEA\", \"AIC\", \"BIC\"))\n\n# Indices of model performance\n\nChi2(0) |   NFI |  NNFI |   CFI | RMSEA |     AIC |      BIC\n------------------------------------------------------------\n0.000   | 1.000 | 1.000 | 1.000 | 0.000 | 991.612 | 1001.785\n\nAIC(path_model_1)\n\n[1] 991.6122\n\n\n\n\nDiagrama da path analysis\n\nP &lt;- semPaths(\n          object = path_model_1,\n          what = \"path\",\n          whatLabels = \"par\",\n          style = \"ram\",\n          layout = \"tree\",\n          rotation = 2,\n          sizeMan = 7,\n          sizeLat = 7,\n          color = \"lightgray\",\n          edge.label.cex = 1.2,\n          label.cex = 1.3\n)"
  },
  {
    "objectID": "lista_8.html#c-cfa",
    "href": "lista_8.html#c-cfa",
    "title": "9  Lista 8 - CFA e Path Analysis",
    "section": "9.3 c) CFA",
    "text": "9.3 c) CFA\n\n\n\n\n\n\nExercício\n\n\n\nVeja o banco de dados Fatorial escala.sav. Faça uma Análise fatorial confirmatória (CFA) gerando os seguintes fatores com base no questionário de apego a amigos (IAA).\n\n\nSegundo a teoria esperada, os fatores teriam o seguinte agrupamento: a. Confianca – Q13 Q14 Q15 b. Alienacao – Q1 Q2 Q3 Monte o diagrama e discuta a qualidade do modelo e suas limitações caso existam.\nEquação do Modelo 1:\ncfa_eq = \" Alienação =~ IAa1 + IAa2 + IAa3 Confiança =~ IAa13 + IAa14 + IAa15  \"\nAnálise Fatorial Confirmatória do modelo 1\ncfa_modelo = cfa(   model = cfa_eq,   data = dados_CFA,   std.lv = TRUE  )\n\ndados_CFA = read.spss(\"fatorial CFA.sav\", to.data.frame=TRUE)\n\n\ncfa_eq = \"\nAlienação =~ IAa1 + IAa2 + IAa3\nConfiança =~ IAa13 + IAa14 + IAa15\n\n\"\n\n\ncfa_modelo = cfa(\n  model = cfa_eq,\n  data = dados_CFA,\n  std.lv = TRUE #If TRUE, the metric of each latent variable is determined by fixing their (residual) variances to 1.0. If FALSE, the metric of each latent variable is determined by fixing the factor loading of the first indicator to 1.0.\n  \n)\n\n\nResultados do modelo sem covariâncias entre os resíduos (modelo 1)\n\nsummary(cfa_modelo) # posso colocar no summary o parametro fit.measures = TRUE\n\nlavaan 0.6.16 ended normally after 18 iterations\n\n  Estimator                                         ML\n  Optimization method                           NLMINB\n  Number of model parameters                        13\n\n                                                  Used       Total\n  Number of observations                           347         348\n\nModel Test User Model:\n                                                      \n  Test statistic                                39.166\n  Degrees of freedom                                 8\n  P-value (Chi-square)                           0.000\n\nParameter Estimates:\n\n  Standard errors                             Standard\n  Information                                 Expected\n  Information saturated (h1) model          Structured\n\nLatent Variables:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n  Alienação =~                                        \n    IAa1              0.578    0.069    8.408    0.000\n    IAa2              0.842    0.069   12.135    0.000\n    IAa3              0.423    0.051    8.278    0.000\n  Confiança =~                                        \n    IAa13             0.580    0.044   13.279    0.000\n    IAa14             0.660    0.052   12.652    0.000\n    IAa15             0.586    0.053   11.105    0.000\n\nCovariances:\n                  Estimate  Std.Err  z-value  P(&gt;|z|)\n  Alienação ~~                                       \n    Confiança        0.865    0.051   16.807    0.000\n\nVariances:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n   .IAa1              1.023    0.088   11.607    0.000\n   .IAa2              0.676    0.089    7.627    0.000\n   .IAa3              0.568    0.049   11.667    0.000\n   .IAa13             0.316    0.036    8.898    0.000\n   .IAa14             0.485    0.051    9.564    0.000\n   .IAa15             0.564    0.052   10.767    0.000\n    Alienação         1.000                           \n    Confiança         1.000                           \n\n\n\nkable(parameterEstimates(cfa_modelo))\n\n\n\n\nlhs\nop\nrhs\nest\nse\nz\npvalue\nci.lower\nci.upper\n\n\n\n\nAlienação\n=~\nIAa1\n0.5783085\n0.0687768\n8.408481\n0\n0.4435084\n0.7131086\n\n\nAlienação\n=~\nIAa2\n0.8419500\n0.0693835\n12.134735\n0\n0.7059609\n0.9779391\n\n\nAlienação\n=~\nIAa3\n0.4226729\n0.0510624\n8.277581\n0\n0.3225925\n0.5227533\n\n\nConfiança\n=~\nIAa13\n0.5796173\n0.0436497\n13.278840\n0\n0.4940655\n0.6651691\n\n\nConfiança\n=~\nIAa14\n0.6603480\n0.0521921\n12.652247\n0\n0.5580533\n0.7626427\n\n\nConfiança\n=~\nIAa15\n0.5856667\n0.0527386\n11.105077\n0\n0.4823008\n0.6890325\n\n\nIAa1\n~~\nIAa1\n1.0234312\n0.0881741\n11.606933\n0\n0.8506131\n1.1962493\n\n\nIAa2\n~~\nIAa2\n0.6763156\n0.0886784\n7.626611\n0\n0.5025092\n0.8501221\n\n\nIAa3\n~~\nIAa3\n0.5677370\n0.0486609\n11.667220\n0\n0.4723635\n0.6631105\n\n\nIAa13\n~~\nIAa13\n0.3160382\n0.0355192\n8.897671\n0\n0.2464219\n0.3856546\n\n\nIAa14\n~~\nIAa14\n0.4851673\n0.0507280\n9.564088\n0\n0.3857422\n0.5845925\n\n\nIAa15\n~~\nIAa15\n0.5636709\n0.0523500\n10.767362\n0\n0.4610669\n0.6662750\n\n\nAlienação\n~~\nAlienação\n1.0000000\n0.0000000\nNA\nNA\n1.0000000\n1.0000000\n\n\nConfiança\n~~\nConfiança\n1.0000000\n0.0000000\nNA\nNA\n1.0000000\n1.0000000\n\n\nAlienação\n~~\nConfiança\n0.8646695\n0.0514471\n16.806951\n0\n0.7638349\n0.9655040\n\n\n\n\n\n\n\nOs resultados da análise de equações estruturais indicam que o modelo ajustado apresenta um bom ajuste aos dados observados (χ² = 39,166, df = 8, p &lt; 0,001). O modelo envolve duas variáveis latentes, “Alienação” e “Confiança”, e suas variáveis observadas.\nOs coeficientes de carga (estimates) indicam que as perguntas associadas a “Alienação” (IAa1, IAa2, IAa3) e “Confiança” (IAa13, IAa14, IAa15) têm influências positivas significativas em suas respectivas variáveis latentes.\nAlém disso, a covariância entre “Alienação” e “Confiança” é estatisticamente significativa (estimate = 0,865, p &lt; 0,001), sugerindo uma relação entre essas duas dimensões.\nEsses resultados fornecem evidências de que o modelo proposto é estatisticamente significativo.\n\n\nÍndices de qualidade do modelo 1\n\nmodel_performance(cfa_modelo, metrics = c(\"Chi2\", \"Chi2_df\", \"NFI\", \"CFI\", \"RMSEA\", \"p_RMSEA\", \"AIC\", \"BIC\", \"NNFI\") )\n\n# Indices of model performance\n\nChi2(8) |   NFI |   CFI | RMSEA | p (RMSEA) |      AIC |      BIC |  NNFI\n-------------------------------------------------------------------------\n39.166  | 0.918 | 0.933 | 0.106 |     0.003 | 5402.476 | 5452.517 | 0.874\n\n\nOs resultados dos índices de qualidade indicam que o modelo apresenta uma adequada qualidade de aderência aos dados observados, conforme evidenciado pelos índices de ajuste (NFI, CFI) acima de 0.9. Apenas o NNFI (ou TFI) está abaixo de 0.9, indicando um bom ajuste relativo.\nNo entanto, o valor do RMSEA é alto (10%), indicando que o modelo pode ser aprimorado.\nOs valores de AIC e BIC serão utilizados para efeito de comparação com os modelos a seguir.\n\n\nDiagrama da CFA com o modelo 1\n\nplot_CFA &lt;- semPaths(\n          object = cfa_modelo,\n          what = \"path\",\n          whatLabels = \"par\",\n          style = \"ram\",\n          layout = \"tree\",\n          rotation = 2,\n          sizeMan = 7,\n          sizeLat = 7,\n          color = \"lightgray\",\n          edge.label.cex = 1.2,\n          label.cex = 1.3\n)\n\n\n\n\n\n\nVerificar os índices de modificações do modelo 1\nOs índices de modificação podem ser obtidos utilizando a função modindices(). Por padrão, os índices de modificação são impressos para cada parâmetro não livre (ou fixado como zero). Os índices de modificação são complementados pelos valores de mudança esperada nos parâmetros (EPC) (coluna epc). As últimas três colunas contêm os valores padronizados de EPC (sepc.lv: padronização apenas das variáveis latentes; sepc.all: padronização de todas as variáveis; sepc.nox: padronização de todas, exceto variáveis observadas exógenas).\n\nkable(modificationindices(cfa_modelo, sort = TRUE, minimum.value = 5))\n\n\n\n\n\nlhs\nop\nrhs\nmi\nepc\nsepc.lv\nsepc.all\nsepc.nox\n\n\n\n\n34\nIAa13\n~~\nIAa14\n18.245523\n0.1825252\n0.1825252\n0.4661302\n0.4661302\n\n\n18\nAlienação\n=~\nIAa15\n18.245517\n0.9569991\n0.9569991\n1.0050447\n1.0050447\n\n\n29\nIAa2\n~~\nIAa14\n17.160433\n-0.2043919\n-0.2043919\n-0.3568151\n-0.3568151\n\n\n30\nIAa2\n~~\nIAa15\n10.461405\n0.1539148\n0.1539148\n0.2492832\n0.2492832\n\n\n20\nConfiança\n=~\nIAa2\n8.403845\n-1.6415789\n-1.6415789\n-1.3947817\n-1.3947817\n\n\n23\nIAa1\n~~\nIAa3\n8.403843\n-0.1390871\n-0.1390871\n-0.1824669\n-0.1824669\n\n\n35\nIAa13\n~~\nIAa15\n5.006171\n-0.0840609\n-0.0840609\n-0.1991642\n-0.1991642\n\n\n17\nAlienação\n=~\nIAa14\n5.006165\n-0.5603084\n-0.5603084\n-0.5837728\n-0.5837728\n\n\n\n\n\n\n\n\n\nNovo modelo com a covariância dos resíduos (modelo 2)\n\ncfa_eq_2 = \"\nAlienação =~ IAa1 + IAa2 + IAa3\nConfiança =~ IAa13 + IAa14 + IAa15\n\n# Covariancia dos resíduos\nIAa1 ~~ IAa3\nIAa13 ~~ IAa14\nIAa13 ~~ IAa15\n\n\"\n\n\ncfa_modelo_2 = cfa(\n  model = cfa_eq_2,\n  data = dados_CFA,\n  std.lv = TRUE\n)\n\nEquação do Modelo 2:\ncfa_eq_2 = \" Alienação =~ IAa1 + IAa2 + IAa3 Confiança =~ IAa13 + IAa14 + IAa15  # Covariancia dos resíduos IAa1 ~~ IAa3  IAa13 ~~ IAa14 IAa13 ~~ IAa15  \"\nAnálise Fatorial Confirmatória do modelo 2\ncfa_modelo_2 = cfa(   model = cfa_eq_2,   data = dados_CFA,   std.lv = TRUE    )\n\n\nResultados modelo 2\n\nsummary(cfa_modelo_2) # posso colocar no summary o parametro fit.measures = TRUE\n\nlavaan 0.6.16 ended normally after 24 iterations\n\n  Estimator                                         ML\n  Optimization method                           NLMINB\n  Number of model parameters                        16\n\n                                                  Used       Total\n  Number of observations                           347         348\n\nModel Test User Model:\n                                                      \n  Test statistic                                14.194\n  Degrees of freedom                                 5\n  P-value (Chi-square)                           0.014\n\nParameter Estimates:\n\n  Standard errors                             Standard\n  Information                                 Expected\n  Information saturated (h1) model          Structured\n\nLatent Variables:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n  Alienação =~                                        \n    IAa1              0.625    0.069    9.009    0.000\n    IAa2              0.844    0.066   12.774    0.000\n    IAa3              0.440    0.052    8.484    0.000\n  Confiança =~                                        \n    IAa13             0.486    0.054    9.010    0.000\n    IAa14             0.558    0.057    9.744    0.000\n    IAa15             0.627    0.058   10.741    0.000\n\nCovariances:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n .IAa1 ~~                                             \n   .IAa3             -0.131    0.047   -2.812    0.005\n .IAa13 ~~                                            \n   .IAa14             0.156    0.042    3.700    0.000\n   .IAa15             0.005    0.037    0.123    0.902\n  Alienação ~~                                        \n    Confiança         0.945    0.063   15.041    0.000\n\nVariances:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n   .IAa1              0.968    0.088   11.049    0.000\n   .IAa2              0.674    0.081    8.299    0.000\n   .IAa3              0.553    0.049   11.303    0.000\n   .IAa13             0.416    0.048    8.717    0.000\n   .IAa14             0.609    0.059   10.323    0.000\n   .IAa15             0.514    0.060    8.497    0.000\n    Alienação         1.000                           \n    Confiança         1.000                           \n\n\n\nkable(parameterEstimates(cfa_modelo_2))\n\n\n\n\nlhs\nop\nrhs\nest\nse\nz\npvalue\nci.lower\nci.upper\n\n\n\n\nAlienação\n=~\nIAa1\n0.6246375\n0.0693348\n9.0090043\n0.0000000\n0.4887438\n0.7605313\n\n\nAlienação\n=~\nIAa2\n0.8436173\n0.0660435\n12.7736683\n0.0000000\n0.7141745\n0.9730601\n\n\nAlienação\n=~\nIAa3\n0.4398298\n0.0518412\n8.4841676\n0.0000000\n0.3382228\n0.5414367\n\n\nConfiança\n=~\nIAa13\n0.4855333\n0.0538885\n9.0099663\n0.0000000\n0.3799138\n0.5911527\n\n\nConfiança\n=~\nIAa14\n0.5583551\n0.0573047\n9.7436136\n0.0000000\n0.4460399\n0.6706703\n\n\nConfiança\n=~\nIAa15\n0.6267943\n0.0583571\n10.7406769\n0.0000000\n0.5124166\n0.7411721\n\n\nIAa1\n~~\nIAa3\n-0.1314725\n0.0467540\n-2.8120052\n0.0049234\n-0.2231086\n-0.0398363\n\n\nIAa13\n~~\nIAa14\n0.1558199\n0.0421126\n3.7000779\n0.0002155\n0.0732807\n0.2383591\n\n\nIAa13\n~~\nIAa15\n0.0045594\n0.0370060\n0.1232056\n0.9019443\n-0.0679712\n0.0770899\n\n\nIAa1\n~~\nIAa1\n0.9676998\n0.0875801\n11.0493149\n0.0000000\n0.7960460\n1.1393536\n\n\nIAa2\n~~\nIAa2\n0.6735053\n0.0811578\n8.2987178\n0.0000000\n0.5144390\n0.8325716\n\n\nIAa3\n~~\nIAa3\n0.5529392\n0.0489190\n11.3031626\n0.0000000\n0.4570597\n0.6488186\n\n\nIAa13\n~~\nIAa13\n0.4162519\n0.0477495\n8.7174157\n0.0000000\n0.3226647\n0.5098391\n\n\nIAa14\n~~\nIAa14\n0.6094664\n0.0590382\n10.3232593\n0.0000000\n0.4937537\n0.7251790\n\n\nIAa15\n~~\nIAa15\n0.5138053\n0.0604718\n8.4966149\n0.0000000\n0.3952828\n0.6323277\n\n\nAlienação\n~~\nAlienação\n1.0000000\n0.0000000\nNA\nNA\n1.0000000\n1.0000000\n\n\nConfiança\n~~\nConfiança\n1.0000000\n0.0000000\nNA\nNA\n1.0000000\n1.0000000\n\n\nAlienação\n~~\nConfiança\n0.9447949\n0.0628146\n15.0410074\n0.0000000\n0.8216805\n1.0679092\n\n\n\n\n\n\n\nOs resultados da análise indicam que o modelo apresenta um razoável ajuste aos dados observados, conforme evidenciado pelos índices de ajuste, embora o teste qui-quadrado seja estatisticamente significativo (χ² = 14.194, df = 5, p = 0.014), indicando diferenças entre o modelo e os dados.\nAs cargas fatoriais para os indicadores associados às variáveis latentes “Alienação” e “Confiança” são todas estatisticamente significativas (p &lt; 0.001), indicando que esses indicadores têm uma relação com suas respectivas variáveis latentes.\n\n\nÍndices de qualidade do modelo 2\n\nmodel_performance(cfa_modelo_2, metrics = c(\"Chi2\", \"Chi2_df\", \"NFI\", \"CFI\", \"RMSEA\", \"p_RMSEA\", \"AIC\", \"BIC\", \"NNFI\"))\n\n# Indices of model performance\n\nChi2(5) |   NFI |   CFI | RMSEA | p (RMSEA) |      AIC |      BIC |  NNFI\n-------------------------------------------------------------------------\n14.194  | 0.970 | 0.980 | 0.073 |     0.165 | 5383.504 | 5445.093 | 0.940\n\n\nOs resultados dos índices de qualidade indicam que o modelo apresenta uma adequada qualidade de aderência aos dados observados, conforme evidenciado pelos índices de ajuste (NFI, CFI e NNFI) acima de 0.9.\nNo entanto, o valor do RMSEA é moderado (7%), indicando que o modelo pode ser aprimorado.\nOs valores de AIC e BIC serão utilizados para efeito de comparação com os modelos a seguir.\n\n\nDiagrama do modelo 2\n\nplot_CFA &lt;- semPaths(\n          object = cfa_modelo_2,\n          what = \"path\",\n          whatLabels = \"par\",\n          style = \"ram\",\n          layout = \"tree\",\n          rotation = 2,\n          sizeMan = 7,\n          sizeLat = 7,\n          color = \"lightgray\",\n          edge.label.cex = 1.2,\n          label.cex = 1.3\n)\n\n\n\n\n\n\nComparação entre os modelos\n\ncompare_performance(cfa_modelo, cfa_modelo_2, \n                    metrics = c(\"NFI\", \"CFI\", \"RMSEA\", \"p_RMSEA\", \"AIC\", \"BIC\", \"NNFI\"),\n                    rank = TRUE, verbose = F)\n\n# Comparison of Model Performance Indices\n\nName         |  Model |   NFI |   CFI | RMSEA | p (RMSEA) |  NNFI | AIC weights | BIC weights | Performance-Score\n-----------------------------------------------------------------------------------------------------------------\ncfa_modelo_2 | lavaan | 0.970 | 0.980 | 0.073 |     0.165 | 0.940 |       1.000 |       0.976 |            85.71%\ncfa_modelo   | lavaan | 0.918 | 0.933 | 0.106 |     0.003 | 0.874 |    7.59e-05 |       0.024 |            14.29%\n\n\nO modelo_2 demonstra superioridade em relação ao modelo_1 com base nos critérios de ajuste avaliados."
  },
  {
    "objectID": "lista_8.html#complementar-modelo-com-apenas-um-fator-latente-modelo-3",
    "href": "lista_8.html#complementar-modelo-com-apenas-um-fator-latente-modelo-3",
    "title": "9  Lista 8 - CFA e Path Analysis",
    "section": "9.4 Complementar: Modelo com apenas um fator latente (modelo 3)",
    "text": "9.4 Complementar: Modelo com apenas um fator latente (modelo 3)\n\ncfa_eq_3 = \"\nF1 =~ IAa1 + IAa2 + IAa3 + IAa13 + IAa14 + IAa15\n\"\n\n\ncfa_modelo_3 = cfa(\n  model = cfa_eq_3,\n  data = dados_CFA,\n  std.lv = TRUE\n)\n\nEquação do modelo 3:\ncfa_eq_3 = \" F1 =~ IAa1 + IAa2 + IAa3 + IAa13 + IAa14 + IAa15 \"\nAnálise Fatorial Confirmatória do modelo 2\ncfa_modelo_3 = cfa(   model = cfa_eq_3,   data = dados_CFA,   std.lv = TRUE    )\n\nResultados do modelo 3\n\nkable(parameterEstimates(cfa_modelo_3))\n\n\n\n\nlhs\nop\nrhs\nest\nse\nz\npvalue\nci.lower\nci.upper\n\n\n\n\nF1\n=~\nIAa1\n0.5580340\n0.0664300\n8.400335\n0\n0.4278336\n0.6882343\n\n\nF1\n=~\nIAa2\n0.7651182\n0.0637750\n11.997154\n0\n0.6401216\n0.8901149\n\n\nF1\n=~\nIAa3\n0.4044799\n0.0493864\n8.190103\n0\n0.3076843\n0.5012755\n\n\nF1\n=~\nIAa13\n0.5564023\n0.0432259\n12.871965\n0\n0.4716811\n0.6411235\n\n\nF1\n=~\nIAa14\n0.6400430\n0.0517363\n12.371268\n0\n0.5386419\n0.7414442\n\n\nF1\n=~\nIAa15\n0.5959511\n0.0519930\n11.462144\n0\n0.4940467\n0.6978555\n\n\nIAa1\n~~\nIAa1\n1.0464704\n0.0865635\n12.089050\n0\n0.8768091\n1.2161317\n\n\nIAa2\n~~\nIAa2\n0.7997900\n0.0764096\n10.467135\n0\n0.6500299\n0.9495502\n\n\nIAa3\n~~\nIAa3\n0.5827853\n0.0479619\n12.151008\n0\n0.4887817\n0.6767889\n\n\nIAa13\n~~\nIAa13\n0.3424110\n0.0348598\n9.822517\n0\n0.2740870\n0.4107349\n\n\nIAa14\n~~\nIAa14\n0.5115718\n0.0501136\n10.208248\n0\n0.4133510\n0.6097926\n\n\nIAa15\n~~\nIAa15\n0.5515190\n0.0510740\n10.798424\n0\n0.4514157\n0.6516222\n\n\nF1\n~~\nF1\n1.0000000\n0.0000000\nNA\nNA\n1.0000000\n1.0000000\n\n\n\n\n\n\n\nO modelo de uma única variável latente “F1” apresenta um ajuste geral adequado aos dados, conforme indicado pelo teste qui-quadrado significativo (χ² = 45.034, df = 9, p = 0.000).\nAs cargas fatoriais dos indicadores para “F1” são todas estatisticamente significativas (p &lt; 0.001), indicando que essas variáveis observadas têm uma relação com a variável latente “F1”.\n\n\nÍndices de qualidade do modelo 3\n\nmodel_performance(cfa_modelo_3, metrics = c(\"Chi2\", \"Chi2_df\", \"NFI\", \"CFI\", \"RMSEA\", \"p_RMSEA\", \"AIC\", \"BIC\", \"NNFI\") )\n\n# Indices of model performance\n\nChi2(9) |   NFI |   CFI | RMSEA | p (RMSEA) |      AIC |      BIC |  NNFI\n-------------------------------------------------------------------------\n45.034  | 0.906 | 0.922 | 0.107 |     0.001 | 5406.344 | 5452.536 | 0.870\n\n\n\n\nDiagrama do modelo 3\n\nplot_CFA &lt;- semPaths(\n          object = cfa_modelo_3,\n          what = \"path\",\n          whatLabels = \"par\",\n          style = \"ram\",\n          layout = \"tree\",\n          rotation = 2,\n          sizeMan = 7,\n          sizeLat = 7,\n          color = \"lightgray\",\n          edge.label.cex = 1.2,\n          label.cex = 1.3\n)\n\n\n\n\n\n\nÍndices de modificação para o modelo\n\nkable(modificationindices(cfa_modelo_3, standardized = FALSE, minimum.value = 5))\n\n\n\n\n\nlhs\nop\nrhs\nmi\nepc\n\n\n\n\n16\nIAa1\n~~\nIAa13\n6.419170\n-0.1034145\n\n\n19\nIAa2\n~~\nIAa3\n5.260435\n0.1017547\n\n\n21\nIAa2\n~~\nIAa14\n19.900038\n-0.2224777\n\n\n22\nIAa2\n~~\nIAa15\n6.284104\n0.1223301\n\n\n26\nIAa13\n~~\nIAa14\n24.013115\n0.1712177"
  },
  {
    "objectID": "lista_8.html#modelo-4-com-covariância-entre-os-resíduos",
    "href": "lista_8.html#modelo-4-com-covariância-entre-os-resíduos",
    "title": "9  Lista 8 - CFA e Path Analysis",
    "section": "9.5 Modelo 4 com covariância entre os resíduos",
    "text": "9.5 Modelo 4 com covariância entre os resíduos\n\ncfa_eq_4 = \"\nF1 =~ IAa1 + IAa2 + IAa3 + IAa13 + IAa14 + IAa15\n\n#Covariância dos resíduos\nIAa2    ~~  IAa14\nIAa13   ~~  IAa14\n\"\n\nAnálise Fatorial Confirmatória do modelo 4\n\ncfa_modelo_4 = cfa(\n  model = cfa_eq_4,\n  data = dados_CFA,\n  std.lv = TRUE\n)\n\n\nResultados do modelo 4\n\nkable(parameterEstimates(cfa_modelo_4))\n\n\n\n\nlhs\nop\nrhs\nest\nse\nz\npvalue\nci.lower\nci.upper\n\n\n\n\nF1\n=~\nIAa1\n0.5755782\n0.0658579\n8.739696\n0.0000000\n0.4464990\n0.7046573\n\n\nF1\n=~\nIAa2\n0.8812882\n0.0659778\n13.357336\n0.0000000\n0.7519740\n1.0106024\n\n\nF1\n=~\nIAa3\n0.4106200\n0.0490163\n8.377216\n0.0000000\n0.3145499\n0.5066902\n\n\nF1\n=~\nIAa13\n0.4773285\n0.0461558\n10.341675\n0.0000000\n0.3868648\n0.5677923\n\n\nF1\n=~\nIAa14\n0.6235655\n0.0604044\n10.323181\n0.0000000\n0.5051751\n0.7419560\n\n\nF1\n=~\nIAa15\n0.5905868\n0.0525289\n11.243084\n0.0000000\n0.4876320\n0.6935415\n\n\nIAa2\n~~\nIAa14\n-0.1604716\n0.0490176\n-3.273757\n0.0010613\n-0.2565442\n-0.0643989\n\n\nIAa13\n~~\nIAa14\n0.1249518\n0.0402391\n3.105235\n0.0019013\n0.0460846\n0.2038189\n\n\nIAa1\n~~\nIAa1\n1.0265817\n0.0852570\n12.041031\n0.0000000\n0.8594811\n1.1936823\n\n\nIAa2\n~~\nIAa2\n0.6085266\n0.0820552\n7.416062\n0.0000000\n0.4477013\n0.7693519\n\n\nIAa3\n~~\nIAa3\n0.5777805\n0.0475147\n12.160028\n0.0000000\n0.4846534\n0.6709077\n\n\nIAa13\n~~\nIAa13\n0.4241519\n0.0395633\n10.720852\n0.0000000\n0.3466093\n0.5016945\n\n\nIAa14\n~~\nIAa14\n0.5298461\n0.0642606\n8.245273\n0.0000000\n0.4038976\n0.6557945\n\n\nIAa15\n~~\nIAa15\n0.5578837\n0.0519546\n10.737912\n0.0000000\n0.4560546\n0.6597128\n\n\nF1\n~~\nF1\n1.0000000\n0.0000000\nNA\nNA\n1.0000000\n1.0000000\n\n\n\n\n\n\n\nOs resultados do modelo sugerem que o ajuste do modelo aos dados é razoável, conforme indicado pelo teste qui-quadrado (χ² = 12.216, df = 7, p = 0.094). O modelo envolve uma única variável latente “F1,” e por seis variáveis observadas (IAa1, IAa2, IAa3, IAa13, IAa14, IAa15). As cargas fatoriais associadas a cada indicador são todas estatisticamente significativas (p &lt; 0.001), indicando uma relação entre esses indicadores e a variável latente “F1”. As variâncias dos indicadores também são significativas, sugerindo que cada indicador contribui para a variabilidade total da variável latente “F1”.\nAlém disso, há duas covariâncias estimadas entre os indicadores: uma entre IAa2 e IAa14, e outra entre IAa13 e IAa14. Essas covariâncias indicam associações adicionais entre os indicadores além daquelas explicadas pelas relações com a variável latente “F1”.\n\n\nÍndices de qualidade do modelo 4\n\nmodel_performance(cfa_modelo_4, metrics = c(\"Chi2\", \"Chi2_df\", \"NFI\", \"CFI\", \"RMSEA\", \"p_RMSEA\", \"AIC\", \"BIC\", \"NNFI\"))\n\n# Indices of model performance\n\nChi2(7) |   NFI |   CFI | RMSEA | p (RMSEA) |      AIC |      BIC |  NNFI\n-------------------------------------------------------------------------\n12.216  | 0.974 | 0.989 | 0.046 |     0.498 | 5377.526 | 5431.416 | 0.976\n\n\nO modelo apresenta índices NFI (0.974), CFI (0.989) e NNFI (0.976) próximos de 1, indicando um bom ajuste. O RMSEA (0.046) é baixo, sugerindo uma adequada aproximação do modelo aos dados.\n\n\nDiagrama do modelo 4\n\nplot_CFA &lt;- semPaths(\n          object = cfa_modelo_4,\n          what = \"path\",\n          whatLabels = \"par\",\n          style = \"ram\",\n          layout = \"tree\",\n          rotation = 2,\n          sizeMan = 7,\n          sizeLat = 7,\n          color = \"lightgray\",\n          edge.label.cex = 1.2,\n          label.cex = 1.3\n)\n\n\n\n\n\n\nComparação entre os modelos\n\ncompare_performance(cfa_modelo, cfa_modelo_2, cfa_modelo_3, cfa_modelo_4,\n                    metrics = c(\"NFI\", \"CFI\", \"RMSEA\", \"p_RMSEA\", \"AIC\", \"BIC\", \"NNFI\"),\n                    rank = TRUE, verbose = F)\n\n# Comparison of Model Performance Indices\n\nName         |  Model |   NFI |   CFI | RMSEA | p (RMSEA) |  NNFI | AIC weights | BIC weights | Performance-Score\n-----------------------------------------------------------------------------------------------------------------\ncfa_modelo_4 | lavaan | 0.974 | 0.989 | 0.046 |     0.498 | 0.976 |       0.952 |       0.999 |            85.71%\ncfa_modelo_2 | lavaan | 0.970 | 0.980 | 0.073 |     0.165 | 0.940 |       0.048 |       0.001 |            47.00%\ncfa_modelo   | lavaan | 0.918 | 0.933 | 0.106 |     0.003 | 0.874 |    3.64e-06 |    2.62e-05 |            19.27%\ncfa_modelo_3 | lavaan | 0.906 | 0.922 | 0.107 |     0.001 | 0.870 |    5.26e-07 |    2.59e-05 |            14.29%\n\n\nO modelo_4 demonstra superioridade em relação aos demais modelos com base nos critérios de ajuste avaliados.\n\n# Links de referência\n\n# https://rdrr.io/cran/performance/man/model_performance.lavaan.html\n# https://methodenlehre.github.io/SGSCLM-R-course/cfa-and-sem-with-lavaan.html#structural-equation-modelling-sem"
  },
  {
    "objectID": "lista_8.html#lista-8-resolvida-no-spss",
    "href": "lista_8.html#lista-8-resolvida-no-spss",
    "title": "9  Lista 8 - CFA e Path Analysis",
    "section": "9.6 Lista 8 resolvida no SPSS",
    "text": "9.6 Lista 8 resolvida no SPSS"
  },
  {
    "objectID": "lista_8.html#extras",
    "href": "lista_8.html#extras",
    "title": "9  Lista 8 - CFA e Path Analysis",
    "section": "9.7 Extras!",
    "text": "9.7 Extras!\n\nMais gráficos\n\nsemPaths(cfa_modelo, \"std\", weighted = FALSE, nCharNodes = 7, shapeMan = \"rectangle\",\n         sizeMan = 8, sizeMan2 = 5)"
  },
  {
    "objectID": "lista_8.html#referências",
    "href": "lista_8.html#referências",
    "title": "9  Lista 8 - CFA e Path Analysis",
    "section": "9.8 Referências",
    "text": "9.8 Referências\nhttps://www.jstatsoft.org/article/view/v048i02\nhttps://lavaan.ugent.be/tutorial/inspect.html"
  },
  {
    "objectID": "lista_8.html#versões-dos-pacotes",
    "href": "lista_8.html#versões-dos-pacotes",
    "title": "9  Lista 8 - CFA e Path Analysis",
    "section": "9.9 Versões dos pacotes",
    "text": "9.9 Versões dos pacotes\n\nreport(sessionInfo())\n\nAnalyses were conducted using the R Statistical language (version 4.3.1; R Core\nTeam, 2023) on Windows 11 x64 (build 22621), using the packages effectsize\n(version 0.8.6; Ben-Shachar MS et al., 2020), semPlot (version 1.1.6; Epskamp\nS, 2022), lubridate (version 1.9.3; Grolemund G, Wickham H, 2011), parameters\n(version 0.21.3; Lüdecke D et al., 2020), performance (version 0.10.8; Lüdecke\nD et al., 2021), easystats (version 0.6.0; Lüdecke D et al., 2022), see\n(version 0.8.1; Lüdecke D et al., 2021), insight (version 0.19.6; Lüdecke D et\nal., 2019), bayestestR (version 0.13.1; Makowski D et al., 2019), modelbased\n(version 0.8.6; Makowski D et al., 2020), report (version 0.5.7; Makowski D et\nal., 2023), correlation (version 0.8.4; Makowski D et al., 2022), tibble\n(version 3.2.1; Müller K, Wickham H, 2023), datawizard (version 0.9.0; Patil I\net al., 2022), foreign (version 0.8.85; R Core Team, 2023), lavaan (version\n0.6.16; Rosseel Y, 2012), ggplot2 (version 3.4.4; Wickham H, 2016), forcats\n(version 1.0.0; Wickham H, 2023), stringr (version 1.5.1; Wickham H, 2023),\ntidyverse (version 2.0.0; Wickham H et al., 2019), dplyr (version 1.1.3;\nWickham H et al., 2023), purrr (version 1.0.2; Wickham H, Henry L, 2023), readr\n(version 2.1.4; Wickham H et al., 2023), tidyr (version 1.3.0; Wickham H et\nal., 2023) and kableExtra (version 1.3.4; Zhu H, 2021).\n\nReferences\n----------\n  - Ben-Shachar MS, Lüdecke D, Makowski D (2020). \"effectsize: Estimation of\nEffect Size Indices and Standardized Parameters.\" _Journal of Open Source\nSoftware_, *5*(56), 2815. doi:10.21105/joss.02815\n&lt;https://doi.org/10.21105/joss.02815&gt;, &lt;https://doi.org/10.21105/joss.02815&gt;.\n  - Epskamp S (2022). _semPlot: Path Diagrams and Visual Analysis of Various SEM\nPackages' Output_. R package version 1.1.6,\n&lt;https://CRAN.R-project.org/package=semPlot&gt;.\n  - Grolemund G, Wickham H (2011). \"Dates and Times Made Easy with lubridate.\"\n_Journal of Statistical Software_, *40*(3), 1-25.\n&lt;https://www.jstatsoft.org/v40/i03/&gt;.\n  - Lüdecke D, Ben-Shachar M, Patil I, Makowski D (2020). \"Extracting, Computing\nand Exploring the Parameters of Statistical Models using R.\" _Journal of Open\nSource Software_, *5*(53), 2445. doi:10.21105/joss.02445\n&lt;https://doi.org/10.21105/joss.02445&gt;.\n  - Lüdecke D, Ben-Shachar M, Patil I, Waggoner P, Makowski D (2021).\n\"performance: An R Package for Assessment, Comparison and Testing of\nStatistical Models.\" _Journal of Open Source Software_, *6*(60), 3139.\ndoi:10.21105/joss.03139 &lt;https://doi.org/10.21105/joss.03139&gt;.\n  - Lüdecke D, Ben-Shachar M, Patil I, Wiernik B, Makowski D (2022). \"easystats:\nFramework for Easy Statistical Modeling, Visualization, and Reporting.\" _CRAN_.\nR package, &lt;https://easystats.github.io/easystats/&gt;.\n  - Lüdecke D, Patil I, Ben-Shachar M, Wiernik B, Waggoner P, Makowski D (2021).\n\"see: An R Package for Visualizing Statistical Models.\" _Journal of Open Source\nSoftware_, *6*(64), 3393. doi:10.21105/joss.03393\n&lt;https://doi.org/10.21105/joss.03393&gt;.\n  - Lüdecke D, Waggoner P, Makowski D (2019). \"insight: A Unified Interface to\nAccess Information from Model Objects in R.\" _Journal of Open Source Software_,\n*4*(38), 1412. doi:10.21105/joss.01412 &lt;https://doi.org/10.21105/joss.01412&gt;.\n  - Makowski D, Ben-Shachar M, Lüdecke D (2019). \"bayestestR: Describing Effects\nand their Uncertainty, Existence and Significance within the Bayesian\nFramework.\" _Journal of Open Source Software_, *4*(40), 1541.\ndoi:10.21105/joss.01541 &lt;https://doi.org/10.21105/joss.01541&gt;,\n&lt;https://joss.theoj.org/papers/10.21105/joss.01541&gt;.\n  - Makowski D, Ben-Shachar M, Patil I, Lüdecke D (2020). \"Estimation of\nModel-Based Predictions, Contrasts and Means.\" _CRAN_.\n&lt;https://github.com/easystats/modelbased&gt;.\n  - Makowski D, Lüdecke D, Patil I, Thériault R, Ben-Shachar M, Wiernik B (2023).\n\"Automated Results Reporting as a Practical Tool to Improve Reproducibility and\nMethodological Best Practices Adoption.\" _CRAN_.\n&lt;https://easystats.github.io/report/&gt;.\n  - Makowski D, Wiernik B, Patil I, Lüdecke D, Ben-Shachar M (2022).\n\"correlation: Methods for Correlation Analysis.\" Version 0.8.3,\n&lt;https://CRAN.R-project.org/package=correlation&gt;. Makowski D, Ben-Shachar M,\nPatil I, Lüdecke D (2020). \"Methods and Algorithms for Correlation Analysis in\nR.\" _Journal of Open Source Software_, *5*(51), 2306. doi:10.21105/joss.02306\n&lt;https://doi.org/10.21105/joss.02306&gt;,\n&lt;https://joss.theoj.org/papers/10.21105/joss.02306&gt;.\n  - Müller K, Wickham H (2023). _tibble: Simple Data Frames_. R package version\n3.2.1, &lt;https://CRAN.R-project.org/package=tibble&gt;.\n  - Patil I, Makowski D, Ben-Shachar M, Wiernik B, Bacher E, Lüdecke D (2022).\n\"datawizard: An R Package for Easy Data Preparation and Statistical\nTransformations.\" _Journal of Open Source Software_, *7*(78), 4684.\ndoi:10.21105/joss.04684 &lt;https://doi.org/10.21105/joss.04684&gt;.\n  - R Core Team (2023). _foreign: Read Data Stored by 'Minitab', 'S', 'SAS',\n'SPSS', 'Stata', 'Systat', 'Weka', 'dBase', ..._. R package version 0.8-85,\n&lt;https://CRAN.R-project.org/package=foreign&gt;.\n  - R Core Team (2023). _R: A Language and Environment for Statistical\nComputing_. R Foundation for Statistical Computing, Vienna, Austria.\n&lt;https://www.R-project.org/&gt;.\n  - Rosseel Y (2012). \"lavaan: An R Package for Structural Equation Modeling.\"\n_Journal of Statistical Software_, *48*(2), 1-36. doi:10.18637/jss.v048.i02\n&lt;https://doi.org/10.18637/jss.v048.i02&gt;.\n  - Wickham H (2016). _ggplot2: Elegant Graphics for Data Analysis_.\nSpringer-Verlag New York. ISBN 978-3-319-24277-4,\n&lt;https://ggplot2.tidyverse.org&gt;.\n  - Wickham H (2023). _forcats: Tools for Working with Categorical Variables\n(Factors)_. R package version 1.0.0,\n&lt;https://CRAN.R-project.org/package=forcats&gt;.\n  - Wickham H (2023). _stringr: Simple, Consistent Wrappers for Common String\nOperations_. R package version 1.5.1,\n&lt;https://CRAN.R-project.org/package=stringr&gt;.\n  - Wickham H, Averick M, Bryan J, Chang W, McGowan LD, François R, Grolemund G,\nHayes A, Henry L, Hester J, Kuhn M, Pedersen TL, Miller E, Bache SM, Müller K,\nOoms J, Robinson D, Seidel DP, Spinu V, Takahashi K, Vaughan D, Wilke C, Woo K,\nYutani H (2019). \"Welcome to the tidyverse.\" _Journal of Open Source Software_,\n*4*(43), 1686. doi:10.21105/joss.01686 &lt;https://doi.org/10.21105/joss.01686&gt;.\n  - Wickham H, François R, Henry L, Müller K, Vaughan D (2023). _dplyr: A Grammar\nof Data Manipulation_. R package version 1.1.3,\n&lt;https://CRAN.R-project.org/package=dplyr&gt;.\n  - Wickham H, Henry L (2023). _purrr: Functional Programming Tools_. R package\nversion 1.0.2, &lt;https://CRAN.R-project.org/package=purrr&gt;.\n  - Wickham H, Hester J, Bryan J (2023). _readr: Read Rectangular Text Data_. R\npackage version 2.1.4, &lt;https://CRAN.R-project.org/package=readr&gt;.\n  - Wickham H, Vaughan D, Girlich M (2023). _tidyr: Tidy Messy Data_. R package\nversion 1.3.0, &lt;https://CRAN.R-project.org/package=tidyr&gt;.\n  - Zhu H (2021). _kableExtra: Construct Complex Table with 'kable' and Pipe\nSyntax_. R package version 1.3.4,\n&lt;https://CRAN.R-project.org/package=kableExtra&gt;."
  },
  {
    "objectID": "lista_8_1.html#a-modelo-causal-teórico",
    "href": "lista_8_1.html#a-modelo-causal-teórico",
    "title": "10  Lista 8.1 - Moderação e Mediação",
    "section": "10.1 a) Modelo causal teórico",
    "text": "10.1 a) Modelo causal teórico\n\n\n\n\n\n\nExercício\n\n\n\nVerifique esse modelo causal teórico e veja se ele faz sentido, utilizando um modelo SEM com mediação. Avalie os efeitos diretos e indiretos e decida se esse modelo teórico faz sentido, utilizando o AMOS e o Process.\n\n\nResolução do exercício foi baseada no vídeo “Simple Mediation using lavaan package of R” https://www.youtube.com/watch?v=nfQOCy9xMnk\n\noriginal = read.spss(\"DADOS PATH.sav\", to.data.frame=TRUE)\nglimpse(original)\n\nRows: 94\nColumns: 4\n$ Idade         &lt;dbl&gt; 57, 41, 29, 26, 33, 37, 26, 44, 31, 36, 30, 55, 43, 27, …\n$ IMC1          &lt;dbl&gt; 28.46122, 32.62609, 26.99050, 19.03602, 28.76650, 24.686…\n$ Treinos       &lt;dbl&gt; 108, 144, 48, 102, 123, 63, 39, 105, 6, 48, 144, 144, 11…\n$ Sociabilidade &lt;dbl&gt; 14, 34, 17, 20, 26, 19, 15, 32, 27, 19, 28, 9, 30, 29, 1…\n\n\n\nmodelo_1 = \"Treinos ~ c_*Sociabilidade + b*IMC1 \n            IMC1 ~ a*Sociabilidade\n            Indireto := a*b\n            Total_direto_C := a*b + c_\"\n\n\nfit_1 = sem(modelo_1, original, se = \"bootstrap\", bootstrap = 500)\n\n\n#summary(fit_1) # parâmetros adicionais summary(fit_1, fit.measures = TRUE, standardized = TRUE, rsquare = TRUE) \n\nkable(parameterEstimates(fit_1))\n\n\n\n\nlhs\nop\nrhs\nlabel\nest\nse\nz\npvalue\nci.lower\nci.upper\n\n\n\n\nTreinos\n~\nSociabilidade\nc_\n0.6052243\n0.6619768\n0.9142682\n0.3605759\n-0.6524603\n1.8245324\n\n\nTreinos\n~\nIMC1\nb\n-1.6497656\n1.0185007\n-1.6197982\n0.1052756\n-3.6551562\n0.4350822\n\n\nIMC1\n~\nSociabilidade\na\n0.0190526\n0.0507549\n0.3753835\n0.7073753\n-0.0861290\n0.1130998\n\n\nTreinos\n~~\nTreinos\n\n2327.0247317\n187.7869286\n12.3918355\n0.0000000\n1884.6418875\n2629.3007296\n\n\nIMC1\n~~\nIMC1\n\n17.7329732\n3.0046312\n5.9018802\n0.0000000\n12.1538364\n23.9097897\n\n\nSociabilidade\n~~\nSociabilidade\n\n65.6008375\n0.0000000\nNA\nNA\n65.6008375\n65.6008375\n\n\nIndireto\n:=\na*b\nIndireto\n-0.0314322\n0.0996909\n-0.3152970\n0.7525362\n-0.2192393\n0.2283743\n\n\nTotal_direto_C\n:=\na*b+c_\nTotal_direto_C\n0.5737921\n0.6689293\n0.8577768\n0.3910157\n-0.7354611\n1.7852540\n\n\n\n\n\n\n\n\nResultados\n\nRegressões:\n\n\nO coeficiente estimado para a relação entre Sociabilidae e Treinos é 0.605, mas não é estatisticamente significativo (p = 0.360).\nO coeficiente estimado para a relação entre IMC e Treinos é -1.650, indicando uma relação negativa. No entanto, esse coeficiente também não é estatisticamente significativo (p = 0.100).\nO coeficiente estimado para a relação entre Sociabilidae e IMC é 0.019 e não é estatisticamente significativo (p = 0.693).\n\n\nParâmetros Definidos:\n\n\nO efeito indireto é estimado como -0.031, mas não é estatisticamente significativo (p = 0.717). Isso sugere que a variável IMC não medeia significativamente a relação entre Sociabilidae e Treinos.\nO efeito direto da Sociabilidade no Treino é estimado como 0.574 e também não é estatisticamente significativo (p = 0.386).\n\nCom base nos resultados, podemos concluir que o modelo teórico não se sustenta, pois não há evidência estatística significativa para sugerir relações entre as variáveis Sociabilidae , IMC e Treinos."
  },
  {
    "objectID": "lista_8_1.html#b-mediação-vs-regressões-lineares",
    "href": "lista_8_1.html#b-mediação-vs-regressões-lineares",
    "title": "10  Lista 8.1 - Moderação e Mediação",
    "section": "10.2 b) Mediação vs Regressões lineares",
    "text": "10.2 b) Mediação vs Regressões lineares\n\n\n\n\n\n\nExercício\n\n\n\nCompare os dados encontrados com aqueles realizados por um conjunto de regressões lineares (OLS). Fazer esta análise de mediação por regressão linear e utilizando o AMOS+Process é a mesma coisa? Coloque também o diagrama gerado aqui.\n\n\n\nValor de “c”\n\nsoc_treinos = lm(Treinos ~ Sociabilidade, data = original) #valor de c\nkable(summary(soc_treinos)$coef)\n\n\n\n\n\nEstimate\nStd. Error\nt value\nPr(&gt;|t|)\n\n\n\n\n(Intercept)\n69.4395522\n14.1638541\n4.9025888\n0.0000041\n\n\nSociabilidade\n0.5737921\n0.6273496\n0.9146289\n0.3627775\n\n\n\n\n\n\n\n\n\nValor de a\n\nsoc_imc = lm(IMC1 ~ Sociabilidade, data = original) \nkable(summary(soc_imc)$coef)\n\n\n\n\n\nEstimate\nStd. Error\nt value\nPr(&gt;|t|)\n\n\n\n\n(Intercept)\n25.3971491\n1.2238100\n20.7525264\n0.0000000\n\n\nSociabilidade\n0.0190526\n0.0542054\n0.3514884\n0.7260257\n\n\n\n\n\n\n\n\n\nvalor de b e de c’\n\nsoc_E_imc_treinos = lm(Treinos ~ IMC1 + Sociabilidade, data = original) \nkable(summary(soc_E_imc_treinos)$coef)\n\n\n\n\n\nEstimate\nStd. Error\nt value\nPr(&gt;|t|)\n\n\n\n\n(Intercept)\n111.3388945\n33.5981763\n3.3138374\n0.0013220\n\n\nIMC1\n-1.6497656\n1.2008507\n-1.3738307\n0.1728690\n\n\nSociabilidade\n0.6052243\n0.6247647\n0.9687235\n0.3352508\n\n\n\n\n\n\n\nOs resultados são diferentes. As mediações apenas por regressão linear não apresentam o resultado do efeito indireto, mostrado no resultado do exercício anterior\n\n\nDiagrama do modelo\n\ndiagrama_1 &lt;- semPaths(\n          object = fit_1,\n          what = \"path\",\n          whatLabels = \"par\",\n          style = \"ram\",\n          layout = \"tree\",\n          rotation = 2,\n          sizeMan = 7,\n          sizeLat = 7,\n          color = \"lightgray\",\n          edge.label.cex = 1.2,\n          label.cex = 1.3\n)"
  },
  {
    "objectID": "lista_8_1.html#modelo-2-opcional-1",
    "href": "lista_8_1.html#modelo-2-opcional-1",
    "title": "10  Lista 8.1 - Moderação e Mediação",
    "section": "10.3 Modelo 2 (Opcional 1)",
    "text": "10.3 Modelo 2 (Opcional 1)\nRefaça o modelo tendo a variável Idade como mediador.\n\nmodelo_2 = \"Treinos ~ c_*Sociabilidade + b*Idade \n            Idade ~ a*Sociabilidade\n            Indireto := a*b\n            Total_direto_C := a*b + c_\"\n\n\nfit_2 = sem(modelo_2, original, se = \"bootstrap\", bootstrap = 500)\n\nkable(parameterEstimates(fit_2)) # parâmetros adicionais summary(fit_1, fit.measures = TRUE, standardized = TRUE, rsquare = TRUE) \n\n\n\n\nlhs\nop\nrhs\nlabel\nest\nse\nz\npvalue\nci.lower\nci.upper\n\n\n\n\nTreinos\n~\nSociabilidade\nc_\n0.4852942\n0.6196786\n0.7831385\n0.4335458\n-0.7090243\n1.6900127\n\n\nTreinos\n~\nIdade\nb\n1.5425565\n0.4588149\n3.3620452\n0.0007737\n0.6913514\n2.4044144\n\n\nIdade\n~\nSociabilidade\na\n0.0573709\n0.1100893\n0.5211310\n0.6022755\n-0.1575502\n0.2725941\n\n\nTreinos\n~~\nTreinos\n\n2179.2955768\n194.4639552\n11.2066813\n0.0000000\n1707.6722717\n2479.7855236\n\n\nIdade\n~~\nIdade\n\n82.3681677\n10.5597227\n7.8002207\n0.0000000\n61.5549212\n102.4772562\n\n\nSociabilidade\n~~\nSociabilidade\n\n65.6008375\n0.0000000\nNA\nNA\n65.6008375\n65.6008375\n\n\nIndireto\n:=\na*b\nIndireto\n0.0884979\n0.1735841\n0.5098273\n0.6101725\n-0.2660349\n0.4446866\n\n\nTotal_direto_C\n:=\na*b+c_\nTotal_direto_C\n0.5737921\n0.6808613\n0.8427445\n0.3993714\n-0.7934420\n1.9182149\n\n\n\n\n\n\n\n\nResultados\n\nRegressões:\n\nA relação estimada entre Sociabilidade e Treinos é 0.485, mas não é estatisticamente significativa (p = 0.384).\nA relação estimada entre Idade e Treinos é 1.543, indicando uma relação positiva e significativa (p = 0.001).\nA relação estimada entre Sociabldd e Idade é 0.057 e não é estatisticamente significativa (p = 0.592).\n\nParâmetros Definidos:\n\nO efeito Indireto é estimado como 0.088, mas não é estatisticamente significativo (p = 0.605). Isso sugere que a variável Idade não medeia significativamente a relação entre Sociabilidade e Treinos.\nO efeito total direto da Sociabilidae nos Treinos é estimado como 0.574 e não é estatisticamente significativo (p = 0.345).\n\n\nOs resultados sugerem que a variável Idade está significativamente relacionada à variável Treinos, enquanto a variável Sociabilidade não tem uma relação significativa com Treinos. O efeito indireto através de Idade não é estatisticamente significativo, e o efeito total direto também não é significativo.\n\n\nDiagrama do modelo 2\n\ndiagrama_2 &lt;- semPaths(\n          object = fit_2,\n          what = \"path\",\n          whatLabels = \"par\",\n          style = \"ram\",\n          layout = \"tree\",\n          rotation = 2,\n          sizeMan = 7,\n          sizeLat = 7,\n          color = \"lightgray\",\n          edge.label.cex = 1.2,\n          label.cex = 1.3\n)\n\n\n\n\n\nmediation_model_2 = lm(Idade ~ Sociabilidade, data = original)\nkable(summary(mediation_model_2)$coef)\n\n\n\n\n\nEstimate\nStd. Error\nt value\nPr(&gt;|t|)\n\n\n\n\n(Intercept)\n32.8228531\n2.6375635\n12.4443843\n0.0000000\n\n\nSociabilidade\n0.0573709\n0.1168237\n0.4910896\n0.6245325\n\n\n\n\n\n\n# library(flexplot)\n# visualize(mediation_model_2) análise gráfica do modelo\n\n\nfull_model_2 = lm(Treinos ~ Idade + Sociabilidade, data = original)\nkable(summary(full_model_2)$coef)\n\n\n\n\n\nEstimate\nStd. Error\nt value\nPr(&gt;|t|)\n\n\n\n\n(Intercept)\n18.8084463\n22.3454098\n0.8417141\n0.4021546\n\n\nIdade\n1.5425565\n0.5392097\n2.8607731\n0.0052418\n\n\nSociabilidade\n0.4852942\n0.6049941\n0.8021469\n0.4245578\n\n\n\n\n\n\n#visualize(full_model_2) análise gráfica do modelo\n\n\nresults_2 = mediate(mediation_model_2, full_model_2,\n                  treat = \"Sociabilidade\",\n                  mediator = \"Idade\",\n                  boot = TRUE,\n                  sims = 500)\n\nsummary(results_2)\n\n\nCausal Mediation Analysis \n\nNonparametric Bootstrap Confidence Intervals with the Percentile Method\n\n               Estimate 95% CI Lower 95% CI Upper p-value\nACME             0.0885      -0.2126         0.45    0.52\nADE              0.4853      -0.6804         1.70    0.37\nTotal Effect     0.5738      -0.6401         1.88    0.33\nProp. Mediated   0.1542      -1.7984         1.59    0.50\n\nSample Size Used: 94 \n\n\nSimulations: 500 \n\n\n\nmediate_plot(Treinos ~ Idade  + Sociabilidade  , data = original)"
  },
  {
    "objectID": "lista_8_1.html#modelo-3-opcional-2",
    "href": "lista_8_1.html#modelo-3-opcional-2",
    "title": "10  Lista 8.1 - Moderação e Mediação",
    "section": "10.4 Modelo 3 (Opcional 2)",
    "text": "10.4 Modelo 3 (Opcional 2)\nTestando outros modelos, foi possível observar que o efeito do IMC sobre o treinamento é mediado pela Idade\n\nmodelo_3 = \"Treinos ~ c_*IMC1 + b*Idade \n            Idade ~ a*IMC1\n            Indireto := a*b\n            Total_direto_C := a*b + c_\"\n\n\nfit_3 = sem(modelo_3, original, se = \"bootstrap\", bootstrap = 500) #demora um tempo para executar\n\n\nkable(parameterEstimates(fit_3)) # parâmetros adicionais summary(fit_1, fit.measures = TRUE, standardized = TRUE, rsquare = TRUE)\n\n\n\n\nlhs\nop\nrhs\nlabel\nest\nse\nz\npvalue\nci.lower\nci.upper\n\n\n\n\nTreinos\n~\nIMC1\nc_\n-2.7781642\n1.0067476\n-2.759544\n0.0057882\n-4.6800358\n-0.6198768\n\n\nTreinos\n~\nIdade\nb\n1.9275620\n0.4583106\n4.205798\n0.0000260\n0.9813260\n2.7588243\n\n\nIdade\n~\nIMC1\na\n0.6075027\n0.2252141\n2.697446\n0.0069874\n0.2357407\n1.0753598\n\n\nTreinos\n~~\nTreinos\n\n2068.5298836\n190.9705838\n10.831668\n0.0000000\n1660.9183246\n2429.8198497\n\n\nIdade\n~~\nIdade\n\n76.0307760\n9.8646493\n7.707398\n0.0000000\n55.5284839\n95.0898386\n\n\nIMC1\n~~\nIMC1\n\n17.7567863\n0.0000000\nNA\nNA\n17.7567863\n17.7567863\n\n\nIndireto\n:=\na*b\nIndireto\n1.1709992\n0.5155848\n2.271206\n0.0231345\n0.3149790\n2.3125077\n\n\nTotal_direto_C\n:=\na*b+c_\nTotal_direto_C\n-1.6071651\n1.0825367\n-1.484629\n0.1376422\n-3.6571736\n0.6752811\n\n\n\n\n\n\n\n\nResultados\n\nRegressões:\n\nA relação estimada entre IMC1 (Índice de Massa Corporal) e Treinos é -2.778, indicando uma relação negativa e significativa (p = 0.006).\nA relação estimada entre Idade e Treinos é 1.928, indicando uma relação positiva e significativa (p = 0.000).\nA relação estimada entre IMC e Idade é 0.608 e é estatisticamente significativa (p = 0.005).\n\nParâmetros Definidos:\n\nO efeito Indireto é estimado como 1.171 e é estatisticamente significativo (p = 0.030). Isso sugere que a variável Idade medeia significativamente a relação entre IMC e Treinos.\nO efeito total direto de IMC nos Treinos é estimado como -1.607, mas não é estatisticamente significativo (p = 0.114).\n\n\nOs resultados indicam que a variável IMC está significativamente relacionada negativamente à variável Treinos. A variável Idade atua como mediadora nessa relação. O efeito indireto é estimado como 1.171 (p = 0.030), indicando que a inclusão de Idade no modelo altera a relação entre IMC1 e Treinos, tornando-a mais negativa do que a relação direta."
  },
  {
    "objectID": "lista_8_1.html#diagrama-do-modelo-3",
    "href": "lista_8_1.html#diagrama-do-modelo-3",
    "title": "10  Lista 8.1 - Moderação e Mediação",
    "section": "10.5 Diagrama do modelo 3",
    "text": "10.5 Diagrama do modelo 3\n\ndiagrama_3 &lt;- semPaths(\n          object = fit_3,\n          what = \"path\",\n          whatLabels = \"par\",\n          style = \"ram\",\n          layout = \"tree\",\n          rotation = 2,\n          sizeMan = 7,\n          sizeLat = 7,\n          color = \"lightgray\",\n          edge.label.cex = 1.2,\n          label.cex = 1.3\n)\n\n\n\n\n\nmediation_model_3 = lm(Idade ~ IMC1, data = original)\nsummary(mediation_model_3)$coef\n\n              Estimate Std. Error  t value    Pr(&gt;|t|)\n(Intercept) 18.3591515   5.639405 3.255512 0.001584908\nIMC1         0.6075027   0.215734 2.815980 0.005949584\n\nvisualize(mediation_model_3) \n\n\n\n\n\nfull_model_3 = lm(Treinos ~ Idade + IMC1, data = original)\nsummary(full_model_3)$coef\n\n             Estimate Std. Error   t value     Pr(&gt;|t|)\n(Intercept) 87.606237 31.2333809  2.804891 0.0061538896\nIdade        1.927562  0.5467836  3.525274 0.0006645242\nIMC1        -2.778164  1.1791838 -2.356006 0.0206193649\n\nvisualize(full_model_3)\n\n\n\n\n\nresults_3 = mediate(mediation_model_3, full_model_3,\n                  treat = \"IMC1\",\n                  mediator = \"Idade\",\n                  boot = TRUE,\n                  sims = 500)\n\nsummary(results_3)\n\n\nCausal Mediation Analysis \n\nNonparametric Bootstrap Confidence Intervals with the Percentile Method\n\n               Estimate 95% CI Lower 95% CI Upper p-value    \nACME              1.171        0.339         2.43  &lt;2e-16 ***\nADE              -2.778       -4.585        -0.62   0.024 *  \nTotal Effect     -1.607       -3.441         0.57   0.156    \nProp. Mediated   -0.729      -11.591         7.21   0.156    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nSample Size Used: 94 \n\n\nSimulations: 500 \n\n\n\nmediate_plot(Treinos ~ Idade  + IMC1  , data = original)"
  },
  {
    "objectID": "lista_8_1.html#lista-8.1-resolvida-no-spss",
    "href": "lista_8_1.html#lista-8.1-resolvida-no-spss",
    "title": "10  Lista 8.1 - Moderação e Mediação",
    "section": "10.6 Lista 8.1 resolvida no SPSS",
    "text": "10.6 Lista 8.1 resolvida no SPSS"
  },
  {
    "objectID": "lista_8_1.html#extras",
    "href": "lista_8_1.html#extras",
    "title": "10  Lista 8.1 - Moderação e Mediação",
    "section": "10.7 Extras!",
    "text": "10.7 Extras!\nOutro tipo de resolução baseada no vídeo do Dustin Fife (How to do a mediation analysis in R…with visuals!)\n\n# Mediação com visualização\nlibrary(mediation)\nlibrary(flexplot)\n\n\nmediation_model = lm(IMC1 ~ Sociabilidade, data = original)\nsummary(mediation_model)\n\n\nCall:\nlm(formula = IMC1 ~ Sociabilidade, data = original)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-7.3645 -2.8931 -0.4598  2.7881 14.5354 \n\nCoefficients:\n              Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)   25.39715    1.22381  20.753   &lt;2e-16 ***\nSociabilidade  0.01905    0.05421   0.351    0.726    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 4.257 on 92 degrees of freedom\nMultiple R-squared:  0.001341,  Adjusted R-squared:  -0.009514 \nF-statistic: 0.1235 on 1 and 92 DF,  p-value: 0.726\n\n\n\nvisualize(mediation_model, plot = \"model\")\n\n\n\n\n\nfull_model = lm(Treinos ~ IMC1 + Sociabilidade, data = original)\nsummary(full_model)\n\n\nCall:\nlm(formula = Treinos ~ IMC1 + Sociabilidade, data = original)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-85.683 -42.165   2.807  47.623  69.596 \n\nCoefficients:\n              Estimate Std. Error t value Pr(&gt;|t|)   \n(Intercept)   111.3389    33.5982   3.314  0.00132 **\nIMC1           -1.6498     1.2009  -1.374  0.17287   \nSociabilidade   0.6052     0.6248   0.969  0.33525   \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 49.03 on 91 degrees of freedom\nMultiple R-squared:  0.02915,   Adjusted R-squared:  0.00781 \nF-statistic: 1.366 on 2 and 91 DF,  p-value: 0.2603\n\n\n\nvisualize(full_model)\n\n\n\n\n\nresults = mediate(mediation_model, full_model,\n                  treat = \"Sociabilidade\",\n                  mediator = \"IMC1\",\n                  boot = TRUE,\n                  sims = 500)\n\n\nsummary(results)\n\n\nCausal Mediation Analysis \n\nNonparametric Bootstrap Confidence Intervals with the Percentile Method\n\n               Estimate 95% CI Lower 95% CI Upper p-value\nACME            -0.0314      -0.1976         0.17    0.78\nADE              0.6052      -0.6669         1.95    0.29\nTotal Effect     0.5738      -0.6201         1.89    0.30\nProp. Mediated  -0.0548      -1.3478         1.26    0.87\n\nSample Size Used: 94 \n\n\nSimulations: 500 \n\n\n\nmediate_plot(Treinos ~ IMC1 +  Sociabilidade, data = original) # Ordem em que aparece as variáveis é muito importante. A última variável será sempre a variável DEPENDENTE (X). Todas as outras que vierem antes dela, serão tratadas como MEDIADORAS (no caso IMC1)"
  },
  {
    "objectID": "lista_8_1.html#referências",
    "href": "lista_8_1.html#referências",
    "title": "10  Lista 8.1 - Moderação e Mediação",
    "section": "10.8 Referências",
    "text": "10.8 Referências\nhttps://www.youtube.com/watch?v=_4Fu8SZID2k"
  },
  {
    "objectID": "lista_8_1.html#versões-dos-pacotes",
    "href": "lista_8_1.html#versões-dos-pacotes",
    "title": "10  Lista 8.1 - Moderação e Mediação",
    "section": "10.9 Versões dos pacotes",
    "text": "10.9 Versões dos pacotes\n\nreport(sessionInfo())\n\nAnalyses were conducted using the R Statistical language (version 4.3.1; R Core\nTeam, 2023) on Windows 11 x64 (build 22621), using the packages Matrix (version\n1.6.0; Bates D et al., 2023), effectsize (version 0.8.6; Ben-Shachar MS et al.,\n2020), semPlot (version 1.1.6; Epskamp S, 2022), flexplot (version 0.20.5; Fife\nD, 2024), mvtnorm (version 1.2.3; Genz A, Bretz F, 2009), lubridate (version\n1.9.3; Grolemund G, Wickham H, 2011), semTools (version 0.5.6; Jorgensen TD et\nal., 2022), parameters (version 0.21.3; Lüdecke D et al., 2020), performance\n(version 0.10.8; Lüdecke D et al., 2021), easystats (version 0.6.0; Lüdecke D\net al., 2022), see (version 0.8.1; Lüdecke D et al., 2021), insight (version\n0.19.6; Lüdecke D et al., 2019), bayestestR (version 0.13.1; Makowski D et al.,\n2019), modelbased (version 0.8.6; Makowski D et al., 2020), report (version\n0.5.7; Makowski D et al., 2023), correlation (version 0.8.4; Makowski D et al.,\n2022), tibble (version 3.2.1; Müller K, Wickham H, 2023), datawizard (version\n0.9.0; Patil I et al., 2022), foreign (version 0.8.85; R Core Team, 2023),\nlavaan (version 0.6.16; Rosseel Y, 2012), mediation (version 4.5.0; Tingley D\net al., 2014), MASS (version 7.3.60; Venables WN, Ripley BD, 2002), ggplot2\n(version 3.4.4; Wickham H, 2016), forcats (version 1.0.0; Wickham H, 2023),\nstringr (version 1.5.1; Wickham H, 2023), tidyverse (version 2.0.0; Wickham H\net al., 2019), dplyr (version 1.1.3; Wickham H et al., 2023), purrr (version\n1.0.2; Wickham H, Henry L, 2023), readr (version 2.1.4; Wickham H et al.,\n2023), tidyr (version 1.3.0; Wickham H et al., 2023), sandwich (version 3.1.0;\nZeileis A et al., 2020) and kableExtra (version 1.3.4; Zhu H, 2021).\n\nReferences\n----------\n  - Bates D, Maechler M, Jagan M (2023). _Matrix: Sparse and Dense Matrix Classes\nand Methods_. R package version 1.6-0,\n&lt;https://CRAN.R-project.org/package=Matrix&gt;.\n  - Ben-Shachar MS, Lüdecke D, Makowski D (2020). \"effectsize: Estimation of\nEffect Size Indices and Standardized Parameters.\" _Journal of Open Source\nSoftware_, *5*(56), 2815. doi:10.21105/joss.02815\n&lt;https://doi.org/10.21105/joss.02815&gt;, &lt;https://doi.org/10.21105/joss.02815&gt;.\n  - Epskamp S (2022). _semPlot: Path Diagrams and Visual Analysis of Various SEM\nPackages' Output_. R package version 1.1.6,\n&lt;https://CRAN.R-project.org/package=semPlot&gt;.\n  - Fife D (2024). _flexplot: Graphically Based Data Analysis Using 'flexplot'_.\nR package version 0.20.5.\n  - Genz A, Bretz F (2009). _Computation of Multivariate Normal and t\nProbabilities_, series Lecture Notes in Statistics. Springer-Verlag,\nHeidelberg. ISBN 978-3-642-01688-2.\n  - Grolemund G, Wickham H (2011). \"Dates and Times Made Easy with lubridate.\"\n_Journal of Statistical Software_, *40*(3), 1-25.\n&lt;https://www.jstatsoft.org/v40/i03/&gt;.\n  - Jorgensen TD, Pornprasertmanit S, Schoemann AM, Rosseel Y (2022).\n_\\texttt{semTools}: Useful tools for structural equation modeling_. R package\nversion 0.5-6, &lt;https://CRAN.R-project.org/package=semTools&gt;.\n  - Lüdecke D, Ben-Shachar M, Patil I, Makowski D (2020). \"Extracting, Computing\nand Exploring the Parameters of Statistical Models using R.\" _Journal of Open\nSource Software_, *5*(53), 2445. doi:10.21105/joss.02445\n&lt;https://doi.org/10.21105/joss.02445&gt;.\n  - Lüdecke D, Ben-Shachar M, Patil I, Waggoner P, Makowski D (2021).\n\"performance: An R Package for Assessment, Comparison and Testing of\nStatistical Models.\" _Journal of Open Source Software_, *6*(60), 3139.\ndoi:10.21105/joss.03139 &lt;https://doi.org/10.21105/joss.03139&gt;.\n  - Lüdecke D, Ben-Shachar M, Patil I, Wiernik B, Makowski D (2022). \"easystats:\nFramework for Easy Statistical Modeling, Visualization, and Reporting.\" _CRAN_.\nR package, &lt;https://easystats.github.io/easystats/&gt;.\n  - Lüdecke D, Patil I, Ben-Shachar M, Wiernik B, Waggoner P, Makowski D (2021).\n\"see: An R Package for Visualizing Statistical Models.\" _Journal of Open Source\nSoftware_, *6*(64), 3393. doi:10.21105/joss.03393\n&lt;https://doi.org/10.21105/joss.03393&gt;.\n  - Lüdecke D, Waggoner P, Makowski D (2019). \"insight: A Unified Interface to\nAccess Information from Model Objects in R.\" _Journal of Open Source Software_,\n*4*(38), 1412. doi:10.21105/joss.01412 &lt;https://doi.org/10.21105/joss.01412&gt;.\n  - Makowski D, Ben-Shachar M, Lüdecke D (2019). \"bayestestR: Describing Effects\nand their Uncertainty, Existence and Significance within the Bayesian\nFramework.\" _Journal of Open Source Software_, *4*(40), 1541.\ndoi:10.21105/joss.01541 &lt;https://doi.org/10.21105/joss.01541&gt;,\n&lt;https://joss.theoj.org/papers/10.21105/joss.01541&gt;.\n  - Makowski D, Ben-Shachar M, Patil I, Lüdecke D (2020). \"Estimation of\nModel-Based Predictions, Contrasts and Means.\" _CRAN_.\n&lt;https://github.com/easystats/modelbased&gt;.\n  - Makowski D, Lüdecke D, Patil I, Thériault R, Ben-Shachar M, Wiernik B (2023).\n\"Automated Results Reporting as a Practical Tool to Improve Reproducibility and\nMethodological Best Practices Adoption.\" _CRAN_.\n&lt;https://easystats.github.io/report/&gt;.\n  - Makowski D, Wiernik B, Patil I, Lüdecke D, Ben-Shachar M (2022).\n\"correlation: Methods for Correlation Analysis.\" Version 0.8.3,\n&lt;https://CRAN.R-project.org/package=correlation&gt;. Makowski D, Ben-Shachar M,\nPatil I, Lüdecke D (2020). \"Methods and Algorithms for Correlation Analysis in\nR.\" _Journal of Open Source Software_, *5*(51), 2306. doi:10.21105/joss.02306\n&lt;https://doi.org/10.21105/joss.02306&gt;,\n&lt;https://joss.theoj.org/papers/10.21105/joss.02306&gt;.\n  - Müller K, Wickham H (2023). _tibble: Simple Data Frames_. R package version\n3.2.1, &lt;https://CRAN.R-project.org/package=tibble&gt;.\n  - Patil I, Makowski D, Ben-Shachar M, Wiernik B, Bacher E, Lüdecke D (2022).\n\"datawizard: An R Package for Easy Data Preparation and Statistical\nTransformations.\" _Journal of Open Source Software_, *7*(78), 4684.\ndoi:10.21105/joss.04684 &lt;https://doi.org/10.21105/joss.04684&gt;.\n  - R Core Team (2023). _foreign: Read Data Stored by 'Minitab', 'S', 'SAS',\n'SPSS', 'Stata', 'Systat', 'Weka', 'dBase', ..._. R package version 0.8-85,\n&lt;https://CRAN.R-project.org/package=foreign&gt;.\n  - R Core Team (2023). _R: A Language and Environment for Statistical\nComputing_. R Foundation for Statistical Computing, Vienna, Austria.\n&lt;https://www.R-project.org/&gt;.\n  - Rosseel Y (2012). \"lavaan: An R Package for Structural Equation Modeling.\"\n_Journal of Statistical Software_, *48*(2), 1-36. doi:10.18637/jss.v048.i02\n&lt;https://doi.org/10.18637/jss.v048.i02&gt;.\n  - Tingley D, Yamamoto T, Hirose K, Keele L, Imai K (2014). \"mediation: R\nPackage for Causal Mediation Analysis.\" _Journal of Statistical Software_,\n*59*(5), 1-38. &lt;http://www.jstatsoft.org/v59/i05/&gt;. Imai K, Keele L, Yamamoto T\n(2010). \"Identification, Inference, and Sensitivity Analysis for Causal\nMediation Effects.\" _Statistical Science_, *25*(1), 51-71.\n&lt;http://imai.princeton.edu/research/mediation.html&gt;. Imai K, Keele L, Tingley D\n(2010). \"A General Approach to Causal Mediation Analysis.\" _Psychological\nMethods_, *15*(4), 309-334.\n&lt;http://imai.princeton.edu/research/BaronKenny.html&gt;. Imai K, Keele L, Tingley\nD, Yamamoto T (2011). \"Unpacking the Black Box of Causality: Learning about\nCausal Mechanisms from Experimental and Observational Studies.\" _American\nPolitical Science Review_, *105*(4), 765-789.\n&lt;http://imai.princeton.edu/research/mediationP.html&gt;. Imai K, Yamamoto T\n(2013). \"Identification and Sensitivity Analysis for Multiple Causal\nMechanisms: Revisiting Evidence from Framing Experiments.\" _Political\nAnalysis_, *21*(2), 141-171. &lt;http://imai.princeton.edu/research/medsens.html&gt;.\nImai K, Keele L, Tingley D, Yamamoto T (2010). \"Causal Mediation Analysis Using\nR.\" In Vinod HD (ed.), _Advances in Social Science Research Using R_.\nSpringer-Verlag, New York.\n  - Venables WN, Ripley BD (2002). _Modern Applied Statistics with S_, Fourth\nedition. Springer, New York. ISBN 0-387-95457-0,\n&lt;https://www.stats.ox.ac.uk/pub/MASS4/&gt;.\n  - Wickham H (2016). _ggplot2: Elegant Graphics for Data Analysis_.\nSpringer-Verlag New York. ISBN 978-3-319-24277-4,\n&lt;https://ggplot2.tidyverse.org&gt;.\n  - Wickham H (2023). _forcats: Tools for Working with Categorical Variables\n(Factors)_. R package version 1.0.0,\n&lt;https://CRAN.R-project.org/package=forcats&gt;.\n  - Wickham H (2023). _stringr: Simple, Consistent Wrappers for Common String\nOperations_. R package version 1.5.1,\n&lt;https://CRAN.R-project.org/package=stringr&gt;.\n  - Wickham H, Averick M, Bryan J, Chang W, McGowan LD, François R, Grolemund G,\nHayes A, Henry L, Hester J, Kuhn M, Pedersen TL, Miller E, Bache SM, Müller K,\nOoms J, Robinson D, Seidel DP, Spinu V, Takahashi K, Vaughan D, Wilke C, Woo K,\nYutani H (2019). \"Welcome to the tidyverse.\" _Journal of Open Source Software_,\n*4*(43), 1686. doi:10.21105/joss.01686 &lt;https://doi.org/10.21105/joss.01686&gt;.\n  - Wickham H, François R, Henry L, Müller K, Vaughan D (2023). _dplyr: A Grammar\nof Data Manipulation_. R package version 1.1.3,\n&lt;https://CRAN.R-project.org/package=dplyr&gt;.\n  - Wickham H, Henry L (2023). _purrr: Functional Programming Tools_. R package\nversion 1.0.2, &lt;https://CRAN.R-project.org/package=purrr&gt;.\n  - Wickham H, Hester J, Bryan J (2023). _readr: Read Rectangular Text Data_. R\npackage version 2.1.4, &lt;https://CRAN.R-project.org/package=readr&gt;.\n  - Wickham H, Vaughan D, Girlich M (2023). _tidyr: Tidy Messy Data_. R package\nversion 1.3.0, &lt;https://CRAN.R-project.org/package=tidyr&gt;.\n  - Zeileis A, Köll S, Graham N (2020). \"Various Versatile Variances: An\nObject-Oriented Implementation of Clustered Covariances in R.\" _Journal of\nStatistical Software_, *95*(1), 1-36. doi:10.18637/jss.v095.i01\n&lt;https://doi.org/10.18637/jss.v095.i01&gt;. Zeileis A (2004). \"Econometric\nComputing with HC and HAC Covariance Matrix Estimators.\" _Journal of\nStatistical Software_, *11*(10), 1-17. doi:10.18637/jss.v011.i10\n&lt;https://doi.org/10.18637/jss.v011.i10&gt;. Zeileis A (2006). \"Object-Oriented\nComputation of Sandwich Estimators.\" _Journal of Statistical Software_,\n*16*(9), 1-16. doi:10.18637/jss.v016.i09\n&lt;https://doi.org/10.18637/jss.v016.i09&gt;.\n  - Zhu H (2021). _kableExtra: Construct Complex Table with 'kable' and Pipe\nSyntax_. R package version 1.3.4,\n&lt;https://CRAN.R-project.org/package=kableExtra&gt;."
  },
  {
    "objectID": "lista_2.html",
    "href": "lista_2.html",
    "title": "Lista 2: GEE Avançado",
    "section": "",
    "text": "📦 Pacotes Necessários\n✓ Pacotes carregados!",
    "crumbs": [
      "Modelos Lineares",
      "Lista 2: GEE Avançado"
    ]
  },
  {
    "objectID": "lista_2.html#exercícios",
    "href": "lista_2.html#exercícios",
    "title": "2  Lista 2 - GEE",
    "section": "2.2 Exercícios",
    "text": "2.2 Exercícios\n\na) GEE com a VD “Pulse”\nUtilize um GEE para verificar o efeito de tempo e grupo sobre os resultados de resp e pulse. Faça 3 modelos para cada variável dependente (com as distribuições Normal, Gamma e Tweedie) e cole aqui apenas as tabelas relevantes para a análise.\n\nDistribuição normal\n\nCriando o modelo\n\nmodel_gee_tweedie &lt;- glmmTMB::glmmTMB(formula = resp ~ Tempo*drug + us(1 + Tempo | ID),\n                                      family = gaussian(),# tweedie(var.power = 1.5, link.power = 0),  # Definindo a família Tweedie\n                                      data = bd_long  # Seu conjunto de dados\n  #corstr = \"exchangeable\"  # Estrutura de correlação (pode ser \"independence\", \"exchangeable\", etc.)\n)\n\nWarning in finalizeTMB(TMBStruc, obj, fit, h, data.tmb.old): Model convergence\nproblem; non-positive-definite Hessian matrix. See vignette('troubleshooting')\n\nAIC(model_gee_tweedie)\n\n[1] NA\n\nrm(model_gee_tweedie)\n\n\nmodelo_gee_pulse_normal &lt;- geeglm(pulse ~ drug + Tempo + drug*Tempo, \n                           data = bd_long,         \n                           id = ID,                 \n                           family = gaussian, #Distribuição normal      \n                           corstr = \"unstructured\")\n\n\n\nResumo do modelo e contrastes\n\nsummary(modelo_gee_pulse_normal)\n\n\nCall:\ngeeglm(formula = pulse ~ drug + Tempo + drug * Tempo, family = gaussian, \n    data = bd_long, id = ID, corstr = \"unstructured\")\n\n Coefficients:\n                   Estimate Std.err     Wald Pr(&gt;|W|)    \n(Intercept)         2.20000 0.04082 2904.000  &lt; 2e-16 ***\ndrugPlacebo         0.46667 0.05092   84.000  &lt; 2e-16 ***\nTempo2              0.01667 0.03664    0.207  0.64921    \nTempo3              0.08333 0.06838    1.485  0.22297    \ndrugPlacebo:Tempo2  0.13333 0.04194   10.105  0.00148 ** \ndrugPlacebo:Tempo3  0.03333 0.08767    0.145  0.70377    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nCorrelation structure = unstructured \nEstimated Scale Parameters:\n\n            Estimate  Std.err\n(Intercept)  0.00963 0.001676\n  Link = identity \n\nEstimated Correlation Parameters:\n          Estimate Std.err\nalpha.1:2   0.7212  0.1690\nalpha.1:3  -0.2885  0.2076\nalpha.2:3   0.1154  0.2665\nNumber of clusters:   12  Maximum cluster size: 3 \n\nemmeans(modelo_gee_pulse_normal, pairwise ~ drug*Tempo)\n\n$emmeans\n drug     Tempo emmean     SE df lower.CL upper.CL\n New Drug 1       2.20 0.0408 30     2.12     2.28\n Placebo  1       2.67 0.0304 30     2.60     2.73\n New Drug 2       2.22 0.0549 30     2.10     2.33\n Placebo  2       2.82 0.0280 30     2.76     2.87\n New Drug 3       2.28 0.0436 30     2.19     2.37\n Placebo  3       2.78 0.0366 30     2.71     2.86\n\nCovariance estimate used: vbeta \nConfidence level used: 0.95 \n\n$contrasts\n contrast                          estimate     SE df t.ratio p.value\n New Drug Tempo1 - Placebo Tempo1   -0.4667 0.0509 30  -9.165  &lt;.0001\n New Drug Tempo1 - New Drug Tempo2  -0.0167 0.0366 30  -0.455  0.9973\n New Drug Tempo1 - Placebo Tempo2   -0.6167 0.0495 30 -12.449  &lt;.0001\n New Drug Tempo1 - New Drug Tempo3  -0.0833 0.0684 30  -1.219  0.8244\n New Drug Tempo1 - Placebo Tempo3   -0.5833 0.0549 30 -10.634  &lt;.0001\n Placebo Tempo1 - New Drug Tempo2    0.4500 0.0627 30   7.173  &lt;.0001\n Placebo Tempo1 - Placebo Tempo2    -0.1500 0.0204 30  -7.348  &lt;.0001\n Placebo Tempo1 - New Drug Tempo3    0.3833 0.0531 30   7.213  &lt;.0001\n Placebo Tempo1 - Placebo Tempo3    -0.1167 0.0549 30  -2.127  0.3013\n New Drug Tempo2 - Placebo Tempo2   -0.6000 0.0616 30  -9.738  &lt;.0001\n New Drug Tempo2 - New Drug Tempo3  -0.0667 0.0609 30  -1.095  0.8793\n New Drug Tempo2 - Placebo Tempo3   -0.5667 0.0660 30  -8.590  &lt;.0001\n Placebo Tempo2 - New Drug Tempo3    0.5333 0.0518 30  10.292  &lt;.0001\n Placebo Tempo2 - Placebo Tempo3     0.0333 0.0509 30   0.655  0.9855\n New Drug Tempo3 - Placebo Tempo3   -0.5000 0.0569 30  -8.783  &lt;.0001\n\nP value adjustment: tukey method for comparing a family of 6 estimates \n\n\n\n\nVerificando os pressupostos\n\n# Plotar o diagnóstico do modelo GEE para a variável 'pulse'\n\ncheck_model(modelo_gee_pulse_normal)\n\nConverting missing values (`NA`) into regular values currently not\n  possible for variables of class `NULL`.\n\n\nFailed to compute posterior predictive checks with `re_formula=NULL`.\n  Trying again with `re_formula=NA` now.\n\n\n\n\n\n\n\n\n\n\n\nPlot dos resultados\n\n# Salvando os resultados do modelo em uma variável\n\nmeans_ci_normal = emmeans(modelo_gee_pulse_normal, specs = ~drug:Tempo)\n\n\n# Plotar as médias e intervalos de confiança\n\nggplot(as.data.frame(means_ci_normal), aes(x = Tempo, y = emmean, color = drug)) +\n  geom_errorbar(aes(ymin = lower.CL, ymax = upper.CL), width = 0.2, position = position_dodge(0.8)) +\n  geom_point(position = position_dodge(0.8), size = 3) +\n  labs(title = \"Distribuição Normal\",\n       x = \"Tempo\",\n       y = \"Pulse\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\n\n\n\nDistribuição gamma\n\nCriando o modelo\n\nmodelo_gee_pulse_gamma &lt;- geeglm(pulse ~ drug + Tempo + drug*Tempo, \n                           data = bd_long,         \n                           id = ID,                 \n                           family = Gamma(link = \"identity\"), #Distribuição Gamma      \n                           corstr = \"unstructured\")\n\n\n\nResumo do modelo e contrastes\n\nsummary(modelo_gee_pulse_gamma)\n\n\nCall:\ngeeglm(formula = pulse ~ drug + Tempo + drug * Tempo, family = Gamma(link = \"identity\"), \n    data = bd_long, id = ID, corstr = \"unstructured\")\n\n Coefficients:\n                   Estimate Std.err    Wald Pr(&gt;|W|)    \n(Intercept)          2.2000  0.0408 2904.00   &lt;2e-16 ***\ndrugPlacebo          0.4667  0.0509   84.00   &lt;2e-16 ***\nTempo2               0.0167  0.0366    0.21   0.6492    \nTempo3               0.0833  0.0684    1.49   0.2230    \ndrugPlacebo:Tempo2   0.1333  0.0419   10.11   0.0015 ** \ndrugPlacebo:Tempo3   0.0333  0.0877    0.14   0.7038    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nCorrelation structure = unstructured \nEstimated Scale Parameters:\n\n            Estimate  Std.err\n(Intercept)  0.00172 0.000372\n  Link = identity \n\nEstimated Correlation Parameters:\n          Estimate Std.err\nalpha.1:2    0.745   0.178\nalpha.1:3   -0.279   0.208\nalpha.2:3    0.156   0.279\nNumber of clusters:   12  Maximum cluster size: 3 \n\nemmeans(modelo_gee_pulse_gamma, pairwise ~ drug*Tempo)\n\n$emmeans\n drug     Tempo emmean     SE df lower.CL upper.CL\n New Drug 1       2.20 0.0408 30     2.12     2.28\n Placebo  1       2.67 0.0304 30     2.60     2.73\n New Drug 2       2.22 0.0549 30     2.10     2.33\n Placebo  2       2.82 0.0281 30     2.76     2.87\n New Drug 3       2.28 0.0436 30     2.19     2.37\n Placebo  3       2.78 0.0366 30     2.71     2.86\n\nCovariance estimate used: vbeta \nConfidence level used: 0.95 \n\n$contrasts\n contrast                          estimate     SE df t.ratio p.value\n New Drug Tempo1 - Placebo Tempo1    -0.467 0.0509 30  -9.170  &lt;.0001\n New Drug Tempo1 - New Drug Tempo2   -0.017 0.0366 30  -0.450  0.9970\n New Drug Tempo1 - Placebo Tempo2    -0.617 0.0495 30 -12.450  &lt;.0001\n New Drug Tempo1 - New Drug Tempo3   -0.083 0.0684 30  -1.220  0.8240\n New Drug Tempo1 - Placebo Tempo3    -0.583 0.0549 30 -10.630  &lt;.0001\n Placebo Tempo1 - New Drug Tempo2     0.450 0.0627 30   7.170  &lt;.0001\n Placebo Tempo1 - Placebo Tempo2     -0.150 0.0204 30  -7.350  &lt;.0001\n Placebo Tempo1 - New Drug Tempo3     0.383 0.0531 30   7.210  &lt;.0001\n Placebo Tempo1 - Placebo Tempo3     -0.117 0.0549 30  -2.130  0.3010\n New Drug Tempo2 - Placebo Tempo2    -0.600 0.0616 30  -9.740  &lt;.0001\n New Drug Tempo2 - New Drug Tempo3   -0.067 0.0609 30  -1.100  0.8790\n New Drug Tempo2 - Placebo Tempo3    -0.567 0.0660 30  -8.590  &lt;.0001\n Placebo Tempo2 - New Drug Tempo3     0.533 0.0518 30  10.290  &lt;.0001\n Placebo Tempo2 - Placebo Tempo3      0.033 0.0509 30   0.650  0.9860\n New Drug Tempo3 - Placebo Tempo3    -0.500 0.0569 30  -8.780  &lt;.0001\n\nP value adjustment: tukey method for comparing a family of 6 estimates \n\n\n\n\nVerificando os pressupostos\n\n# Plotar o diagnóstico do modelo GEE para a variável 'pulse'\n\ncheck_model(modelo_gee_pulse_gamma)\n\nConverting missing values (`NA`) into regular values currently not\n  possible for variables of class `NULL`.\n\n\nFailed to compute posterior predictive checks with `re_formula=NULL`.\n  Trying again with `re_formula=NA` now.\n\n\nCannot simulate residuals for models of class `geeglm`. Please try\n  `check_model(..., residual_type = \"normal\")` instead.\n\n\n\n\n\n\n\n\n\n\n\nPlot dos resultados\n\n# Salvando os resultados do modelo em uma variável\n\nmeans_ci_gamma = emmeans(modelo_gee_pulse_gamma, specs = ~drug:Tempo)\n\n\n# Plotar as médias e intervalos de confiança\n\nggplot(as.data.frame(means_ci_gamma), aes(x = Tempo, y = emmean, color = drug)) +\n  geom_errorbar(aes(ymin = lower.CL, ymax = upper.CL), width = 0.2, position = position_dodge(0.8)) +\n  geom_point(position = position_dodge(0.8), size = 3) +\n  labs(title = \"Distribuição Gamma\",\n       x = \"Tempo\",\n       y = \"Pulse\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\n\n\n\nDistribuição tweedie\n\nCriando o modelo\n\nmodelo_gee_pulse_tweedie &lt;- glm(pulse ~ drug + Tempo + drug*Tempo, \n                           data = bd_long,\n                          # id = ID, \n                           family = tweedie(var.power=2, link.power = 0),\n                          contrasts = )\n\n\n\n\n\n\n\nAviso!\n\n\n\nUtilizamos a função glm para criar o modelo Tweedie. Estamos trabalhando para criar o modelo com a função GEE. Por hora utilize o SPSS🤮.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nResumo do modelo e contrastes\n\nsummary(modelo_gee_pulse_tweedie)\n\n\nCall:\nglm(formula = pulse ~ drug + Tempo + drug * Tempo, family = tweedie(var.power = 2, \n    link.power = 0), data = bd_long)\n\nCoefficients:\n                   Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)         0.78846    0.01857   42.47  &lt; 2e-16 ***\ndrugPlacebo         0.19237    0.02626    7.33  3.7e-08 ***\nTempo2              0.00755    0.02626    0.29     0.78    \nTempo3              0.03718    0.02626    1.42     0.17    \ndrugPlacebo:Tempo2  0.04718    0.03713    1.27     0.21    \ndrugPlacebo:Tempo3  0.00564    0.03713    0.15     0.88    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for Tweedie family taken to be 0.00207)\n\n    Null deviance: 0.473395  on 35  degrees of freedom\nResidual deviance: 0.062212  on 30  degrees of freedom\nAIC: NA\n\nNumber of Fisher Scoring iterations: 3\n\nemmeans(modelo_gee_pulse_tweedie, pairwise ~ drug*Tempo)\n\n$emmeans\n drug     Tempo emmean     SE  df asymp.LCL asymp.UCL\n New Drug 1      0.788 0.0186 Inf     0.752     0.825\n Placebo  1      0.981 0.0186 Inf     0.944     1.017\n New Drug 2      0.796 0.0186 Inf     0.760     0.832\n Placebo  2      1.036 0.0186 Inf     0.999     1.072\n New Drug 3      0.826 0.0186 Inf     0.789     0.862\n Placebo  3      1.024 0.0186 Inf     0.987     1.060\n\nResults are given on the mu^0 (not the response) scale. \nConfidence level used: 0.95 \n\n$contrasts\n contrast                          estimate     SE  df z.ratio p.value\n New Drug Tempo1 - Placebo Tempo1   -0.1924 0.0263 Inf  -7.330  &lt;.0001\n New Drug Tempo1 - New Drug Tempo2  -0.0075 0.0263 Inf  -0.290  1.0000\n New Drug Tempo1 - Placebo Tempo2   -0.2471 0.0263 Inf  -9.410  &lt;.0001\n New Drug Tempo1 - New Drug Tempo3  -0.0372 0.0263 Inf  -1.420  0.7170\n New Drug Tempo1 - Placebo Tempo3   -0.2352 0.0263 Inf  -8.960  &lt;.0001\n Placebo Tempo1 - New Drug Tempo2    0.1848 0.0263 Inf   7.040  &lt;.0001\n Placebo Tempo1 - Placebo Tempo2    -0.0547 0.0263 Inf  -2.080  0.2950\n Placebo Tempo1 - New Drug Tempo3    0.1552 0.0263 Inf   5.910  &lt;.0001\n Placebo Tempo1 - Placebo Tempo3    -0.0428 0.0263 Inf  -1.630  0.5780\n New Drug Tempo2 - Placebo Tempo2   -0.2395 0.0263 Inf  -9.120  &lt;.0001\n New Drug Tempo2 - New Drug Tempo3  -0.0296 0.0263 Inf  -1.130  0.8700\n New Drug Tempo2 - Placebo Tempo3   -0.2276 0.0263 Inf  -8.670  &lt;.0001\n Placebo Tempo2 - New Drug Tempo3    0.2099 0.0263 Inf   7.990  &lt;.0001\n Placebo Tempo2 - Placebo Tempo3     0.0119 0.0263 Inf   0.450  0.9980\n New Drug Tempo3 - Placebo Tempo3   -0.1980 0.0263 Inf  -7.540  &lt;.0001\n\nNote: contrasts are still on the mu^0 scale. Consider using\n      regrid() if you want contrasts of back-transformed estimates. \nP value adjustment: tukey method for comparing a family of 6 estimates \n\n\n\n\nVerificando os pressupostos\n\n# Plotar o diagnóstico do modelo GEE para a variável 'pulse'\n\ncheck_model(modelo_gee_pulse_tweedie)\n\nCannot simulate residuals for models of class `glm`. Please try\n  `check_model(..., residual_type = \"normal\")` instead.\n\n\n\n\n\n\n\n\n\n\n\nPlot dos resultados\n\n# Salvando os resultados do modelo em uma variável\n\nmeans_ci_tweedie = emmeans(modelo_gee_pulse_tweedie, specs = ~drug:Tempo)\n\n\n# Plotar as médias e intervalos de confiança\n\nggplot(as.data.frame(means_ci_tweedie), aes(x = Tempo, y = emmean, color = drug)) +\n  geom_errorbar(aes(ymin = asymp.LCL, ymax = asymp.UCL), width = 0.2, position = position_dodge(0.8)) +\n  geom_point(position = position_dodge(0.8), size = 3) +\n  labs(title = \"Distribuição Tweedie\",\n       x = \"Tempo\",\n       y = \"Pulse\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\n\n\n\n\nb) QIC\nCompare cada um dos modelos com diferentes distribuições utilizando o QIC (Quasi Likehood Independence Criterion). Os modelos têm diferença entre si nos resultados?\n\n\n\n\n\n\nNota\n\n\n\nA função QIC() não funciona para modelos gerados com as funções glm e lm, apenas com o GEE. Resolveremos em breve! Por hora utilize o SPSS🤮.\n\n\n\nQIC(modelo_gee_pulse_normal)\n\n      QIC      QICu Quasi Lik       CIC    params      QICC \n   12.347    12.347    -0.173     6.000     6.000   102.347 \n\nQIC(modelo_gee_pulse_gamma)\n\n      QIC      QICu Quasi Lik       CIC    params      QICC \n    125.2     125.2     -56.6       6.0       6.0     215.2 \n\n#QIC(modelo_gee_pulse_tweedie)\n\n\n\nc) Sumarizando os resultados\n\n\n\n\n\n\nNota\n\n\n\nA função report() não funciona para modelos gerados com as funções GEE. Aproveite para treinar a escrita no formato de uma publicação acadêmica.\n\n\n\nResutados com distribuição Tweedie\n\nreport(modelo_gee_pulse_tweedie)\n\nWe fitted a general linear model (Tweedie family with a mu^0 link) (estimated\nusing ML) to predict pulse with drug and Tempo (formula: pulse ~ drug + Tempo +\ndrug * Tempo). The model's explanatory power is substantial (Nagelkerke's R2 =\n0.87). The model's intercept, corresponding to drug = New Drug and Tempo = 1,\nis at 0.79 (95% CI [0.75, 0.83], p &lt; .001). Within this model:\n\n  - The effect of drug [Placebo] is statistically significant and positive (beta\n= 0.19, 95% CI [0.14, 0.24], p &lt; .001; Std. beta = 0.19, 95% CI [0.14, 0.24])\n  - The effect of Tempo [2] is statistically non-significant and positive (beta =\n7.55e-03, 95% CI [-0.04, 0.06], p = 0.774; Std. beta = 7.55e-03, 95% CI [-0.04,\n0.06])\n  - The effect of Tempo [3] is statistically non-significant and positive (beta =\n0.04, 95% CI [-0.01, 0.09], p = 0.157; Std. beta = 0.04, 95% CI [-0.01, 0.09])\n  - The effect of drug [Placebo] × Tempo [2] is statistically non-significant and\npositive (beta = 0.05, 95% CI [-0.03, 0.12], p = 0.204; Std. beta = 0.05, 95%\nCI [-0.03, 0.12])\n  - The effect of drug [Placebo] × Tempo [3] is statistically non-significant and\npositive (beta = 5.64e-03, 95% CI [-0.07, 0.08], p = 0.879; Std. beta =\n5.64e-03, 95% CI [-0.07, 0.08])\n\nStandardized parameters were obtained by fitting the model on a standardized\nversion of the dataset. 95% Confidence Intervals (CIs) and p-values were\ncomputed using a Wald z-distribution approximation.",
    "crumbs": [
      "GLM, GEE, GMM, GzLM",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Lista 2 - GEE</span>"
    ]
  },
  {
    "objectID": "lista_2.html#considerações-finais",
    "href": "lista_2.html#considerações-finais",
    "title": "2  Lista 2 - GEE",
    "section": "2.3 Considerações finais",
    "text": "2.3 Considerações finais\nRealizamos todas as análises para a VD Pulse! Agora faça as análises para a variável Reps!\n\n\n\n\n\n\nDica!\n\n\n\nNão faça apenas um copy/paste dos scripts! Treine escrever os códigos e lembre-se de mudar o nome das variáveis do modelo para que não ocorra nenhum conflito! Compare seus resultados com os da aula prática.",
    "crumbs": [
      "GLM, GEE, GMM, GzLM",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Lista 2 - GEE</span>"
    ]
  },
  {
    "objectID": "lista_2.html#lista-2-resolvida-no-spss",
    "href": "lista_2.html#lista-2-resolvida-no-spss",
    "title": "2  Lista 2 - GEE",
    "section": "2.4 Lista 2 resolvida no SPSS",
    "text": "2.4 Lista 2 resolvida no SPSS",
    "crumbs": [
      "GLM, GEE, GMM, GzLM",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Lista 2 - GEE</span>"
    ]
  },
  {
    "objectID": "lista_2.html#referências",
    "href": "lista_2.html#referências",
    "title": "2  Lista 2 - GEE",
    "section": "2.5 Referências",
    "text": "2.5 Referências",
    "crumbs": [
      "GLM, GEE, GMM, GzLM",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Lista 2 - GEE</span>"
    ]
  },
  {
    "objectID": "lista_2.html#versões-dos-pacotes",
    "href": "lista_2.html#versões-dos-pacotes",
    "title": "2  Lista 2 - GEE",
    "section": "2.6 Versões dos pacotes",
    "text": "2.6 Versões dos pacotes\n\nreport(sessionInfo())\n\nAnalyses were conducted using the R Statistical language (version 4.3.3; R Core\nTeam, 2024) on Windows 11 x64 (build 22631), using the packages lme4 (version\n1.1.35.5; Bates D et al., 2015), Matrix (version 1.6.5; Bates D et al., 2024),\neffectsize (version 0.8.9; Ben-Shachar MS et al., 2020), gee (version 4.13.27;\nCarey VJ, 2024), pwr (version 1.3.0; Champely S, 2020), htmltools (version\n0.5.8.1; Cheng J et al., 2024), fitdistrplus (version 1.2.1; Delignette-Muller\nML, Dutang C, 2015), tweedie (version 2.3.5; Dunn PK, Smyth GK, 2005), tm\n(version 0.7.14; Feinerer I, Hornik K, 2024), flexplot (version 0.21.2; Fife,\nD, 2022), effects (version 4.2.2; Fox J, Weisberg S, 2019), car (version 3.1.3;\nFox J, Weisberg S, 2019), carData (version 3.0.5; Fox J et al., 2022), mvtnorm\n(version 1.3.2; Genz A, Bretz F, 2009), statmod (version 1.5.0; Giner G, Smyth\nGK, 2016), geepack (version 1.3.11; Halekoh U et al., 2006), NLP (version\n0.3.0; Hornik K, 2024), TH.data (version 1.1.2; Hothorn T, 2023), multcomp\n(version 1.4.26; Hothorn T et al., 2008), rstatix (version 0.7.2; Kassambara A,\n2023), emmeans (version 1.10.5; Lenth R, 2024), sjstats (version 0.19.0;\nLüdecke D, 2024), parameters (version 0.23.0; Lüdecke D et al., 2020),\nperformance (version 0.12.4; Lüdecke D et al., 2021), easystats (version 0.7.3;\nLüdecke D et al., 2022), see (version 0.8.5; Lüdecke D et al., 2021), insight\n(version 0.20.5; Lüdecke D et al., 2019), survey (version 4.4.2; Lumley T,\n2024), bayestestR (version 0.15.0; Makowski D et al., 2019), modelbased\n(version 0.8.8; Makowski D et al., 2020), report (version 0.5.9; Makowski D et\nal., 2023), correlation (version 0.8.5; Makowski D et al., 2022), datawizard\n(version 0.13.0; Patil I et al., 2022), nlme (version 3.1.166; Pinheiro J et\nal., 2024), foreign (version 0.8.87; R Core Team, 2024), GGally (version 2.2.1;\nSchloerke B et al., 2024), rempsyc (version 0.1.8; Thériault R, 2023), survival\n(version 3.7.0; Therneau T, 2024), MASS (version 7.3.60.0.1; Venables WN,\nRipley BD, 2002), ggplot2 (version 3.5.1; Wickham H, 2016), dplyr (version\n1.1.4; Wickham H et al., 2023), tidyr (version 1.3.1; Wickham H et al., 2024)\nand mime (version 0.12; Xie Y, 2021).\n\nReferences\n----------\n  - Bates D, Mächler M, Bolker B, Walker S (2015). \"Fitting Linear Mixed-Effects\nModels Using lme4.\" _Journal of Statistical Software_, *67*(1), 1-48.\ndoi:10.18637/jss.v067.i01 &lt;https://doi.org/10.18637/jss.v067.i01&gt;.\n  - Bates D, Maechler M, Jagan M (2024). _Matrix: Sparse and Dense Matrix Classes\nand Methods_. R package version 1.6-5,\n&lt;https://CRAN.R-project.org/package=Matrix&gt;.\n  - Ben-Shachar MS, Lüdecke D, Makowski D (2020). \"effectsize: Estimation of\nEffect Size Indices and Standardized Parameters.\" _Journal of Open Source\nSoftware_, *5*(56), 2815. doi:10.21105/joss.02815\n&lt;https://doi.org/10.21105/joss.02815&gt;, &lt;https://doi.org/10.21105/joss.02815&gt;.\n  - Carey VJ (2024). _gee: Generalized Estimation Equation Solver_. R package\nversion 4.13-27, &lt;https://CRAN.R-project.org/package=gee&gt;.\n  - Champely S (2020). _pwr: Basic Functions for Power Analysis_. R package\nversion 1.3-0, &lt;https://CRAN.R-project.org/package=pwr&gt;.\n  - Cheng J, Sievert C, Schloerke B, Chang W, Xie Y, Allen J (2024). _htmltools:\nTools for HTML_. R package version 0.5.8.1,\n&lt;https://CRAN.R-project.org/package=htmltools&gt;.\n  - Delignette-Muller ML, Dutang C (2015). \"fitdistrplus: An R Package for\nFitting Distributions.\" _Journal of Statistical Software_, *64*(4), 1-34.\ndoi:10.18637/jss.v064.i04 &lt;https://doi.org/10.18637/jss.v064.i04&gt;.\n  - Dunn PK, Smyth GK (2005). \"Series evaluation of Tweedie exponential\ndispersion models.\" _Statistics and Computing_, *15*(4), 267-280. Dunn PK,\nSmyth GK (2008). \"Evaluation of Tweedie exponential dispersion models using\nFourier inversion.\" _Statistics and Computing_, *18*(1), 73-86. Dunn PK (2022).\n_Tweedie: Evaluation of Tweedie Exponential Family Models_. R package version\n2.3.5.\n  - Feinerer I, Hornik K (2024). _tm: Text Mining Package_. R package version\n0.7-14, &lt;https://CRAN.R-project.org/package=tm&gt;. Feinerer I, Hornik K, Meyer D\n(2008). \"Text Mining Infrastructure in R.\" _Journal of Statistical Software_,\n*25*(5), 1-54. doi:10.18637/jss.v025.i05\n&lt;https://doi.org/10.18637/jss.v025.i05&gt;.\n  - Fife, A. D (2022). \"Flexplot: Graphically-based data analysis.\"\n_Psychological Methods_, *27*(4), -19. &lt;doi.org/10.1037/met0000424&gt;.\n  - Fox J, Weisberg S (2019). _An R Companion to Applied Regression_, 3rd\nedition. Sage, Thousand Oaks CA.\n&lt;https://socialsciences.mcmaster.ca/jfox/Books/Companion/index.html&gt;. Fox J,\nWeisberg S (2018). \"Visualizing Fit and Lack of Fit in Complex Regression\nModels with Predictor Effect Plots and Partial Residuals.\" _Journal of\nStatistical Software_, *87*(9), 1-27. doi:10.18637/jss.v087.i09\n&lt;https://doi.org/10.18637/jss.v087.i09&gt;. Fox J (2003). \"Effect Displays in R\nfor Generalised Linear Models.\" _Journal of Statistical Software_, *8*(15),\n1-27. doi:10.18637/jss.v008.i15 &lt;https://doi.org/10.18637/jss.v008.i15&gt;. Fox J,\nHong J (2009). \"Effect Displays in R for Multinomial and Proportional-Odds\nLogit Models: Extensions to the effects Package.\" _Journal of Statistical\nSoftware_, *32*(1), 1-24. doi:10.18637/jss.v032.i01\n&lt;https://doi.org/10.18637/jss.v032.i01&gt;.\n  - Fox J, Weisberg S (2019). _An R Companion to Applied Regression_, Third\nedition. Sage, Thousand Oaks CA. &lt;https://www.john-fox.ca/Companion/&gt;.\n  - Fox J, Weisberg S, Price B (2022). _carData: Companion to Applied Regression\nData Sets_. R package version 3.0-5,\n&lt;https://CRAN.R-project.org/package=carData&gt;.\n  - Genz A, Bretz F (2009). _Computation of Multivariate Normal and t\nProbabilities_, series Lecture Notes in Statistics. Springer-Verlag,\nHeidelberg. ISBN 978-3-642-01688-2.\n  - Giner G, Smyth GK (2016). \"statmod: probability calculations for the inverse\nGaussian distribution.\" _R Journal_, *8*(1), 339-351. Phipson B, Smyth GK\n(2010). \"Permutation p-values should never be zero: calculating exact p-values\nwhen permutations are randomly drawn.\" _Statistical Applications in Genetics\nand Molecular Biology_, *9*(1), Article 39. Hu Y, Smyth GK (2009). \"ELDA:\nextreme limiting dilution analysis for comparing depleted and enriched\npopulations in stem cell and other assays.\" _Journal of Immunological Methods_,\n*347*(1), 70-78. Smyth GK (2005). \"Optimization and nonlinear equations.\"\n_Encyclopedia of Biostatistics_, 3088-3095. Smyth GK (2005). \"Numerical\nintegration.\" _Encyclopedia of Biostatistics_, 3088-3095. Smyth GK (2002). \"An\nefficient algorithm for REML in heteroscedastic regression.\" _Journal of\nComputational and Graphical Statistics_, *11*, 836-847. Dunn PK, Smyth GK\n(1996). \"Randomized quantile residuals.\" _J. Comput. Graph. Statist_, *5*,\n236-244.\n  - Halekoh U, Højsgaard S, Yan J (2006). \"The R Package geepack for Generalized\nEstimating Equations.\" _Journal of Statistical Software_, *15/2*, 1-11. Yan J,\nFine JP (2004). \"Estimating Equations for Association Structures.\" _Statistics\nin Medicine_, *23*, 859-880. Yan J (2002). \"geepack: Yet Another Package for\nGeneralized Estimating Equations.\" _R-News_, *2/3*, 12-14.\n  - Hornik K (2024). _NLP: Natural Language Processing Infrastructure_. R package\nversion 0.3-0, &lt;https://CRAN.R-project.org/package=NLP&gt;.\n  - Hothorn T (2023). _TH.data: TH's Data Archive_. R package version 1.1-2,\n&lt;https://CRAN.R-project.org/package=TH.data&gt;.\n  - Hothorn T, Bretz F, Westfall P (2008). \"Simultaneous Inference in General\nParametric Models.\" _Biometrical Journal_, *50*(3), 346-363.\n  - Kassambara A (2023). _rstatix: Pipe-Friendly Framework for Basic Statistical\nTests_. R package version 0.7.2, &lt;https://CRAN.R-project.org/package=rstatix&gt;.\n  - Lenth R (2024). _emmeans: Estimated Marginal Means, aka Least-Squares Means_.\nR package version 1.10.5, &lt;https://CRAN.R-project.org/package=emmeans&gt;.\n  - Lüdecke D (2024). _sjstats: Statistical Functions for Regression Models\n(Version 0.19.0)_. doi:10.5281/zenodo.1284472\n&lt;https://doi.org/10.5281/zenodo.1284472&gt;,\n&lt;https://CRAN.R-project.org/package=sjstats&gt;.\n  - Lüdecke D, Ben-Shachar M, Patil I, Makowski D (2020). \"Extracting, Computing\nand Exploring the Parameters of Statistical Models using R.\" _Journal of Open\nSource Software_, *5*(53), 2445. doi:10.21105/joss.02445\n&lt;https://doi.org/10.21105/joss.02445&gt;.\n  - Lüdecke D, Ben-Shachar M, Patil I, Waggoner P, Makowski D (2021).\n\"performance: An R Package for Assessment, Comparison and Testing of\nStatistical Models.\" _Journal of Open Source Software_, *6*(60), 3139.\ndoi:10.21105/joss.03139 &lt;https://doi.org/10.21105/joss.03139&gt;.\n  - Lüdecke D, Ben-Shachar M, Patil I, Wiernik B, Bacher E, Thériault R, Makowski\nD (2022). \"easystats: Framework for Easy Statistical Modeling, Visualization,\nand Reporting.\" _CRAN_. doi:10.32614/CRAN.package.easystats\n&lt;https://doi.org/10.32614/CRAN.package.easystats&gt;, R package,\n&lt;https://easystats.github.io/easystats/&gt;.\n  - Lüdecke D, Patil I, Ben-Shachar M, Wiernik B, Waggoner P, Makowski D (2021).\n\"see: An R Package for Visualizing Statistical Models.\" _Journal of Open Source\nSoftware_, *6*(64), 3393. doi:10.21105/joss.03393\n&lt;https://doi.org/10.21105/joss.03393&gt;.\n  - Lüdecke D, Waggoner P, Makowski D (2019). \"insight: A Unified Interface to\nAccess Information from Model Objects in R.\" _Journal of Open Source Software_,\n*4*(38), 1412. doi:10.21105/joss.01412 &lt;https://doi.org/10.21105/joss.01412&gt;.\n  - Lumley T (2024). \"survey: analysis of complex survey samples.\" R package\nversion 4.4. Lumley T (2004). \"Analysis of Complex Survey Samples.\" _Journal of\nStatistical Software_, *9*(1), 1-19. R package verson 2.2. Lumley T (2010).\n_Complex Surveys: A Guide to Analysis Using R: A Guide to Analysis Using R_.\nJohn Wiley and Sons.\n  - Makowski D, Ben-Shachar M, Lüdecke D (2019). \"bayestestR: Describing Effects\nand their Uncertainty, Existence and Significance within the Bayesian\nFramework.\" _Journal of Open Source Software_, *4*(40), 1541.\ndoi:10.21105/joss.01541 &lt;https://doi.org/10.21105/joss.01541&gt;,\n&lt;https://joss.theoj.org/papers/10.21105/joss.01541&gt;.\n  - Makowski D, Ben-Shachar M, Patil I, Lüdecke D (2020). \"Estimation of\nModel-Based Predictions, Contrasts and Means.\" _CRAN_.\n&lt;https://github.com/easystats/modelbased&gt;.\n  - Makowski D, Lüdecke D, Patil I, Thériault R, Ben-Shachar M, Wiernik B (2023).\n\"Automated Results Reporting as a Practical Tool to Improve Reproducibility and\nMethodological Best Practices Adoption.\" _CRAN_.\n&lt;https://easystats.github.io/report/&gt;.\n  - Makowski D, Wiernik B, Patil I, Lüdecke D, Ben-Shachar M (2022).\n\"correlation: Methods for Correlation Analysis.\" Version 0.8.3,\n&lt;https://CRAN.R-project.org/package=correlation&gt;. Makowski D, Ben-Shachar M,\nPatil I, Lüdecke D (2020). \"Methods and Algorithms for Correlation Analysis in\nR.\" _Journal of Open Source Software_, *5*(51), 2306. doi:10.21105/joss.02306\n&lt;https://doi.org/10.21105/joss.02306&gt;,\n&lt;https://joss.theoj.org/papers/10.21105/joss.02306&gt;.\n  - Patil I, Makowski D, Ben-Shachar M, Wiernik B, Bacher E, Lüdecke D (2022).\n\"datawizard: An R Package for Easy Data Preparation and Statistical\nTransformations.\" _Journal of Open Source Software_, *7*(78), 4684.\ndoi:10.21105/joss.04684 &lt;https://doi.org/10.21105/joss.04684&gt;.\n  - Pinheiro J, Bates D, R Core Team (2024). _nlme: Linear and Nonlinear Mixed\nEffects Models_. R package version 3.1-166,\n&lt;https://CRAN.R-project.org/package=nlme&gt;. Pinheiro JC, Bates DM (2000).\n_Mixed-Effects Models in S and S-PLUS_. Springer, New York. doi:10.1007/b98882\n&lt;https://doi.org/10.1007/b98882&gt;.\n  - R Core Team (2024). _foreign: Read Data Stored by 'Minitab', 'S', 'SAS',\n'SPSS', 'Stata', 'Systat', 'Weka', 'dBase', ..._. R package version 0.8-87,\n&lt;https://CRAN.R-project.org/package=foreign&gt;.\n  - R Core Team (2024). _R: A Language and Environment for Statistical\nComputing_. R Foundation for Statistical Computing, Vienna, Austria.\n&lt;https://www.R-project.org/&gt;.\n  - Schloerke B, Cook D, Larmarange J, Briatte F, Marbach M, Thoen E, Elberg A,\nCrowley J (2024). _GGally: Extension to 'ggplot2'_. R package version 2.2.1,\n&lt;https://CRAN.R-project.org/package=GGally&gt;.\n  - Thériault R (2023). \"rempsyc: Convenience functions for psychology.\" _Journal\nof Open Source Software_, *8*(87), 5466. doi:10.21105/joss.05466\n&lt;https://doi.org/10.21105/joss.05466&gt;, &lt;https://doi.org/10.21105/joss.05466&gt;.\n  - Therneau T (2024). _A Package for Survival Analysis in R_. R package version\n3.7-0, &lt;https://CRAN.R-project.org/package=survival&gt;. Terry M. Therneau,\nPatricia M. Grambsch (2000). _Modeling Survival Data: Extending the Cox Model_.\nSpringer, New York. ISBN 0-387-98784-3.\n  - Venables WN, Ripley BD (2002). _Modern Applied Statistics with S_, Fourth\nedition. Springer, New York. ISBN 0-387-95457-0,\n&lt;https://www.stats.ox.ac.uk/pub/MASS4/&gt;.\n  - Wickham H (2016). _ggplot2: Elegant Graphics for Data Analysis_.\nSpringer-Verlag New York. ISBN 978-3-319-24277-4,\n&lt;https://ggplot2.tidyverse.org&gt;.\n  - Wickham H, François R, Henry L, Müller K, Vaughan D (2023). _dplyr: A Grammar\nof Data Manipulation_. R package version 1.1.4,\n&lt;https://CRAN.R-project.org/package=dplyr&gt;.\n  - Wickham H, Vaughan D, Girlich M (2024). _tidyr: Tidy Messy Data_. R package\nversion 1.3.1, &lt;https://CRAN.R-project.org/package=tidyr&gt;.\n  - Xie Y (2021). _mime: Map Filenames to MIME Types_. R package version 0.12,\n&lt;https://CRAN.R-project.org/package=mime&gt;.",
    "crumbs": [
      "GLM, GEE, GMM, GzLM",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Lista 2 - GEE</span>"
    ]
  },
  {
    "objectID": "ARIMA.html",
    "href": "ARIMA.html",
    "title": "ARIMA",
    "section": "",
    "text": "Fundamentos do ARIMA:\nAutoRegressivo (AR): Refere-se à relação entre uma observação atual e suas observações passadas. O termo “AutoRegressivo” destaca a dependência linear de uma observação em relação a suas antecessoras.\nIntegrated (I): Indica o número de diferenciações necessárias para tornar a série temporal estacionária, ou seja, para remover tendências e padrões sistemáticos. A estacionarização é crucial para garantir a estabilidade do modelo.\nMédia Móvel (MA): Considera os erros residuais das observações anteriores para prever a próxima. O componente “Média Móvel” reflete a média dos erros anteriores, incorporando informações sobre o comportamento recente da série.\nNúmero de observações: O número ideal de observações repetidas para uma única unidade de análise é de pelo menos 40, sendo preferível alcançar 50 observações. Não é necessário ter um grande número de pessoas ou unidades de análise; até mesmo com N = 1, você pode obter várias observações do mesmo indivíduo, tornando o ARIMA uma ferramenta eficaz de análise.",
    "crumbs": [
      "ARIMA"
    ]
  },
  {
    "objectID": "SEM.html",
    "href": "SEM.html",
    "title": "SEM",
    "section": "",
    "text": "Análise Fatorial Confirmatória (CFA)\nA Análise de Fator Confirmatória é uma técnica estatística utilizada para avaliar a validade de uma estrutura teórica subjacente a um conjunto de dados. Especificamente, ela é empregada para testar e confirmar a consistência entre os dados observados e a estrutura de fatores previamente proposta. Neste método, um modelo teórico é formulado com fatores latentes e suas respectivas variáveis observadas, e as relações entre eles são testadas em relação aos dados observados. A CFA é comumente utilizada em pesquisas nas áreas de psicologia, educação e ciências sociais para validar construtos teóricos e entender a relação entre variáveis latentes.\nDesenho de Estudo Sugerido: Uma pesquisa que busca validar um modelo teórico de construtos psicológicos, educacionais ou sociais por meio de dados observados em um conjunto de participantes.\nExemplo: Avaliação da validade de um modelo teórico que postula a relação entre variáveis como autoestima, motivação e desempenho acadêmico em estudantes universitários, utilizando a Análise de Fator Confirmatória para testar a consistência dos dados observados com a estrutura proposta.",
    "crumbs": [
      "SEM"
    ]
  },
  {
    "objectID": "SEM.html#análise-de-caminhos-path-analysis",
    "href": "SEM.html#análise-de-caminhos-path-analysis",
    "title": "SEM",
    "section": "Análise de Caminhos (Path Analysis)",
    "text": "Análise de Caminhos (Path Analysis)\nAnálise de Caminhos é uma técnica estatística utilizada para examinar as relações causais entre variáveis em um modelo teórico complexo. Esta abordagem permite explorar e quantificar as vias diretas e indiretas entre diferentes variáveis, identificando assim o impacto de cada componente no modelo. A análise de caminhos é frequentemente empregada em pesquisas nas áreas de psicologia, sociologia e ciências sociais, proporcionando insights sobre como variáveis interagem e contribuem para um fenômeno específico.\nDesenho de Estudo Sugerido: Um estudo que investiga as relações causais entre múltiplas variáveis por meio de um modelo teórico, utilizando dados observados para testar as conexões propostas.\nExemplo: Exame das interações entre variáveis como ambiente familiar, apoio social e desempenho acadêmico em adolescentes, por meio de um modelo de análise de caminhos. A pesquisa busca compreender como fatores familiares e sociais influenciam diretamente ou indiretamente o sucesso acadêmico dos jovens.",
    "crumbs": [
      "SEM"
    ]
  },
  {
    "objectID": "survival.html",
    "href": "survival.html",
    "title": "SURVIVAL",
    "section": "",
    "text": "Pressupostos da Cox regression\nA Regressão de Cox é uma técnica robusta, mas, como qualquer método estatístico, possui alguns pressupostos importantes. Os principais pressupostos da Regressão de Cox são:\nOs pressupostos de 2 a 6 são inerentes ao desenho do experimento e do acompanhamento durante as observações. O único que vamos abordar aqui no tutorial é o de proporcionalidade dos riscos.",
    "crumbs": [
      "SURVIVAL"
    ]
  },
  {
    "objectID": "index.html#origem-do-conteúdo",
    "href": "index.html#origem-do-conteúdo",
    "title": "Técnicas e Métodos de Pesquisa no R",
    "section": "📚 Origem do Conteúdo",
    "text": "📚 Origem do Conteúdo\nAs aulas são disponibilizadas gratuitamente através de lives no canal Cientística & Podcast Naruhodo do YouTube. Você pode acessar a playlist completa das aulas práticas e a playlist da disciplina completa.\n\n\n\n\n\n\nAgradecimento Especial\n\n\n\n\n\nAgradecimento especial à Professora Maria Lucia Oliveira De Souza Formigoni por tornar possível a realização desta disciplina.",
    "crumbs": [
      "Bem-vindo"
    ]
  },
  {
    "objectID": "index.html#o-que-você-vai-aprender",
    "href": "index.html#o-que-você-vai-aprender",
    "title": "Técnicas e Métodos de Pesquisa no R",
    "section": "🎯 O que Você Vai Aprender",
    "text": "🎯 O que Você Vai Aprender\nEste tutorial cobre análises estatísticas avançadas organizadas nos seguintes módulos:\n\nPreparação de DadosModelos LinearesAnálise de SobrevidaAnálises Avançadas\n\n\n\nTransformação e manipulação de dados\nBoas práticas de organização\n\n\n\n\nGLM - Modelo Linear Geral de medidas repetidas\nGEE - Equações de Estimação Generalizadas\nGMM - Modelos Mistos e Hierárquicos\nGzLM - Modelos Lineares Generalizados\n\n\n\n\nKaplan-Meier\nRegressão de Cox\nCox com covariáveis tempo-dependentes\n\n\n\n\nSéries Temporais - Modelos ARIMA\nSEM - Modelagem de Equações Estruturais\n\nPath Analysis\nAnálise Fatorial Confirmatória (CFA)\nModeração e Mediação\n\n\n\n\n\n\n\n\n\n\n\nSeção “Extras”\n\n\n\nAo final de cada capítulo, você encontrará a seção Extras com dicas sobre pacotes úteis que não estão disponíveis no SPSS ou Jamovi.",
    "crumbs": [
      "Bem-vindo"
    ]
  },
  {
    "objectID": "index.html#pré-requisitos",
    "href": "index.html#pré-requisitos",
    "title": "Técnicas e Métodos de Pesquisa no R",
    "section": "⚠️ Pré-requisitos",
    "text": "⚠️ Pré-requisitos\n\n\n\n\n\n\nImportante!\n\n\n\nEste material é complementar às aulas teóricas e práticas. É fundamental que você:\n\nAssista às aulas correspondentes antes de trabalhar com os exercícios\nTenha conhecimento básico em estatística (preferencialmente Estatística Aplicada a Psicobiologia I)\nPossua familiaridade mínima com o ambiente R",
    "crumbs": [
      "Bem-vindo"
    ]
  },
  {
    "objectID": "index.html#configurando-seu-ambiente",
    "href": "index.html#configurando-seu-ambiente",
    "title": "Técnicas e Métodos de Pesquisa no R",
    "section": "🛠️ Configurando seu Ambiente",
    "text": "🛠️ Configurando seu Ambiente\n\nInstalando R e RStudio\nEmbora as aulas originais utilizem SPSS, este tutorial replica todas as análises no R — que é gratuito e open source!\n\n\nR (Base)\n\n📥 Download do R\n\n\nRStudio (IDE)\n\n📥 Download do RStudio\n\n\n\n\nEstrutura Recomendada de Projeto\nOrganizar seus projetos adequadamente facilita a reprodutibilidade e colaboração:\nmeu_projeto/\n├── meu_projeto.Rproj\n├── dados/\n│   ├── raw/          # Dados originais (não modificar)\n│   └── processed/    # Dados processados\n├── scripts/\n│   └── analises.R\n├── outputs/\n│   ├── figuras/\n│   └── tabelas/\n└── README.md\n\n\n\n\n\n\nComo Criar um Projeto no RStudio\n\n\n\n\n\n\nAbra o RStudio\nVá em File → New Project\nEscolha New Directory → New Project\nDefina o nome e localização do projeto\nClique em Create Project\n\nVantagens: - Caminhos relativos automáticos - Facilita compartilhamento - Mantém ambiente organizado - Evita conflitos entre projetos",
    "crumbs": [
      "Bem-vindo"
    ]
  },
  {
    "objectID": "index.html#gerenciamento-de-pacotes",
    "href": "index.html#gerenciamento-de-pacotes",
    "title": "Técnicas e Métodos de Pesquisa no R",
    "section": "📦 Gerenciamento de Pacotes",
    "text": "📦 Gerenciamento de Pacotes\n\nInstalação (apenas uma vez)\n\n# Instalar um pacote\ninstall.packages(\"tidyverse\")\n\n# Instalar múltiplos pacotes\npacotes &lt;- c(\"dplyr\", \"ggplot2\", \"lme4\")\ninstall.packages(pacotes)\n\n\n\nCarregamento (a cada sessão)\n\n# Carregar biblioteca\nlibrary(tidyverse)\n\n\n\n\n\n\n\n💡 Analogia\n\n\n\nPense nos pacotes como livros em uma biblioteca:\n\ninstall.packages() = Comprar/adquirir o livro\nlibrary() = Pegar o livro da prateleira para usar\n\n\n\n\n\nLista de Pacotes Principais\nNo início de cada capítulo, você encontrará uma lista específica dos pacotes necessários. Aqui está uma visão geral dos principais:\n\nManipulaçãoVisualizaçãoModelagemEstatísticas\n\n\n\nlibrary(dplyr)      # Manipulação de dados\nlibrary(tidyr)      # Organização de dados\nlibrary(foreign)    # Importação de dados\n\n\n\n\nlibrary(ggplot2)    # Gráficos elegantes\nlibrary(flexplot)   # Visualização flexível\nlibrary(effects)    # Efeitos de modelos\n\n\n\n\nlibrary(lme4)       # Modelos mistos\nlibrary(nlme)       # Modelos não-lineares\nlibrary(geepack)    # GEE\nlibrary(car)        # Análise de regressão\n\n\n\n\nlibrary(emmeans)    # Médias estimadas\nlibrary(multcomp)   # Comparações múltiplas\nlibrary(rstatix)    # Análises simplificadas\nlibrary(easystats)  # Suite completa",
    "crumbs": [
      "Bem-vindo"
    ]
  },
  {
    "objectID": "index.html#material-de-apoio",
    "href": "index.html#material-de-apoio",
    "title": "Técnicas e Métodos de Pesquisa no R",
    "section": "📹 Material de Apoio",
    "text": "📹 Material de Apoio\n\n\n\n\n\n\nAulas em Vídeo\n\n\n\nOs vídeos das aulas práticas no SPSS estão disponíveis ao final de cada capítulo para referência.\nNota: Pequenas diferenças nos resultados entre SPSS e R podem ocorrer devido a algoritmos diferentes de estimação. O importante é sempre documentar seu método de análise.",
    "crumbs": [
      "Bem-vindo"
    ]
  },
  {
    "objectID": "index.html#boas-práticas-de-reprodutibilidade",
    "href": "index.html#boas-práticas-de-reprodutibilidade",
    "title": "Técnicas e Métodos de Pesquisa no R",
    "section": "🤝 Boas Práticas de Reprodutibilidade",
    "text": "🤝 Boas Práticas de Reprodutibilidade\n\n\n\n\n\n\nChecklist para Análises Reproduzíveis\n\n\n\n\nUse projetos do RStudio\nDocumente versões de pacotes (sessionInfo())\nComente seu código adequadamente\nNunca modifique dados originais\nUse caminhos relativos (não absolutos)\nCompartilhe código e dados quando possível\nReporte métodos detalhadamente",
    "crumbs": [
      "Bem-vindo"
    ]
  },
  {
    "objectID": "index.html#recursos-adicionais",
    "href": "index.html#recursos-adicionais",
    "title": "Técnicas e Métodos de Pesquisa no R",
    "section": "📚 Recursos Adicionais",
    "text": "📚 Recursos Adicionais\nPara aprofundar seus conhecimentos:\n\nR for Data Science - Livro gratuito online\nQuarto Documentation - Documentação oficial\nRStudio Cheatsheets - Guias de referência rápida\n\n\n\n\n\n\n\n\nPronto para Começar?\n\n\n\nAgora que seu ambiente está configurado, você está pronto para explorar os próximos capítulos! Cada um apresenta análises específicas com exemplos práticos e exercícios.\nDica: Trabalhe ativamente com os códigos — não apenas leia, execute e experimente!",
    "crumbs": [
      "Bem-vindo"
    ]
  },
  {
    "objectID": "lms.html",
    "href": "lms.html",
    "title": "Modelos Lineares",
    "section": "",
    "text": "📊 Os Quatro Modelos",
    "crumbs": [
      "Modelos Lineares"
    ]
  },
  {
    "objectID": "lms.html#os-quatro-modelos",
    "href": "lms.html#os-quatro-modelos",
    "title": "Modelos Lineares",
    "section": "",
    "text": "GLM - Medidas RepetidasGEE - Equações EstimadasGMM - Modelos MistosGzLM - Lineares Generalizados\n\n\nModelo Linear Geral de Medidas Repetidas\nExtensão do modelo linear tradicional projetado especificamente para dados com observações correlacionadas ao longo do tempo.\nQuando usar: - Estudos longitudinais com medições repetidas - Mesmos participantes avaliados em múltiplos momentos - Necessidade de modelar estrutura de covariância entre medições\nExemplo prático: Acompanhamento de pacientes em tratamento médico, medindo regularmente biomarcadores para observar mudanças ao longo do tempo.\n\n\nGeneralized Estimated Equations\nAbordagem robusta para dados longitudinais que fornece estimativas eficientes mesmo quando a especificação da covariância não é perfeita.\nQuando usar: - Estudos observacionais longitudinais - Ensaios clínicos com medições correlacionadas - Estudos epidemiológicos multicêntricos\nExemplo prático: Investigação da eficácia de programa de intervenção em saúde onde observações estão correlacionadas dentro de grupos de participantes.\n\n\nModelos Mistos e Hierárquicos\nCombinam componentes fixos e aleatórios, ideais para dados com estrutura hierárquica ou multicêntrica.\nQuando usar: - Dados com estrutura hierárquica - Estudos multicêntricos - Observações agrupadas em diferentes níveis\nExemplo prático: Avaliação de desempenho acadêmico onde alunos (nível 1) estão agrupados em salas (nível 2) e escolas (nível 3), considerando efeitos individuais e contextuais.\n\n\nGeneralized Linear Models\nExtensão dos modelos lineares para variáveis resposta não-normais, permitindo diferentes distribuições e funções de ligação.\nQuando usar: - Dados de contagem (Poisson) - Dados binários (Logística) - Dados com distribuição não-normal\nExemplo prático: Análise de número de eventos adversos (contagem) em ensaio clínico ou modelagem de probabilidade de sucesso em tratamento (binário).",
    "crumbs": [
      "Modelos Lineares"
    ]
  },
  {
    "objectID": "lms.html#por-que-usar-modelos-de-medidas-repetidas",
    "href": "lms.html#por-que-usar-modelos-de-medidas-repetidas",
    "title": "Modelos Lineares",
    "section": "🎯 Por que usar Modelos de Medidas Repetidas?",
    "text": "🎯 Por que usar Modelos de Medidas Repetidas?\n\n\n\n\n\n\nVantagens sobre ANOVA Tradicional\n\n\n\nOs modelos lineares modernos oferecem melhorias substanciais sobre a ANOVA clássica:\n\nModelagem Flexível\n\nMúltiplos fatores independentes em um único modelo\nAnálise de interações complexas\nEstruturas de covariância personalizadas\n\nRobustez a Violações\n\nDados desequilibrados\nHeterogeneidade de variâncias\nDesvios da normalidade\n\nControle Estatístico\n\nInclusão de covariáveis\nAjuste para variáveis confundidoras\nMaior precisão nas estimativas\n\nPoder Estatístico\n\nAproveitamento da correlação entre medidas\nDetecção de efeitos com amostras menores\nAnálise eficiente de designs complexos\n\nVersatilidade\n\nVariáveis dependentes contínuas ou categóricas\nDiferentes distribuições de probabilidade\nEstruturas temporais variadas",
    "crumbs": [
      "Modelos Lineares"
    ]
  },
  {
    "objectID": "lms.html#pacotes-necessários",
    "href": "lms.html#pacotes-necessários",
    "title": "Modelos Lineares",
    "section": "📦 Pacotes Necessários",
    "text": "📦 Pacotes Necessários\n\n# Modelagem e análise\nlibrary(lme4)        # Modelos lineares mistos\nlibrary(nlme)        # Modelos não-lineares mistos\nlibrary(geepack)     # Equações de estimação generalizadas\n\n# Médias e comparações\nlibrary(emmeans)     # Médias estimadas marginais\nlibrary(multcomp)    # Comparações múltiplas\nlibrary(effects)     # Visualização de efeitos\n\n# Estatísticas e diagnósticos\nlibrary(performance) # Diagnósticos de modelos\nlibrary(sjstats)     # Estatísticas descritivas\nlibrary(rstatix)     # Análises simplificadas\nlibrary(car)         # Testes complementares\n\n# Manipulação de dados\nlibrary(dplyr)       # Transformação de dados\nlibrary(tidyr)       # Organização de dados\nlibrary(foreign)     # Importação SPSS/Stata\n\n# Visualização\nlibrary(flexplot)    # Gráficos flexíveis\nlibrary(see)         # Visualizações do easystats\n\n# Suites integradas\nlibrary(easystats)   # Suite completa de análise\nlibrary(rempsyc)     # Métodos psicométricos",
    "crumbs": [
      "Modelos Lineares"
    ]
  },
  {
    "objectID": "lms.html#materiais-para-download",
    "href": "lms.html#materiais-para-download",
    "title": "Modelos Lineares",
    "section": "📥 Materiais para Download",
    "text": "📥 Materiais para Download\n\n\n\n\n\n\nArquivos Necessários\n\n\n\nFaça o download do pacote completo abaixo e descompacte todos os arquivos na pasta do seu projeto.\nConteúdo do pacote:\n\nbd_New drug_respiratory&pulse.sav - Banco de dados principal\nLista 1.R - Script parcialmente preenchido para prática\nlista_1.docx - Exercícios para resolução",
    "crumbs": [
      "Modelos Lineares"
    ]
  },
  {
    "objectID": "lms.html#preparação-dos-dados",
    "href": "lms.html#preparação-dos-dados",
    "title": "Modelos Lineares",
    "section": "🔄 Preparação dos Dados",
    "text": "🔄 Preparação dos Dados\n\nCarregamento Inicial\n\n# Importar dados do SPSS\noriginal_wide &lt;- read.spss(\"bd_New drug_respiratory&pulse.sav\", \n                           to.data.frame = TRUE)\n\n# Visualizar estrutura\nhead(original_wide)\n\n      drug resp1 resp2 resp3 pulse1 pulse2 pulse3\n1 New Drug   3.4   3.3   3.3    2.2    2.1    2.1\n2 New Drug   3.4   3.4   3.3    2.2    2.1    2.2\n3 New Drug   3.3   3.4   3.4    2.3    2.4    2.3\n4 New Drug   3.4   3.4   3.4    2.3    2.4    2.3\n5 New Drug   3.3   3.4   3.3    2.2    2.2    2.4\n6 New Drug   3.3   3.3   3.3    2.0    2.1    2.4\n\n\n\n\n\n\n\n\nSobre a função read.spss()\n\n\n\n\n\n\nOrigem: Pacote foreign\nParâmetro to.data.frame = TRUE: Converte para data frame do R\nAlternativa: Pacote haven com read_sav() (mais moderno)\n\n\n\n\n\n\n\nTransformação Wide → Long\nPara análises de medidas repetidas, precisamos converter os dados de formato wide (uma linha por sujeito) para long (uma linha por observação).\n\nPasso 1: Renomear Colunas\n\nbd &lt;- original_wide %&gt;%\n  rename_with(~gsub(\"(resp|pulse)(\\\\d+)\", \"\\\\1_\\\\2\", .), -drug) %&gt;%\n  mutate(ID = row_number()) %&gt;%\n  select(ID, everything())\n\nhead(bd)\n\n  ID     drug resp_1 resp_2 resp_3 pulse_1 pulse_2 pulse_3\n1  1 New Drug    3.4    3.3    3.3     2.2     2.1     2.1\n2  2 New Drug    3.4    3.4    3.3     2.2     2.1     2.2\n3  3 New Drug    3.3    3.4    3.4     2.3     2.4     2.3\n4  4 New Drug    3.4    3.4    3.4     2.3     2.4     2.3\n5  5 New Drug    3.3    3.4    3.3     2.2     2.2     2.4\n6  6 New Drug    3.3    3.3    3.3     2.0     2.1     2.4\n\n\n\n\n\n\n\n\n🔍 Entendendo a Expressão Regular\n\n\n\n\n\nA regex (resp|pulse)(\\\\d+) funciona assim:\n\n(resp|pulse) - Captura “resp” OU “pulse”\n(\\\\d+) - Captura um ou mais dígitos\n\nTransformação: - resp1 → resp_1 - pulse2 → pulse_2\nIsso facilita a separação posterior em variável e tempo!\n\n\n\n\n\nPasso 2: Pivotar para Formato Long\n\nbd_long &lt;- pivot_longer(\n  bd,\n  cols = resp_1:pulse_3,\n  names_to = c(\".value\", \"Tempo\"),\n  names_pattern = \"(.+)_(.+)\"\n)\n\nhead(bd_long)\n\n# A tibble: 6 × 5\n     ID drug     Tempo  resp pulse\n  &lt;int&gt; &lt;fct&gt;    &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt;\n1     1 New Drug 1       3.4   2.2\n2     1 New Drug 2       3.3   2.1\n3     1 New Drug 3       3.3   2.1\n4     2 New Drug 1       3.4   2.2\n5     2 New Drug 2       3.4   2.1\n6     2 New Drug 3       3.3   2.2\n\n\n\n\n\n\n\n\nEstrutura do pivot_longer()\n\n\n\n\ncols: Colunas a transformar\n.value: Nome da coluna vem da primeira parte\nTempo: Criada da segunda parte do nome\nnames_pattern: Regex para dividir nomes\n\n\n\n\n\nPasso 3: Converter Tempo em Fator\n\nbd_long$Tempo &lt;- factor(bd_long$Tempo)",
    "crumbs": [
      "Modelos Lineares"
    ]
  },
  {
    "objectID": "lms.html#verificação-de-pressupostos",
    "href": "lms.html#verificação-de-pressupostos",
    "title": "Modelos Lineares",
    "section": "✅ Verificação de Pressupostos",
    "text": "✅ Verificação de Pressupostos\n\nNormalidade da Variável Dependente\nA distribuição normal é pressuposto fundamental em muitos testes estatísticos.\n\nDistribuição NormalDistribuição Não-Normal\n\n\n\nset.seed(123)\ndados_normais &lt;- rnorm(1000, mean = 0, sd = 1)\n\n# Criar visualizações\npar(mfrow = c(1, 2))\n\n# Histograma\nhist(dados_normais, \n     main = \"Distribuição Normal\",\n     col = \"lightblue\", \n     border = \"black\")\n\n# Q-Q Plot\nqqnorm(dados_normais, main = \"Q-Q Plot - Normal\")\nqqline(dados_normais, col = \"red\", lwd = 2)\n\n\n\n\n\n\n\npar(mfrow = c(1, 1))\n\nCaracterísticas: - Histograma em forma de sino - Q-Q plot segue linha diagonal - Simetria em torno da média\n\n\n\nset.seed(123)\ndados_nao_normais &lt;- abs(rnorm(1000, mean = 0, sd = 1))\n\npar(mfrow = c(1, 2))\n\nhist(dados_nao_normais,\n     main = \"Distribuição Assimétrica\",\n     col = \"lightcoral\",\n     border = \"black\")\n\nqqnorm(dados_nao_normais, main = \"Q-Q Plot - Não Normal\")\nqqline(dados_nao_normais, col = \"red\", lwd = 2)\n\n\n\n\n\n\n\npar(mfrow = c(1, 1))\n\nCaracterísticas: - Assimetria evidente - Desvios da linha no Q-Q plot - Concentração em uma região\n\n\n\n\n\n\nTeste de Shapiro-Wilk\n\n\n\n\n\n\nHipóteses do Teste\n\n\n\nH₀: Os dados seguem distribuição normal\nH₁: Os dados NÃO seguem distribuição normal\nDecisão: - p &gt; 0,05 → Não rejeita H₀ (assume normalidade) - p &lt; 0,05 → Rejeita H₀ (evidência de não-normalidade)\n⚠️ Atenção: Com amostras muito grandes, pequenos desvios podem ser significativos.\n\n\nExemplo com dados normais:\n\nshapiro.test(dados_normais)\n\n\n    Shapiro-Wilk normality test\n\ndata:  dados_normais\nW = 0.99838, p-value = 0.4765\n\n\nExemplo com dados não-normais:\n\nshapiro.test(dados_nao_normais)\n\n\n    Shapiro-Wilk normality test\n\ndata:  dados_nao_normais\nW = 0.92344, p-value &lt; 2.2e-16\n\n\n\n\n\nNormalidade das Variáveis do Estudo\n\nVariável “Pulse”\n\n# Visualização combinada\nnice_normality(\n  data = bd_long,\n  variable = \"pulse\",\n  histogram = TRUE\n)\n\n\n\n\n\n\n\n# Teste formal\nshapiro.test(bd_long$pulse)\n\n\n    Shapiro-Wilk normality test\n\ndata:  bd_long$pulse\nW = 0.90791, p-value = 0.005655\n\n\n\n\n\n\n\n\nInterpretação\n\n\n\nTanto a análise gráfica quanto o teste de Shapiro-Wilk indicam que pulse não possui distribuição normal.",
    "crumbs": [
      "Modelos Lineares"
    ]
  },
  {
    "objectID": "lms.html#esfericidade-medidas-repetidas",
    "href": "lms.html#esfericidade-medidas-repetidas",
    "title": "Modelos Lineares",
    "section": "🔄 Esfericidade (Medidas Repetidas)",
    "text": "🔄 Esfericidade (Medidas Repetidas)\n\n\n\n\n\n\nO que é Esfericidade?\n\n\n\nA esfericidade avalia se as variâncias das diferenças entre todos os pares de medidas repetidas são homogêneas.\nViolação de esfericidade: - Infla erro Tipo I (falsos positivos) - Requer correções nos graus de liberdade - Comum em medidas repetidas\n\n\n\nTeste de Mauchly para “Pulse”\n\npulse_mauchly &lt;- anova_test(\n  data = bd_long,\n  dv = pulse,\n  wid = ID,\n  within = Tempo\n)\n\npulse_mauchly\n\nANOVA Table (type III tests)\n\n$ANOVA\n  Effect DFn DFd    F     p p&lt;.05   ges\n1  Tempo   2  22 3.48 0.049     * 0.024\n\n$`Mauchly's Test for Sphericity`\n  Effect     W    p p&lt;.05\n1  Tempo 0.781 0.29      \n\n$`Sphericity Corrections`\n  Effect  GGe      DF[GG] p[GG] p[GG]&lt;.05   HFe      DF[HF] p[HF] p[HF]&lt;.05\n1  Tempo 0.82 1.64, 18.04 0.061           0.945 1.89, 20.78 0.052          \n\n\n\n\n\n\n\n\n📊 Interpretando os Resultados\n\n\n\n\n\nANOVA Table: - F = 3,48, p = 0,049 → Efeito significativo de Tempo - ges = medida de tamanho de efeito\nTeste de Mauchly: - W = 0,781, p = 0,29 → Esfericidade NÃO violada\nCorreções (quando necessárias): - GGe = 0,82 → Correção de Greenhouse-Geisser - HFe = 0,945 → Correção de Huynh-Feldt\n\n\n\n\n\n\nTeste de Mauchly para “Resp”\n\nresp_mauchly &lt;- anova_test(\n  data = bd_long,\n  dv = resp,\n  wid = ID,\n  within = Tempo\n)\n\nresp_mauchly\n\nANOVA Table (type III tests)\n\n$ANOVA\n  Effect DFn DFd     F     p p&lt;.05  ges\n1  Tempo   2  22 0.344 0.713       0.01\n\n$`Mauchly's Test for Sphericity`\n  Effect     W     p p&lt;.05\n1  Tempo 0.501 0.032     *\n\n$`Sphericity Corrections`\n  Effect   GGe      DF[GG] p[GG] p[GG]&lt;.05   HFe      DF[HF] p[HF] p[HF]&lt;.05\n1  Tempo 0.667 1.33, 14.68 0.629           0.725 1.45, 15.94 0.646          \n\n\n\n\n\n\n\n\n⚠️ Esfericidade Violada!\n\n\n\nTeste de Mauchly: - W = 0,501, p &lt; 0,05 → Esfericidade VIOLADA\nImplicações: - Graus de liberdade devem ser corrigidos - Usar valores p corrigidos (GGe ou HFe) - GGe = 0,667 (redução de ~33%) - HFe = 0,725 (redução de ~27,5%)\nResultado após correção: - Efeito de Tempo permanece não-significativo",
    "crumbs": [
      "Modelos Lineares"
    ]
  },
  {
    "objectID": "lms.html#coeficientes-de-correção",
    "href": "lms.html#coeficientes-de-correção",
    "title": "Modelos Lineares",
    "section": "🔧 Coeficientes de Correção",
    "text": "🔧 Coeficientes de Correção\n\nGreenhouse-Geisser (GGe)Huynh-Feldt (HFe)Quando Usar Qual?\n\n\nCaracterísticas: - Correção mais conservadora - Recomendado quando GGe &lt; 0,75 - Reduz graus de liberdade proporcionalmente\nInterpretação: - GGe próximo de 1 → Pouca violação - GGe &lt; 0,75 → Violação substancial\nExemplo (Resp): - GGe = 0,667 → Redução de 33% nos GL\n\n\nCaracterísticas: - Menos conservador que GGe - Melhor para amostras pequenas - Pode exceder 1 (truncado em 1)\nInterpretação: - HFe próximo de 1 → Pouca violação - Diferença com GGe indica severidade\nExemplo (Resp): - HFe = 0,725 → Redução de 27,5% nos GL\n\n\n\n\n\nSituação\nRecomendação\n\n\n\n\nGGe &gt; 0,75\nQualquer correção\n\n\nGGe &lt; 0,75\nPreferir GGe\n\n\nAmostra pequena\nConsiderar HFe\n\n\np próximo de 0,05\nComparar ambos",
    "crumbs": [
      "Modelos Lineares"
    ]
  },
  {
    "objectID": "lms.html#resumo-dos-pressupostos",
    "href": "lms.html#resumo-dos-pressupostos",
    "title": "Modelos Lineares",
    "section": "🎓 Resumo dos Pressupostos",
    "text": "🎓 Resumo dos Pressupostos\n\n\n\n\n\n\nChecklist de Verificação\n\n\n\n\n\n\n\n\n\n\n\n\nPressuposto\nPulse\nResp\nAção\n\n\n\n\nNormalidade\n❌ Violado\n-\nConsiderar transformação ou GLM robusto\n\n\nEsfericidade\n✅ OK\n❌ Violado\nUsar correções GGe/HFe\n\n\nHomogeneidade\n-\n-\nVerificar com Levene (próximo capítulo)\n\n\n\nPróximos passos: Agora que verificamos os pressupostos, podemos prosseguir para as análises GLM, GEE e GMM!",
    "crumbs": [
      "Modelos Lineares"
    ]
  },
  {
    "objectID": "lms.html#conceitos-chave",
    "href": "lms.html#conceitos-chave",
    "title": "Modelos Lineares",
    "section": "📚 Conceitos-Chave",
    "text": "📚 Conceitos-Chave\n\n\n\n\n\n\nGlossário Rápido\n\n\n\n\n\nWide vs Long: - Wide: Uma linha por sujeito, múltiplas colunas de tempo - Long: Uma linha por observação, coluna de tempo\nEsfericidade: - Homogeneidade das variâncias das diferenças - Crítico para ANOVA de medidas repetidas\nGGe/HFe: - Correções para violação de esfericidade - Ajustam graus de liberdade\nQ-Q Plot: - Quantis observados vs esperados - Linha diagonal = normalidade perfeita\n\n\n\n\n\n\n\n\n\n\n🚀 Pronto para Análises!\n\n\n\nCom os dados preparados e pressupostos verificados, você está pronto para explorar:\n\nGLM - Modelo Linear Geral\nGEE - Equações de Estimação Generalizadas\n\nGMM - Modelos Mistos\nGzLM - Modelos Lineares Generalizados\n\nSiga para os próximos capítulos onde implementaremos cada modelo em detalhe!",
    "crumbs": [
      "Modelos Lineares"
    ]
  },
  {
    "objectID": "lista_1.html",
    "href": "lista_1.html",
    "title": "1  Lista 1: GLM, GEE e GMM",
    "section": "",
    "text": "1.1 📥 Dados e Materiais",
    "crumbs": [
      "Modelos Lineares",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Lista 1: GLM, GEE e GMM</span>"
    ]
  },
  {
    "objectID": "lista_1.html#dados-e-materiais",
    "href": "lista_1.html#dados-e-materiais",
    "title": "1  Lista 1: GLM, GEE e GMM",
    "section": "",
    "text": "Download Necessário\n\n\n\nFaça o download do banco de dados “new drug respiratory&pulse” e salve na pasta do seu projeto.",
    "crumbs": [
      "Modelos Lineares",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Lista 1: GLM, GEE e GMM</span>"
    ]
  },
  {
    "objectID": "lista_1.html#parte-1-glm-modelo-linear-geral",
    "href": "lista_1.html#parte-1-glm-modelo-linear-geral",
    "title": "1  Lista 1: GLM, GEE e GMM",
    "section": "1.2 📊 Parte 1: GLM (Modelo Linear Geral)",
    "text": "1.2 📊 Parte 1: GLM (Modelo Linear Geral)\n\nModelo para “Resp”\nVamos ajustar um modelo de medidas repetidas para a variável respiratória:\n\\[\n\\text{resp} = \\beta_0 + \\beta_1\\text{drug} + \\beta_2\\text{Tempo} + \\beta_3\\text{drug} \\times \\text{Tempo} + \\varepsilon\n\\]\n\nmodelo1_resp &lt;- lm(resp ~ drug + Tempo + drug*Tempo, \n                   data = bd_long)\n\nsummary(modelo1_resp)\n\n\nCall:\nlm(formula = resp ~ drug + Tempo + drug * Tempo, data = bd_long)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.15000 -0.05000 -0.03333  0.05000  0.15000 \n\nCoefficients:\n                     Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)         3.350e+00  2.635e-02 127.124  &lt; 2e-16 ***\ndrugPlacebo        -1.167e-01  3.727e-02  -3.130  0.00387 ** \nTempo2              1.667e-02  3.727e-02   0.447  0.65793    \nTempo3             -1.667e-02  3.727e-02  -0.447  0.65793    \ndrugPlacebo:Tempo2  1.904e-15  5.270e-02   0.000  1.00000    \ndrugPlacebo:Tempo3  3.333e-02  5.270e-02   0.632  0.53188    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.06455 on 30 degrees of freedom\nMultiple R-squared:  0.4559,    Adjusted R-squared:  0.3652 \nF-statistic: 5.027 on 5 and 30 DF,  p-value: 0.001836\n\n\n\n\n\n\n\n\n📖 Interpretando os Coeficientes\n\n\n\n\n\n\nIntercept: Valor médio de resp no grupo referência (placebo) no tempo 1\ndrug: Diferença entre tratamento e placebo no tempo 1\nTempo: Mudança ao longo do tempo no grupo placebo\ndrug:Tempo: Como o efeito da droga muda ao longo do tempo (interação)\n\nSignificância estatística é indicada pelos valores-p na coluna Pr(&gt;|t|).\n\n\n\n\n\nDiagnóstico do Modelo\n\nPredição e LinearidadeHomogeneidade e OutliersColinearidade e Normalidade\n\n\n\ncheck_model(modelo1_resp, \n            check = c(\"pp_check\", \"linearity\"))\n\n\n\n\n\n\n\n\nPosterior Predictive Check: Compara dados observados (verde) com simulações do modelo (azul). Boa sobreposição indica ajuste adequado.\nLinearidade: Linha horizontal sugere relação linear apropriada. Padrões em U indicam necessidade de termos quadráticos.\n\n\n\ncheck_model(modelo1_resp, \n            check = c(\"homogeneity\", \"outliers\"))\n\n\n\n\n\n\n\n\nHomogeneidade: Pontos devem se distribuir uniformemente. Padrões (cone, curva) indicam heterocedasticidade.\nObservações Influentes: Pontos fora das linhas tracejadas (Distância de Cook) são observações influentes que merecem investigação.\n\n\n\ncheck_model(modelo1_resp, \n            check = c(\"vif\", \"normality\"))\n\n\n\n\n\n\n\n\nVIF (Variance Inflation Factor): - VIF &lt; 5: Sem problemas - VIF 5-10: Colinearidade moderada - VIF &gt; 10: Colinearidade severa\nNormalidade dos Resíduos: Pontos devem seguir a linha diagonal. Desvios nas caudas indicam problemas de predição nesses extremos.\n\n\n\n\n\n\n\n\n\n⚠️ Avaliação dos Pressupostos\n\n\n\nEste modelo apresenta violações em diversos pressupostos. Veja a seção de soluções ao final deste capítulo para estratégias de correção.\n\n\n\n\n\nVisualização Completa\n\n\n\n\n\n\n💡 Painel Completo de Diagnósticos\n\n\n\nUse check_model() sem especificar check para ver todos os diagnósticos em um único painel:\n\n\n\ncheck_model(modelo1_resp)\n\n\n\n\n\n\n\n\n\n\n\nVisualização do Modelo\n\nvisualize(modelo1_resp, plot = \"model\")\n\n\n\n\n\n\n\n\n\n\n\nRelatório Automatizado\n\n\n\n\n\n\n⚡ Poder do report()\n\n\n\nA função report() do pacote easystats gera texto formatado para publicação em inglês, reduzindo erros de digitação e aumentando reprodutibilidade.\nImportante: Use com sabedoria! Sempre revise e compreenda os resultados antes de usar em publicações.\n\n\n\nreport(modelo1_resp)\n\nWe fitted a linear model (estimated using OLS) to predict resp with drug and\nTempo (formula: resp ~ drug + Tempo + drug * Tempo). The model explains a\nstatistically significant and substantial proportion of variance (R2 = 0.46,\nF(5, 30) = 5.03, p = 0.002, adj. R2 = 0.37). The model's intercept,\ncorresponding to drug = New Drug and Tempo = 1, is at 3.35 (95% CI [3.30,\n3.40], t(30) = 127.12, p &lt; .001). Within this model:\n\n  - The effect of drug [Placebo] is statistically significant and negative (beta\n= -0.12, 95% CI [-0.19, -0.04], t(30) = -3.13, p = 0.004; Std. beta = -1.44,\n95% CI [-2.38, -0.50])\n  - The effect of Tempo [2] is statistically non-significant and positive (beta =\n0.02, 95% CI [-0.06, 0.09], t(30) = 0.45, p = 0.658; Std. beta = 0.21, 95% CI\n[-0.73, 1.15])\n  - The effect of Tempo [3] is statistically non-significant and negative (beta =\n-0.02, 95% CI [-0.09, 0.06], t(30) = -0.45, p = 0.658; Std. beta = -0.21, 95%\nCI [-1.15, 0.73])\n  - The effect of drug [Placebo] × Tempo [2] is statistically non-significant and\npositive (beta = 1.90e-15, 95% CI [-0.11, 0.11], t(30) = 3.61e-14, p &gt; .999;\nStd. beta = -1.65e-15, 95% CI [-1.33, 1.33])\n  - The effect of drug [Placebo] × Tempo [3] is statistically non-significant and\npositive (beta = 0.03, 95% CI [-0.07, 0.14], t(30) = 0.63, p = 0.532; Std. beta\n= 0.41, 95% CI [-0.92, 1.74])\n\nStandardized parameters were obtained by fitting the model on a standardized\nversion of the dataset. 95% Confidence Intervals (CIs) and p-values were\ncomputed using a Wald t-distribution approximation.\n\n\n\n\n\n\nModelo para “Pulse”\nAgora ajustaremos o mesmo modelo para a variável de pulso:\n\\[\n\\text{pulse} = \\beta_0 + \\beta_1\\text{drug} + \\beta_2\\text{Tempo} + \\beta_3\\text{drug} \\times \\text{Tempo} + \\varepsilon\n\\]\n\nmodelo1_pulse &lt;- lm(pulse ~ drug + Tempo + drug*Tempo, \n                    data = bd_long)\n\nsummary(modelo1_pulse)\n\n\nCall:\nlm(formula = pulse ~ drug + Tempo + drug * Tempo, data = bd_long)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.20000 -0.08333  0.00000  0.08750  0.18333 \n\nCoefficients:\n                   Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)         2.20000    0.04389  50.131  &lt; 2e-16 ***\ndrugPlacebo         0.46667    0.06206   7.519 2.21e-08 ***\nTempo2              0.01667    0.06206   0.269    0.790    \nTempo3              0.08333    0.06206   1.343    0.189    \ndrugPlacebo:Tempo2  0.13333    0.08777   1.519    0.139    \ndrugPlacebo:Tempo3  0.03333    0.08777   0.380    0.707    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.1075 on 30 degrees of freedom\nMultiple R-squared:  0.8804,    Adjusted R-squared:  0.8605 \nF-statistic: 44.17 on 5 and 30 DF,  p-value: 6.029e-13\n\n\n\n\nDiagnóstico do Modelo\n\nPredição e LinearidadeHomogeneidade e OutliersColinearidade e Normalidade\n\n\n\ncheck_model(modelo1_pulse, \n            check = c(\"pp_check\", \"linearity\"))\n\n\n\n\n\n\n\n\n\n\n\ncheck_model(modelo1_pulse, \n            check = c(\"homogeneity\", \"outliers\"))\n\n\n\n\n\n\n\n\n\n\n\ncheck_model(modelo1_pulse, \n            check = c(\"vif\", \"normality\"))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVisualização do Modelo\n\nvisualize(modelo1_pulse, plot = \"model\")\n\n\n\n\n\n\n\n\n\n\nRelatório Automatizado\n\nreport(modelo1_pulse)\n\nWe fitted a linear model (estimated using OLS) to predict pulse with drug and\nTempo (formula: pulse ~ drug + Tempo + drug * Tempo). The model explains a\nstatistically significant and substantial proportion of variance (R2 = 0.88,\nF(5, 30) = 44.17, p &lt; .001, adj. R2 = 0.86). The model's intercept,\ncorresponding to drug = New Drug and Tempo = 1, is at 2.20 (95% CI [2.11,\n2.29], t(30) = 50.13, p &lt; .001). Within this model:\n\n  - The effect of drug [Placebo] is statistically significant and positive (beta\n= 0.47, 95% CI [0.34, 0.59], t(30) = 7.52, p &lt; .001; Std. beta = 1.62, 95% CI\n[1.18, 2.06])\n  - The effect of Tempo [2] is statistically non-significant and positive (beta =\n0.02, 95% CI [-0.11, 0.14], t(30) = 0.27, p = 0.790; Std. beta = 0.06, 95% CI\n[-0.38, 0.50])\n  - The effect of Tempo [3] is statistically non-significant and positive (beta =\n0.08, 95% CI [-0.04, 0.21], t(30) = 1.34, p = 0.189; Std. beta = 0.29, 95% CI\n[-0.15, 0.73])\n  - The effect of drug [Placebo] × Tempo [2] is statistically non-significant and\npositive (beta = 0.13, 95% CI [-0.05, 0.31], t(30) = 1.52, p = 0.139; Std. beta\n= 0.46, 95% CI [-0.16, 1.09])\n  - The effect of drug [Placebo] × Tempo [3] is statistically non-significant and\npositive (beta = 0.03, 95% CI [-0.15, 0.21], t(30) = 0.38, p = 0.707; Std. beta\n= 0.12, 95% CI [-0.51, 0.74])\n\nStandardized parameters were obtained by fitting the model on a standardized\nversion of the dataset. 95% Confidence Intervals (CIs) and p-values were\ncomputed using a Wald t-distribution approximation.",
    "crumbs": [
      "Modelos Lineares",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Lista 1: GLM, GEE e GMM</span>"
    ]
  },
  {
    "objectID": "lista_1.html#parte-2-gee-equações-de-estimação-generalizadas",
    "href": "lista_1.html#parte-2-gee-equações-de-estimação-generalizadas",
    "title": "1  Lista 1: GLM, GEE e GMM",
    "section": "1.3 📊 Parte 2: GEE (Equações de Estimação Generalizadas)",
    "text": "1.3 📊 Parte 2: GEE (Equações de Estimação Generalizadas)\n\nModelo GEE para “Resp”\nGEE oferece estimativas robustas mesmo quando a estrutura de correlação não é perfeitamente especificada.\n\nmodelo_gee_resp &lt;- geeglm(\n  resp ~ drug + Tempo + drug*Tempo,\n  data = bd_long,\n  id = ID,\n  family = gaussian,\n  corstr = \"unstructured\"\n)\n\nsummary(modelo_gee_resp)\n\n\nCall:\ngeeglm(formula = resp ~ drug + Tempo + drug * Tempo, family = gaussian, \n    data = bd_long, id = ID, corstr = \"unstructured\")\n\n Coefficients:\n                     Estimate    Std.err      Wald Pr(&gt;|W|)    \n(Intercept)         3.350e+00  2.041e-02 26934.000  &lt; 2e-16 ***\ndrugPlacebo        -1.167e-01  2.805e-02    17.294  3.2e-05 ***\nTempo2              1.667e-02  2.805e-02     0.353    0.552    \nTempo3             -1.667e-02  2.805e-02     0.353    0.552    \ndrugPlacebo:Tempo2  4.022e-18  3.967e-02     0.000    1.000    \ndrugPlacebo:Tempo3  3.333e-02  5.693e-02     0.343    0.558    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nCorrelation structure = unstructured \nEstimated Scale Parameters:\n\n            Estimate   Std.err\n(Intercept) 0.003472 0.0007618\n  Link = identity \n\nEstimated Correlation Parameters:\n            Estimate Std.err\nalpha.1:2 -9.252e-18 0.19596\nalpha.1:3 -2.400e-01 0.27321\nalpha.2:3  7.600e-01 0.09074\nNumber of clusters:   12  Maximum cluster size: 3 \n\n\n\n\n\n\n\n\n🔍 Parâmetros do GEE\n\n\n\n\n\n\nid: Identificador do sujeito (observações repetidas)\nfamily: Distribuição da variável resposta (gaussian, binomial, poisson)\ncorstr: Estrutura de correlação\n\n\"independence\": Sem correlação\n\"exchangeable\": Correlação constante\n\"ar1\": Autorregressiva de ordem 1\n\"unstructured\": Sem restrições (mais flexível)\n\n\n\n\n\n\n\nDiagnóstico do Modelo GEE\n\ncheck_model(modelo_gee_resp)\n\n\n\n\n\n\n\n\n\n\nVisualização do Modelo\n\nvisualize(modelo_gee_resp, plot = \"model\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n⚠️ Limitação do report()\n\n\n\nA função report() não funciona para modelos GEE. Pratique escrever seus resultados manualmente!\n\n\n\n\n\n\nModelo GEE para “Pulse”\n\nmodelo_gee_pulse &lt;- geeglm(\n  pulse ~ drug + Tempo + drug*Tempo,\n  data = bd_long,\n  id = ID,\n  family = gaussian,\n  corstr = \"unstructured\"\n)\n\nsummary(modelo_gee_pulse)\n\n\nCall:\ngeeglm(formula = pulse ~ drug + Tempo + drug * Tempo, family = gaussian, \n    data = bd_long, id = ID, corstr = \"unstructured\")\n\n Coefficients:\n                   Estimate Std.err    Wald Pr(&gt;|W|)    \n(Intercept)          2.2000  0.0408 2904.00   &lt;2e-16 ***\ndrugPlacebo          0.4667  0.0509   84.00   &lt;2e-16 ***\nTempo2               0.0167  0.0366    0.21   0.6492    \nTempo3               0.0833  0.0684    1.49   0.2230    \ndrugPlacebo:Tempo2   0.1333  0.0419   10.11   0.0015 ** \ndrugPlacebo:Tempo3   0.0333  0.0877    0.14   0.7038    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nCorrelation structure = unstructured \nEstimated Scale Parameters:\n\n            Estimate Std.err\n(Intercept)  0.00963 0.00168\n  Link = identity \n\nEstimated Correlation Parameters:\n          Estimate Std.err\nalpha.1:2    0.721   0.169\nalpha.1:3   -0.288   0.208\nalpha.2:3    0.115   0.267\nNumber of clusters:   12  Maximum cluster size: 3 \n\n\n\n\nDiagnóstico do Modelo\n\ncheck_model(modelo_gee_pulse)\n\n\n\n\n\n\n\n\n\n\nVisualização do Modelo\n\nvisualize(modelo_gee_pulse, plot = \"model\")",
    "crumbs": [
      "Modelos Lineares",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Lista 1: GLM, GEE e GMM</span>"
    ]
  },
  {
    "objectID": "lista_1.html#parte-3-gmm-modelos-mistos-generalizados",
    "href": "lista_1.html#parte-3-gmm-modelos-mistos-generalizados",
    "title": "1  Lista 1: GLM, GEE e GMM",
    "section": "1.4 📊 Parte 3: GMM (Modelos Mistos Generalizados)",
    "text": "1.4 📊 Parte 3: GMM (Modelos Mistos Generalizados)\n\nModelo GMM para “Resp”\nModelos mistos incorporam efeitos fixos e aleatórios, capturando variabilidade entre e dentro de sujeitos.\n\nmodelo_gmm_resp &lt;- lme(\n  fixed = resp ~ drug + Tempo + drug*Tempo,\n  random = ~1|ID,\n  data = bd_long\n)\n\nsummary(modelo_gmm_resp)\n\nLinear mixed-effects model fit by REML\n  Data: bd_long \n    AIC   BIC logLik\n  -53.4 -42.2   34.7\n\nRandom effects:\n Formula: ~1 | ID\n        (Intercept) Residual\nStdDev:      0.0269   0.0587\n\nFixed effects:  resp ~ drug + Tempo + drug * Tempo \n                   Value Std.Error DF t-value p-value\n(Intercept)         3.35    0.0264 20   127.1  0.0000\ndrugPlacebo        -0.12    0.0373 10    -3.1  0.0107\nTempo2              0.02    0.0339 20     0.5  0.6282\nTempo3             -0.02    0.0339 20    -0.5  0.6282\ndrugPlacebo:Tempo2  0.00    0.0479 20     0.0  1.0000\ndrugPlacebo:Tempo3  0.03    0.0479 20     0.7  0.4947\n Correlation: \n                   (Intr) drgPlc Tempo2 Tempo3 drP:T2\ndrugPlacebo        -0.707                            \nTempo2             -0.643  0.455                     \nTempo3             -0.643  0.455  0.500              \ndrugPlacebo:Tempo2  0.455 -0.643 -0.707 -0.354       \ndrugPlacebo:Tempo3  0.455 -0.643 -0.354 -0.707  0.500\n\nStandardized Within-Group Residuals:\n   Min     Q1    Med     Q3    Max \n-2.263 -0.560 -0.257  0.685  2.190 \n\nNumber of Observations: 36\nNumber of Groups: 12 \n\n\n\n\n\n\n\n\n🔍 Estrutura do Modelo Misto\n\n\n\n\n\n\nfixed: Efeitos fixos (mesmos do GLM)\nrandom = ~1|ID: Intercepto aleatório por sujeito\n\nCaptura variabilidade baseline entre indivíduos\n~1 indica apenas intercepto aleatório\n|ID agrupa por sujeito\n\n\nEstruturas mais complexas: - ~Tempo|ID: Intercepto e slope aleatórios - ~1|Escola/Sala: Hierarquia aninhada\n\n\n\n\n\nDiagnóstico do Modelo\n\ncheck_model(modelo_gmm_resp)\n\n\n\n\n\n\n\n\n\n\n\nVisualização do Modelo\n\n\n\n\n\n\n💡 Visualização Manual com ggplot2\n\n\n\nA função visualize() nem sempre funciona com modelos complexos. Vamos criar gráficos manualmente com ggplot2:\n\n\n\n# Calcular médias marginais estimadas\nmeans_ci_gmm_resp &lt;- emmeans(modelo_gmm_resp, \n                              specs = ~drug:Tempo)\n\n# Criar gráfico\nggplot(as.data.frame(means_ci_gmm_resp), \n       aes(x = Tempo, y = emmean, color = drug, group = drug)) +\n  geom_errorbar(aes(ymin = lower.CL, ymax = upper.CL),\n                width = 0.2,\n                position = position_dodge(0.1)) +\n  geom_point(position = position_dodge(0.1), \n             size = 3) +\n  geom_line(position = position_dodge(0.1)) +\n  labs(\n    title = \"Efeito da Droga na Respiração ao Longo do Tempo\",\n    subtitle = \"Médias marginais estimadas com IC 95%\",\n    x = \"Tempo\",\n    y = \"Respiração (Resp)\",\n    color = \"Tratamento\"\n  ) +\n  theme_minimal() +\n  theme(\n    legend.position = \"bottom\",\n    plot.title = element_text(face = \"bold\")\n  )\n\n\n\n\n\n\n\n\n\n\nRelatório Automatizado\n\nreport(modelo_gmm_resp)\n\nWe fitted a linear mixed model (estimated using REML and nlminb optimizer) to\npredict resp with drug and Tempo (formula: resp ~ drug + Tempo + drug * Tempo).\nThe model included ID as random effect (formula: ~1 | ID). The model's total\nexplanatory power is substantial (conditional R2 = 0.52) and the part related\nto the fixed effects alone (marginal R2) is of 0.42. The model's intercept,\ncorresponding to drug = New Drug and Tempo = 1, is at 3.35 (95% CI [3.30,\n3.40], t(20) = 127.12, p &lt; .001). Within this model:\n\n  - The effect of drug [Placebo] is statistically significant and negative (beta\n= -0.12, 95% CI [-0.20, -0.03], t(10) = -3.13, p = 0.011; Std. beta = -1.44,\n95% CI [-2.47, -0.42])\n  - The effect of Tempo [2] is statistically non-significant and positive (beta =\n0.02, 95% CI [-0.05, 0.09], t(20) = 0.49, p = 0.628; Std. beta = 0.21, 95% CI\n[-0.67, 1.08])\n  - The effect of Tempo [3] is statistically non-significant and negative (beta =\n-0.02, 95% CI [-0.09, 0.05], t(20) = -0.49, p = 0.628; Std. beta = -0.21, 95%\nCI [-1.08, 0.67])\n  - The effect of drug [Placebo] × Tempo [2] is statistically non-significant and\nnegative (beta = -6.16e-16, 95% CI [-0.10, 0.10], t(20) = -1.29e-14, p &gt; .999;\nStd. beta = -3.14e-16, 95% CI [-1.23, 1.23])\n  - The effect of drug [Placebo] × Tempo [3] is statistically non-significant and\npositive (beta = 0.03, 95% CI [-0.07, 0.13], t(20) = 0.70, p = 0.495; Std. beta\n= 0.41, 95% CI [-0.82, 1.65])\n\nStandardized parameters were obtained by fitting the model on a standardized\nversion of the dataset. 95% Confidence Intervals (CIs) and p-values were\ncomputed using a Wald t-distribution approximation.\n\n\n\n\n\n\nModelo GMM para “Pulse”\n\nmodelo_gmm_pulse &lt;- lme(\n  fixed = pulse ~ drug + Tempo + drug*Tempo,\n  random = ~1|ID,\n  data = bd_long\n)\n\nsummary(modelo_gmm_pulse)\n\nLinear mixed-effects model fit by REML\n  Data: bd_long \n    AIC   BIC logLik\n  -22.9 -11.6   19.4\n\nRandom effects:\n Formula: ~1 | ID\n        (Intercept) Residual\nStdDev:      0.0459   0.0972\n\nFixed effects:  pulse ~ drug + Tempo + drug * Tempo \n                   Value Std.Error DF t-value p-value\n(Intercept)        2.200    0.0439 20    50.1   0.000\ndrugPlacebo        0.467    0.0621 10     7.5   0.000\nTempo2             0.017    0.0561 20     0.3   0.769\nTempo3             0.083    0.0561 20     1.5   0.153\ndrugPlacebo:Tempo2 0.133    0.0793 20     1.7   0.108\ndrugPlacebo:Tempo3 0.033    0.0793 20     0.4   0.679\n Correlation: \n                   (Intr) drgPlc Tempo2 Tempo3 drP:T2\ndrugPlacebo        -0.707                            \nTempo2             -0.639  0.452                     \nTempo3             -0.639  0.452  0.500              \ndrugPlacebo:Tempo2  0.452 -0.639 -0.707 -0.354       \ndrugPlacebo:Tempo3  0.452 -0.639 -0.354 -0.707  0.500\n\nStandardized Within-Group Residuals:\n   Min     Q1    Med     Q3    Max \n-1.783 -0.629 -0.178  0.630  1.476 \n\nNumber of Observations: 36\nNumber of Groups: 12 \n\n\n\n\nDiagnóstico do Modelo\n\ncheck_model(modelo_gmm_pulse)\n\n\n\n\n\n\n\n\n\n\n\nVisualização do Modelo\n\n# Calcular médias marginais\nmeans_ci_gmm_pulse &lt;- emmeans(modelo_gmm_pulse, \n                               specs = ~drug:Tempo)\n\n# Criar gráfico\nggplot(as.data.frame(means_ci_gmm_pulse),\n       aes(x = Tempo, y = emmean, color = drug, group = drug)) +\n  geom_errorbar(aes(ymin = lower.CL, ymax = upper.CL),\n                width = 0.2,\n                position = position_dodge(0.1)) +\n  geom_point(position = position_dodge(0.1),\n             size = 3) +\n  geom_line(position = position_dodge(0.1)) +\n  labs(\n    title = \"Efeito da Droga no Pulso ao Longo do Tempo\",\n    subtitle = \"Médias marginais estimadas com IC 95%\",\n    x = \"Tempo\",\n    y = \"Pulso (Pulse)\",\n    color = \"Tratamento\"\n  ) +\n  theme_minimal() +\n  theme(\n    legend.position = \"bottom\",\n    plot.title = element_text(face = \"bold\")\n  )\n\n\n\n\n\n\n\n\n\n\nRelatório Automatizado\n\nreport(modelo_gmm_pulse)\n\nWe fitted a linear mixed model (estimated using REML and nlminb optimizer) to\npredict pulse with drug and Tempo (formula: pulse ~ drug + Tempo + drug *\nTempo). The model included ID as random effect (formula: ~1 | ID). The model's\ntotal explanatory power is substantial (conditional R2 = 0.89) and the part\nrelated to the fixed effects alone (marginal R2) is of 0.86. The model's\nintercept, corresponding to drug = New Drug and Tempo = 1, is at 2.20 (95% CI\n[2.11, 2.29], t(20) = 50.13, p &lt; .001). Within this model:\n\n  - The effect of drug [Placebo] is statistically significant and positive (beta\n= 0.47, 95% CI [0.33, 0.60], t(10) = 7.52, p &lt; .001; Std. beta = 1.62, 95% CI\n[1.14, 2.10])\n  - The effect of Tempo [2] is statistically non-significant and positive (beta =\n0.02, 95% CI [-0.10, 0.13], t(20) = 0.30, p = 0.769; Std. beta = 0.06, 95% CI\n[-0.35, 0.46])\n  - The effect of Tempo [3] is statistically non-significant and positive (beta =\n0.08, 95% CI [-0.03, 0.20], t(20) = 1.49, p = 0.153; Std. beta = 0.29, 95% CI\n[-0.12, 0.70])\n  - The effect of drug [Placebo] × Tempo [2] is statistically non-significant and\npositive (beta = 0.13, 95% CI [-0.03, 0.30], t(20) = 1.68, p = 0.108; Std. beta\n= 0.46, 95% CI [-0.11, 1.04])\n  - The effect of drug [Placebo] × Tempo [3] is statistically non-significant and\npositive (beta = 0.03, 95% CI [-0.13, 0.20], t(20) = 0.42, p = 0.679; Std. beta\n= 0.12, 95% CI [-0.46, 0.69])\n\nStandardized parameters were obtained by fitting the model on a standardized\nversion of the dataset. 95% Confidence Intervals (CIs) and p-values were\ncomputed using a Wald t-distribution approximation.",
    "crumbs": [
      "Modelos Lineares",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Lista 1: GLM, GEE e GMM</span>"
    ]
  },
  {
    "objectID": "lista_1.html#sec-violacoes",
    "href": "lista_1.html#sec-violacoes",
    "title": "1  Lista 1: GLM, GEE e GMM",
    "section": "1.5 🔧 Violação dos Pressupostos: O Que Fazer?",
    "text": "1.5 🔧 Violação dos Pressupostos: O Que Fazer?\n\n\n\n\n\n\nGuia de Soluções para Violações\n\n\n\nQuando seu modelo viola pressupostos, considere as seguintes estratégias:\n\n\n\nMulticolinearidadeNormalidadeHomogeneidadeOutliersLinearidadeAjuste Global\n\n\nProblema: Preditores altamente correlacionados entre si (VIF &gt; 10)\nSoluções:\n\nIdentificar correlações\n\ncor(bd_long[, c(\"var1\", \"var2\", \"var3\")])\n\nRemover variável redundante\n\nManter a mais teoricamente relevante\nOu a com maior poder explicativo\n\nCriar índices compostos\n\nMédia ou soma ponderada de variáveis correlacionadas\nAnálise de componentes principais (PCA)\n\nCentralizar variáveis\n\nbd_long$var_centered &lt;- scale(bd_long$var, scale = FALSE)\n\n\n\n\nProblema: Resíduos não seguem distribuição normal\nSoluções:\n\nTransformações de dados\n\n# Logarítmica\nbd_long$resp_log &lt;- log(bd_long$resp + 1)\n\n# Raiz quadrada\nbd_long$resp_sqrt &lt;- sqrt(bd_long$resp)\n\n# Box-Cox\nlibrary(MASS)\nbc &lt;- boxcox(modelo1_resp)\nlambda &lt;- bc$x[which.max(bc$y)]\n\nModelos robustos\n\nlibrary(robustbase)\nmodelo_robusto &lt;- lmrob(resp ~ drug + Tempo, data = bd_long)\n\nModelos generalizados (GzLM)\n\nUse distribuições mais apropriadas (Gamma, Poisson)\n\n\n\n\nProblema: Variância não constante dos resíduos\nSoluções:\n\nTransformação da variável resposta\n\nMesmas transformações da normalidade\n\nPesos heterocedásticos\n\nlibrary(nlme)\nmodelo_hetero &lt;- gls(\n  resp ~ drug + Tempo,\n  weights = varIdent(form = ~1|drug),\n  data = bd_long\n)\n\nErros-padrão robustos\n\nlibrary(sandwich)\nlibrary(lmtest)\ncoeftest(modelo1_resp, vcov = vcovHC(modelo1_resp, type = \"HC3\"))\n\n\n\n\nProblema: Observações extremamente influentes\nSoluções:\n\nInvestigar outliers\n\n# Identificar outliers\noutliers &lt;- which(cooks.distance(modelo1_resp) &gt; 4/nrow(bd_long))\nbd_long[outliers, ]\n\nAnálise de sensibilidade\n\nRefazer análise com e sem outliers\nReportar ambos os resultados\n\nModelos robustos\n\nMenos sensíveis a outliers\n\nTransformações\n\nReduzir impacto de valores extremos\n\n\n\n\nProblema: Relação não-linear entre preditores e resposta\nSoluções:\n\nTermos polinomiais\n\nmodelo_quad &lt;- lm(resp ~ drug + Tempo + I(Tempo^2), \n                  data = bd_long)\n\nSplines\n\nlibrary(splines)\nmodelo_spline &lt;- lm(resp ~ drug + bs(Tempo, df = 3), \n                    data = bd_long)\n\nModelos aditivos generalizados (GAM)\n\nlibrary(mgcv)\nmodelo_gam &lt;- gam(resp ~ drug + s(Tempo), \n                  data = bd_long)\n\n\n\n\nProblema: Modelo não se ajusta bem aos dados (Posterior Predictive)\nSoluções:\n\nRevisar especificação do modelo\n\nAdicionar interações relevantes\nIncluir preditores omitidos\n\nMudar distribuição\n\nDe gaussian para Gamma, Poisson, etc.\n\nConsiderar não-linearidades\n\nGAM, splines, polinômios\n\nModelos mais flexíveis\n\nRandom forests, boosting (exploratório)\n\n\n\n\n\n\n\n\n\n\n\n💡 Estratégia Geral\n\n\n\n\nIdentifique todas as violações\nPriorize as mais severas\nAplique soluções sequencialmente\nReavalie após cada mudança\nDocumente todas as tentativas\nSe tudo falhar, reconheça limitações do modelo",
    "crumbs": [
      "Modelos Lineares",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Lista 1: GLM, GEE e GMM</span>"
    ]
  },
  {
    "objectID": "lista_1.html#conclusão",
    "href": "lista_1.html#conclusão",
    "title": "1  Lista 1: GLM, GEE e GMM",
    "section": "1.6 📝 Conclusão",
    "text": "1.6 📝 Conclusão\n\n\n\n\n\n\nResumo da Lista\n\n\n\nNeste tutorial, exploramos três abordagens complementares para análise de medidas repetidas:\nGLM: Abordagem clássica, pressupõe esfericidade\nGEE: Robusto à especificação de correlação, foco em efeitos populacionais\nGMM: Modela variabilidade individual, permite estruturas hierárquicas\nCada método tem vantagens específicas. A escolha depende de: - Estrutura dos dados - Pergunta de pesquisa - Pressupostos atendidos - Interpretação desejada\nPróximos passos: Listas subsequentes compararão estes métodos em diferentes cenários.",
    "crumbs": [
      "Modelos Lineares",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Lista 1: GLM, GEE e GMM</span>"
    ]
  },
  {
    "objectID": "lista_1.html#recursos-complementares",
    "href": "lista_1.html#recursos-complementares",
    "title": "1  Lista 1: GLM, GEE e GMM",
    "section": "1.7 📚 Recursos Complementares",
    "text": "1.7 📚 Recursos Complementares\n\nAula em Vídeo (SPSS)\n\n\n\n\nReferências Recomendadas\n\n\n\n\n\n\n📖 Leituras Complementares\n\n\n\n\n\nTestes e pressupostos: - Mauchly’s Test of Sphericity in R\nManipulação de dados: - Pivoting multiple variables - YouTube - Wide to long format part 2 - YouTube\nModelos avançados: - Pinheiro & Bates (2000). Mixed-Effects Models in S and S-PLUS - Fitzmaurice et al. (2011). Applied Longitudinal Analysis - West et al. (2014). Linear Mixed Models: A Practical Guide",
    "crumbs": [
      "Modelos Lineares",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Lista 1: GLM, GEE e GMM</span>"
    ]
  },
  {
    "objectID": "lista_1.html#informações-de-sessão",
    "href": "lista_1.html#informações-de-sessão",
    "title": "1  Lista 1: GLM, GEE e GMM",
    "section": "1.8 🔧 Informações de Sessão",
    "text": "1.8 🔧 Informações de Sessão\n\nreport(sessionInfo())\n\nAnalyses were conducted using the R Statistical language (version 4.4.2; R Core\nTeam, 2024) on Windows 11 x64 (build 26100), using the packages lme4 (version\n1.1.37; Bates D et al., 2015), Matrix (version 1.7.1; Bates D et al., 2024),\neffectsize (version 1.0.1; Ben-Shachar MS et al., 2020), flexplot (version\n0.24.3; Fife, D, 2022), effects (version 4.2.4; Fox J, Weisberg S, 2019),\ncarData (version 3.0.5; Fox J et al., 2022), mvtnorm (version 1.3.3; Genz A,\nBretz F, 2009), geepack (version 1.3.13; Halekoh U et al., 2006), TH.data\n(version 1.1.3; Hothorn T, 2025), multcomp (version 1.4.28; Hothorn T et al.,\n2008), rstatix (version 0.7.2; Kassambara A, 2023), emmeans (version 1.11.0;\nLenth R, 2025), sjstats (version 0.19.1; Lüdecke D, 2025), parameters (version\n0.28.3; Lüdecke D et al., 2020), performance (version 0.15.2; Lüdecke D et al.,\n2021), easystats (version 0.7.5; Lüdecke D et al., 2022), see (version 0.12.0;\nLüdecke D et al., 2021), insight (version 1.4.4; Lüdecke D et al., 2019),\nbayestestR (version 0.17.0; Makowski D et al., 2019), modelbased (version\n0.13.1; Makowski D et al., 2025), report (version 0.6.3; Makowski D et al.,\n2023), correlation (version 0.8.8; Makowski D et al., 2022), datawizard\n(version 1.3.0; Patil I et al., 2022), nlme (version 3.1.166; Pinheiro J et\nal., 2024), foreign (version 0.8.87; R Core Team, 2024), rempsyc (version\n0.2.0; Thériault R, 2023), survival (version 3.7.0; Therneau T, 2024), MASS\n(version 7.3.61; Venables WN, Ripley BD, 2002), ggplot2 (version 4.0.1; Wickham\nH, 2016), dplyr (version 1.1.4; Wickham H et al., 2023) and tidyr (version\n1.3.1; Wickham H et al., 2024).\n\nReferences\n----------\n  - Bates D, Mächler M, Bolker B, Walker S (2015). \"Fitting Linear Mixed-Effects\nModels Using lme4.\" _Journal of Statistical Software_, *67*(1), 1-48.\ndoi:10.18637/jss.v067.i01 &lt;https://doi.org/10.18637/jss.v067.i01&gt;.\n  - Bates D, Maechler M, Jagan M (2024). _Matrix: Sparse and Dense Matrix Classes\nand Methods_. R package version 1.7-1,\n&lt;https://CRAN.R-project.org/package=Matrix&gt;.\n  - Ben-Shachar MS, Lüdecke D, Makowski D (2020). \"effectsize: Estimation of\nEffect Size Indices and Standardized Parameters.\" _Journal of Open Source\nSoftware_, *5*(56), 2815. doi:10.21105/joss.02815\n&lt;https://doi.org/10.21105/joss.02815&gt;, &lt;https://doi.org/10.21105/joss.02815&gt;.\n  - Fife, A. D (2022). \"Flexplot: Graphically-based data analysis.\"\n_Psychological Methods_, *27*(4), -19. &lt;doi.org/10.1037/met0000424&gt;.\n  - Fox J, Weisberg S (2019). _An R Companion to Applied Regression_, 3rd\nedition. Sage, Thousand Oaks CA.\n&lt;https://www.john-fox.ca/Companion/index.html&gt;. Fox J, Weisberg S (2018).\n\"Visualizing Fit and Lack of Fit in Complex Regression Models with Predictor\nEffect Plots and Partial Residuals.\" _Journal of Statistical Software_,\n*87*(9), 1-27. doi:10.18637/jss.v087.i09\n&lt;https://doi.org/10.18637/jss.v087.i09&gt;. Fox J (2003). \"Effect Displays in R\nfor Generalised Linear Models.\" _Journal of Statistical Software_, *8*(15),\n1-27. doi:10.18637/jss.v008.i15 &lt;https://doi.org/10.18637/jss.v008.i15&gt;. Fox J,\nHong J (2009). \"Effect Displays in R for Multinomial and Proportional-Odds\nLogit Models: Extensions to the effects Package.\" _Journal of Statistical\nSoftware_, *32*(1), 1-24. doi:10.18637/jss.v032.i01\n&lt;https://doi.org/10.18637/jss.v032.i01&gt;.\n  - Fox J, Weisberg S, Price B (2022). _carData: Companion to Applied Regression\nData Sets_. R package version 3.0-5,\n&lt;https://CRAN.R-project.org/package=carData&gt;.\n  - Genz A, Bretz F (2009). _Computation of Multivariate Normal and t\nProbabilities_, series Lecture Notes in Statistics. Springer-Verlag,\nHeidelberg. ISBN 978-3-642-01688-2.\n  - Halekoh U, Højsgaard S, Yan J (2006). \"The R Package geepack for Generalized\nEstimating Equations.\" _Journal of Statistical Software_, *15/2*, 1-11. Yan J,\nFine JP (2004). \"Estimating Equations for Association Structures.\" _Statistics\nin Medicine_, *23*, 859-880. Yan J (2002). \"geepack: Yet Another Package for\nGeneralized Estimating Equations.\" _R-News_, *2/3*, 12-14. Xu, Z., Fine, P. J,\nSong, W., Yan, J. (2025). \"On GEE for mean-variance-correlation models:\nVariance estimation and model selection.\" _Statistics in Medicine_, *44*, 1-2.\n  - Hothorn T (2025). _TH.data: TH's Data Archive_. R package version 1.1-3,\n&lt;https://CRAN.R-project.org/package=TH.data&gt;.\n  - Hothorn T, Bretz F, Westfall P (2008). \"Simultaneous Inference in General\nParametric Models.\" _Biometrical Journal_, *50*(3), 346-363.\n  - Kassambara A (2023). _rstatix: Pipe-Friendly Framework for Basic Statistical\nTests_. R package version 0.7.2, &lt;https://CRAN.R-project.org/package=rstatix&gt;.\n  - Lenth R (2025). _emmeans: Estimated Marginal Means, aka Least-Squares Means_.\nR package version 1.11.0, &lt;https://CRAN.R-project.org/package=emmeans&gt;.\n  - Lüdecke D (2025). _sjstats: Statistical Functions for Regression Models\n(Version 0.19.1)_. doi:10.5281/zenodo.1284472\n&lt;https://doi.org/10.5281/zenodo.1284472&gt;,\n&lt;https://CRAN.R-project.org/package=sjstats&gt;.\n  - Lüdecke D, Ben-Shachar M, Patil I, Makowski D (2020). \"Extracting, Computing\nand Exploring the Parameters of Statistical Models using R.\" _Journal of Open\nSource Software_, *5*(53), 2445. doi:10.21105/joss.02445\n&lt;https://doi.org/10.21105/joss.02445&gt;.\n  - Lüdecke D, Ben-Shachar M, Patil I, Waggoner P, Makowski D (2021).\n\"performance: An R Package for Assessment, Comparison and Testing of\nStatistical Models.\" _Journal of Open Source Software_, *6*(60), 3139.\ndoi:10.21105/joss.03139 &lt;https://doi.org/10.21105/joss.03139&gt;.\n  - Lüdecke D, Ben-Shachar M, Patil I, Wiernik B, Bacher E, Thériault R, Makowski\nD (2022). \"easystats: Framework for Easy Statistical Modeling, Visualization,\nand Reporting.\" _CRAN_. doi:10.32614/CRAN.package.easystats\n&lt;https://doi.org/10.32614/CRAN.package.easystats&gt;, R package,\n&lt;https://easystats.github.io/easystats/&gt;.\n  - Lüdecke D, Patil I, Ben-Shachar M, Wiernik B, Waggoner P, Makowski D (2021).\n\"see: An R Package for Visualizing Statistical Models.\" _Journal of Open Source\nSoftware_, *6*(64), 3393. doi:10.21105/joss.03393\n&lt;https://doi.org/10.21105/joss.03393&gt;.\n  - Lüdecke D, Waggoner P, Makowski D (2019). \"insight: A Unified Interface to\nAccess Information from Model Objects in R.\" _Journal of Open Source Software_,\n*4*(38), 1412. doi:10.21105/joss.01412 &lt;https://doi.org/10.21105/joss.01412&gt;.\n  - Makowski D, Ben-Shachar M, Lüdecke D (2019). \"bayestestR: Describing Effects\nand their Uncertainty, Existence and Significance within the Bayesian\nFramework.\" _Journal of Open Source Software_, *4*(40), 1541.\ndoi:10.21105/joss.01541 &lt;https://doi.org/10.21105/joss.01541&gt;,\n&lt;https://joss.theoj.org/papers/10.21105/joss.01541&gt;.\n  - Makowski D, Ben-Shachar M, Wiernik B, Patil I, Thériault R, Lüdecke D (2025).\n\"modelbased: An R package to make the most out of your statistical models\nthrough marginal means, marginal effects, and model predictions.\" _Journal of\nOpen Source Software_, *10*(109), 7969. doi:10.21105/joss.07969\n&lt;https://doi.org/10.21105/joss.07969&gt;,\n&lt;https://joss.theoj.org/papers/10.21105/joss.07969&gt;.\n  - Makowski D, Lüdecke D, Patil I, Thériault R, Ben-Shachar M, Wiernik B (2023).\n\"Automated Results Reporting as a Practical Tool to Improve Reproducibility and\nMethodological Best Practices Adoption.\" _CRAN_.\ndoi:10.32614/CRAN.package.report\n&lt;https://doi.org/10.32614/CRAN.package.report&gt;,\n&lt;https://easystats.github.io/report/&gt;.\n  - Makowski D, Wiernik B, Patil I, Lüdecke D, Ben-Shachar M (2022).\n\"correlation: Methods for Correlation Analysis.\" Version 0.8.3,\n&lt;https://CRAN.R-project.org/package=correlation&gt;. Makowski D, Ben-Shachar M,\nPatil I, Lüdecke D (2020). \"Methods and Algorithms for Correlation Analysis in\nR.\" _Journal of Open Source Software_, *5*(51), 2306. doi:10.21105/joss.02306\n&lt;https://doi.org/10.21105/joss.02306&gt;,\n&lt;https://joss.theoj.org/papers/10.21105/joss.02306&gt;.\n  - Patil I, Makowski D, Ben-Shachar M, Wiernik B, Bacher E, Lüdecke D (2022).\n\"datawizard: An R Package for Easy Data Preparation and Statistical\nTransformations.\" _Journal of Open Source Software_, *7*(78), 4684.\ndoi:10.21105/joss.04684 &lt;https://doi.org/10.21105/joss.04684&gt;.\n  - Pinheiro J, Bates D, R Core Team (2024). _nlme: Linear and Nonlinear Mixed\nEffects Models_. R package version 3.1-166,\n&lt;https://CRAN.R-project.org/package=nlme&gt;. Pinheiro JC, Bates DM (2000).\n_Mixed-Effects Models in S and S-PLUS_. Springer, New York. doi:10.1007/b98882\n&lt;https://doi.org/10.1007/b98882&gt;.\n  - R Core Team (2024). _foreign: Read Data Stored by 'Minitab', 'S', 'SAS',\n'SPSS', 'Stata', 'Systat', 'Weka', 'dBase', ..._. R package version 0.8-87,\n&lt;https://CRAN.R-project.org/package=foreign&gt;.\n  - R Core Team (2024). _R: A Language and Environment for Statistical\nComputing_. R Foundation for Statistical Computing, Vienna, Austria.\n&lt;https://www.R-project.org/&gt;.\n  - Thériault R (2023). \"rempsyc: Convenience functions for psychology.\" _Journal\nof Open Source Software_, *8*(87), 5466. doi:10.21105/joss.05466\n&lt;https://doi.org/10.21105/joss.05466&gt;, &lt;https://doi.org/10.21105/joss.05466&gt;.\n  - Therneau T (2024). _A Package for Survival Analysis in R_. R package version\n3.7-0, &lt;https://CRAN.R-project.org/package=survival&gt;. Terry M. Therneau,\nPatricia M. Grambsch (2000). _Modeling Survival Data: Extending the Cox Model_.\nSpringer, New York. ISBN 0-387-98784-3.\n  - Venables WN, Ripley BD (2002). _Modern Applied Statistics with S_, Fourth\nedition. Springer, New York. ISBN 0-387-95457-0,\n&lt;https://www.stats.ox.ac.uk/pub/MASS4/&gt;.\n  - Wickham H (2016). _ggplot2: Elegant Graphics for Data Analysis_.\nSpringer-Verlag New York. ISBN 978-3-319-24277-4,\n&lt;https://ggplot2.tidyverse.org&gt;.\n  - Wickham H, François R, Henry L, Müller K, Vaughan D (2023). _dplyr: A Grammar\nof Data Manipulation_. R package version 1.1.4,\n&lt;https://CRAN.R-project.org/package=dplyr&gt;.\n  - Wickham H, Vaughan D, Girlich M (2024). _tidyr: Tidy Messy Data_. R package\nversion 1.3.1, &lt;https://CRAN.R-project.org/package=tidyr&gt;.\n\n\n\n\n\n\n\n\n💡 Reprodutibilidade\n\n\n\nSempre inclua sessionInfo() ao final de suas análises para documentar versões de pacotes e garantir reprodutibilidade!",
    "crumbs": [
      "Modelos Lineares",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Lista 1: GLM, GEE e GMM</span>"
    ]
  },
  {
    "objectID": "lista_2.html#preparação-dos-dados",
    "href": "lista_2.html#preparação-dos-dados",
    "title": "Lista 2: GEE Avançado",
    "section": "📥 Preparação dos Dados",
    "text": "📥 Preparação dos Dados\n\n\n\n\n\n\nDownload Necessário\n\n\n\nUse o mesmo banco “New Drug” da Lista 1.\n\n\n\nCarregamento e Transformação\n\n# 1. Carregar dados originais\noriginal_wide &lt;- read.spss(\"bd_New drug_respiratory&pulse.sav\", \n                           to.data.frame = TRUE)\n\n# 2. Renomear colunas\nbd &lt;- original_wide %&gt;%\n  rename_with(~gsub(\"(resp|pulse)(\\\\d+)\", \"\\\\1_\\\\2\", .), -drug) %&gt;%\n  mutate(ID = row_number()) %&gt;%\n  select(ID, everything())\n\n# 3. Converter para formato long\nbd_long &lt;- pivot_longer(\n  bd,\n  cols = resp_1:pulse_3,\n  names_to = c(\".value\", \"Tempo\"),\n  names_pattern = \"(.+)_(.+)\"\n)\n\n# 4. Converter para fatores\nbd_long$ID &lt;- factor(bd_long$ID)\nbd_long$Tempo &lt;- factor(bd_long$Tempo)\n\n# Visualizar estrutura\nhead(bd_long)\n\n# A tibble: 6 × 5\n  ID    drug     Tempo  resp pulse\n  &lt;fct&gt; &lt;fct&gt;    &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 1     New Drug 1       3.4   2.2\n2 1     New Drug 2       3.3   2.1\n3 1     New Drug 3       3.3   2.1\n4 2     New Drug 1       3.4   2.2\n5 2     New Drug 2       3.4   2.1\n6 2     New Drug 3       3.3   2.2",
    "crumbs": [
      "Modelos Lineares",
      "Lista 2: GEE Avançado"
    ]
  },
  {
    "objectID": "lista_2.html#parte-a-modelos-gee-com-diferentes-distribuições",
    "href": "lista_2.html#parte-a-modelos-gee-com-diferentes-distribuições",
    "title": "Lista 2: GEE Avançado",
    "section": "🎯 Parte A: Modelos GEE com Diferentes Distribuições",
    "text": "🎯 Parte A: Modelos GEE com Diferentes Distribuições\n\n\n\n\n\n\nPor que Testar Diferentes Distribuições?\n\n\n\nA escolha da distribuição afeta: - Ajuste do modelo aos dados - Interpretação dos coeficientes - Precisão das predições - Validade das inferências\nTestar múltiplas distribuições ajuda a identificar qual melhor representa seus dados.\n\n\n\n\nModelo 1: Distribuição Normal (Gaussian)\n\nAjuste do Modelo\n\nmodelo_gee_pulse_normal &lt;- geeglm(\n  pulse ~ drug + Tempo + drug*Tempo,\n  data = bd_long,\n  id = ID,\n  family = gaussian,\n  corstr = \"unstructured\"\n)\n\n\n\n\n\n\n\n📊 Quando Usar Distribuição Normal?\n\n\n\n\n\nAdequada para: - Variáveis contínuas - Distribuição simétrica - Sem limite inferior ou superior rígido\nCaracterísticas: - Link: identidade (padrão) - Variância: constante - Suporte: \\((-\\infty, +\\infty)\\)\n\n\n\n\n\n\nResultados e Contrastes\n\nsummary(modelo_gee_pulse_normal)\n\n\nCall:\ngeeglm(formula = pulse ~ drug + Tempo + drug * Tempo, family = gaussian, \n    data = bd_long, id = ID, corstr = \"unstructured\")\n\n Coefficients:\n                   Estimate Std.err     Wald Pr(&gt;|W|)    \n(Intercept)         2.20000 0.04082 2904.000  &lt; 2e-16 ***\ndrugPlacebo         0.46667 0.05092   84.000  &lt; 2e-16 ***\nTempo2              0.01667 0.03664    0.207  0.64921    \nTempo3              0.08333 0.06838    1.485  0.22297    \ndrugPlacebo:Tempo2  0.13333 0.04194   10.105  0.00148 ** \ndrugPlacebo:Tempo3  0.03333 0.08767    0.145  0.70377    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nCorrelation structure = unstructured \nEstimated Scale Parameters:\n\n            Estimate  Std.err\n(Intercept)  0.00963 0.001676\n  Link = identity \n\nEstimated Correlation Parameters:\n          Estimate Std.err\nalpha.1:2   0.7212  0.1690\nalpha.1:3  -0.2885  0.2076\nalpha.2:3   0.1154  0.2665\nNumber of clusters:   12  Maximum cluster size: 3 \n\n\n\nMédias MarginaisComparações Par-a-Par\n\n\n\nemmeans(modelo_gee_pulse_normal, \n        specs = ~drug*Tempo)\n\n drug     Tempo emmean     SE df lower.CL upper.CL\n New Drug 1       2.20 0.0408 30     2.12     2.28\n Placebo  1       2.67 0.0304 30     2.60     2.73\n New Drug 2       2.22 0.0549 30     2.10     2.33\n Placebo  2       2.82 0.0280 30     2.76     2.87\n New Drug 3       2.28 0.0436 30     2.19     2.37\n Placebo  3       2.78 0.0366 30     2.71     2.86\n\nCovariance estimate used: vbeta \nConfidence level used: 0.95 \n\n\n\n\n\nemmeans(modelo_gee_pulse_normal, \n        pairwise ~ drug*Tempo)\n\n$emmeans\n drug     Tempo emmean     SE df lower.CL upper.CL\n New Drug 1       2.20 0.0408 30     2.12     2.28\n Placebo  1       2.67 0.0304 30     2.60     2.73\n New Drug 2       2.22 0.0549 30     2.10     2.33\n Placebo  2       2.82 0.0280 30     2.76     2.87\n New Drug 3       2.28 0.0436 30     2.19     2.37\n Placebo  3       2.78 0.0366 30     2.71     2.86\n\nCovariance estimate used: vbeta \nConfidence level used: 0.95 \n\n$contrasts\n contrast                          estimate     SE df t.ratio p.value\n New Drug Tempo1 - Placebo Tempo1   -0.4667 0.0509 30  -9.165  &lt;.0001\n New Drug Tempo1 - New Drug Tempo2  -0.0167 0.0366 30  -0.455  0.9973\n New Drug Tempo1 - Placebo Tempo2   -0.6167 0.0495 30 -12.449  &lt;.0001\n New Drug Tempo1 - New Drug Tempo3  -0.0833 0.0684 30  -1.219  0.8244\n New Drug Tempo1 - Placebo Tempo3   -0.5833 0.0549 30 -10.634  &lt;.0001\n Placebo Tempo1 - New Drug Tempo2    0.4500 0.0627 30   7.173  &lt;.0001\n Placebo Tempo1 - Placebo Tempo2    -0.1500 0.0204 30  -7.348  &lt;.0001\n Placebo Tempo1 - New Drug Tempo3    0.3833 0.0531 30   7.213  &lt;.0001\n Placebo Tempo1 - Placebo Tempo3    -0.1167 0.0549 30  -2.127  0.3013\n New Drug Tempo2 - Placebo Tempo2   -0.6000 0.0616 30  -9.738  &lt;.0001\n New Drug Tempo2 - New Drug Tempo3  -0.0667 0.0609 30  -1.095  0.8793\n New Drug Tempo2 - Placebo Tempo3   -0.5667 0.0660 30  -8.590  &lt;.0001\n Placebo Tempo2 - New Drug Tempo3    0.5333 0.0518 30  10.292  &lt;.0001\n Placebo Tempo2 - Placebo Tempo3     0.0333 0.0509 30   0.655  0.9855\n New Drug Tempo3 - Placebo Tempo3   -0.5000 0.0569 30  -8.783  &lt;.0001\n\nP value adjustment: tukey method for comparing a family of 6 estimates \n\n\n\n\n\n\n\n\nDiagnóstico do Modelo\n\ncheck_model(modelo_gee_pulse_normal)\n\n\n\n\n\n\n\n\n\n\n\nVisualização dos Resultados\n\n# Calcular médias marginais\nmeans_ci_normal &lt;- emmeans(modelo_gee_pulse_normal, \n                           specs = ~drug:Tempo)\n\n# Criar gráfico elegante\nggplot(as.data.frame(means_ci_normal), \n       aes(x = Tempo, y = emmean, color = drug, group = drug)) +\n  geom_errorbar(\n    aes(ymin = lower.CL, ymax = upper.CL),\n    width = 0.2,\n    position = position_dodge(0.1)\n  ) +\n  geom_point(\n    position = position_dodge(0.1),\n    size = 4\n  ) +\n  geom_line(\n    position = position_dodge(0.1),\n    linewidth = 1\n  ) +\n  labs(\n    title = \"GEE com Distribuição Normal\",\n    subtitle = \"Médias marginais estimadas com IC 95%\",\n    x = \"Tempo\",\n    y = \"Pulso (bpm)\",\n    color = \"Tratamento\"\n  ) +\n  theme_minimal(base_size = 13) +\n  theme(\n    legend.position = \"bottom\",\n    plot.title = element_text(face = \"bold\", size = 15),\n    panel.grid.minor = element_blank()\n  ) +\n  scale_color_brewer(palette = \"Set1\")\n\n\n\n\n\n\n\n\n\n\n\n\nModelo 2: Distribuição Gamma\n\nAjuste do Modelo\n\nmodelo_gee_pulse_gamma &lt;- geeglm(\n  pulse ~ drug + Tempo + drug*Tempo,\n  data = bd_long,\n  id = ID,\n  family = Gamma(link = \"identity\"),\n  corstr = \"unstructured\"\n)\n\n\n\n\n\n\n\n📊 Quando Usar Distribuição Gamma?\n\n\n\n\n\nAdequada para: - Variáveis contínuas positivas - Distribuição assimétrica à direita - Variância proporcional à média\nCaracterísticas: - Link comum: log ou identity - Variância: aumenta com a média - Suporte: \\((0, +\\infty)\\)\nExemplos: - Tempo de reação - Tempo de sobrevida - Concentrações biomarcadores\n\n\n\n\n\n\nResultados e Contrastes\n\nsummary(modelo_gee_pulse_gamma)\n\n\nCall:\ngeeglm(formula = pulse ~ drug + Tempo + drug * Tempo, family = Gamma(link = \"identity\"), \n    data = bd_long, id = ID, corstr = \"unstructured\")\n\n Coefficients:\n                   Estimate Std.err    Wald Pr(&gt;|W|)    \n(Intercept)          2.2000  0.0408 2904.00   &lt;2e-16 ***\ndrugPlacebo          0.4667  0.0509   84.00   &lt;2e-16 ***\nTempo2               0.0167  0.0366    0.21   0.6492    \nTempo3               0.0833  0.0684    1.49   0.2230    \ndrugPlacebo:Tempo2   0.1333  0.0419   10.11   0.0015 ** \ndrugPlacebo:Tempo3   0.0333  0.0877    0.14   0.7038    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nCorrelation structure = unstructured \nEstimated Scale Parameters:\n\n            Estimate  Std.err\n(Intercept)  0.00172 0.000372\n  Link = identity \n\nEstimated Correlation Parameters:\n          Estimate Std.err\nalpha.1:2    0.745   0.178\nalpha.1:3   -0.279   0.208\nalpha.2:3    0.156   0.279\nNumber of clusters:   12  Maximum cluster size: 3 \n\n\n\nMédias MarginaisComparações Par-a-Par\n\n\n\nemmeans(modelo_gee_pulse_gamma, \n        specs = ~drug*Tempo)\n\n drug     Tempo emmean     SE df lower.CL upper.CL\n New Drug 1       2.20 0.0408 30     2.12     2.28\n Placebo  1       2.67 0.0304 30     2.60     2.73\n New Drug 2       2.22 0.0549 30     2.10     2.33\n Placebo  2       2.82 0.0281 30     2.76     2.87\n New Drug 3       2.28 0.0436 30     2.19     2.37\n Placebo  3       2.78 0.0366 30     2.71     2.86\n\nCovariance estimate used: vbeta \nConfidence level used: 0.95 \n\n\n\n\n\nemmeans(modelo_gee_pulse_gamma, \n        pairwise ~ drug*Tempo)\n\n$emmeans\n drug     Tempo emmean     SE df lower.CL upper.CL\n New Drug 1       2.20 0.0408 30     2.12     2.28\n Placebo  1       2.67 0.0304 30     2.60     2.73\n New Drug 2       2.22 0.0549 30     2.10     2.33\n Placebo  2       2.82 0.0281 30     2.76     2.87\n New Drug 3       2.28 0.0436 30     2.19     2.37\n Placebo  3       2.78 0.0366 30     2.71     2.86\n\nCovariance estimate used: vbeta \nConfidence level used: 0.95 \n\n$contrasts\n contrast                          estimate     SE df t.ratio p.value\n New Drug Tempo1 - Placebo Tempo1    -0.467 0.0509 30  -9.170  &lt;.0001\n New Drug Tempo1 - New Drug Tempo2   -0.017 0.0366 30  -0.450  0.9970\n New Drug Tempo1 - Placebo Tempo2    -0.617 0.0495 30 -12.450  &lt;.0001\n New Drug Tempo1 - New Drug Tempo3   -0.083 0.0684 30  -1.220  0.8240\n New Drug Tempo1 - Placebo Tempo3    -0.583 0.0549 30 -10.630  &lt;.0001\n Placebo Tempo1 - New Drug Tempo2     0.450 0.0627 30   7.170  &lt;.0001\n Placebo Tempo1 - Placebo Tempo2     -0.150 0.0204 30  -7.350  &lt;.0001\n Placebo Tempo1 - New Drug Tempo3     0.383 0.0531 30   7.210  &lt;.0001\n Placebo Tempo1 - Placebo Tempo3     -0.117 0.0549 30  -2.130  0.3010\n New Drug Tempo2 - Placebo Tempo2    -0.600 0.0616 30  -9.740  &lt;.0001\n New Drug Tempo2 - New Drug Tempo3   -0.067 0.0609 30  -1.100  0.8790\n New Drug Tempo2 - Placebo Tempo3    -0.567 0.0660 30  -8.590  &lt;.0001\n Placebo Tempo2 - New Drug Tempo3     0.533 0.0518 30  10.290  &lt;.0001\n Placebo Tempo2 - Placebo Tempo3      0.033 0.0509 30   0.650  0.9860\n New Drug Tempo3 - Placebo Tempo3    -0.500 0.0569 30  -8.780  &lt;.0001\n\nP value adjustment: tukey method for comparing a family of 6 estimates \n\n\n\n\n\n\n\n\nDiagnóstico do Modelo\n\ncheck_model(modelo_gee_pulse_gamma)\n\n\n\n\n\n\n\n\n\n\n\nVisualização dos Resultados\n\n# Calcular médias marginais\nmeans_ci_gamma &lt;- emmeans(modelo_gee_pulse_gamma, \n                          specs = ~drug:Tempo)\n\n# Criar gráfico\nggplot(as.data.frame(means_ci_gamma),\n       aes(x = Tempo, y = emmean, color = drug, group = drug)) +\n  geom_errorbar(\n    aes(ymin = lower.CL, ymax = upper.CL),\n    width = 0.2,\n    position = position_dodge(0.1)\n  ) +\n  geom_point(\n    position = position_dodge(0.1),\n    size = 4\n  ) +\n  geom_line(\n    position = position_dodge(0.1),\n    linewidth = 1\n  ) +\n  labs(\n    title = \"GEE com Distribuição Gamma\",\n    subtitle = \"Médias marginais estimadas com IC 95%\",\n    x = \"Tempo\",\n    y = \"Pulso (bpm)\",\n    color = \"Tratamento\"\n  ) +\n  theme_minimal(base_size = 13) +\n  theme(\n    legend.position = \"bottom\",\n    plot.title = element_text(face = \"bold\", size = 15),\n    panel.grid.minor = element_blank()\n  ) +\n  scale_color_brewer(palette = \"Set1\")\n\n\n\n\n\n\n\n\n\n\n\n\nModelo 3: Distribuição Tweedie\n\n\n\n\n\n\n⚠️ Implementação Limitada\n\n\n\nAtualmente, a função geeglm() não suporta nativamente a família Tweedie. Estamos usando glm() como alternativa, mas isso não captura a estrutura de correlação das medidas repetidas.\nRecomendações: - Para análises definitivas, use SPSS ou SAS que implementam GEE-Tweedie - Considere glmmTMB::glmmTMB() como alternativa (modelo misto) - Aguarde atualizações do pacote geepack\n\n\n\nAjuste do Modelo (Limitado)\n\nmodelo_gee_pulse_tweedie &lt;- glm(\n  pulse ~ drug + Tempo + drug*Tempo,\n  data = bd_long,\n  family = tweedie(var.power = 2, link.power = 0)\n)\n\n\n\n\n\n\n\n📊 Quando Usar Distribuição Tweedie?\n\n\n\n\n\nAdequada para: - Dados com excesso de zeros - Distribuição assimétrica - Variância aumenta com a média\nCaracterísticas: - Parâmetro var.power: - 0 = Normal - 1 = Poisson - 2 = Gamma - 1-2 = Distribuições compostas - Flexível para diferentes tipos de assimetria\nExemplos: - Custos médicos (muitos zeros) - Precipitação pluviométrica - Dados de contagem inflados de zeros\n\n\n\n\n\n\nResultados e Contrastes\n\nsummary(modelo_gee_pulse_tweedie)\n\n\nCall:\nglm(formula = pulse ~ drug + Tempo + drug * Tempo, family = tweedie(var.power = 2, \n    link.power = 0), data = bd_long)\n\nCoefficients:\n                   Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)         0.78846    0.01857   42.47  &lt; 2e-16 ***\ndrugPlacebo         0.19237    0.02626    7.33  3.7e-08 ***\nTempo2              0.00755    0.02626    0.29     0.78    \nTempo3              0.03718    0.02626    1.42     0.17    \ndrugPlacebo:Tempo2  0.04718    0.03713    1.27     0.21    \ndrugPlacebo:Tempo3  0.00564    0.03713    0.15     0.88    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for Tweedie family taken to be 0.00207)\n\n    Null deviance: 0.473395  on 35  degrees of freedom\nResidual deviance: 0.062212  on 30  degrees of freedom\nAIC: NA\n\nNumber of Fisher Scoring iterations: 3\n\n\n\nMédias MarginaisComparações Par-a-Par\n\n\n\nemmeans(modelo_gee_pulse_tweedie, \n        specs = ~drug*Tempo)\n\n drug     Tempo emmean     SE  df asymp.LCL asymp.UCL\n New Drug 1      0.788 0.0186 Inf     0.752     0.825\n Placebo  1      0.981 0.0186 Inf     0.944     1.017\n New Drug 2      0.796 0.0186 Inf     0.760     0.832\n Placebo  2      1.036 0.0186 Inf     0.999     1.072\n New Drug 3      0.826 0.0186 Inf     0.789     0.862\n Placebo  3      1.024 0.0186 Inf     0.987     1.060\n\nResults are given on the mu^0 (not the response) scale. \nConfidence level used: 0.95 \n\n\n\n\n\nemmeans(modelo_gee_pulse_tweedie, \n        pairwise ~ drug*Tempo)\n\n$emmeans\n drug     Tempo emmean     SE  df asymp.LCL asymp.UCL\n New Drug 1      0.788 0.0186 Inf     0.752     0.825\n Placebo  1      0.981 0.0186 Inf     0.944     1.017\n New Drug 2      0.796 0.0186 Inf     0.760     0.832\n Placebo  2      1.036 0.0186 Inf     0.999     1.072\n New Drug 3      0.826 0.0186 Inf     0.789     0.862\n Placebo  3      1.024 0.0186 Inf     0.987     1.060\n\nResults are given on the mu^0 (not the response) scale. \nConfidence level used: 0.95 \n\n$contrasts\n contrast                          estimate     SE  df z.ratio p.value\n New Drug Tempo1 - Placebo Tempo1   -0.1924 0.0263 Inf  -7.330  &lt;.0001\n New Drug Tempo1 - New Drug Tempo2  -0.0075 0.0263 Inf  -0.290  1.0000\n New Drug Tempo1 - Placebo Tempo2   -0.2471 0.0263 Inf  -9.410  &lt;.0001\n New Drug Tempo1 - New Drug Tempo3  -0.0372 0.0263 Inf  -1.420  0.7170\n New Drug Tempo1 - Placebo Tempo3   -0.2352 0.0263 Inf  -8.960  &lt;.0001\n Placebo Tempo1 - New Drug Tempo2    0.1848 0.0263 Inf   7.040  &lt;.0001\n Placebo Tempo1 - Placebo Tempo2    -0.0547 0.0263 Inf  -2.080  0.2950\n Placebo Tempo1 - New Drug Tempo3    0.1552 0.0263 Inf   5.910  &lt;.0001\n Placebo Tempo1 - Placebo Tempo3    -0.0428 0.0263 Inf  -1.630  0.5780\n New Drug Tempo2 - Placebo Tempo2   -0.2395 0.0263 Inf  -9.120  &lt;.0001\n New Drug Tempo2 - New Drug Tempo3  -0.0296 0.0263 Inf  -1.130  0.8700\n New Drug Tempo2 - Placebo Tempo3   -0.2276 0.0263 Inf  -8.670  &lt;.0001\n Placebo Tempo2 - New Drug Tempo3    0.2099 0.0263 Inf   7.990  &lt;.0001\n Placebo Tempo2 - Placebo Tempo3     0.0119 0.0263 Inf   0.450  0.9980\n New Drug Tempo3 - Placebo Tempo3   -0.1980 0.0263 Inf  -7.540  &lt;.0001\n\nNote: contrasts are still on the mu^0 scale. Consider using\n      regrid() if you want contrasts of back-transformed estimates. \nP value adjustment: tukey method for comparing a family of 6 estimates \n\n\n\n\n\n\n\n\nDiagnóstico do Modelo\n\ncheck_model(modelo_gee_pulse_tweedie)\n\n\n\n\n\n\n\n\n\n\n\nVisualização dos Resultados\n\n# Calcular médias marginais\nmeans_ci_tweedie &lt;- emmeans(modelo_gee_pulse_tweedie, \n                            specs = ~drug:Tempo)\n\n# Criar gráfico\nggplot(as.data.frame(means_ci_tweedie),\n       aes(x = Tempo, y = emmean, color = drug, group = drug)) +\n  geom_errorbar(\n    aes(ymin = asymp.LCL, ymax = asymp.UCL),\n    width = 0.2,\n    position = position_dodge(0.1)\n  ) +\n  geom_point(\n    position = position_dodge(0.1),\n    size = 4\n  ) +\n  geom_line(\n    position = position_dodge(0.1),\n    linewidth = 1\n  ) +\n  labs(\n    title = \"GLM com Distribuição Tweedie\",\n    subtitle = \"Médias marginais estimadas com IC 95% (sem estrutura de correlação)\",\n    x = \"Tempo\",\n    y = \"Pulso (bpm)\",\n    color = \"Tratamento\",\n    caption = \"Nota: Modelo não captura correlação entre medidas repetidas\"\n  ) +\n  theme_minimal(base_size = 13) +\n  theme(\n    legend.position = \"bottom\",\n    plot.title = element_text(face = \"bold\", size = 15),\n    panel.grid.minor = element_blank(),\n    plot.caption = element_text(face = \"italic\", hjust = 0)\n  ) +\n  scale_color_brewer(palette = \"Set1\")",
    "crumbs": [
      "Modelos Lineares",
      "Lista 2: GEE Avançado"
    ]
  },
  {
    "objectID": "lista_2.html#parte-b-comparação-de-modelos-com-qic",
    "href": "lista_2.html#parte-b-comparação-de-modelos-com-qic",
    "title": "Lista 2: GEE Avançado",
    "section": "🎯 Parte B: Comparação de Modelos com QIC",
    "text": "🎯 Parte B: Comparação de Modelos com QIC\n\n\n\n\n\n\nO que é QIC?\n\n\n\nQuasi-likelihood Information Criterion é análogo ao AIC, mas para modelos GEE.\nInterpretação: - Menor QIC = melhor modelo - Diferença &gt; 2 indica melhoria substancial - Penaliza complexidade do modelo\nComponentes: - QIC: Informação geral - QICu: Versão não ajustada - Quasi Lik: Quasi-verossimilhança\n\n\n\nCálculo do QIC\n\n# Calcular QIC para modelos GEE\nqic_normal &lt;- QIC(modelo_gee_pulse_normal)\nqic_gamma &lt;- QIC(modelo_gee_pulse_gamma)\n\n# Criar tabela comparativa\ntabela_qic &lt;- data.frame(\n  Modelo = c(\"Normal\", \"Gamma\"),\n  QIC = c(qic_normal[1], qic_gamma[1]),\n  QICu = c(qic_normal[2], qic_gamma[2]),\n  QuasiLik = c(qic_normal[3], qic_gamma[3])\n)\n\n# Ordenar por QIC\ntabela_qic &lt;- tabela_qic[order(tabela_qic$QIC), ]\n\n# Adicionar ranking\ntabela_qic$Ranking &lt;- 1:nrow(tabela_qic)\n\n# Exibir resultado\nknitr::kable(\n  tabela_qic,\n  digits = 2,\n  caption = \"Comparação de Modelos via QIC (menor é melhor)\"\n)\n\n\nComparação de Modelos via QIC (menor é melhor)\n\n\nModelo\nQIC\nQICu\nQuasiLik\nRanking\n\n\n\n\nNormal\n12.3\n12.3\n-0.17\n1\n\n\nGamma\n125.2\n125.2\n-56.58\n2\n\n\n\n\n\n\n\n\n\n\n\n⚠️ Limitação do QIC\n\n\n\nA função QIC() não funciona com modelos glm() ou lm(), apenas com geeglm().\nPara o modelo Tweedie, você precisará: - Usar software específico (SPSS, SAS) - Aguardar implementação em R - Comparar apenas Normal vs Gamma por enquanto\n\n\n\n\n\nInterpretação dos Resultados\n\nDiferenças SubstantivasOutros Critérios\n\n\nRegra prática: - ΔqIC &lt; 2: Modelos equivalentes - ΔqIC 2-10: Diferença moderada - ΔqIC &gt; 10: Diferença substancial\n\n# Calcular diferenças\ndelta_qic &lt;- abs(diff(tabela_qic$QIC))\n\ncat(\"Diferença QIC:\", round(delta_qic, 2), \"\\n\")\n\nDiferença QIC: 113 \n\nif (delta_qic &lt; 2) {\n  cat(\"→ Modelos são equivalentes\\n\")\n} else if (delta_qic &lt; 10) {\n  cat(\"→ Diferença moderada - considere outros fatores\\n\")\n} else {\n  cat(\"→ Diferença substancial - prefira modelo com menor QIC\\n\")\n}\n\n→ Diferença substancial - prefira modelo com menor QIC\n\n\n\n\nAlém do QIC, considere:\n\nPressupostos teóricos\n\nQual distribuição faz sentido para a variável?\nPulse tem limite inferior (&gt; 0)?\n\nDiagnósticos visuais\n\nQual modelo tem melhores diagnósticos?\nResíduos mais bem comportados?\n\nInterpretabilidade\n\nCoeficientes fazem sentido?\nIntervalos de confiança plausíveis?\n\nValidação cruzada\n\nComo o modelo prediz novos dados?",
    "crumbs": [
      "Modelos Lineares",
      "Lista 2: GEE Avançado"
    ]
  },
  {
    "objectID": "lista_2.html#parte-c-sumarizando-resultados",
    "href": "lista_2.html#parte-c-sumarizando-resultados",
    "title": "Lista 2: GEE Avançado",
    "section": "📝 Parte C: Sumarizando Resultados",
    "text": "📝 Parte C: Sumarizando Resultados\n\n\n\n\n\n\nLimitação do report()\n\n\n\nA função report() não funciona para modelos GEE (geeglm).\nFunciona apenas para: glm, lm, lme, etc.\nAproveite para treinar escrita científica!\n\n\n\nExemplo de Relatório - Modelo Tweedie\n\nreport(modelo_gee_pulse_tweedie)\n\nWe fitted a general linear model (Tweedie family with a mu^0 link) (estimated\nusing ML) to predict pulse with drug and Tempo (formula: pulse ~ drug + Tempo +\ndrug * Tempo). The model's explanatory power is substantial (Nagelkerke's R2 =\n0.87). The model's intercept, corresponding to drug = New Drug and Tempo = 1,\nis at 0.79 (95% CI [0.75, 0.83], p &lt; .001). Within this model:\n\n  - The effect of drug [Placebo] is statistically significant and positive (beta\n= 0.19, 95% CI [0.14, 0.24], p &lt; .001; Std. beta = 0.19, 95% CI [0.14, 0.24])\n  - The effect of Tempo [2] is statistically non-significant and positive (beta =\n7.55e-03, 95% CI [-0.04, 0.06], p = 0.774; Std. beta = 7.55e-03, 95% CI [-0.04,\n0.06])\n  - The effect of Tempo [3] is statistically non-significant and positive (beta =\n0.04, 95% CI [-0.01, 0.09], p = 0.157; Std. beta = 0.04, 95% CI [-0.01, 0.09])\n  - The effect of drug [Placebo] × Tempo [2] is statistically non-significant and\npositive (beta = 0.05, 95% CI [-0.03, 0.12], p = 0.204; Std. beta = 0.05, 95%\nCI [-0.03, 0.12])\n  - The effect of drug [Placebo] × Tempo [3] is statistically non-significant and\npositive (beta = 5.64e-03, 95% CI [-0.07, 0.08], p = 0.879; Std. beta =\n5.64e-03, 95% CI [-0.07, 0.08])\n\nStandardized parameters were obtained by fitting the model on a standardized\nversion of the dataset. 95% Confidence Intervals (CIs) and p-values were\ncomputed using a Wald z-distribution approximation.\n\n\n\n\n\nTemplate para Redação Manual\n\n\n\n\n\n\n📝 Estrutura Sugerida para Resultados\n\n\n\n\n\nPara GEE, estruture seus resultados assim:\n\nAnálise de Medidas Repetidas via GEE\nUtilizamos Equações de Estimação Generalizadas (GEE) com estrutura de correlação não-estruturada para modelar a trajetória de pulso ao longo de três momentos de avaliação (Tempo 1, 2, 3), comparando grupo experimental (droga) e controle (placebo).\nComparação de Distribuições\nTestamos três especificações de distribuição: - Gaussiana (Normal) - Gamma - Tweedie (var.power = 2)\nA comparação via QIC indicou que [MODELO X] apresentou melhor ajuste (QIC = X.XX), seguido por [MODELO Y] (QIC = Y.YY, ΔQIC = Z.ZZ).\nResultados Principais\nNo modelo [ESCOLHIDO]:\nEfeito de Grupo: - O grupo que recebeu droga apresentou [maior/menor] pulso comparado ao placebo (β = X.XX, EP = Y.YY, p = Z.ZZ)\nEfeito de Tempo: - Observou-se [aumento/redução/estabilidade] no pulso ao longo do tempo (β_Tempo2 = X.XX, p = Y.YY; β_Tempo3 = A.AA, p = B.BB)\nInteração Grupo × Tempo: - [Houve/Não houve] interação significativa, indicando que [INTERPRETAÇÃO]\nMédias Estimadas\nAs médias marginais estimadas revelaram que: - No Tempo 1: Droga M = X.X (IC95% Y.Y-Z.Z), Placebo M = A.A (IC95% B.B-C.C) - No Tempo 2: [continuar…] - No Tempo 3: [continuar…]\nConclusão\n[Resumo dos achados principais e implicações]\n\n🎯 Desafio: Análise da Variável “Resp”\n\n\n\n\n\n\nSua Vez!\n\n\n\nAgora replique todas as análises para a variável “resp” (respiração):\nChecklist: - [ ] Modelo GEE com distribuição Normal - [ ] Modelo GEE com distribuição Gamma - [ ] Modelo GLM com distribuição Tweedie - [ ] Diagnósticos de cada modelo - [ ] Visualizações com ggplot2 - [ ] Comparação via QIC - [ ] Interpretação dos resultados - [ ] Redação científica dos achados\n\n\n\n\n\n\n\n\n💡 Dica Importante\n\n\n\nNão faça apenas copy/paste!\n\nDigite os códigos para treinar sintaxe\nRenomeie variáveis apropriadamente:\n\nmodelo_gee_pulse_normal → modelo_gee_resp_normal\nmeans_ci_normal → means_ci_resp_normal\n\nAjuste labels nos gráficos (Pulse → Resp)\nCompare seus resultados com a aula prática\nReflita sobre diferenças entre as variáveis\n\n\n\n\n\n\n📚 Material Complementar\n\nAula em Vídeo (SPSS)\n\n\n\n\nAprofundamento Teórico\n\n\n\n\n\n\n📖 Entendendo Distribuições\n\n\n\n\n\nNormal (Gaussian): - Clássica, simétrica, bem conhecida - Assume variância constante - Adequada para muitas variáveis contínuas\nGamma: - Assimétrica à direita - Variância aumenta com a média - Ideal para tempos, concentrações\nTweedie: - Família flexível entre Poisson e Gamma - var.power controla forma: - 0: Normal - 1: Poisson\n- 2: Gamma - 1 &lt; p &lt; 2: Distribuições compostas - Útil para dados com zeros\nComo escolher? 1. Examine distribuição dos dados (histogramas) 2. Considere natureza da variável (positiva? contínua?) 3. Teste múltiplas e compare QIC 4. Verifique pressupostos (diagnósticos)\n\n\n\n\n\n\nEstruturas de Correlação GEE\n\n\n\n\n\n\n🔗 Tipos de corstr\n\n\n\n\n\nIndependence: - Assume observações independentes - Mais simples, menos realista\nExchangeable: - Correlação constante entre momentos - Assume simetria composta\nAR(1) - Autorregressiva: - Correlação diminui com distância temporal - Adequada para séries temporais\nUnstructured: - Sem restrições, mais flexível - Estima todas as correlações - Requer mais dados\nComo escolher? - Depende da estrutura temporal - unstructured é mais flexível mas menos eficiente - AR(1) para medições igualmente espaçadas - Teste e compare resultados\n\n\n\n\n\n\n\n🔧 Informações de Sessão\n\nreport(sessionInfo())\n\nAnalyses were conducted using the R Statistical language (version 4.4.2; R Core\nTeam, 2024) on Windows 11 x64 (build 26100), using the packages lme4 (version\n1.1.37; Bates D et al., 2015), Matrix (version 1.7.1; Bates D et al., 2024),\neffectsize (version 1.0.1; Ben-Shachar MS et al., 2020), gee (version 4.13.29;\nCarey VJ, 2024), statmod (version 1.5.1; Chen Y et al., 2025), fitdistrplus\n(version 1.2.2; Delignette-Muller ML, Dutang C, 2015), tweedie (version 2.3.5;\nDunn PK, Smyth GK, 2005), flexplot (version 0.24.3; Fife, D, 2022), effects\n(version 4.2.4; Fox J, Weisberg S, 2019), car (version 3.1.3; Fox J, Weisberg\nS, 2019), carData (version 3.0.5; Fox J et al., 2022), mvtnorm (version 1.3.3;\nGenz A, Bretz F, 2009), geepack (version 1.3.13; Halekoh U et al., 2006),\nTH.data (version 1.1.3; Hothorn T, 2025), multcomp (version 1.4.28; Hothorn T\net al., 2008), rstatix (version 0.7.2; Kassambara A, 2023), emmeans (version\n1.11.0; Lenth R, 2025), sjstats (version 0.19.1; Lüdecke D, 2025), parameters\n(version 0.28.3; Lüdecke D et al., 2020), performance (version 0.15.2; Lüdecke\nD et al., 2021), easystats (version 0.7.5; Lüdecke D et al., 2022), see\n(version 0.12.0; Lüdecke D et al., 2021), insight (version 1.4.4; Lüdecke D et\nal., 2019), bayestestR (version 0.17.0; Makowski D et al., 2019), modelbased\n(version 0.13.1; Makowski D et al., 2025), report (version 0.6.3; Makowski D et\nal., 2023), correlation (version 0.8.8; Makowski D et al., 2022), datawizard\n(version 1.3.0; Patil I et al., 2022), nlme (version 3.1.166; Pinheiro J et\nal., 2024), foreign (version 0.8.87; R Core Team, 2024), GGally (version 2.2.1;\nSchloerke B et al., 2024), rempsyc (version 0.2.0; Thériault R, 2023), survival\n(version 3.7.0; Therneau T, 2024), MASS (version 7.3.61; Venables WN, Ripley\nBD, 2002), ggplot2 (version 4.0.1; Wickham H, 2016), dplyr (version 1.1.4;\nWickham H et al., 2023) and tidyr (version 1.3.1; Wickham H et al., 2024).\n\nReferences\n----------\n  - Bates D, Mächler M, Bolker B, Walker S (2015). \"Fitting Linear Mixed-Effects\nModels Using lme4.\" _Journal of Statistical Software_, *67*(1), 1-48.\ndoi:10.18637/jss.v067.i01 &lt;https://doi.org/10.18637/jss.v067.i01&gt;.\n  - Bates D, Maechler M, Jagan M (2024). _Matrix: Sparse and Dense Matrix Classes\nand Methods_. R package version 1.7-1,\n&lt;https://CRAN.R-project.org/package=Matrix&gt;.\n  - Ben-Shachar MS, Lüdecke D, Makowski D (2020). \"effectsize: Estimation of\nEffect Size Indices and Standardized Parameters.\" _Journal of Open Source\nSoftware_, *5*(56), 2815. doi:10.21105/joss.02815\n&lt;https://doi.org/10.21105/joss.02815&gt;, &lt;https://doi.org/10.21105/joss.02815&gt;.\n  - Carey VJ (2024). _gee: Generalized Estimation Equation Solver_. R package\nversion 4.13-29, &lt;https://CRAN.R-project.org/package=gee&gt;.\n  - Chen Y, Chen L, Lun ATL, Baldoni P, Smyth GK (2025). \"edgeR v4: powerful\ndifferential analysis of sequencing data with expanded functionality and\nimproved support for small counts and larger datasets.\" _Nucleic Acids\nResearch_, *53*(2), gkaf018. doi:10.1093/nar/gkaf018\n&lt;https://doi.org/10.1093/nar/gkaf018&gt;. Dunn PK, Smyth GK (1996). \"Randomized\nquantile residuals.\" _J. Comput. Graph. Statist_, *5*, 236-244. Giner G, Smyth\nGK (2016). \"statmod: probability calculations for the inverse Gaussian\ndistribution.\" _R Journal_, *8*(1), 339-351. Hu Y, Smyth GK (2009). \"ELDA:\nextreme limiting dilution analysis for comparing depleted and enriched\npopulations in stem cell and other assays.\" _Journal of Immunological Methods_,\n*347*(1), 70-78. Phipson B, Smyth GK (2010). \"Permutation p-values should never\nbe zero: calculating exact p-values when permutations are randomly drawn.\"\n_Statistical Applications in Genetics and Molecular Biology_, *9*(1), Article\n39. Smyth GK (2005). \"Numerical integration.\" _Encyclopedia of Biostatistics_,\n3088-3095. Smyth GK (2005). \"Optimization and nonlinear equations.\"\n_Encyclopedia of Biostatistics_, 3088-3095. Smyth GK (2002). \"An efficient\nalgorithm for REML in heteroscedastic regression.\" _Journal of Computational\nand Graphical Statistics_, *11*, 836-847.\n  - Delignette-Muller ML, Dutang C (2015). \"fitdistrplus: An R Package for\nFitting Distributions.\" _Journal of Statistical Software_, *64*(4), 1-34.\ndoi:10.18637/jss.v064.i04 &lt;https://doi.org/10.18637/jss.v064.i04&gt;.\n  - Dunn PK, Smyth GK (2005). \"Series evaluation of Tweedie exponential\ndispersion models.\" _Statistics and Computing_, *15*(4), 267-280. Dunn PK,\nSmyth GK (2008). \"Evaluation of Tweedie exponential dispersion models using\nFourier inversion.\" _Statistics and Computing_, *18*(1), 73-86. Dunn PK (2022).\n_Tweedie: Evaluation of Tweedie Exponential Family Models_. R package version\n2.3.5.\n  - Fife, A. D (2022). \"Flexplot: Graphically-based data analysis.\"\n_Psychological Methods_, *27*(4), -19. &lt;doi.org/10.1037/met0000424&gt;.\n  - Fox J, Weisberg S (2019). _An R Companion to Applied Regression_, 3rd\nedition. Sage, Thousand Oaks CA.\n&lt;https://www.john-fox.ca/Companion/index.html&gt;. Fox J, Weisberg S (2018).\n\"Visualizing Fit and Lack of Fit in Complex Regression Models with Predictor\nEffect Plots and Partial Residuals.\" _Journal of Statistical Software_,\n*87*(9), 1-27. doi:10.18637/jss.v087.i09\n&lt;https://doi.org/10.18637/jss.v087.i09&gt;. Fox J (2003). \"Effect Displays in R\nfor Generalised Linear Models.\" _Journal of Statistical Software_, *8*(15),\n1-27. doi:10.18637/jss.v008.i15 &lt;https://doi.org/10.18637/jss.v008.i15&gt;. Fox J,\nHong J (2009). \"Effect Displays in R for Multinomial and Proportional-Odds\nLogit Models: Extensions to the effects Package.\" _Journal of Statistical\nSoftware_, *32*(1), 1-24. doi:10.18637/jss.v032.i01\n&lt;https://doi.org/10.18637/jss.v032.i01&gt;.\n  - Fox J, Weisberg S (2019). _An R Companion to Applied Regression_, Third\nedition. Sage, Thousand Oaks CA. &lt;https://www.john-fox.ca/Companion/&gt;.\n  - Fox J, Weisberg S, Price B (2022). _carData: Companion to Applied Regression\nData Sets_. R package version 3.0-5,\n&lt;https://CRAN.R-project.org/package=carData&gt;.\n  - Genz A, Bretz F (2009). _Computation of Multivariate Normal and t\nProbabilities_, series Lecture Notes in Statistics. Springer-Verlag,\nHeidelberg. ISBN 978-3-642-01688-2.\n  - Halekoh U, Højsgaard S, Yan J (2006). \"The R Package geepack for Generalized\nEstimating Equations.\" _Journal of Statistical Software_, *15/2*, 1-11. Yan J,\nFine JP (2004). \"Estimating Equations for Association Structures.\" _Statistics\nin Medicine_, *23*, 859-880. Yan J (2002). \"geepack: Yet Another Package for\nGeneralized Estimating Equations.\" _R-News_, *2/3*, 12-14. Xu, Z., Fine, P. J,\nSong, W., Yan, J. (2025). \"On GEE for mean-variance-correlation models:\nVariance estimation and model selection.\" _Statistics in Medicine_, *44*, 1-2.\n  - Hothorn T (2025). _TH.data: TH's Data Archive_. R package version 1.1-3,\n&lt;https://CRAN.R-project.org/package=TH.data&gt;.\n  - Hothorn T, Bretz F, Westfall P (2008). \"Simultaneous Inference in General\nParametric Models.\" _Biometrical Journal_, *50*(3), 346-363.\n  - Kassambara A (2023). _rstatix: Pipe-Friendly Framework for Basic Statistical\nTests_. R package version 0.7.2, &lt;https://CRAN.R-project.org/package=rstatix&gt;.\n  - Lenth R (2025). _emmeans: Estimated Marginal Means, aka Least-Squares Means_.\nR package version 1.11.0, &lt;https://CRAN.R-project.org/package=emmeans&gt;.\n  - Lüdecke D (2025). _sjstats: Statistical Functions for Regression Models\n(Version 0.19.1)_. doi:10.5281/zenodo.1284472\n&lt;https://doi.org/10.5281/zenodo.1284472&gt;,\n&lt;https://CRAN.R-project.org/package=sjstats&gt;.\n  - Lüdecke D, Ben-Shachar M, Patil I, Makowski D (2020). \"Extracting, Computing\nand Exploring the Parameters of Statistical Models using R.\" _Journal of Open\nSource Software_, *5*(53), 2445. doi:10.21105/joss.02445\n&lt;https://doi.org/10.21105/joss.02445&gt;.\n  - Lüdecke D, Ben-Shachar M, Patil I, Waggoner P, Makowski D (2021).\n\"performance: An R Package for Assessment, Comparison and Testing of\nStatistical Models.\" _Journal of Open Source Software_, *6*(60), 3139.\ndoi:10.21105/joss.03139 &lt;https://doi.org/10.21105/joss.03139&gt;.\n  - Lüdecke D, Ben-Shachar M, Patil I, Wiernik B, Bacher E, Thériault R, Makowski\nD (2022). \"easystats: Framework for Easy Statistical Modeling, Visualization,\nand Reporting.\" _CRAN_. doi:10.32614/CRAN.package.easystats\n&lt;https://doi.org/10.32614/CRAN.package.easystats&gt;, R package,\n&lt;https://easystats.github.io/easystats/&gt;.\n  - Lüdecke D, Patil I, Ben-Shachar M, Wiernik B, Waggoner P, Makowski D (2021).\n\"see: An R Package for Visualizing Statistical Models.\" _Journal of Open Source\nSoftware_, *6*(64), 3393. doi:10.21105/joss.03393\n&lt;https://doi.org/10.21105/joss.03393&gt;.\n  - Lüdecke D, Waggoner P, Makowski D (2019). \"insight: A Unified Interface to\nAccess Information from Model Objects in R.\" _Journal of Open Source Software_,\n*4*(38), 1412. doi:10.21105/joss.01412 &lt;https://doi.org/10.21105/joss.01412&gt;.\n  - Makowski D, Ben-Shachar M, Lüdecke D (2019). \"bayestestR: Describing Effects\nand their Uncertainty, Existence and Significance within the Bayesian\nFramework.\" _Journal of Open Source Software_, *4*(40), 1541.\ndoi:10.21105/joss.01541 &lt;https://doi.org/10.21105/joss.01541&gt;,\n&lt;https://joss.theoj.org/papers/10.21105/joss.01541&gt;.\n  - Makowski D, Ben-Shachar M, Wiernik B, Patil I, Thériault R, Lüdecke D (2025).\n\"modelbased: An R package to make the most out of your statistical models\nthrough marginal means, marginal effects, and model predictions.\" _Journal of\nOpen Source Software_, *10*(109), 7969. doi:10.21105/joss.07969\n&lt;https://doi.org/10.21105/joss.07969&gt;,\n&lt;https://joss.theoj.org/papers/10.21105/joss.07969&gt;.\n  - Makowski D, Lüdecke D, Patil I, Thériault R, Ben-Shachar M, Wiernik B (2023).\n\"Automated Results Reporting as a Practical Tool to Improve Reproducibility and\nMethodological Best Practices Adoption.\" _CRAN_.\ndoi:10.32614/CRAN.package.report\n&lt;https://doi.org/10.32614/CRAN.package.report&gt;,\n&lt;https://easystats.github.io/report/&gt;.\n  - Makowski D, Wiernik B, Patil I, Lüdecke D, Ben-Shachar M (2022).\n\"correlation: Methods for Correlation Analysis.\" Version 0.8.3,\n&lt;https://CRAN.R-project.org/package=correlation&gt;. Makowski D, Ben-Shachar M,\nPatil I, Lüdecke D (2020). \"Methods and Algorithms for Correlation Analysis in\nR.\" _Journal of Open Source Software_, *5*(51), 2306. doi:10.21105/joss.02306\n&lt;https://doi.org/10.21105/joss.02306&gt;,\n&lt;https://joss.theoj.org/papers/10.21105/joss.02306&gt;.\n  - Patil I, Makowski D, Ben-Shachar M, Wiernik B, Bacher E, Lüdecke D (2022).\n\"datawizard: An R Package for Easy Data Preparation and Statistical\nTransformations.\" _Journal of Open Source Software_, *7*(78), 4684.\ndoi:10.21105/joss.04684 &lt;https://doi.org/10.21105/joss.04684&gt;.\n  - Pinheiro J, Bates D, R Core Team (2024). _nlme: Linear and Nonlinear Mixed\nEffects Models_. R package version 3.1-166,\n&lt;https://CRAN.R-project.org/package=nlme&gt;. Pinheiro JC, Bates DM (2000).\n_Mixed-Effects Models in S and S-PLUS_. Springer, New York. doi:10.1007/b98882\n&lt;https://doi.org/10.1007/b98882&gt;.\n  - R Core Team (2024). _foreign: Read Data Stored by 'Minitab', 'S', 'SAS',\n'SPSS', 'Stata', 'Systat', 'Weka', 'dBase', ..._. R package version 0.8-87,\n&lt;https://CRAN.R-project.org/package=foreign&gt;.\n  - R Core Team (2024). _R: A Language and Environment for Statistical\nComputing_. R Foundation for Statistical Computing, Vienna, Austria.\n&lt;https://www.R-project.org/&gt;.\n  - Schloerke B, Cook D, Larmarange J, Briatte F, Marbach M, Thoen E, Elberg A,\nCrowley J (2024). _GGally: Extension to 'ggplot2'_. R package version 2.2.1,\n&lt;https://CRAN.R-project.org/package=GGally&gt;.\n  - Thériault R (2023). \"rempsyc: Convenience functions for psychology.\" _Journal\nof Open Source Software_, *8*(87), 5466. doi:10.21105/joss.05466\n&lt;https://doi.org/10.21105/joss.05466&gt;, &lt;https://doi.org/10.21105/joss.05466&gt;.\n  - Therneau T (2024). _A Package for Survival Analysis in R_. R package version\n3.7-0, &lt;https://CRAN.R-project.org/package=survival&gt;. Terry M. Therneau,\nPatricia M. Grambsch (2000). _Modeling Survival Data: Extending the Cox Model_.\nSpringer, New York. ISBN 0-387-98784-3.\n  - Venables WN, Ripley BD (2002). _Modern Applied Statistics with S_, Fourth\nedition. Springer, New York. ISBN 0-387-95457-0,\n&lt;https://www.stats.ox.ac.uk/pub/MASS4/&gt;.\n  - Wickham H (2016). _ggplot2: Elegant Graphics for Data Analysis_.\nSpringer-Verlag New York. ISBN 978-3-319-24277-4,\n&lt;https://ggplot2.tidyverse.org&gt;.\n  - Wickham H, François R, Henry L, Müller K, Vaughan D (2023). _dplyr: A Grammar\nof Data Manipulation_. R package version 1.1.4,\n&lt;https://CRAN.R-project.org/package=dplyr&gt;.\n  - Wickham H, Vaughan D, Girlich M (2024). _tidyr: Tidy Messy Data_. R package\nversion 1.3.1, &lt;https://CRAN.R-project.org/package=tidyr&gt;.\n\n\n\n\n\n\n\n\n\n🎓 Resumo da Lista 2\n\n\n\nNesta lista você:\n✅ Ajustou modelos GEE com três distribuições diferentes\n✅ Aprendeu a comparar modelos via QIC\n✅ Criou visualizações profissionais com ggplot2\n✅ Interpretou diagnósticos de modelos complexos\n✅ Praticou redação científica de resultados\nPróximos passos: - Complete análises para variável “resp” - Compare resultados entre pulse e resp - Reflita sobre qual distribuição é mais adequada - Prepare-se para Lista 3: Modelos Mistos!",
    "crumbs": [
      "Modelos Lineares",
      "Lista 2: GEE Avançado"
    ]
  },
  {
    "objectID": "lista_2.html#desafio-análise-da-variável-resp",
    "href": "lista_2.html#desafio-análise-da-variável-resp",
    "title": "Lista 2: GEE Avançado",
    "section": "🎯 Desafio: Análise da Variável “Resp”",
    "text": "🎯 Desafio: Análise da Variável “Resp”\n\n\n\n\n\n\nSua Vez!\n\n\n\nAgora replique todas as análises para a variável “resp” (respiração):\nChecklist: - [ ] Modelo GEE com distribuição Normal - [ ] Modelo GEE com distribuição Gamma - [ ] Modelo GLM com distribuição Tweedie - [ ] Diagnósticos de cada modelo - [ ] Visualizações com ggplot2 - [ ] Comparação via QIC - [ ] Interpretação dos resultados - [ ] Redação científica dos achados\n\n\n\n\n\n\n\n\n💡 Dica Importante\n\n\n\nNão faça apenas copy/paste!\n\nDigite os códigos para treinar sintaxe\nRenomeie variáveis apropriadamente:\n\nmodelo_gee_pulse_normal → modelo_gee_resp_normal\nmeans_ci_normal → means_ci_resp_normal\n\nAjuste labels nos gráficos (Pulse → Resp)\nCompare seus resultados com a aula prática\nReflita sobre diferenças entre as variáveis",
    "crumbs": [
      "Modelos Lineares",
      "Lista 2: GEE Avançado"
    ]
  },
  {
    "objectID": "lista_2.html#material-complementar",
    "href": "lista_2.html#material-complementar",
    "title": "Lista 2: GEE Avançado",
    "section": "📚 Material Complementar",
    "text": "📚 Material Complementar\n\nAula em Vídeo (SPSS)\n\n\n\n\nAprofundamento Teórico\n\n\n\n\n\n\n📖 Entendendo Distribuições\n\n\n\n\n\nNormal (Gaussian): - Clássica, simétrica, bem conhecida - Assume variância constante - Adequada para muitas variáveis contínuas\nGamma: - Assimétrica à direita - Variância aumenta com a média - Ideal para tempos, concentrações\nTweedie: - Família flexível entre Poisson e Gamma - var.power controla forma: - 0: Normal - 1: Poisson\n- 2: Gamma - 1 &lt; p &lt; 2: Distribuições compostas - Útil para dados com zeros\nComo escolher? 1. Examine distribuição dos dados (histogramas) 2. Considere natureza da variável (positiva? contínua?) 3. Teste múltiplas e compare QIC 4. Verifique pressupostos (diagnósticos)\n\n\n\n\n\n\nEstruturas de Correlação GEE\n\n\n\n\n\n\n🔗 Tipos de corstr\n\n\n\n\n\nIndependence: - Assume observações independentes - Mais simples, menos realista\nExchangeable: - Correlação constante entre momentos - Assume simetria composta\nAR(1) - Autorregressiva: - Correlação diminui com distância temporal - Adequada para séries temporais\nUnstructured: - Sem restrições, mais flexível - Estima todas as correlações - Requer mais dados\nComo escolher? - Depende da estrutura temporal - unstructured é mais flexível mas menos eficiente - AR(1) para medições igualmente espaçadas - Teste e compare resultados",
    "crumbs": [
      "Modelos Lineares",
      "Lista 2: GEE Avançado"
    ]
  },
  {
    "objectID": "lista_2.html#informações-de-sessão",
    "href": "lista_2.html#informações-de-sessão",
    "title": "Lista 2: GEE Avançado",
    "section": "🔧 Informações de Sessão",
    "text": "🔧 Informações de Sessão\n\nreport(sessionInfo())\n\nAnalyses were conducted using the R Statistical language (version 4.4.2; R Core\nTeam, 2024) on Windows 11 x64 (build 26100), using the packages lme4 (version\n1.1.37; Bates D et al., 2015), Matrix (version 1.7.1; Bates D et al., 2024),\neffectsize (version 1.0.1; Ben-Shachar MS et al., 2020), gee (version 4.13.29;\nCarey VJ, 2024), statmod (version 1.5.1; Chen Y et al., 2025), fitdistrplus\n(version 1.2.2; Delignette-Muller ML, Dutang C, 2015), tweedie (version 2.3.5;\nDunn PK, Smyth GK, 2005), flexplot (version 0.24.3; Fife, D, 2022), effects\n(version 4.2.4; Fox J, Weisberg S, 2019), car (version 3.1.3; Fox J, Weisberg\nS, 2019), carData (version 3.0.5; Fox J et al., 2022), mvtnorm (version 1.3.3;\nGenz A, Bretz F, 2009), geepack (version 1.3.13; Halekoh U et al., 2006),\nTH.data (version 1.1.3; Hothorn T, 2025), multcomp (version 1.4.28; Hothorn T\net al., 2008), rstatix (version 0.7.2; Kassambara A, 2023), emmeans (version\n1.11.0; Lenth R, 2025), sjstats (version 0.19.1; Lüdecke D, 2025), parameters\n(version 0.28.3; Lüdecke D et al., 2020), performance (version 0.15.2; Lüdecke\nD et al., 2021), easystats (version 0.7.5; Lüdecke D et al., 2022), see\n(version 0.12.0; Lüdecke D et al., 2021), insight (version 1.4.4; Lüdecke D et\nal., 2019), bayestestR (version 0.17.0; Makowski D et al., 2019), modelbased\n(version 0.13.1; Makowski D et al., 2025), report (version 0.6.3; Makowski D et\nal., 2023), correlation (version 0.8.8; Makowski D et al., 2022), datawizard\n(version 1.3.0; Patil I et al., 2022), nlme (version 3.1.166; Pinheiro J et\nal., 2024), foreign (version 0.8.87; R Core Team, 2024), GGally (version 2.2.1;\nSchloerke B et al., 2024), rempsyc (version 0.2.0; Thériault R, 2023), survival\n(version 3.7.0; Therneau T, 2024), MASS (version 7.3.61; Venables WN, Ripley\nBD, 2002), ggplot2 (version 4.0.1; Wickham H, 2016), dplyr (version 1.1.4;\nWickham H et al., 2023) and tidyr (version 1.3.1; Wickham H et al., 2024).\n\nReferences\n----------\n  - Bates D, Mächler M, Bolker B, Walker S (2015). \"Fitting Linear Mixed-Effects\nModels Using lme4.\" _Journal of Statistical Software_, *67*(1), 1-48.\ndoi:10.18637/jss.v067.i01 &lt;https://doi.org/10.18637/jss.v067.i01&gt;.\n  - Bates D, Maechler M, Jagan M (2024). _Matrix: Sparse and Dense Matrix Classes\nand Methods_. R package version 1.7-1,\n&lt;https://CRAN.R-project.org/package=Matrix&gt;.\n  - Ben-Shachar MS, Lüdecke D, Makowski D (2020). \"effectsize: Estimation of\nEffect Size Indices and Standardized Parameters.\" _Journal of Open Source\nSoftware_, *5*(56), 2815. doi:10.21105/joss.02815\n&lt;https://doi.org/10.21105/joss.02815&gt;, &lt;https://doi.org/10.21105/joss.02815&gt;.\n  - Carey VJ (2024). _gee: Generalized Estimation Equation Solver_. R package\nversion 4.13-29, &lt;https://CRAN.R-project.org/package=gee&gt;.\n  - Chen Y, Chen L, Lun ATL, Baldoni P, Smyth GK (2025). \"edgeR v4: powerful\ndifferential analysis of sequencing data with expanded functionality and\nimproved support for small counts and larger datasets.\" _Nucleic Acids\nResearch_, *53*(2), gkaf018. doi:10.1093/nar/gkaf018\n&lt;https://doi.org/10.1093/nar/gkaf018&gt;. Dunn PK, Smyth GK (1996). \"Randomized\nquantile residuals.\" _J. Comput. Graph. Statist_, *5*, 236-244. Giner G, Smyth\nGK (2016). \"statmod: probability calculations for the inverse Gaussian\ndistribution.\" _R Journal_, *8*(1), 339-351. Hu Y, Smyth GK (2009). \"ELDA:\nextreme limiting dilution analysis for comparing depleted and enriched\npopulations in stem cell and other assays.\" _Journal of Immunological Methods_,\n*347*(1), 70-78. Phipson B, Smyth GK (2010). \"Permutation p-values should never\nbe zero: calculating exact p-values when permutations are randomly drawn.\"\n_Statistical Applications in Genetics and Molecular Biology_, *9*(1), Article\n39. Smyth GK (2005). \"Numerical integration.\" _Encyclopedia of Biostatistics_,\n3088-3095. Smyth GK (2005). \"Optimization and nonlinear equations.\"\n_Encyclopedia of Biostatistics_, 3088-3095. Smyth GK (2002). \"An efficient\nalgorithm for REML in heteroscedastic regression.\" _Journal of Computational\nand Graphical Statistics_, *11*, 836-847.\n  - Delignette-Muller ML, Dutang C (2015). \"fitdistrplus: An R Package for\nFitting Distributions.\" _Journal of Statistical Software_, *64*(4), 1-34.\ndoi:10.18637/jss.v064.i04 &lt;https://doi.org/10.18637/jss.v064.i04&gt;.\n  - Dunn PK, Smyth GK (2005). \"Series evaluation of Tweedie exponential\ndispersion models.\" _Statistics and Computing_, *15*(4), 267-280. Dunn PK,\nSmyth GK (2008). \"Evaluation of Tweedie exponential dispersion models using\nFourier inversion.\" _Statistics and Computing_, *18*(1), 73-86. Dunn PK (2022).\n_Tweedie: Evaluation of Tweedie Exponential Family Models_. R package version\n2.3.5.\n  - Fife, A. D (2022). \"Flexplot: Graphically-based data analysis.\"\n_Psychological Methods_, *27*(4), -19. &lt;doi.org/10.1037/met0000424&gt;.\n  - Fox J, Weisberg S (2019). _An R Companion to Applied Regression_, 3rd\nedition. Sage, Thousand Oaks CA.\n&lt;https://www.john-fox.ca/Companion/index.html&gt;. Fox J, Weisberg S (2018).\n\"Visualizing Fit and Lack of Fit in Complex Regression Models with Predictor\nEffect Plots and Partial Residuals.\" _Journal of Statistical Software_,\n*87*(9), 1-27. doi:10.18637/jss.v087.i09\n&lt;https://doi.org/10.18637/jss.v087.i09&gt;. Fox J (2003). \"Effect Displays in R\nfor Generalised Linear Models.\" _Journal of Statistical Software_, *8*(15),\n1-27. doi:10.18637/jss.v008.i15 &lt;https://doi.org/10.18637/jss.v008.i15&gt;. Fox J,\nHong J (2009). \"Effect Displays in R for Multinomial and Proportional-Odds\nLogit Models: Extensions to the effects Package.\" _Journal of Statistical\nSoftware_, *32*(1), 1-24. doi:10.18637/jss.v032.i01\n&lt;https://doi.org/10.18637/jss.v032.i01&gt;.\n  - Fox J, Weisberg S (2019). _An R Companion to Applied Regression_, Third\nedition. Sage, Thousand Oaks CA. &lt;https://www.john-fox.ca/Companion/&gt;.\n  - Fox J, Weisberg S, Price B (2022). _carData: Companion to Applied Regression\nData Sets_. R package version 3.0-5,\n&lt;https://CRAN.R-project.org/package=carData&gt;.\n  - Genz A, Bretz F (2009). _Computation of Multivariate Normal and t\nProbabilities_, series Lecture Notes in Statistics. Springer-Verlag,\nHeidelberg. ISBN 978-3-642-01688-2.\n  - Halekoh U, Højsgaard S, Yan J (2006). \"The R Package geepack for Generalized\nEstimating Equations.\" _Journal of Statistical Software_, *15/2*, 1-11. Yan J,\nFine JP (2004). \"Estimating Equations for Association Structures.\" _Statistics\nin Medicine_, *23*, 859-880. Yan J (2002). \"geepack: Yet Another Package for\nGeneralized Estimating Equations.\" _R-News_, *2/3*, 12-14. Xu, Z., Fine, P. J,\nSong, W., Yan, J. (2025). \"On GEE for mean-variance-correlation models:\nVariance estimation and model selection.\" _Statistics in Medicine_, *44*, 1-2.\n  - Hothorn T (2025). _TH.data: TH's Data Archive_. R package version 1.1-3,\n&lt;https://CRAN.R-project.org/package=TH.data&gt;.\n  - Hothorn T, Bretz F, Westfall P (2008). \"Simultaneous Inference in General\nParametric Models.\" _Biometrical Journal_, *50*(3), 346-363.\n  - Kassambara A (2023). _rstatix: Pipe-Friendly Framework for Basic Statistical\nTests_. R package version 0.7.2, &lt;https://CRAN.R-project.org/package=rstatix&gt;.\n  - Lenth R (2025). _emmeans: Estimated Marginal Means, aka Least-Squares Means_.\nR package version 1.11.0, &lt;https://CRAN.R-project.org/package=emmeans&gt;.\n  - Lüdecke D (2025). _sjstats: Statistical Functions for Regression Models\n(Version 0.19.1)_. doi:10.5281/zenodo.1284472\n&lt;https://doi.org/10.5281/zenodo.1284472&gt;,\n&lt;https://CRAN.R-project.org/package=sjstats&gt;.\n  - Lüdecke D, Ben-Shachar M, Patil I, Makowski D (2020). \"Extracting, Computing\nand Exploring the Parameters of Statistical Models using R.\" _Journal of Open\nSource Software_, *5*(53), 2445. doi:10.21105/joss.02445\n&lt;https://doi.org/10.21105/joss.02445&gt;.\n  - Lüdecke D, Ben-Shachar M, Patil I, Waggoner P, Makowski D (2021).\n\"performance: An R Package for Assessment, Comparison and Testing of\nStatistical Models.\" _Journal of Open Source Software_, *6*(60), 3139.\ndoi:10.21105/joss.03139 &lt;https://doi.org/10.21105/joss.03139&gt;.\n  - Lüdecke D, Ben-Shachar M, Patil I, Wiernik B, Bacher E, Thériault R, Makowski\nD (2022). \"easystats: Framework for Easy Statistical Modeling, Visualization,\nand Reporting.\" _CRAN_. doi:10.32614/CRAN.package.easystats\n&lt;https://doi.org/10.32614/CRAN.package.easystats&gt;, R package,\n&lt;https://easystats.github.io/easystats/&gt;.\n  - Lüdecke D, Patil I, Ben-Shachar M, Wiernik B, Waggoner P, Makowski D (2021).\n\"see: An R Package for Visualizing Statistical Models.\" _Journal of Open Source\nSoftware_, *6*(64), 3393. doi:10.21105/joss.03393\n&lt;https://doi.org/10.21105/joss.03393&gt;.\n  - Lüdecke D, Waggoner P, Makowski D (2019). \"insight: A Unified Interface to\nAccess Information from Model Objects in R.\" _Journal of Open Source Software_,\n*4*(38), 1412. doi:10.21105/joss.01412 &lt;https://doi.org/10.21105/joss.01412&gt;.\n  - Makowski D, Ben-Shachar M, Lüdecke D (2019). \"bayestestR: Describing Effects\nand their Uncertainty, Existence and Significance within the Bayesian\nFramework.\" _Journal of Open Source Software_, *4*(40), 1541.\ndoi:10.21105/joss.01541 &lt;https://doi.org/10.21105/joss.01541&gt;,\n&lt;https://joss.theoj.org/papers/10.21105/joss.01541&gt;.\n  - Makowski D, Ben-Shachar M, Wiernik B, Patil I, Thériault R, Lüdecke D (2025).\n\"modelbased: An R package to make the most out of your statistical models\nthrough marginal means, marginal effects, and model predictions.\" _Journal of\nOpen Source Software_, *10*(109), 7969. doi:10.21105/joss.07969\n&lt;https://doi.org/10.21105/joss.07969&gt;,\n&lt;https://joss.theoj.org/papers/10.21105/joss.07969&gt;.\n  - Makowski D, Lüdecke D, Patil I, Thériault R, Ben-Shachar M, Wiernik B (2023).\n\"Automated Results Reporting as a Practical Tool to Improve Reproducibility and\nMethodological Best Practices Adoption.\" _CRAN_.\ndoi:10.32614/CRAN.package.report\n&lt;https://doi.org/10.32614/CRAN.package.report&gt;,\n&lt;https://easystats.github.io/report/&gt;.\n  - Makowski D, Wiernik B, Patil I, Lüdecke D, Ben-Shachar M (2022).\n\"correlation: Methods for Correlation Analysis.\" Version 0.8.3,\n&lt;https://CRAN.R-project.org/package=correlation&gt;. Makowski D, Ben-Shachar M,\nPatil I, Lüdecke D (2020). \"Methods and Algorithms for Correlation Analysis in\nR.\" _Journal of Open Source Software_, *5*(51), 2306. doi:10.21105/joss.02306\n&lt;https://doi.org/10.21105/joss.02306&gt;,\n&lt;https://joss.theoj.org/papers/10.21105/joss.02306&gt;.\n  - Patil I, Makowski D, Ben-Shachar M, Wiernik B, Bacher E, Lüdecke D (2022).\n\"datawizard: An R Package for Easy Data Preparation and Statistical\nTransformations.\" _Journal of Open Source Software_, *7*(78), 4684.\ndoi:10.21105/joss.04684 &lt;https://doi.org/10.21105/joss.04684&gt;.\n  - Pinheiro J, Bates D, R Core Team (2024). _nlme: Linear and Nonlinear Mixed\nEffects Models_. R package version 3.1-166,\n&lt;https://CRAN.R-project.org/package=nlme&gt;. Pinheiro JC, Bates DM (2000).\n_Mixed-Effects Models in S and S-PLUS_. Springer, New York. doi:10.1007/b98882\n&lt;https://doi.org/10.1007/b98882&gt;.\n  - R Core Team (2024). _foreign: Read Data Stored by 'Minitab', 'S', 'SAS',\n'SPSS', 'Stata', 'Systat', 'Weka', 'dBase', ..._. R package version 0.8-87,\n&lt;https://CRAN.R-project.org/package=foreign&gt;.\n  - R Core Team (2024). _R: A Language and Environment for Statistical\nComputing_. R Foundation for Statistical Computing, Vienna, Austria.\n&lt;https://www.R-project.org/&gt;.\n  - Schloerke B, Cook D, Larmarange J, Briatte F, Marbach M, Thoen E, Elberg A,\nCrowley J (2024). _GGally: Extension to 'ggplot2'_. R package version 2.2.1,\n&lt;https://CRAN.R-project.org/package=GGally&gt;.\n  - Thériault R (2023). \"rempsyc: Convenience functions for psychology.\" _Journal\nof Open Source Software_, *8*(87), 5466. doi:10.21105/joss.05466\n&lt;https://doi.org/10.21105/joss.05466&gt;, &lt;https://doi.org/10.21105/joss.05466&gt;.\n  - Therneau T (2024). _A Package for Survival Analysis in R_. R package version\n3.7-0, &lt;https://CRAN.R-project.org/package=survival&gt;. Terry M. Therneau,\nPatricia M. Grambsch (2000). _Modeling Survival Data: Extending the Cox Model_.\nSpringer, New York. ISBN 0-387-98784-3.\n  - Venables WN, Ripley BD (2002). _Modern Applied Statistics with S_, Fourth\nedition. Springer, New York. ISBN 0-387-95457-0,\n&lt;https://www.stats.ox.ac.uk/pub/MASS4/&gt;.\n  - Wickham H (2016). _ggplot2: Elegant Graphics for Data Analysis_.\nSpringer-Verlag New York. ISBN 978-3-319-24277-4,\n&lt;https://ggplot2.tidyverse.org&gt;.\n  - Wickham H, François R, Henry L, Müller K, Vaughan D (2023). _dplyr: A Grammar\nof Data Manipulation_. R package version 1.1.4,\n&lt;https://CRAN.R-project.org/package=dplyr&gt;.\n  - Wickham H, Vaughan D, Girlich M (2024). _tidyr: Tidy Messy Data_. R package\nversion 1.3.1, &lt;https://CRAN.R-project.org/package=tidyr&gt;.\n\n\n\n\n\n\n\n\n\n🎓 Resumo da Lista 2\n\n\n\nNesta lista você:\n✅ Ajustou modelos GEE com três distribuições diferentes\n✅ Aprendeu a comparar modelos via QIC\n✅ Criou visualizações profissionais com ggplot2\n✅ Interpretou diagnósticos de modelos complexos\n✅ Praticou redação científica de resultados\nPróximos passos: - Complete análises para variável “resp” - Compare resultados entre pulse e resp - Reflita sobre qual distribuição é mais adequada - Prepare-se para Lista 3: Modelos Mistos!",
    "crumbs": [
      "Modelos Lineares",
      "Lista 2: GEE Avançado"
    ]
  }
]