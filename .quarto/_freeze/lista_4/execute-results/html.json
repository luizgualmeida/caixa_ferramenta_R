{
  "hash": "1ca9cbff4d5a9a478ba9729b74f18859",
  "result": {
    "markdown": "# Lista 4 - GMM e ICC\n\nPara resolver a lista de exercícios 4 vamos utilizar o [banco de dados THKS2](https://drive.google.com/file/d/1GVse4Sq6B66Cs9qeyA5BJwv2SxgYrip-/view?usp=sharing). O banco apresenta dados do programa \"Television, School and Family Smoking Prevention and Cessation Project (TVSFP)\", que avaliou a eficácia de um programa presencial para parar de fumar (Currículo) em conjunto com um programa em vídeo (TV) para prevenir o início do tabagismo e fortalecer a resiliência daqueles que deixaram de fumar.\n\nO estudo adotou um delineamento 2x2 com quatro grupos distintos, considerando a presença do \"school-based social-resistance curriculum (CC)\" e do \"television-based prevention program (TV)\". Esses grupos foram categorizados como \"Curriculum & TV\", \"Curriculum\", \"TV\" e \"Neither\". Este último indicando que as pessoas do grupo não participaram de nenhuma intervenção.\n\nA randomização da amostra ocorreu em dois níveis: por escolas e por salas de aula. O banco de dados inclui informações de 1600 alunos de 135 classes distintas em 28 escolas localizadas em Los Angeles. A variável dependente, a Escala de Conhecimento em Tabaco e Saúde (THKS), foi avaliada antes da randomização e após a implementação dos efeitos de cada grupo.\n\nCom base nestes dados, por favor, apresente as questões específicas e descreva os resultados utilizando as notações apropriadas.\n\n## Pacotes que vamos utilizar\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Seu código R aqui\nlibrary(emmeans)\nlibrary(lme4)\nlibrary(nlme)\nlibrary(flexplot)\nlibrary(foreign)\nlibrary(dplyr)\nlibrary(multcomp)\nlibrary(effects)\nlibrary(sjstats)\nlibrary(tm)\nlibrary(report)\nlibrary(ggplot2)\nlibrary(forcats)\nlibrary(performance)\nlibrary(rempsyc)\nlibrary(easystats)\nlibrary(fitdistrplus)\nlibrary(sjPlot)\nlibrary(kableExtra)\nlibrary(psychometric)\nlibrary(misty)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ndataset = read.spss(\"THKS2.sav\", to.data.frame=TRUE)\n```\n:::\n\n\nComo já mencionado no capítulo anterior, é muito importante averiguar os tipos de variáveis antes de começar as análises. Para isso vamos utilizar a função `glimpse()`.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nglimpse(dataset)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nRows: 1,600\nColumns: 5\n$ SchoolID <dbl> 404, 404, 404, 404, 404, 404, 404, 404, 404, 404, 404, 404, 4…\n$ ClassID  <dbl> 404101, 404101, 404101, 404101, 404101, 404101, 404101, 40410…\n$ PreTHKS  <dbl> 1, 2, 4, 3, 1, 1, 2, 0, 1, 2, 2, 1, 1, 0, 4, 1, 2, 1, 2, 2, 2…\n$ PosTHKS  <dbl> 3, 4, 2, 3, 2, 1, 3, 5, 2, 3, 4, 3, 1, 0, 4, 5, 3, 3, 4, 2, 3…\n$ Group    <fct> Curriculum & TV, Curriculum & TV, Curriculum & TV, Curriculum…\n```\n:::\n:::\n\n\nAo analisar os arquivos provenientes de outros programas, percebe-se que todas as variáveis numéricas são tratadas como contínuas. No entanto, todas as variáveis no banco de dados são, na verdade, categóricas. Portanto, é necessário modificar o tipo das variáveis antes de iniciar as análises. Para isso vamos utilizar a função `as.factor()` nas 4 variáveis contínuas.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndataset$SchoolID = as.factor(dataset$SchoolID)\ndataset$ClassID = as.factor(dataset$ClassID)\ndataset$PreTHKS = as.integer(dataset$PreTHKS)\ndataset$PosTHKS = as.integer(dataset$PosTHKS)\n```\n:::\n\n\nRodando novamente a função `glimpse()` podemos verificar se a mudança aconteceu.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nglimpse(dataset)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nRows: 1,600\nColumns: 5\n$ SchoolID <fct> 404, 404, 404, 404, 404, 404, 404, 404, 404, 404, 404, 404, 4…\n$ ClassID  <fct> 404101, 404101, 404101, 404101, 404101, 404101, 404101, 40410…\n$ PreTHKS  <int> 1, 2, 4, 3, 1, 1, 2, 0, 1, 2, 2, 1, 1, 0, 4, 1, 2, 1, 2, 2, 2…\n$ PosTHKS  <int> 3, 4, 2, 3, 2, 1, 3, 5, 2, 3, 4, 3, 1, 0, 4, 5, 3, 3, 4, 2, 3…\n$ Group    <fct> Curriculum & TV, Curriculum & TV, Curriculum & TV, Curriculum…\n```\n:::\n:::\n\n\nPodemos também calcular o número de alunos por classe também. Isso será bem útil para uma análise Extra no fim do capítulo.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndataset$Tamanho_Classe <- ave(dataset$PreTHKS, dataset$SchoolID, dataset$ClassID, FUN = length)\n```\n:::\n\n\n## a) Modelos hierárquicos\n\n::: callout-note\n#### Exercício\n\nCom base no desenho apresentado, qual é a pergunta que este estudo quer responder?\n:::\n\nPara abordar as questões específicas relacionadas ao banco de dados THKS2 utilizando um modelo linear GMM hierárquico, precisamos formular perguntas específicas que desejamos responder com a análise. Dado que o THKS é a variável dependente e foi avaliado antes e depois da implementação dos diferentes grupos de intervenção, podemos considerar algumas perguntas relevantes:\n\n-   Efeito geral da intervenção: Como a média da escala THKS varia entre os grupos \"Curriculum & TV\", \"Curriculum\", \"TV\" e \"Neither\" após a implementação das intervenções?\n\n-   Diferenças entre grupos específicos: Há diferenças significativas nas mudanças médias da escala THKS entre os grupos \"Curriculum & TV\", \"Curriculum\", \"TV\" e \"Neither\"?\n\n-   Variação entre escolas e salas de aula: A variação nas médias da escala THKS é significativa entre as escolas ou entre as salas de aula, considerando o efeito das intervenções?\n\nA análise gráfica pode ser fundamental para avaliar a validade da escolha de um modelo hierárquico. Ao comparar as médias do PreTHKS e do PosTHKS para diferentes escolas e salas de aula, os gráficos podem revelar padrões ou tendências que indicam se há variação sistemática ou não nas médias entre esses níveis hierárquicos. A identificação de padrões específicos pode orientar a decisão de usar um modelo hierárquico para capturar a estrutura aninhada dos dados.\n\nVamos criar um gráfico das médias de THKS entre as escolas antes e depois das intervenções.\n\n### Média por Escola\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Instale o pacote ggplot2 se ainda não o tiver instalado\n# install.packages(\"ggplot2\")\n\n\n# Crie um novo dataframe para armazenar a média das notas por escola\nmedia_por_escola <- aggregate(cbind(PosTHKS, PreTHKS) ~ SchoolID, data = dataset, FUN = mean)\n\n# Transforme os dados em formato longo (tidy)\nmedia_por_escola_long <- tidyr::pivot_longer(media_por_escola, cols = c(\"PreTHKS\", \"PosTHKS\"), names_to = \"tempo\", values_to = \"media\")\n\n# Crie um gráfico de dispersão com uma linha contínua conectando as médias das notas\nggplot(data = media_por_escola_long, aes(x = forcats::fct_rev(tempo), y = media, color = SchoolID, group = SchoolID)) +\n  geom_point() +\n  geom_line() +\n  labs(title = \"Médias por Escola\",\n       x = \"\",\n       y = \"Valores das médias de THKS\") +\n  theme_minimal() +\n  theme(legend.position = \"right\")  # Posição da leg\n```\n\n::: {.cell-output-display}\n![](lista_4_files/figure-html/unnamed-chunk-7-1.png){width=672}\n:::\n:::\n\n\nObserve no gráfico que o efeito da intervenção é basicamente constante. Antes da intervenção a média de THKS era menor e após a intervenção a média aumentou em praticamente todas as escolas analisadas.\n\nVamos fazer o mesmo mas separando as médias por classes.\n\n### Média por classe\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Instale o pacote ggplot2 se ainda não o tiver instalado\n# install.packages(\"ggplot2\")\n\n\n# Crie um novo dataframe para armazenar a média das notas por escola\nmedia_por_classe <- aggregate(cbind(PreTHKS, PosTHKS) ~ ClassID, data = dataset, FUN = mean)\n\n# Transforme os dados em formato longo (tidy)\nmedia_por_classe_long <- tidyr::pivot_longer(media_por_classe, cols = c(\"PreTHKS\", \"PosTHKS\"), names_to = \"tempo\", values_to = \"media\")\n\n# Crie um gráfico de dispersão com uma linha contínua conectando as médias das notas\nggplot(data = media_por_classe_long, aes(x = forcats::fct_rev(tempo), y = media, color = ClassID, group = ClassID)) +\n  geom_point() +\n  geom_line() +\n  labs(title = \"Médias por Classe\",\n       x = \"\",\n       y = \"Média de Notas\") +\n  #scale_color_manual(values = rainbow(length(top_50_escolas))) +  # Ajuste as cores manualmente\n  theme_minimal() +\n  theme(legend.position = \"none\")  # Posição da legenda\n```\n\n::: {.cell-output-display}\n![](lista_4_files/figure-html/unnamed-chunk-8-1.png){width=672}\n:::\n:::\n\n\nObservamos que, em alguns casos, a média de THKS diminui após a intervenção, enquanto em outros ocorre um aumento. A falta de um padrão claro sugere que a classe também desempenha um papel na resposta à intervenção, indicando a necessidade de utilizar modelos hierárquicos com fatores aleatórios nessa variável.\n\n### Média por Grupo\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Instale o pacote ggplot2 se ainda não o tiver instalado\n# install.packages(\"ggplot2\")\nhead(dataset)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n  SchoolID ClassID PreTHKS PosTHKS           Group Tamanho_Classe\n1      404  404101       1       3 Curriculum & TV             11\n2      404  404101       2       4 Curriculum & TV             11\n3      404  404101       4       2 Curriculum & TV             11\n4      404  404101       3       3 Curriculum & TV             11\n5      404  404101       1       2 Curriculum & TV             11\n6      404  404101       1       1 Curriculum & TV             11\n```\n:::\n\n```{.r .cell-code}\n# Crie um novo dataframe para armazenar a média das notas por escola\nmedia_por_grupo <- aggregate(cbind(PosTHKS, PreTHKS) ~ Group, data = dataset, FUN = mean)\n\n# Transforme os dados em formato longo (tidy)\nmedia_por_grupo_long <- tidyr::pivot_longer(media_por_grupo, cols = c(\"PreTHKS\", \"PosTHKS\"), names_to = \"tempo\", values_to = \"media\")\n\n# Crie um gráfico de dispersão com uma linha contínua conectando as médias das notas\nggplot(data = media_por_grupo_long, aes(x = forcats::fct_rev(tempo), y = media, color = Group, group = Group)) +\n  geom_point() +\n  geom_line() +\n  labs(title = \"Médias por Grupo\",\n       x = \"\",\n       y = \"Valores das médias de THKS\") +\n  theme_minimal() +\n  theme(legend.position = \"right\")  # Posição da leg\n```\n\n::: {.cell-output-display}\n![](lista_4_files/figure-html/unnamed-chunk-9-1.png){width=672}\n:::\n:::\n\n\nOs grupos também parecem ter um padrão constante de aumento na média de THKS após a intervenção, indicano que não há necessidade de colocar essa variável como efeito aleatório.\n\n## b) Efeitos fixos e aleatórios\n\n::: callout-note\n#### Exercício\n\nDentre os efeitos observados -- Grupo, Classe e Escola -- quais são efeitos fixos e aleatórios pelo menos do ponto de vista teórico?\n:::\n\nos gráficos são apenas uma das diversas maneiras de verificar a necessidade ou não de efeitos aleatórios. Mais a frente vamos ver outras métricas que podemos nos ajudar com a decisão.\n\nCom base nos gráficos anteriores, podemos inferir que a classe é um efeito aleatório, enquanto a escola e o grupo são efeitos fixos. Para seguir a abordagem prática exemplificada durante a aula no SPSS, iremos construir vários modelos considerando efeitos fixos e aleatórios. Posteriormente, compararemos os índices de aderência e os resultados obtidos, com o intuito de selecionar o modelo mais adequado para os nossos dados.\n\n## c) GLM univariado\n\n::: callout-note\n#### Exercício\n\nFaça um GLM univariado tendo o THKS pós como VD e os grupos, escolas e classes como variáveis independentes. Coloque as variáveis como efeitos fixos e aleatórios adequadamente conforme a questão anterior. Descreva os resultados encontrados.\n:::\n\nCaso queira repetir o modelo que o Altay apresentou no vídeo, execute o código abaixo. Assim como no SPSS, no R os valores serão calculados por muito tempo e o modelo não vai convergir.\n\n::: {.callout-caution collapse=\"true\"}\n#### Por conta e risco!\n\n`modelo1 <- lm(PosTHKS ~ Group * SchoolID * ClassID * PreTHKS, data=dataset)`\n:::\n\n## d) Componentes da variância e ICC\n\n::: callout-note\n#### Exercício\n\nUtilizando o \"Variance Components\", verifique se Classe e Escola podem ser considerados fatores aleatórios. Utilize o ICC (Coeficiente de Correlação Intraclasse) como critério para decidir.\n:::\n\nVamos utilizar a função `lmer()` do pacote `lme4` para criar nossos primeiro modelo com efeitos fixos e aleatórios **(modelo 1)**. Em seguida vamos extrair os componentes da variância dos resultados.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmodelo_1 = lmer(PosTHKS ~ 1 + Group * PreTHKS + # Efeitos fixos\n                  (1|SchoolID:ClassID) + # intercepto aleatório da classe aninhado na escola\n                  (1|SchoolID), # intercepto aleatório apenas da escola\n                data = dataset, \n                REML = TRUE) # Método de estimação dos parâmetros\n```\n:::\n\n\nImportante notar em nosso modelo que os efeitos fixos estão fora dos parênteses, ao passo que os efeitos aleatórios (SchooID e ClassID) estão contidos dentro dos parênteses. Essa estrutura informa à função lmer quais variáveis têm efeitos fixos e quais têm efeitos aleatórios.\n\nQuanto os métodos de estimação dos parâmetros, não deixe de ler a seção \"@sec-extras\"\n\nO primeiro passo para mostrar os componentes da variância é extrair os valores do modelo utilizando a função `VarCorr`. Vamos guardar a saída da função em um data-frame, tornando a visualização mais acessível. Em seguida, utilizaremos os estimadores de variância desejados no cálculo do ICC.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nvar_modelo_1 = as.data.frame(VarCorr(modelo_1))\nvar_modelo_1\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n               grp        var1 var2       vcov     sdcor\n1 SchoolID:ClassID (Intercept) <NA> 0.06467071 0.2543044\n2         SchoolID (Intercept) <NA> 0.03844644 0.1960776\n3         Residual        <NA> <NA> 1.59946785 1.2647007\n```\n:::\n:::\n\n\nOs valores que precisamos para calcular o ICC estão na coluna `vcov`.\n\nvamos agora armazenar os valores desejados em outras variáveis.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nvar_classe_1 = var_modelo_1$vcov[1] # classe\nvar_escola_1 = var_modelo_1$vcov[2] # school\nvar_erro_1 = var_modelo_1$vcov[3] # total\n```\n:::\n\n\nO que fizemos aqui foi acessar o data-frame (comp_var_modelo_1), indicar a coluna que queremos acessar O cifrão (`$vcoc`) e a linha em que se encontra o valor, indicada pelo número dentra das chaves `[]`.\n\nTudo o que precisamos fazer agora é calcular o ICC, que se dá pela seguinte fórmula:\n\n$$\nICC = \\frac{\\sigma^2_{\\text{entre grupos}}}{\\sigma^2_{\\text{entre grupos}} + \\sigma^2_{\\text{do erro}}}\n$$\n\n### ICC Escola (modelo 1)\n\nVamos primeiro calcular o ICC da Escola.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# ICC Escola\nicc_escola_1 = var_escola_1 / (var_escola_1 + var_erro_1)\nround(icc_escola_1, 3)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.023\n```\n:::\n:::\n\n\nArredondando o valor do cálculo temos que o valor do ICC da escola é de 0,023, ou de aproximadamente 2,3%. Se um valor de 5% fosse estabelecido para considerar uma variabilidade significativa entre os grupos, o ICC de 0,023 seria bastante baixo em relação a esse limiar.\n\n### ICC Classe (modelo 1)\n\nPara calcular o ICC da classe temos:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# ICC Classe\nicc_class_1 = var_classe_1 / (var_classe_1 + var_erro_1)\nround(icc_class_1, 3)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.039\n```\n:::\n:::\n\n\nAqui também temos um valor de ICC abaixo dos 5%, indicando que, por esse critério, a Classe também não deveria ser considerada como um fator aletaório.\n\nUma manipulação viável para avaliar o ICC exclusivamente a partir das variáveis que você considera como aleatórias é incluir apenas essas variáveis no modelo, excluindo todas as outras que tenham efeito fixo. Vamos refazer todos os passos anteriores, apenas mudando o modelo **(modelo 2)**.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmodelo_2 = lmer(PosTHKS ~ 1 +\n                  (1|SchoolID:ClassID) +\n                  (1|SchoolID), \n                data = dataset, \n                REML = TRUE) # Método de estimação dos parâmetros\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nvar_modelo_2 = as.data.frame(VarCorr(modelo_2))\nvar_modelo_2\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n               grp        var1 var2       vcov     sdcor\n1 SchoolID:ClassID (Intercept) <NA> 0.08497895 0.2915115\n2         SchoolID (Intercept) <NA> 0.11659673 0.3414626\n3         Residual        <NA> <NA> 1.72359029 1.3128558\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nvar_classe_2 = var_modelo_2$vcov[1] # classe\nvar_escola_2 = var_modelo_2$vcov[2] # escola\nvar_erro_2 = var_modelo_2$vcov[3] # total\n```\n:::\n\n\n### ICC Escola (modelo 2)\n\nCalculando o ICC da escola para o modelo 2 temos\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# ICC escola\n\nicc_school_2 = var_escola_2 / (var_escola_2 + var_erro_2)\nround(icc_school_2, 3)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.063\n```\n:::\n:::\n\n\nAgora temos que o ICC da escola é maior que 5%, indicando que a variável é uma boa candidata para ser designada tendo efeito aleatório.\n\n### ICC Classe (modelo 2)\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# ICC classe\n\nicc_class_2 = var_classe_2 / (var_classe_2 + var_erro_2)\nround(icc_class_2, 3)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.047\n```\n:::\n:::\n\n\nJá a classe continua com um valor de ICC abaixo dos 5%\n\n### ICC com função\n\nPodemos utilizar a função `multilevel.icc` do pacote `misty` para não precisar calcular na mão o ICC. Digno de nota que a função não aceita efeitos fixos, portanto teremos **APENAS** o ICC do modelo com efeitos aleatórios. Além disso a função pode assumir 3 tipos:\n\n-   ICC(1) - Mostra quanto da variação ocorre entre os grupos (nível 2) e entre os grupos de grupos (nível 3), que é semelhante ao que calculamos na mão.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmultilevel.icc(PosTHKS, # Variável dependente\n               data = dataset, # Banco de dados\n               cluster = c(\"SchoolID\", \"ClassID\")) # Ordem dos clusters importa. Primeiro o L3 e depois o L2\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n       L3        L2 \n0.0605645 0.0441411 \n```\n:::\n:::\n\n\n-   ICC(1b) - Representa a correlação esperada entre dois elementos escolhidos aleatoriamente no mesmo grupo.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmultilevel.icc(PosTHKS, \n               data = dataset, \n               cluster = c(\"SchoolID\", \"ClassID\"),\n               type = \"1b\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n       L3        L2 \n0.0605645 0.1607378 \n```\n:::\n:::\n\n\n-   ICC(2) Indica quão confiáveis são as médias dos grupos (nível 2 e 3). Ou seja, o quão representativas são as médias dos grupos em relação às diferenças individuais dentro desses grupos.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmultilevel.icc(PosTHKS, data = dataset, cluster = c(\"SchoolID\", \"ClassID\"),\ntype = \"2\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n       L3        L2 \n0.7092913 0.3688212 \n```\n:::\n:::\n\n\nNotem que a primeira fórmula apresenta resultado similar ao que calculamos na mão.\n\n::: callout-important\n#### Importante!\n\nNão existe um conceito fechado de como definir se uma variável deve ser considerada ou não como efeito aleatório. A teoria deve sempre prevalecer sobre os demais critérios.\n:::\n\nPelo critério teórico, vamos assumir que tanto escola quanto classe terão efeito aleatório em nosso modelo final.\n\n## e) Interpretando os resultados\n\n::: callout-note\n#### Exercício\n\nRealize um Modelo Misto Hierárquico (caso os fatores aleatórios sejam relevantes com base em d). Descreva os resultados adequadamente e verifique qual combinação de fatores aleatórios é a mais adequada para explicar a variação dos resultados do THKS (com base no ICC).\n:::\n\n### Verificando a referência do Grupo\n\nPara seguir os passos do vídeo feito pelo Altay no SPSS primeiro temos que ajustar o nível de referência da variável Grupo. No SPSS a referência é o grupo que não fez nada (Neither). Para verificar qual o nível de referência aqui no R vamos utilizar a função `levels()`.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlevels(dataset$Group)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"Curriculum & TV\" \"Curriculum\"      \"TV\"              \"Neither\"        \n```\n:::\n:::\n\n\nO nível de referência é sempre primeiro que aparece na lista, no caso \"Curriculum & TV\".\n\nVamos mudar para que a referência seja \"Neither\", utilizando a função relevel.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndataset$Group <- relevel(dataset$Group, ref = \"Neither\")\nlevels(dataset$Group)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"Neither\"         \"Curriculum & TV\" \"Curriculum\"      \"TV\"             \n```\n:::\n:::\n\n\nAgora sim podemos seguir com nossa análise.\n\n### Criando o modelo\n\nAo contrário do SPSS, não enfrentaremos problemas de convergência em nossos modelos se a matriz de covariância não for modificada. Para demonstrar que alterar a matriz de covariância não afeta significativamente os coeficientes, podemos criar dois modelos para verificação:\n\n-   a\\) modelo com matriz de covariância simétrica;\n\n-   b\\) modelo com matriz de covariância diagonal (padrão caso não definamos explicitamente a matriz).\n\nA função `lmer()` não oferece uma maneira direta de modificar a matriz de covariância. Portanto, da mesma forma que fizemos na Lista de Exercícios 3, vamos utilizar a função `lme()`.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Modelo a)\nmodelo_a = lme(\n  fixed = PosTHKS ~ 1 + PreTHKS + Group, \n  random =~ 1|SchoolID/ClassID,\n  correlation = corCompSymm(form = ~1|SchoolID/ClassID), # Aqui definimos a matriz simétrica\n  data = dataset, \n  method = \"REML\")\n\n# Armazenando os valores dos coeficientes do modelo a) em uma variável\ncoef_a = modelo_a$coefficients$fixed\n\n# Modelo b)\nmodelo_b = lme(\n  fixed = PosTHKS ~ 1 + PreTHKS + Group, \n  random =~ 1|SchoolID/ClassID,\n  data = dataset, \n  method = \"REML\") # Matriz diagonal por padrão\n\n# Armazenando os valores dos coeficientes do modelo b) em uma variável\ncoef_b = modelo_b$coefficients$fixed\n\n\n# Criar um dataframe\ndf_coeficientes <- data.frame(Modelo_a = coef_a,\n                              Modelo_b = coef_b)\ndf_coeficientes\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n                      Modelo_a  Modelo_b\n(Intercept)          1.7019847 1.7019852\nPreTHKS              0.3053629 0.3053628\nGroupCurriculum & TV 0.4924670 0.4924662\nGroupCurriculum      0.6413248 0.6413260\nGroupTV              0.1820783 0.1820802\n```\n:::\n:::\n\n\nPodemos observar que os valores mudam apenas depois da 3 casa após a vírgula. Portanto podemos construir os modelos sem alterar a matriz de covariância neste caso específico.\n\n<!-- Vamos continuar utilizando a função `lmer()`, mas caso precise alterar a matriz de variância do seu modelo, veja a resolução dos exercícios da lista 3 (@sec-lista-3). -->\n\nVamos ao modelo:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmodelo_3 = lme(\n  fixed = PosTHKS ~ 1 + PreTHKS + Group, \n  random =~ 1|SchoolID/ClassID,\n  data = dataset, \n  method = \"REML\")\n\n# Escolhi utilizar o lme() por ele apresentar mais resultados na saída da função anova()\n```\n:::\n\n\n### ICC do modelo\n\nNão encontramos uma maneira fácil de mostrar o ICC para modelos de 3 níveis com variáveis independentes fixas. Por isso mostramos como calcular na mão o ICC anteriormente. Podemos acessar os valores de variância do modelo com a seguinte função:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nkable(VarCorr(modelo_3)) # O kable é só pra deixar com um visual melhor a saída.\n```\n\n::: {.cell-output-display}\n`````{=html}\n<table>\n <thead>\n  <tr>\n   <th style=\"text-align:left;\">   </th>\n   <th style=\"text-align:left;\"> Variance </th>\n   <th style=\"text-align:left;\"> StdDev </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:left;\"> SchoolID = </td>\n   <td style=\"text-align:left;\"> pdLogChol(1) </td>\n   <td style=\"text-align:left;\">  </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> (Intercept) </td>\n   <td style=\"text-align:left;\"> 0.03864002 </td>\n   <td style=\"text-align:left;\"> 0.1965706 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> ClassID = </td>\n   <td style=\"text-align:left;\"> pdLogChol(1) </td>\n   <td style=\"text-align:left;\">  </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> (Intercept) </td>\n   <td style=\"text-align:left;\"> 0.06466151 </td>\n   <td style=\"text-align:left;\"> 0.2542863 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> Residual </td>\n   <td style=\"text-align:left;\"> 1.60229394 </td>\n   <td style=\"text-align:left;\"> 1.2658175 </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n:::\n\n\nAgora queremos acessar cada variância separadamente. Para isso executamos o scritp a seguir.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nvar_escola = VarCorr(modelo_3)[2] # Variancia da Escola\n\nvar_classe = VarCorr(modelo_3)[4] # Variancia da Classe\n\nvar_res = VarCorr(modelo_3)[5] # Variancia do resíduo\n```\n:::\n\n\nSe você tentar fazer contas com essas variáveis vai notar algo bem estranho\n\n\n::: {.cell}\n\n```{.r .cell-code}\nvar_classe + var_res\n```\n:::\n\n\nIsso acontece porque elas saíram como caracteres (símbolos, letras...) e não como números!\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntypeof(var_classe)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"character\"\n```\n:::\n:::\n\n\nVamos resolver isso transformando elas para números\n\n\n::: {.cell}\n\n```{.r .cell-code}\nvar_escola = as.numeric(var_escola)\nvar_classe = as.numeric(var_classe)\nvar_res = as.numeric(var_res)\n```\n:::\n\n\nAgora sim!\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntypeof(var_escola)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"double\"\n```\n:::\n:::\n\n\nCalculando o ICC da Escola temos:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nvar_escola/(var_escola+var_res) #ICC da escola\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.02354758\n```\n:::\n:::\n\n\nICC da classe:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nvar_classe/(var_classe+var_res)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.03879018\n```\n:::\n:::\n\n\n### Pressupostos do modelo\n\nComo já vimos, parte importante de analisar os modelos é verificar os pressupostos. Não entraremos em detalhes, vamos apenas vislumbrar quandos todos os pressupostos são atendidos! O melhor de tudo, usando apenas 3 palavras na linha de código, graças à função `check_model()`.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncheck_model(modelo_3)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nConverting missing values (`NA`) into regular values currently not\n  possible for variables of class `NULL`.\n```\n:::\n\n::: {.cell-output-display}\n![](lista_4_files/figure-html/unnamed-chunk-35-1.png){width=672}\n:::\n:::\n\n\nQue beleza, não? Resíduos normais, baixa colinearidade e ótima linearidade do modelo! Podemos interpretar os resultados com tranquilidade!\n\n### Resultados\n\nVamos verificar se o efeito do grupo é significante, que é a principal variável dependente do nosso modelo. Para isso podemos utilizar a função `anova()` que é muito versátil para diversas ocasiões.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nkable(anova(modelo_3)) #função kable apenas para deixar mais bonita a tabela\n```\n\n::: {.cell-output-display}\n`````{=html}\n<table>\n <thead>\n  <tr>\n   <th style=\"text-align:left;\">   </th>\n   <th style=\"text-align:right;\"> numDF </th>\n   <th style=\"text-align:right;\"> denDF </th>\n   <th style=\"text-align:right;\"> F-value </th>\n   <th style=\"text-align:right;\"> p-value </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:left;\"> (Intercept) </td>\n   <td style=\"text-align:right;\"> 1 </td>\n   <td style=\"text-align:right;\"> 1464 </td>\n   <td style=\"text-align:right;\"> 2240.036555 </td>\n   <td style=\"text-align:right;\"> 0.0000000 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> PreTHKS </td>\n   <td style=\"text-align:right;\"> 1 </td>\n   <td style=\"text-align:right;\"> 1464 </td>\n   <td style=\"text-align:right;\"> 136.795261 </td>\n   <td style=\"text-align:right;\"> 0.0000000 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> Group </td>\n   <td style=\"text-align:right;\"> 3 </td>\n   <td style=\"text-align:right;\"> 24 </td>\n   <td style=\"text-align:right;\"> 6.610438 </td>\n   <td style=\"text-align:right;\"> 0.0020567 </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n:::\n\n\nBoa! Descobrimos que o efeito do grupo é significativo. Agora precisamos saber entre quais grupos está a diferença e de quanto ela é.\n\nPara tanto vamos utilizar mais uma vez a função `summary()`.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsummary(modelo_3)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nLinear mixed-effects model fit by REML\n  Data: dataset \n       AIC      BIC    logLik\n  5389.335 5432.332 -2686.668\n\nRandom effects:\n Formula: ~1 | SchoolID\n        (Intercept)\nStdDev:   0.1965706\n\n Formula: ~1 | ClassID %in% SchoolID\n        (Intercept) Residual\nStdDev:   0.2542863 1.265817\n\nFixed effects:  PosTHKS ~ 1 + PreTHKS + Group \n                         Value  Std.Error   DF   t-value p-value\n(Intercept)          1.7019852 0.12543004 1464 13.569199  0.0000\nPreTHKS              0.3053628 0.02589132 1464 11.794021  0.0000\nGroupCurriculum & TV 0.4924662 0.15864165   24  3.104268  0.0048\nGroupCurriculum      0.6413260 0.16094729   24  3.984696  0.0005\nGroupTV              0.1820802 0.15724054   24  1.157972  0.2583\n Correlation: \n                     (Intr) PrTHKS GrC&TV GrpCrr\nPreTHKS              -0.442                     \nGroupCurriculum & TV -0.649  0.029              \nGroupCurriculum      -0.634  0.015  0.496       \nGroupTV              -0.645  0.008  0.508  0.501\n\nStandardized Within-Group Residuals:\n        Min          Q1         Med          Q3         Max \n-2.49874557 -0.69757194 -0.01721254  0.68240735  3.14602049 \n\nNumber of Observations: 1600\nNumber of Groups: \n             SchoolID ClassID %in% SchoolID \n                   28                   135 \n```\n:::\n:::\n\n\nComo vocês já podem ter percebido as saídas da função `summary()` no R não geram as saídas mais fáceis de interpretar, como podemos ver no exemplo abaixo.\n\nAgora que você enfrentou a busca nos detalhes desse fascinante output gerado pela função summary, é com satisfação que compartilhamos a boa notícia de que muitos desenvolvedores compartilham da sua experiência e criaram vários pacotes para aprimorar a visualização dos resultados. Ao longo dos exercícios, apresentaremos algumas abordagens para alcançar isso. No final da seção de modelos lineares, você encontrará um glossário que ajudará na geração de outputs mais amigáveis e formatados para publicações acadêmicas.\n\nPor hora, vamos compartilhar uma abordagem mais \"na mão\" para melhorar a visualização dos resultados, para caso algum pacote não atenda completamente às suas necessidades.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Resumo do modelo\n\nresumo_modelo <- summary(modelo_3)\n\n# Extração de estimadores, intervalos de confiança e p-valores\n\ncoeficientes <- resumo_modelo$coefficients$fixed # essa linha varia muito dependendo do modelo\nintervalos_confianca <- intervals(modelo_3, which = \"fixed\") # Função `confint()` pode ser utilizadas para outros modelos\np_valores <- resumo_modelo$tTable[, \"p-value\"]\n\n# Criar um data frame\n\nresultados_modelo <- data.frame(\n  Estimador = round(coeficientes, 3),\n  IC_Inf = round(intervalos_confianca$fixed[, 1], 3),\n  IC_Sup = round(intervalos_confianca$fixed[, 2], 3),\n  p = round(p_valores, 3)\n)\n\n# Apresentando os resultados\nkable(resultados_modelo)\n```\n\n::: {.cell-output-display}\n`````{=html}\n<table>\n <thead>\n  <tr>\n   <th style=\"text-align:left;\">   </th>\n   <th style=\"text-align:right;\"> Estimador </th>\n   <th style=\"text-align:right;\"> IC_Inf </th>\n   <th style=\"text-align:right;\"> IC_Sup </th>\n   <th style=\"text-align:right;\"> p </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:left;\"> (Intercept) </td>\n   <td style=\"text-align:right;\"> 1.702 </td>\n   <td style=\"text-align:right;\"> 1.456 </td>\n   <td style=\"text-align:right;\"> 1.702 </td>\n   <td style=\"text-align:right;\"> 0.000 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> PreTHKS </td>\n   <td style=\"text-align:right;\"> 0.305 </td>\n   <td style=\"text-align:right;\"> 0.255 </td>\n   <td style=\"text-align:right;\"> 0.305 </td>\n   <td style=\"text-align:right;\"> 0.000 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> GroupCurriculum &amp; TV </td>\n   <td style=\"text-align:right;\"> 0.492 </td>\n   <td style=\"text-align:right;\"> 0.165 </td>\n   <td style=\"text-align:right;\"> 0.492 </td>\n   <td style=\"text-align:right;\"> 0.005 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> GroupCurriculum </td>\n   <td style=\"text-align:right;\"> 0.641 </td>\n   <td style=\"text-align:right;\"> 0.309 </td>\n   <td style=\"text-align:right;\"> 0.641 </td>\n   <td style=\"text-align:right;\"> 0.001 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> GroupTV </td>\n   <td style=\"text-align:right;\"> 0.182 </td>\n   <td style=\"text-align:right;\"> -0.142 </td>\n   <td style=\"text-align:right;\"> 0.182 </td>\n   <td style=\"text-align:right;\"> 0.258 </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n:::\n\n\n------------------------------------------------------------------------\n\nMelhorou um pouco né? Achou muito trabalhoso??\n\nQue tal fazer tudo em uma linha de código e ainda com correção de Bonferroni!?\n\n\n::: {.cell}\n\n```{.r .cell-code}\nemmeans(modelo_3, pairwise ~ Group, adjust = \"bonferroni\") # por padrão temos a correção de Tukey\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n$emmeans\n Group           emmean    SE df lower.CL upper.CL\n Neither           2.33 0.113 27     2.10     2.56\n Curriculum & TV   2.83 0.112 24     2.60     3.06\n Curriculum        2.98 0.115 24     2.74     3.21\n TV                2.52 0.110 24     2.29     2.74\n\nDegrees-of-freedom method: containment \nConfidence level used: 0.95 \n\n$contrasts\n contrast                     estimate    SE df t.ratio p.value\n Neither - Curriculum & TV      -0.492 0.159 24  -3.104  0.0290\n Neither - Curriculum           -0.641 0.161 24  -3.985  0.0033\n Neither - TV                   -0.182 0.157 24  -1.158  1.0000\n Curriculum & TV - Curriculum   -0.149 0.160 24  -0.928  1.0000\n Curriculum & TV - TV            0.310 0.157 24   1.981  0.3550\n Curriculum - TV                 0.459 0.159 24   2.888  0.0485\n\nDegrees-of-freedom method: containment \nP value adjustment: bonferroni method for 6 tests \n```\n:::\n:::\n\n\nOs valores estão negativos porque ajustamos o nível de referência da variável Group para \"Neither\". No resultado temos que \"Curriculum\" apresenta a maior média geral. Logo seria interessante deixá-lo como variável de referência, caso queira que seus estimadores fiquem positivo. Já vimos como fazer isso anteriormente!\n\nTente modificar a referência para \"Curriculum\", mas **CUIDADO!** Não se esqueça de criar o modelo novamente, caso contrário os resultados ficarão errados!\n\nPara acessar apenas os resultados de contraste podemos fazer o seguinte:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nemmeans(modelo_3, pairwise ~ Group, adjust = \"bonferroni\")$contrasts\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n contrast                     estimate    SE df t.ratio p.value\n Neither - Curriculum & TV      -0.492 0.159 24  -3.104  0.0290\n Neither - Curriculum           -0.641 0.161 24  -3.985  0.0033\n Neither - TV                   -0.182 0.157 24  -1.158  1.0000\n Curriculum & TV - Curriculum   -0.149 0.160 24  -0.928  1.0000\n Curriculum & TV - TV            0.310 0.157 24   1.981  0.3550\n Curriculum - TV                 0.459 0.159 24   2.888  0.0485\n\nDegrees-of-freedom method: containment \nP value adjustment: bonferroni method for 6 tests \n```\n:::\n:::\n\n\n## Extras! {#sec-extras}\n\n### Métodos de estimação dos parâmetros do modelo\n\nO REML (Residual Maximum Likelihood) e o ML (Maximum Likelihood) são duas abordagens distintas para a estimação de parâmetros em modelos de regressão linear mista (ou modelos hierárquicos). Ambas são baseadas no método da máxima verossimilhança, mas diferem na maneira como tratam os graus de liberdade.\n\n**Maximum Likelihood (ML):**\n\nNa abordagem ML, o foco é maximizar a verossimilhança do modelo, considerando tanto os efeitos fixos quanto os efeitos aleatórios. O ML leva em conta todos os parâmetros do modelo para maximizar a probabilidade de observar os dados dados os parâmetros. É mais adequado quando o interesse principal é fazer inferências sobre os parâmetros fixos do modelo.\n\n**Residual Maximum Likelihood (REML):**\n\nA abordagem REML é uma variação do ML que remove os efeitos fixos do modelo antes de calcular a verossimilhança. O REML estima a verossimilhança condicional dos efeitos aleatórios, removendo a contribuição dos efeitos fixos. Ele tende a ser mais eficiente na estimação dos efeitos aleatórios, especialmente em amostras pequenas, e fornece estimativas menos enviesadas para a variância dos efeitos aleatórios. O REML é frequentemente preferido quando o foco está na estimação dos parâmetros aleatórios e quando a inferência sobre os parâmetros fixos não é o objetivo principal.\n\n### Extraindo valores de summary\n\nPodemos extrair diversos valores individualmente da função `summary()`.\n\n\n\n\n\n### Tamanho da classe importa?\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntheme_set(theme_bw(base_size = 7, base_family = \"\")) \n\nggplot(data = dataset, aes(x = Tamanho_Classe, y=PosTHKS))+\n  facet_grid(~SchoolID)+\n  coord_cartesian(ylim=c(0,30))+\n  geom_point()+\n  geom_smooth(method = \"lm\", se = TRUE)+\n  xlab(\"Tamanho da Classe\")+ylab(\"PosTHKS\")+\n  theme(legend.position = \"top\")\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n`geom_smooth()` using formula = 'y ~ x'\n```\n:::\n\n::: {.cell-output-display}\n![](lista_4_files/figure-html/unnamed-chunk-42-1.png){width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nPlot.Means<-dataset %>% group_by(SchoolID) %>%  \n  dplyr::summarize(PosTHKSM = mean(PosTHKS, na.rm=TRUE),\n                   Tamanho_CLasseM=mean(Tamanho_Classe, na.rm=TRUE))\n\n\n\nggplot(data = Plot.Means, aes(x = reorder(SchoolID, -PosTHKSM), y=PosTHKSM))+\n  geom_point(aes(size = Tamanho_CLasseM))+\n  xlab(\"\")+ylab(\"PosTHKS\")+\n  theme_bw()+\n  theme(legend.position = \"top\")\n```\n\n::: {.cell-output-display}\n![](lista_4_files/figure-html/unnamed-chunk-43-1.png){width=672}\n:::\n:::\n\n\n### Comparando modelos\n\nPodemos comparar diversos modelos utilizando a função `model.comparison()` do pacote `flexplot`.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmodel.comparison(modelo_1, modelo_2)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nrefitting model(s) with ML (instead of REML)\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n$statistics\n              aic      bic bayes.factor      p\nmodelo_1 5400.422 5459.578 2.090546e+16 <2e-16\nmodelo_2 5513.224 5534.735 0.000000e+00       \n\n$predicted_differences\n   0%   25%   50%   75%  100% \n0.001 0.113 0.243 0.436 1.310 \n\n$r_squared_change\n   Residual (Intercept) (Intercept) \n 0.07201389  0.67026142  0.23897964 \n```\n:::\n\n```{.r .cell-code}\n# O modelo 1 apresenta melhores resultados\n```\n:::\n\n\n### Plot do modelo\n\nCriando um gráfico com os coeficientes gerados pelo modelo.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Com a correção de Bonferroni\nresults_modelo_3 = emmeans(modelo_3, pairwise ~ Group, adjust = \"bonferroni\")\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(as.data.frame(results_modelo_3$emmeans), aes(x = Group, y = emmean, color = Group)) +\n  geom_errorbar(aes(ymin = lower.CL, ymax = upper.CL), width = 0.2, position = position_dodge(0.8)) +\n  geom_point(position = position_dodge(0.8), size = 3) +\n  labs(title = \"Distribuição normal\",\n       x = \"Tratamento\",\n       y = \"THKS\") +\n  theme_minimal() +\n  theme(legend.position = \"none\") \n```\n\n::: {.cell-output-display}\n![](lista_4_files/figure-html/unnamed-chunk-46-1.png){width=672}\n:::\n:::\n\n\n### Função para calcular o ICC\n\nCaso você queira calcular o ICC para diferentes modelos de 3 níveis, sugiro criar uma função que faça o trabalho repetitivo ao invés de ficar calculando tudo sempre na mão.\n\n::: callout-important\n## Importante\n\nFunciona apenas para modelos gerados pela função `lme()`.\n:::\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Criando minha própria função\n\nicc_lme_3nv = function(modelo) {\n  # Extração da variância entre grupos e total\n  var_escola = as.numeric(VarCorr(modelo)[2])\n  var_classe = as.numeric(VarCorr(modelo)[4])\n  var_total = as.numeric(VarCorr(modelo)[5])\n\n  # Cálculo do ICC\n  icc_escola = var_escola/(var_escola+var_res)\n  icc_classe = var_classe/(var_classe+var_res)\n  \n  # Retorna o valor do ICC \n  return(list(\"ICC-Escola\" = icc_escola, \"ICC-Classe\" = icc_classe))\n}\n\n# Uso\n# icc_lme_3nv(modelo) - basta substitui \"modelo\" pelo nome da variável que você escolheu para salvar seu modelo.\n```\n:::\n\n\n## Observações\n\nTreine criar mais modelos multinível, inclusive com apenas 2 níveis. Inclusive, se for utilzar a função `lmer()`, MUITO CUIDADO!\n\nEste modelo:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmodelo_5b = lmer(PosTHKS ~ 1 + Group +\n                   (1|SchoolID:ClassID),\n                 dataset,\n                 REML = TRUE)\n```\n:::\n\n\nÉ diferente deste modelo:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmodelo_5b = lmer(PosTHKS ~ 1 + Group +\n                   (1|SchoolID) + # Escola como efeito aleatório\n                   (1|SchoolID:ClassID), # Classe como efeito aleatório\n                 dataset,\n                 REML = TRUE)\n```\n:::\n\n\nCom a função `lmer()` precisamos indicar no modelo que queremos Escola e Classe como efeito aleatórios em linhas separadas!\n\n## Lista 4 resolvida no SPSS\n\n\n{{< video https://www.youtube.com/watch?v=_1lUvEu8M9c title=’ HGMM - Hierarchical Generalized Mixed Models - Aula Prática #4 (SPSS)’ >}}\n\n\n\n## Referências\n\nhttps://lmudge13.github.io/sample_code/mixed_effects.html \\# Tabelas e gráficos de modelos lme\n\nhttps://rpsychologist.com/r-guide-longitudinal-lme-lmer#three-level-models\n\nhttps://search.r-project.org/CRAN/refmans/misty/html/multilevel.icc.html\n\nhttps://www.rdocumentation.org/packages/psychometric/versions/2.4/topics/ICC.lme\n\nhttps://www.alexanderdemos.org/Mixed5.html\n\nhttps://cran.r-project.org/web/packages/rempsyc/vignettes/assumptions.html#categorical-predictors \\# pressupostos dos modelos com variáveis categóricas como preditoras.\n\n\n## Versões dos pacotes\n\n\n::: {.cell}\n\n```{.r .cell-code}\nreport(sessionInfo())\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nAnalyses were conducted using the R Statistical language (version 4.3.1; R Core\nTeam, 2023) on Windows 11 x64 (build 22621), using the packages lme4 (version\n1.1.34; Bates D et al., 2015), Matrix (version 1.6.0; Bates D et al., 2023),\neffectsize (version 0.8.6; Ben-Shachar MS et al., 2020), multilevel (version\n2.7; Bliese P, 2022), fitdistrplus (version 1.1.11; Delignette-Muller ML,\nDutang C, 2015), tm (version 0.7.11; Feinerer I, Hornik K, 2023), flexplot\n(version 0.20.5; Fife D, 2024), psychometric (version 2.4; Fletcher TD, 2023),\neffects (version 4.2.2; Fox J, Weisberg S, 2019), carData (version 3.0.5; Fox J\net al., 2022), mvtnorm (version 1.2.3; Genz A, Bretz F, 2009), NLP (version\n0.2.1; Hornik K, 2020), TH.data (version 1.1.2; Hothorn T, 2023), multcomp\n(version 1.4.25; Hothorn T et al., 2008), emmeans (version 1.8.8; Lenth R,\n2023), sjstats (version 0.18.2; Lüdecke D, 2022), sjPlot (version 2.8.15;\nLüdecke D, 2023), parameters (version 0.21.3; Lüdecke D et al., 2020),\nperformance (version 0.10.8; Lüdecke D et al., 2021), easystats (version 0.6.0;\nLüdecke D et al., 2022), see (version 0.8.1; Lüdecke D et al., 2021), insight\n(version 0.19.6; Lüdecke D et al., 2019), bayestestR (version 0.13.1; Makowski\nD et al., 2019), modelbased (version 0.8.6; Makowski D et al., 2020), report\n(version 0.5.7; Makowski D et al., 2023), correlation (version 0.8.4; Makowski\nD et al., 2022), datawizard (version 0.9.0; Patil I et al., 2022), nlme\n(version 3.1.163; Pinheiro J et al., 2023), foreign (version 0.8.85; R Core\nTeam, 2023), rempsyc (version 0.1.6; Thériault R, 2023), survival (version\n3.5.7; Therneau T, 2023), MASS (version 7.3.60; Venables WN, Ripley BD, 2002),\nggplot2 (version 3.4.4; Wickham H, 2016), forcats (version 1.0.0; Wickham H,\n2023), dplyr (version 1.1.3; Wickham H et al., 2023), purrr (version 1.0.2;\nWickham H, Henry L, 2023), misty (version 0.6.1; Yanagida T, 2024) and\nkableExtra (version 1.3.4; Zhu H, 2021).\n\nReferences\n----------\n  - Bates D, Mächler M, Bolker B, Walker S (2015). \"Fitting Linear Mixed-Effects\nModels Using lme4.\" _Journal of Statistical Software_, *67*(1), 1-48.\ndoi:10.18637/jss.v067.i01 <https://doi.org/10.18637/jss.v067.i01>.\n  - Bates D, Maechler M, Jagan M (2023). _Matrix: Sparse and Dense Matrix Classes\nand Methods_. R package version 1.6-0,\n<https://CRAN.R-project.org/package=Matrix>.\n  - Ben-Shachar MS, Lüdecke D, Makowski D (2020). \"effectsize: Estimation of\nEffect Size Indices and Standardized Parameters.\" _Journal of Open Source\nSoftware_, *5*(56), 2815. doi:10.21105/joss.02815\n<https://doi.org/10.21105/joss.02815>, <https://doi.org/10.21105/joss.02815>.\n  - Bliese P (2022). _multilevel: Multilevel Functions_. R package version 2.7,\n<https://CRAN.R-project.org/package=multilevel>.\n  - Delignette-Muller ML, Dutang C (2015). \"fitdistrplus: An R Package for\nFitting Distributions.\" _Journal of Statistical Software_, *64*(4), 1-34.\ndoi:10.18637/jss.v064.i04 <https://doi.org/10.18637/jss.v064.i04>.\n  - Feinerer I, Hornik K (2023). _tm: Text Mining Package_. R package version\n0.7-11, <https://CRAN.R-project.org/package=tm>. Feinerer I, Hornik K, Meyer D\n(2008). \"Text Mining Infrastructure in R.\" _Journal of Statistical Software_,\n*25*(5), 1-54. doi:10.18637/jss.v025.i05\n<https://doi.org/10.18637/jss.v025.i05>.\n  - Fife D (2024). _flexplot: Graphically Based Data Analysis Using 'flexplot'_.\nR package version 0.20.5.\n  - Fletcher TD (2023). _psychometric: Applied Psychometric Theory_. R package\nversion 2.4, <https://CRAN.R-project.org/package=psychometric>.\n  - Fox J, Weisberg S (2019). _An R Companion to Applied Regression_, 3rd\nedition. Sage, Thousand Oaks CA.\n<https://socialsciences.mcmaster.ca/jfox/Books/Companion/index.html>. Fox J,\nWeisberg S (2018). \"Visualizing Fit and Lack of Fit in Complex Regression\nModels with Predictor Effect Plots and Partial Residuals.\" _Journal of\nStatistical Software_, *87*(9), 1-27. doi:10.18637/jss.v087.i09\n<https://doi.org/10.18637/jss.v087.i09>. Fox J (2003). \"Effect Displays in R\nfor Generalised Linear Models.\" _Journal of Statistical Software_, *8*(15),\n1-27. doi:10.18637/jss.v008.i15 <https://doi.org/10.18637/jss.v008.i15>. Fox J,\nHong J (2009). \"Effect Displays in R for Multinomial and Proportional-Odds\nLogit Models: Extensions to the effects Package.\" _Journal of Statistical\nSoftware_, *32*(1), 1-24. doi:10.18637/jss.v032.i01\n<https://doi.org/10.18637/jss.v032.i01>.\n  - Fox J, Weisberg S, Price B (2022). _carData: Companion to Applied Regression\nData Sets_. R package version 3.0-5,\n<https://CRAN.R-project.org/package=carData>.\n  - Genz A, Bretz F (2009). _Computation of Multivariate Normal and t\nProbabilities_, series Lecture Notes in Statistics. Springer-Verlag,\nHeidelberg. ISBN 978-3-642-01688-2.\n  - Hornik K (2020). _NLP: Natural Language Processing Infrastructure_. R package\nversion 0.2-1, <https://CRAN.R-project.org/package=NLP>.\n  - Hothorn T (2023). _TH.data: TH's Data Archive_. R package version 1.1-2,\n<https://CRAN.R-project.org/package=TH.data>.\n  - Hothorn T, Bretz F, Westfall P (2008). \"Simultaneous Inference in General\nParametric Models.\" _Biometrical Journal_, *50*(3), 346-363.\n  - Lenth R (2023). _emmeans: Estimated Marginal Means, aka Least-Squares Means_.\nR package version 1.8.8, <https://CRAN.R-project.org/package=emmeans>.\n  - Lüdecke D (2022). _sjstats: Statistical Functions for Regression Models\n(Version 0.18.2)_. doi:10.5281/zenodo.1284472\n<https://doi.org/10.5281/zenodo.1284472>,\n<https://CRAN.R-project.org/package=sjstats>.\n  - Lüdecke D (2023). _sjPlot: Data Visualization for Statistics in Social\nScience_. R package version 2.8.15,\n<https://CRAN.R-project.org/package=sjPlot>.\n  - Lüdecke D, Ben-Shachar M, Patil I, Makowski D (2020). \"Extracting, Computing\nand Exploring the Parameters of Statistical Models using R.\" _Journal of Open\nSource Software_, *5*(53), 2445. doi:10.21105/joss.02445\n<https://doi.org/10.21105/joss.02445>.\n  - Lüdecke D, Ben-Shachar M, Patil I, Waggoner P, Makowski D (2021).\n\"performance: An R Package for Assessment, Comparison and Testing of\nStatistical Models.\" _Journal of Open Source Software_, *6*(60), 3139.\ndoi:10.21105/joss.03139 <https://doi.org/10.21105/joss.03139>.\n  - Lüdecke D, Ben-Shachar M, Patil I, Wiernik B, Makowski D (2022). \"easystats:\nFramework for Easy Statistical Modeling, Visualization, and Reporting.\" _CRAN_.\nR package, <https://easystats.github.io/easystats/>.\n  - Lüdecke D, Patil I, Ben-Shachar M, Wiernik B, Waggoner P, Makowski D (2021).\n\"see: An R Package for Visualizing Statistical Models.\" _Journal of Open Source\nSoftware_, *6*(64), 3393. doi:10.21105/joss.03393\n<https://doi.org/10.21105/joss.03393>.\n  - Lüdecke D, Waggoner P, Makowski D (2019). \"insight: A Unified Interface to\nAccess Information from Model Objects in R.\" _Journal of Open Source Software_,\n*4*(38), 1412. doi:10.21105/joss.01412 <https://doi.org/10.21105/joss.01412>.\n  - Makowski D, Ben-Shachar M, Lüdecke D (2019). \"bayestestR: Describing Effects\nand their Uncertainty, Existence and Significance within the Bayesian\nFramework.\" _Journal of Open Source Software_, *4*(40), 1541.\ndoi:10.21105/joss.01541 <https://doi.org/10.21105/joss.01541>,\n<https://joss.theoj.org/papers/10.21105/joss.01541>.\n  - Makowski D, Ben-Shachar M, Patil I, Lüdecke D (2020). \"Estimation of\nModel-Based Predictions, Contrasts and Means.\" _CRAN_.\n<https://github.com/easystats/modelbased>.\n  - Makowski D, Lüdecke D, Patil I, Thériault R, Ben-Shachar M, Wiernik B (2023).\n\"Automated Results Reporting as a Practical Tool to Improve Reproducibility and\nMethodological Best Practices Adoption.\" _CRAN_.\n<https://easystats.github.io/report/>.\n  - Makowski D, Wiernik B, Patil I, Lüdecke D, Ben-Shachar M (2022).\n\"correlation: Methods for Correlation Analysis.\" Version 0.8.3,\n<https://CRAN.R-project.org/package=correlation>. Makowski D, Ben-Shachar M,\nPatil I, Lüdecke D (2020). \"Methods and Algorithms for Correlation Analysis in\nR.\" _Journal of Open Source Software_, *5*(51), 2306. doi:10.21105/joss.02306\n<https://doi.org/10.21105/joss.02306>,\n<https://joss.theoj.org/papers/10.21105/joss.02306>.\n  - Patil I, Makowski D, Ben-Shachar M, Wiernik B, Bacher E, Lüdecke D (2022).\n\"datawizard: An R Package for Easy Data Preparation and Statistical\nTransformations.\" _Journal of Open Source Software_, *7*(78), 4684.\ndoi:10.21105/joss.04684 <https://doi.org/10.21105/joss.04684>.\n  - Pinheiro J, Bates D, R Core Team (2023). _nlme: Linear and Nonlinear Mixed\nEffects Models_. R package version 3.1-163,\n<https://CRAN.R-project.org/package=nlme>. Pinheiro JC, Bates DM (2000).\n_Mixed-Effects Models in S and S-PLUS_. Springer, New York. doi:10.1007/b98882\n<https://doi.org/10.1007/b98882>.\n  - R Core Team (2023). _foreign: Read Data Stored by 'Minitab', 'S', 'SAS',\n'SPSS', 'Stata', 'Systat', 'Weka', 'dBase', ..._. R package version 0.8-85,\n<https://CRAN.R-project.org/package=foreign>.\n  - R Core Team (2023). _R: A Language and Environment for Statistical\nComputing_. R Foundation for Statistical Computing, Vienna, Austria.\n<https://www.R-project.org/>.\n  - Thériault R (2023). \"rempsyc: Convenience functions for psychology.\" _Journal\nof Open Source Software_, *8*(87), 5466. doi:10.21105/joss.05466\n<https://doi.org/10.21105/joss.05466>, <https://doi.org/10.21105/joss.05466>.\n  - Therneau T (2023). _A Package for Survival Analysis in R_. R package version\n3.5-7, <https://CRAN.R-project.org/package=survival>. Terry M. Therneau,\nPatricia M. Grambsch (2000). _Modeling Survival Data: Extending the Cox Model_.\nSpringer, New York. ISBN 0-387-98784-3.\n  - Venables WN, Ripley BD (2002). _Modern Applied Statistics with S_, Fourth\nedition. Springer, New York. ISBN 0-387-95457-0,\n<https://www.stats.ox.ac.uk/pub/MASS4/>.\n  - Wickham H (2016). _ggplot2: Elegant Graphics for Data Analysis_.\nSpringer-Verlag New York. ISBN 978-3-319-24277-4,\n<https://ggplot2.tidyverse.org>.\n  - Wickham H (2023). _forcats: Tools for Working with Categorical Variables\n(Factors)_. R package version 1.0.0,\n<https://CRAN.R-project.org/package=forcats>.\n  - Wickham H, François R, Henry L, Müller K, Vaughan D (2023). _dplyr: A Grammar\nof Data Manipulation_. R package version 1.1.3,\n<https://CRAN.R-project.org/package=dplyr>.\n  - Wickham H, Henry L (2023). _purrr: Functional Programming Tools_. R package\nversion 1.0.2, <https://CRAN.R-project.org/package=purrr>.\n  - Yanagida T (2024). _misty: Miscellaneous Functions 'T. Yanagida'_. R package\nversion 0.6.1, <https://CRAN.R-project.org/package=misty>.\n  - Zhu H (2021). _kableExtra: Construct Complex Table with 'kable' and Pipe\nSyntax_. R package version 1.3.4,\n<https://CRAN.R-project.org/package=kableExtra>.\n```\n:::\n:::",
    "supporting": [
      "lista_4_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}